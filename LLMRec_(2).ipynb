{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpQy1R3MIQKv",
        "outputId": "625405aa-994f-4ab6-d435-efff41b5c6c6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/MyDrive/Rec_Proj_DL'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 70 (delta 25), reused 48 (delta 12), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (70/70), 27.16 KiB | 5.43 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SoheilHoseini/A-LLMRec.git /content/drive/MyDrive/Rec_Proj_DL/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda create -n [env name] python=3.10 pip\n",
        "!conda install pytorch==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
        "!conda install numpy=1.26.3\n",
        "!conda install tqdm\n",
        "!conda install pytz\n",
        "!conda install transformers=4.32.1\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!conda install conda-forge::accelerate=0.25.0\n",
        "!conda install conda-forge::bitsandbytes=0.42.0\n",
        "\n",
        "!pip install -U sentence-transformers\n",
        "\n",
        "import torch.serialization\n",
        "import argparse\n",
        "torch.serialization.add_safe_globals([argparse.Namespace])\n",
        "\n",
        "import torch.serialization\n",
        "import argparse\n",
        "torch.serialization.add_safe_globals([argparse.Namespace])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t8Joi6DOJpP_",
        "outputId": "8f98c48e-40c7-40ac-fd6d-e50408841684",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0 \n",
            "  certifi                           2024.12.14-pyhd8ed1ab_0 --> 2025.8.3-pyhd8ed1ab_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "  openssl                                  3.4.0-h7b32b05_1 --> 3.5.2-h26f9b46_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-3_kmp_llvm \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0.0002817717778921578/1 [00:00<05:59, 359.68s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0.0036004176722214173/1 [00:00<00:27, 28.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   1% 0.006734660096088046/1 [00:00<00:14, 14.98s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   0% 0.0025369471444828097/1 [00:00<00:39, 39.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0.0025359460010294203/1 [00:00<01:09, 69.79s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   2% 0.02175904593212074/1 [00:00<00:08,  8.28s/it]  \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   4% 0.038812909501139005/1 [00:00<00:04,  4.66s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   2% 0.023678173348506224/1 [00:00<00:07,  7.72s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   2% 0.022538642645096488/1 [00:00<00:11, 11.74s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.005249303862213162/1 [00:00<00:50, 50.71s/it] \n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   6% 0.060346099018894206/1 [00:00<00:04,  4.73s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   5% 0.053275890034139003/1 [00:00<00:04,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   3% 0.031081861476285444/1 [00:00<00:11, 11.92s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.008661873172240406/1 [00:00<00:39, 39.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   8% 0.07727118177570558/1 [00:00<00:04,  4.64s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   8% 0.08152483274211846/1 [00:00<00:04,  5.16s/it] \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.011959646572756033/1 [00:00<00:35, 35.73s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   9% 0.08617521428512566/1 [00:00<00:04,  5.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  10% 0.1046490697099159/1 [00:00<00:03,  4.24s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.014766928359903826/1 [00:00<00:35, 35.94s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   5% 0.05070121326449324/1 [00:00<00:10, 11.11s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  14% 0.1356209660988102/1 [00:00<00:03,  3.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  11% 0.10863868976181146/1 [00:00<00:04,  5.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  13% 0.133984290332699/1 [00:00<00:03,  4.26s/it]  \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.017553338163504052/1 [00:00<00:36, 37.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  16% 0.16183608659179924/1 [00:00<00:03,  3.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  13% 0.12797136726265254/1 [00:00<00:04,  5.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  16% 0.15773282856627266/1 [00:00<00:03,  4.37s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   7% 0.07289640992642636/1 [00:00<00:09, 10.09s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  19% 0.18741697029866755/1 [00:00<00:03,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.020256260032914013/1 [00:00<00:39, 40.45s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  15% 0.14691269501651305/1 [00:00<00:04,  5.58s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   9% 0.08590442653873918/1 [00:00<00:08,  9.21s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.02276089805862208/1 [00:00<00:40, 41.35s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  16% 0.16499305332701625/1 [00:00<00:04,  5.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  21% 0.2101036722082205/1 [00:00<00:03,  4.43s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  10% 0.09680883650417635/1 [00:01<00:08,  9.62s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.02520292013368745/1 [00:01<00:41, 43.00s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  23% 0.2330546849040995/1 [00:01<00:03,  4.59s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  18% 0.18221244219416216/1 [00:01<00:05,  6.37s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  11% 0.10728393899065929/1 [00:01<00:08,  9.71s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.027686686175847953/1 [00:01<00:41, 42.22s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  26% 0.2551195581136511/1 [00:01<00:03,  4.71s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  20% 0.1981795118709702/1 [00:01<00:05,  6.54s/it] \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  12% 0.12050660934244922/1 [00:01<00:07,  8.98s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.03021219618510359/1 [00:01<00:40, 41.46s/it] \n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  28% 0.2768299755286718/1 [00:01<00:03,  4.68s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  21% 0.2136769618514015/1 [00:01<00:05,  6.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.03335342970901246/1 [00:01<00:36, 38.17s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  13% 0.13171153454315435/1 [00:01<00:08, 10.33s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  30% 0.298363165046427/1 [00:01<00:03,  4.74s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  24% 0.2356708176317106/1 [00:01<00:04,  6.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.035993735627779716/1 [00:01<00:37, 39.03s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  14% 0.14175732955068304/1 [00:01<00:08, 10.28s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  33% 0.32521319148214645/1 [00:01<00:02,  4.40s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  26% 0.2550817650819478/1 [00:01<00:04,  5.73s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.03857142559590427/1 [00:01<00:38, 39.99s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  15% 0.1532627699866561/1 [00:01<00:08,  9.81s/it] \u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  36% 0.35667114324676824/1 [00:01<00:02,  3.96s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  27% 0.27284904359486656/1 [00:01<00:04,  5.84s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.04119085953112396/1 [00:01<00:37, 39.47s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  16% 0.1638237339689299/1 [00:01<00:08,  9.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  38% 0.38219196045299664/1 [00:01<00:02,  4.21s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  29% 0.29225999104510375/1 [00:01<00:04,  5.70s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  42% 0.416270743957221/1 [00:01<00:02,  4.17s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.04373724152392716/1 [00:01<00:39, 41.62s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  41% 0.4062949544811012/1 [00:01<00:02,  4.31s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  31% 0.3102620794062108/1 [00:01<00:03,  5.71s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  44% 0.44058315409184795/1 [00:01<00:02,  4.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.04644016339333712/1 [00:01<00:38, 40.27s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  33% 0.32889032736248686/1 [00:01<00:03,  5.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  43% 0.4296890369201439/1 [00:01<00:02,  4.46s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  46% 0.46478985809545476/1 [00:01<00:02,  4.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.04897610939436654/1 [00:02<00:38, 40.19s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  45% 0.45228559382149197/1 [00:02<00:02,  4.55s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  35% 0.34681414577419784/1 [00:02<00:03,  5.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  49% 0.4942818686500674/1 [00:02<00:02,  4.07s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.051480747420074614/1 [00:02<00:39, 41.56s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  48% 0.47621135995233105/1 [00:02<00:02,  4.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  36% 0.3637987247931554/1 [00:02<00:03,  6.08s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.054100181355294305/1 [00:02<00:38, 40.61s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  22% 0.21868922977927907/1 [00:02<00:07, 10.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  50% 0.49836484711051543/1 [00:02<00:02,  4.57s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  39% 0.38555777072527614/1 [00:02<00:03,  5.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.05691789913421588/1 [00:02<00:36, 39.06s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  23% 0.22882088628259864/1 [00:02<00:07, 10.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  52% 0.5203411063714343/1 [00:02<00:02,  4.64s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.05962082100362584/1 [00:02<00:36, 38.44s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  24% 0.24294510234019243/1 [00:02<00:06,  8.96s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  57% 0.5666905683988476/1 [00:02<00:01,  4.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  55% 0.5451530119886008/1 [00:04<00:13, 30.45s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  42% 0.4214054075486981/1 [00:05<00:31, 53.83s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  59% 0.5895230926991929/1 [00:05<00:18, 43.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  56% 0.5606604529993299/1 [00:05<00:18, 41.09s/it]\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.06224025493884553/1 [00:05<06:17, 402.16s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  43% 0.4339285994520769/1 [00:05<00:26, 47.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  62% 0.6160553315852423/1 [00:05<00:11, 31.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.06520407660260008/1 [00:05<04:24, 283.18s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  27% 0.26552667573318434/1 [00:05<00:49, 67.67s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  45% 0.45349608680110637/1 [00:05<00:18, 33.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  65% 0.647344346367197/1 [00:05<00:07, 21.41s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.06819920624167598/1 [00:05<03:09, 203.67s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  28% 0.2779765926228567/1 [00:05<00:35, 48.82s/it] \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  47% 0.4730635741501358/1 [00:05<00:12, 24.29s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  68% 0.6758850017426286/1 [00:06<00:05, 15.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.07099605203704999/1 [00:06<02:23, 154.35s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  29% 0.28905272557987555/1 [00:06<00:26, 37.71s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  49% 0.49364857084131475/1 [00:06<00:09, 17.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  71% 0.7062226613454021/1 [00:06<00:03, 11.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.0739807456843521/1 [00:06<01:48, 117.43s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  30% 0.30279056490641054/1 [00:06<00:19, 27.55s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  51% 0.5121985488481947/1 [00:06<00:07, 14.40s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.07654799966070287/1 [00:06<01:29, 97.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  74% 0.7365603209481757/1 [00:06<00:02,  9.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  31% 0.31365204412395226/1 [00:06<00:16, 23.35s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  53% 0.5286352382213794/1 [00:06<00:05, 12.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  76% 0.7612955556068831/1 [00:06<00:02,  8.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.07903176570286338/1 [00:06<01:20, 87.38s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  32% 0.323697839131481/1 [00:06<00:14, 21.07s/it]  \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  54% 0.5448371177463758/1 [00:06<00:05, 11.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  72% 0.7242418021753632/1 [00:06<00:02,  7.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.08140073583551226/1 [00:06<01:09, 75.68s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  57% 0.5671440533242693/1 [00:06<00:03,  9.11s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  34% 0.3361048252732579/1 [00:06<00:11, 17.23s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  75% 0.7495853914843261/1 [00:06<00:01,  6.85s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.08471938121957545/1 [00:06<00:56, 61.35s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  35% 0.3494133571208387/1 [00:06<00:09, 14.17s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  59% 0.5885117495094095/1 [00:06<00:03,  7.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  78% 0.7781190829440675/1 [00:06<00:01,  5.70s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.08767276689155622/1 [00:06<00:48, 53.45s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  36% 0.3634087809347462/1 [00:06<00:07, 11.85s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  61% 0.6090967462005885/1 [00:06<00:02,  6.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  88% 0.8819062511008368/1 [00:06<00:00,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.09077225644836995/1 [00:06<00:43, 47.96s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  38% 0.3756869748328369/1 [00:06<00:06, 11.00s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  63% 0.6339083201591578/1 [00:06<00:02,  6.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  91% 0.911081143262389/1 [00:06<00:00,  4.21s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.09366302616970802/1 [00:06<00:40, 44.18s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  39% 0.3871494845209145/1 [00:06<00:06, 10.39s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  66% 0.6562152557370514/1 [00:06<00:01,  5.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  85% 0.8528206416414652/1 [00:07<00:00,  4.74s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.09636594803911798/1 [00:07<00:38, 42.87s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  68% 0.6763306327318537/1 [00:07<00:01,  5.58s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  40% 0.39972819365427315/1 [00:07<00:06, 10.05s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.09906886990852794/1 [00:07<00:37, 41.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  97% 0.9673168049650913/1 [00:07<00:00,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  41% 0.4109760496028737/1 [00:07<00:05,  9.80s/it] \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  70% 0.6959763900302792/1 [00:07<00:01,  5.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.10183440772858059/1 [00:07<00:35, 40.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 0.9978658768299051/1 [00:07<00:00,  3.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  42% 0.4228249360220101/1 [00:07<00:05,  9.40s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  72% 0.7167179266202505/1 [00:07<00:01,  5.35s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  92% 0.9218509076263677/1 [00:07<00:00,  5.04s/it]\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.10449558563089542/1 [00:07<00:38, 43.08s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  74% 0.736363683918676/1 [00:07<00:01,  5.89s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.1073759193604597/1 [00:07<00:36, 40.57s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  45% 0.44510599417973407/1 [00:07<00:05, 10.31s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.10995360932858425/1 [00:07<00:36, 40.97s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  97% 0.9655375843023073/1 [00:07<00:00,  5.22s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  46% 0.45523765068305366/1 [00:07<00:05, 10.43s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.11263565921444664/1 [00:07<00:35, 40.18s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  99% 0.9852984948474077/1 [00:07<00:00,  5.29s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  47% 0.46781635981641223/1 [00:07<00:05,  9.90s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.115849944680772/1 [00:07<00:34, 38.70s/it]  \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  48% 0.48022334595818916/1 [00:07<00:04,  9.37s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.1189076902704906/1 [00:07<00:32, 36.83s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  49% 0.49112775592362634/1 [00:07<00:04,  9.46s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  84% 0.8399148269697397/1 [00:07<00:00,  5.17s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.12166279209876947/1 [00:08<00:36, 41.43s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  86% 0.8595605842681654/1 [00:08<00:00,  5.79s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.12415699413270376/1 [00:08<00:36, 41.41s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  88% 0.8790498016677987/1 [00:08<00:00,  5.74s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.12663032418309048/1 [00:08<00:37, 43.38s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  90% 0.8968953501301136/1 [00:08<00:00,  5.74s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.1290410382828345/1 [00:08<00:37, 43.19s/it] \n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.13143088039903095/1 [00:08<00:37, 43.67s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  54% 0.54238706891076/1 [00:08<00:04, 10.70s/it]  \u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.13405031433425063/1 [00:08<00:36, 42.10s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  56% 0.5570264539430989/1 [00:08<00:04,  9.46s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.13721241984170707/1 [00:08<00:33, 38.56s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  57% 0.5711936007485882/1 [00:08<00:03,  8.65s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.14047888526690136/1 [00:08<00:31, 36.18s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.14468458995173614/1 [00:08<00:26, 31.49s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.14894247459543986/1 [00:09<00:24, 28.89s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  62% 0.6237408361725846/1 [00:09<00:02,  6.66s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:09<00:00,  3.96s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0.00010941492379625203/1 [00:09<24:55:26, 89736.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [00:10<00:00,  5.29s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0.0022977133997212924/1 [00:10<52:06, 3133.26s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.0001619872369599508/1 [00:10<17:15:32, 62142.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0.003610692485276317/1 [00:10<29:03, 1750.13s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.004535642634878622/1 [00:10<26:25, 1592.95s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [00:10<00:00,  4.74s/it]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0.004923671570831341/1 [00:10<18:09, 1094.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0.00017172886155179142/1 [00:10<16:38:17, 59907.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.006017820808793861/1 [00:10<13:19, 804.58s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0.002060746338621497/1 [00:10<1:01:01, 3668.93s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.008909298032797294/1 [00:10<11:46, 712.78s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.007330799894348886/1 [00:10<09:03, 547.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0.004121492677242994/1 [00:10<25:11, 1517.76s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.011501093824156507/1 [00:10<08:08, 494.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.00864377897990391/1 [00:10<06:26, 389.83s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.006353967877416282/1 [00:10<13:28, 813.52s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.009847343141662681/1 [00:10<05:24, 327.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.008242985354485989/1 [00:10<09:13, 558.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.013768915141595818/1 [00:10<06:16, 381.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.011160322227217707/1 [00:10<04:04, 247.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.010132002831555693/1 [00:10<06:21, 385.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.015712761985115228/1 [00:11<04:51, 295.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.01247330131277273/1 [00:11<03:11, 193.95s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.012192749170177191/1 [00:11<04:24, 268.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.017656608828634637/1 [00:11<03:45, 229.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   1% 0.013786280398327754/1 [00:11<02:35, 158.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.014253495508798689/1 [00:11<03:12, 195.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.019600455672154047/1 [00:11<02:56, 179.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.015208674407679031/1 [00:11<02:09, 131.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.016485970708971977/1 [00:11<02:23, 145.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.021706289752633407/1 [00:11<02:17, 140.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.016521653493234055/1 [00:11<01:53, 114.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.018718445909145266/1 [00:11<01:51, 113.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.023812123833112767/1 [00:11<01:50, 113.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.01783463257878908/1 [00:11<01:42, 104.19s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.020779192247766764/1 [00:11<01:32, 94.05s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.025755970676632177/1 [00:11<01:34, 96.55s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.019147611664344102/1 [00:11<01:35, 96.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.022839938586388258/1 [00:11<01:19, 81.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.027699817520151587/1 [00:11<01:22, 85.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.02046059074989913/1 [00:11<01:29, 91.65s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.024900684925009756/1 [00:11<01:09, 71.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.029805651600630947/1 [00:11<01:12, 74.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   2% 0.021773569835454153/1 [00:11<01:25, 87.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   3% 0.026961431263631253/1 [00:11<01:03, 64.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.1524280958478836/1 [00:11<03:40, 259.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   4% 0.03949878749044698/1 [00:11<00:17, 17.80s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   5% 0.050488285296226676/1 [00:11<00:13, 14.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  64% 0.6388095286838776/1 [00:11<00:21, 60.31s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.1549118618900441/1 [00:11<02:58, 210.66s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   6% 0.060834697630716125/1 [00:12<00:09, 10.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   9% 0.09032938117624228/1 [00:12<00:05,  6.59s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  10% 0.09962215073036974/1 [00:12<00:05,  6.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.15729126801446677/1 [00:12<02:24, 172.06s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   8% 0.08315534208515153/1 [00:12<00:06,  7.44s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  13% 0.1324029522564312/1 [00:12<00:03,  4.48s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  13% 0.13331549601803952/1 [00:12<00:04,  4.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  66% 0.6594592184215755/1 [00:12<00:13, 40.76s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.15956631422115158/1 [00:12<02:00, 143.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  17% 0.17275923472110216/1 [00:12<00:03,  3.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  17% 0.16668486683178937/1 [00:12<00:03,  4.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  67% 0.6690757059501501/1 [00:12<00:11, 33.58s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.161862232411384/1 [00:12<01:38, 117.68s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  21% 0.20744846475456405/1 [00:12<00:02,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  21% 0.20588577817609746/1 [00:12<00:02,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  68% 0.6785204704871428/1 [00:12<00:09, 28.36s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.1640850986591999/1 [00:12<01:23, 99.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  24% 0.23801620211078292/1 [00:12<00:02,  3.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  24% 0.23617739148760827/1 [00:12<00:02,  3.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.1661931689975042/1 [00:12<01:12, 86.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  18% 0.18031579441622334/1 [00:12<00:04,  5.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  27% 0.26669492198993205/1 [00:12<00:02,  3.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  27% 0.2650111196664795/1 [00:12<00:02,  3.66s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.16825949536871335/1 [00:12<01:06, 80.30s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  30% 0.3027579829158083/1 [00:12<00:02,  3.45s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  21% 0.20602830150834256/1 [00:12<00:04,  5.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  29% 0.2933588861344709/1 [00:12<00:02,  3.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.17043018165766036/1 [00:12<00:58, 71.05s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  33% 0.3328105336873718/1 [00:12<00:02,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  23% 0.2275830414962042/1 [00:12<00:03,  5.02s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  32% 0.3239744739199016/1 [00:12<00:02,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  72% 0.7155267751729966/1 [00:12<00:04, 16.78s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.17240258410290546/1 [00:12<00:55, 66.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  25% 0.24979427102684337/1 [00:12<00:03,  4.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  36% 0.3628514107902898/1 [00:12<00:02,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  72% 0.7239412017604993/1 [00:12<00:04, 15.49s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.17476111824378054/1 [00:13<00:48, 59.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  40% 0.3970307177888394/1 [00:12<00:01,  3.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  27% 0.270473691624335/1 [00:12<00:03,  4.97s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  73% 0.7332142433059103/1 [00:13<00:03, 14.27s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  45% 0.4542228388044883/1 [00:13<00:01,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  29% 0.29093428237423413/1 [00:13<00:03,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.17681700862321592/1 [00:13<00:48, 59.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  50% 0.5002461737003684/1 [00:13<00:01,  2.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  74% 0.7417145313892038/1 [00:13<00:03, 14.42s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  31% 0.31117604327654075/1 [00:13<00:03,  4.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.17888333499442508/1 [00:13<00:46, 56.31s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  75% 0.7496996504977523/1 [00:13<00:03, 14.11s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.1817427967404418/1 [00:13<00:39, 48.55s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  49% 0.49211722588433054/1 [00:13<00:01,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  54% 0.5394003541341769/1 [00:13<00:01,  2.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  76% 0.7590585535389544/1 [00:13<00:03, 13.12s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.18398653497180528/1 [00:13<00:39, 48.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  53% 0.5322900606503983/1 [00:13<00:01,  3.07s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  58% 0.5807870097681586/1 [00:13<00:01,  2.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.18650160898928714/1 [00:13<00:36, 45.45s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  77% 0.7673012571348753/1 [00:13<00:03, 13.54s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  57% 0.5716529592316664/1 [00:13<00:01,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  62% 0.6180521727248973/1 [00:13<00:01,  2.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.189256710817566/1 [00:13<00:34, 42.42s/it]  \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  78% 0.7767889524197635/1 [00:13<00:02, 12.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  61% 0.6116638067607743/1 [00:13<00:01,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  66% 0.6553173356816361/1 [00:13<00:00,  2.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  79% 0.7851175175114754/1 [00:13<00:02, 12.67s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.19169873289263137/1 [00:13<00:36, 44.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  65% 0.6476249733658833/1 [00:13<00:01,  2.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  69% 0.6912086677459605/1 [00:13<00:00,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  80% 0.7951633125190041/1 [00:13<00:02, 11.79s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.19427642286075592/1 [00:13<00:34, 42.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  69% 0.6882837698428309/1 [00:13<00:00,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  74% 0.7399796644266693/1 [00:13<00:00,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  80% 0.8038782543417747/1 [00:13<00:02, 11.74s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.1966662649769524/1 [00:13<00:36, 45.44s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  73% 0.7294285280306585/1 [00:13<00:00,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  78% 0.7762144542140972/1 [00:13<00:00,  2.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  81% 0.8125931961645454/1 [00:14<00:02, 11.78s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  49% 0.4894129541406353/1 [00:14<00:02,  4.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.19892043920008964/1 [00:14<00:37, 46.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  81% 0.8121057862784217/1 [00:14<00:00,  2.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  82% 0.8216515839704794/1 [00:14<00:02, 11.60s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  51% 0.5146878015375695/1 [00:14<00:02,  4.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.2011119974725842/1 [00:14<00:37, 47.01s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  85% 0.8481688472042979/1 [00:14<00:00,  2.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  83% 0.8310963485074723/1 [00:14<00:01, 11.49s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  54% 0.5423697772580213/1 [00:14<00:01,  4.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.20326181177798364/1 [00:14<00:39, 49.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  89% 0.8873230276381063/1 [00:14<00:00,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  84% 0.8418719662292231/1 [00:14<00:01, 10.89s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  89% 0.8909298032797294/1 [00:14<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.20583950174610818/1 [00:14<00:38, 47.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  92% 0.923729546287086/1 [00:14<00:00,  2.95s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  85% 0.8522182764720198/1 [00:14<00:01, 10.97s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  59% 0.5885428751000397/1 [00:14<00:01,  4.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.2088241953934103/1 [00:14<00:34, 43.34s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  96% 0.9603077937976177/1 [00:14<00:00,  2.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  86% 0.86140545652164/1 [00:14<00:01, 11.00s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.21122447350138052/1 [00:14<00:33, 42.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  97% 0.9659298939921867/1 [00:16<00:00, 18.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  87% 0.8705497058233649/1 [00:16<00:09, 75.67s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 0.9953404815541831/1 [00:17<00:00, 26.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  64% 0.6427032623791844/1 [00:17<00:14, 40.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.21358300764225563/1 [00:18<05:48, 443.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  99% 0.9926577880905785/1 [00:18<00:00, 25.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  66% 0.6598814054151959/1 [00:18<00:12, 35.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.21625462153634423/1 [00:18<04:06, 314.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  68% 0.6772783782988/1 [00:18<00:09, 28.15s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.218967979397528/1 [00:18<02:57, 227.59s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  71% 0.7066015778761956/1 [00:18<00:05, 18.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.22171264523403308/1 [00:18<02:10, 167.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  73% 0.729359882025816/1 [00:18<00:03, 14.73s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.22435295115280032/1 [00:18<01:39, 128.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.22719154091526947/1 [00:18<01:16, 99.29s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  93% 0.9314255063390732/1 [00:18<00:01, 22.45s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.22973792290807268/1 [00:18<01:03, 82.43s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  94% 0.940870270876066/1 [00:18<00:01, 19.38s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.23225299692555454/1 [00:18<00:54, 70.61s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  95% 0.9501433124214771/1 [00:18<00:00, 17.89s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.23473676296771503/1 [00:18<00:50, 65.39s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  96% 0.9594592847147837/1 [00:18<00:00, 15.97s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.237053553141495/1 [00:18<00:45, 59.48s/it]  \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  97% 0.9684318110249268/1 [00:18<00:00, 14.93s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.2393494713317274/1 [00:19<00:46, 61.21s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  98% 0.9769750298561157/1 [00:19<00:00, 15.01s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  89% 0.8938105124915827/1 [00:19<00:00,  5.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.24141579770293656/1 [00:19<00:44, 59.30s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  92% 0.9179912106505544/1 [00:19<00:00,  5.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  99% 0.9936750907874349/1 [00:19<00:00, 14.01s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.2434299441152768/1 [00:19<00:45, 59.68s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  25% 0.24545452651939081/1 [00:19<00:44, 58.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  25% 0.2526240528679802/1 [00:19<00:37, 50.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  25% 0.2549825870088553/1 [00:19<00:35, 48.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  26% 0.2571219653224809/1 [00:20<00:36, 48.66s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  26% 0.2592195996690114/1 [00:20<00:37, 50.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  26% 0.26149464587569626/1 [00:20<00:35, 48.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  26% 0.26360271621400055/1 [00:20<00:36, 49.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  27% 0.26607604626438724/1 [00:20<00:35, 48.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  27% 0.2688728920597613/1 [00:20<00:34, 46.60s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  27% 0.2710331423569345/1 [00:20<00:34, 47.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  27% 0.27345429244845226/1 [00:20<00:33, 45.50s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  28% 0.2757397746469109/1 [00:20<00:32, 44.99s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  28% 0.27824441267261896/1 [00:21<00:33, 47.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  28% 0.28039422697801836/1 [00:21<00:34, 47.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  28% 0.28250229731632265/1 [00:21<00:36, 51.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.28684366989421667/1 [00:21<00:35, 49.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [00:21<00:00, 25.98s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.28888912428187824/1 [00:21<00:37, 52.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.29081978276002823/1 [00:21<00:39, 55.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.2934392166952479/1 [00:21<00:35, 49.76s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.2954951070746833/1 [00:21<00:35, 51.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.298980728327127/1 [00:22<00:30, 43.81s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.3012870825091332/1 [00:22<00:33, 47.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.30410480028805476/1 [00:22<00:30, 43.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  31% 0.3121926939127371/1 [00:22<00:26, 39.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.3162836026880603/1 [00:22<00:23, 34.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.31921611637649344/1 [00:22<00:24, 35.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.32232604192508096/1 [00:22<00:23, 34.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  37% 0.37470282020542084/1 [00:22<00:22, 35.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [00:22<00:00,  4.41s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.3253211715641569/1 [00:22<00:23, 34.28s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  59% 0.5885854757475129/1 [00:23<00:07, 18.37s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.3282536852525901/1 [00:23<00:23, 35.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  80% 0.8049171693301633/1 [00:23<00:02, 10.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:23<00:00, 16.65s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.3341813285800992/1 [00:23<00:23, 35.70s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:23<00:00, 16.42s/it]                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:23<00:00, 16.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  34% 0.3402342038088937/1 [00:23<00:22, 34.37s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | : 100% 1.0/1 [00:23<00:00, 16.58s/it]                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  34% 0.34317715348910066/1 [00:23<00:22, 34.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | :   1% 0.006530765830350761/1 [00:23<59:51, 3615.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:23<00:00, 10.95s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.34649579887316384/1 [00:23<00:21, 33.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [00:23<00:00,  4.87s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   1% 0.006761307362165732/1 [00:23<58:07, 3510.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | :   1% 0.01047260975338487/1 [00:23<37:23, 2267.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   1% 0.011206734985068174/1 [00:23<34:57, 2121.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.34967877636416783/1 [00:23<00:21, 32.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   1% 0.01364371451460054/1 [00:23<28:42, 1746.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:23<00:00, 2121.70s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:23<00:00, 16.77s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:23<00:00, 16.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [00:23<00:00, 1746.26s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.3538114291065862/1 [00:23<00:19, 29.87s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  44% 0.4414946319899162/1 [00:25<00:10, 19.56s/it] \n",
            "pytorch-2.1.2        | 1.46 GB   | : 100% 1.0/1 [00:54<00:00, 19.04s/it]               \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [01:03<00:00,  3.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [01:07<00:00,  5.29s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [01:28<00:00, 26.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [01:52<00:00,  4.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | : 100% 1.0/1 [01:53<00:00,  2.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [01:55<00:00, 25.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [01:56<00:00, 16.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [01:56<00:00, 16.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | : 100% 1.0/1 [01:56<00:00, 16.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [01:59<00:00,  4.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | : 100% 1.0/1 [02:00<00:00, 113.48s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | : 100% 1.0/1 [02:00<00:00, 113.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [02:00<00:00, 10.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | : 100% 1.0/1 [02:00<00:00, 113.88s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | : 100% 1.0/1 [02:00<00:00, 113.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [02:00<00:00, 113.97s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [02:00<00:00, 113.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [02:01<00:00, 16.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [02:01<00:00, 114.60s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [02:01<00:00, 114.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [02:28<00:00,  4.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | : 100% 1.0/1 [06:00<00:00, 19.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - numpy=1.26.3\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    numpy-1.26.3               |  py311h64a7726_0         7.8 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         7.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  numpy              conda-forge/linux-64::numpy-1.26.3-py311h64a7726_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytz\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pytz-2025.2                |     pyhd8ed1ab_0         185 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         185 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  pytz               conda-forge/noarch::pytz-2025.2-pyhd8ed1ab_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - transformers=4.32.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _python_abi3_support-1.0   |       hd8ed1ab_2           8 KB  conda-forge\n",
            "    aiohappyeyeballs-2.6.1     |     pyhd8ed1ab_0          19 KB  conda-forge\n",
            "    aiohttp-3.12.15            |  py311h3778330_0         988 KB  conda-forge\n",
            "    aiosignal-1.4.0            |     pyhd8ed1ab_0          13 KB  conda-forge\n",
            "    attrs-25.3.0               |     pyh71513ae_0          56 KB  conda-forge\n",
            "    aws-c-auth-0.8.1           |       h205f482_0         106 KB  conda-forge\n",
            "    aws-c-cal-0.8.1            |       h1a47875_3          46 KB  conda-forge\n",
            "    aws-c-common-0.10.6        |       hb9d3cd8_0         231 KB  conda-forge\n",
            "    aws-c-compression-0.3.0    |       h4e1184b_5          19 KB  conda-forge\n",
            "    aws-c-event-stream-0.5.0   |      h7959bf6_11          53 KB  conda-forge\n",
            "    aws-c-http-0.9.2           |       hefd7a92_4         193 KB  conda-forge\n",
            "    aws-c-io-0.15.3            |       h173a860_6         154 KB  conda-forge\n",
            "    aws-c-mqtt-0.11.0          |      h11f4f37_12         190 KB  conda-forge\n",
            "    aws-c-s3-0.7.9             |       he1b24dc_1         113 KB  conda-forge\n",
            "    aws-c-sdkutils-0.2.2       |       h4e1184b_0          55 KB  conda-forge\n",
            "    aws-checksums-0.2.2        |       h4e1184b_4          71 KB  conda-forge\n",
            "    aws-crt-cpp-0.29.9         |       he0e7f3f_2         345 KB  conda-forge\n",
            "    aws-sdk-cpp-1.11.489       |       h4d475cb_0         3.0 MB  conda-forge\n",
            "    azure-core-cpp-1.14.0      |       h5cfcd09_0         337 KB  conda-forge\n",
            "    azure-identity-cpp-1.10.0  |       h113e628_0         227 KB  conda-forge\n",
            "    azure-storage-blobs-cpp-12.13.0|       h3cf044e_1         536 KB  conda-forge\n",
            "    azure-storage-common-cpp-12.8.0|       h736e048_1         146 KB  conda-forge\n",
            "    azure-storage-files-datalake-cpp-12.12.0|       ha633028_1         281 KB  conda-forge\n",
            "    click-8.2.1                |     pyh707e725_0          86 KB  conda-forge\n",
            "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
            "    datasets-3.6.0             |     pyhd8ed1ab_0         331 KB  conda-forge\n",
            "    dill-0.3.8                 |     pyhd8ed1ab_0          86 KB  conda-forge\n",
            "    frozenlist-1.7.0           |  py311h52bc045_0          54 KB  conda-forge\n",
            "    fsspec-2025.3.0            |     pyhd8ed1ab_0         138 KB  conda-forge\n",
            "    gflags-2.2.2               |    h5888daf_1005         117 KB  conda-forge\n",
            "    glog-0.7.1                 |       hbabe93e_0         140 KB  conda-forge\n",
            "    hf-xet-1.1.7               |   py39h598437d_0         2.5 MB  conda-forge\n",
            "    huggingface_hub-0.34.4     |     pyhd8ed1ab_0         326 KB  conda-forge\n",
            "    importlib-metadata-8.7.0   |     pyhe01879c_1          34 KB  conda-forge\n",
            "    importlib_metadata-8.7.0   |       h40b2b14_1          22 KB  conda-forge\n",
            "    joblib-1.5.1               |     pyhd8ed1ab_0         219 KB  conda-forge\n",
            "    libabseil-20240722.0       | cxx17_hbbce691_4         1.3 MB  conda-forge\n",
            "    libarrow-19.0.1            |   hfa2a6e7_0_cpu         8.6 MB  conda-forge\n",
            "    libarrow-acero-19.0.1      |   hcb10f89_0_cpu         623 KB  conda-forge\n",
            "    libarrow-dataset-19.0.1    |   hcb10f89_0_cpu         590 KB  conda-forge\n",
            "    libarrow-substrait-19.0.1  |   h08228c5_0_cpu         511 KB  conda-forge\n",
            "    libbrotlicommon-1.1.0      |       hb9d3cd8_2          67 KB  conda-forge\n",
            "    libbrotlidec-1.1.0         |       hb9d3cd8_2          32 KB  conda-forge\n",
            "    libbrotlienc-1.1.0         |       hb9d3cd8_2         275 KB  conda-forge\n",
            "    libcrc32c-1.1.2            |       h9c3ff4c_0          20 KB  conda-forge\n",
            "    libevent-2.1.12            |       hf998b51_1         417 KB  conda-forge\n",
            "    libgoogle-cloud-2.35.0     |       h2b5623c_0         1.2 MB  conda-forge\n",
            "    libgoogle-cloud-storage-2.35.0|       h0121fbd_0         767 KB  conda-forge\n",
            "    libgrpc-1.67.1             |       h25350d4_2         7.8 MB  conda-forge\n",
            "    libopentelemetry-cpp-1.18.0|       hfcad708_1         783 KB  conda-forge\n",
            "    libopentelemetry-cpp-headers-1.18.0|       ha770c72_1         313 KB  conda-forge\n",
            "    libparquet-19.0.1          |   h081d1f1_0_cpu         1.2 MB  conda-forge\n",
            "    libprotobuf-5.28.3         |       h6128344_1         2.8 MB  conda-forge\n",
            "    libre2-11-2024.07.02       |       hbbce691_2         205 KB  conda-forge\n",
            "    libthrift-0.21.0           |       h0e7cc3e_0         416 KB  conda-forge\n",
            "    libutf8proc-2.10.0         |       h202a827_0          81 KB  conda-forge\n",
            "    multidict-6.6.3            |  py311h2dc5d0c_0          95 KB  conda-forge\n",
            "    multiprocess-0.70.16       |  py311h9ecbd09_1         340 KB  conda-forge\n",
            "    nlohmann_json-3.12.0       |       h3f2d84a_0         133 KB  conda-forge\n",
            "    orc-2.0.3                  |       h12ee42a_2         1.1 MB  conda-forge\n",
            "    pandas-2.3.1               |  py311hed34c8f_0        14.7 MB  conda-forge\n",
            "    prometheus-cpp-1.3.0       |       ha5d0236_0         195 KB  conda-forge\n",
            "    propcache-0.3.1            |  py311h2dc5d0c_0          53 KB  conda-forge\n",
            "    pyarrow-19.0.1             |  py311h38be061_0          25 KB  conda-forge\n",
            "    pyarrow-core-19.0.1        |py311h4854187_0_cpu         4.5 MB  conda-forge\n",
            "    python-dateutil-2.9.0.post0|     pyhe01879c_2         228 KB  conda-forge\n",
            "    python-gil-3.11.13         |       hd8ed1ab_0          46 KB  conda-forge\n",
            "    python-tzdata-2025.2       |     pyhd8ed1ab_0         141 KB  conda-forge\n",
            "    python-xxhash-3.5.0        |  py311h9ecbd09_2          23 KB  conda-forge\n",
            "    re2-2024.07.02             |       h9925aae_2          26 KB  conda-forge\n",
            "    regex-2025.7.34            |  py311h49ec1c0_0         406 KB  conda-forge\n",
            "    s2n-1.5.11                 |       h072c03f_0         348 KB  conda-forge\n",
            "    sacremoses-0.0.53          |     pyhd8ed1ab_0         427 KB  conda-forge\n",
            "    safetensors-0.6.2          |  py311hc8fb587_0         433 KB  conda-forge\n",
            "    six-1.17.0                 |     pyhe01879c_1          18 KB  conda-forge\n",
            "    snappy-1.2.2               |       h03e3b7b_0          45 KB  conda-forge\n",
            "    tokenizers-0.13.3          |  py311h1b04a43_0         3.9 MB  conda-forge\n",
            "    transformers-4.32.1        |     pyhd8ed1ab_0         2.5 MB  conda-forge\n",
            "    typing-extensions-4.14.1   |       h4440ef1_0          88 KB  conda-forge\n",
            "    xxhash-0.8.3               |       hb47aa4a_0         106 KB  conda-forge\n",
            "    yarl-1.20.1                |  py311h2dc5d0c_0         148 KB  conda-forge\n",
            "    zipp-3.23.0                |     pyhd8ed1ab_0          22 KB  conda-forge\n",
            "    zlib-1.3.1                 |       hb9d3cd8_2          90 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        68.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _python_abi3_supp~ conda-forge/noarch::_python_abi3_support-1.0-hd8ed1ab_2 \n",
            "  aiohappyeyeballs   conda-forge/noarch::aiohappyeyeballs-2.6.1-pyhd8ed1ab_0 \n",
            "  aiohttp            conda-forge/linux-64::aiohttp-3.12.15-py311h3778330_0 \n",
            "  aiosignal          conda-forge/noarch::aiosignal-1.4.0-pyhd8ed1ab_0 \n",
            "  attrs              conda-forge/noarch::attrs-25.3.0-pyh71513ae_0 \n",
            "  aws-c-auth         conda-forge/linux-64::aws-c-auth-0.8.1-h205f482_0 \n",
            "  aws-c-cal          conda-forge/linux-64::aws-c-cal-0.8.1-h1a47875_3 \n",
            "  aws-c-common       conda-forge/linux-64::aws-c-common-0.10.6-hb9d3cd8_0 \n",
            "  aws-c-compression  conda-forge/linux-64::aws-c-compression-0.3.0-h4e1184b_5 \n",
            "  aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.5.0-h7959bf6_11 \n",
            "  aws-c-http         conda-forge/linux-64::aws-c-http-0.9.2-hefd7a92_4 \n",
            "  aws-c-io           conda-forge/linux-64::aws-c-io-0.15.3-h173a860_6 \n",
            "  aws-c-mqtt         conda-forge/linux-64::aws-c-mqtt-0.11.0-h11f4f37_12 \n",
            "  aws-c-s3           conda-forge/linux-64::aws-c-s3-0.7.9-he1b24dc_1 \n",
            "  aws-c-sdkutils     conda-forge/linux-64::aws-c-sdkutils-0.2.2-h4e1184b_0 \n",
            "  aws-checksums      conda-forge/linux-64::aws-checksums-0.2.2-h4e1184b_4 \n",
            "  aws-crt-cpp        conda-forge/linux-64::aws-crt-cpp-0.29.9-he0e7f3f_2 \n",
            "  aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.11.489-h4d475cb_0 \n",
            "  azure-core-cpp     conda-forge/linux-64::azure-core-cpp-1.14.0-h5cfcd09_0 \n",
            "  azure-identity-cpp conda-forge/linux-64::azure-identity-cpp-1.10.0-h113e628_0 \n",
            "  azure-storage-blo~ conda-forge/linux-64::azure-storage-blobs-cpp-12.13.0-h3cf044e_1 \n",
            "  azure-storage-com~ conda-forge/linux-64::azure-storage-common-cpp-12.8.0-h736e048_1 \n",
            "  azure-storage-fil~ conda-forge/linux-64::azure-storage-files-datalake-cpp-12.12.0-ha633028_1 \n",
            "  click              conda-forge/noarch::click-8.2.1-pyh707e725_0 \n",
            "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3 \n",
            "  datasets           conda-forge/noarch::datasets-3.6.0-pyhd8ed1ab_0 \n",
            "  dill               conda-forge/noarch::dill-0.3.8-pyhd8ed1ab_0 \n",
            "  frozenlist         conda-forge/linux-64::frozenlist-1.7.0-py311h52bc045_0 \n",
            "  fsspec             conda-forge/noarch::fsspec-2025.3.0-pyhd8ed1ab_0 \n",
            "  gflags             conda-forge/linux-64::gflags-2.2.2-h5888daf_1005 \n",
            "  glog               conda-forge/linux-64::glog-0.7.1-hbabe93e_0 \n",
            "  hf-xet             conda-forge/linux-64::hf-xet-1.1.7-py39h598437d_0 \n",
            "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.34.4-pyhd8ed1ab_0 \n",
            "  importlib-metadata conda-forge/noarch::importlib-metadata-8.7.0-pyhe01879c_1 \n",
            "  importlib_metadata conda-forge/noarch::importlib_metadata-8.7.0-h40b2b14_1 \n",
            "  joblib             conda-forge/noarch::joblib-1.5.1-pyhd8ed1ab_0 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20240722.0-cxx17_hbbce691_4 \n",
            "  libarrow           conda-forge/linux-64::libarrow-19.0.1-hfa2a6e7_0_cpu \n",
            "  libarrow-acero     conda-forge/linux-64::libarrow-acero-19.0.1-hcb10f89_0_cpu \n",
            "  libarrow-dataset   conda-forge/linux-64::libarrow-dataset-19.0.1-hcb10f89_0_cpu \n",
            "  libarrow-substrait conda-forge/linux-64::libarrow-substrait-19.0.1-h08228c5_0_cpu \n",
            "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.1.0-hb9d3cd8_2 \n",
            "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.1.0-hb9d3cd8_2 \n",
            "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.1.0-hb9d3cd8_2 \n",
            "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 \n",
            "  libevent           conda-forge/linux-64::libevent-2.1.12-hf998b51_1 \n",
            "  libgoogle-cloud    conda-forge/linux-64::libgoogle-cloud-2.35.0-h2b5623c_0 \n",
            "  libgoogle-cloud-s~ conda-forge/linux-64::libgoogle-cloud-storage-2.35.0-h0121fbd_0 \n",
            "  libgrpc            conda-forge/linux-64::libgrpc-1.67.1-h25350d4_2 \n",
            "  libopentelemetry-~ conda-forge/linux-64::libopentelemetry-cpp-1.18.0-hfcad708_1 \n",
            "  libopentelemetry-~ conda-forge/linux-64::libopentelemetry-cpp-headers-1.18.0-ha770c72_1 \n",
            "  libparquet         conda-forge/linux-64::libparquet-19.0.1-h081d1f1_0_cpu \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-5.28.3-h6128344_1 \n",
            "  libre2-11          conda-forge/linux-64::libre2-11-2024.07.02-hbbce691_2 \n",
            "  libthrift          conda-forge/linux-64::libthrift-0.21.0-h0e7cc3e_0 \n",
            "  libutf8proc        conda-forge/linux-64::libutf8proc-2.10.0-h202a827_0 \n",
            "  multidict          conda-forge/linux-64::multidict-6.6.3-py311h2dc5d0c_0 \n",
            "  multiprocess       conda-forge/linux-64::multiprocess-0.70.16-py311h9ecbd09_1 \n",
            "  nlohmann_json      conda-forge/linux-64::nlohmann_json-3.12.0-h3f2d84a_0 \n",
            "  orc                conda-forge/linux-64::orc-2.0.3-h12ee42a_2 \n",
            "  pandas             conda-forge/linux-64::pandas-2.3.1-py311hed34c8f_0 \n",
            "  prometheus-cpp     conda-forge/linux-64::prometheus-cpp-1.3.0-ha5d0236_0 \n",
            "  propcache          conda-forge/linux-64::propcache-0.3.1-py311h2dc5d0c_0 \n",
            "  pyarrow            conda-forge/linux-64::pyarrow-19.0.1-py311h38be061_0 \n",
            "  pyarrow-core       conda-forge/linux-64::pyarrow-core-19.0.1-py311h4854187_0_cpu \n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhe01879c_2 \n",
            "  python-gil         conda-forge/noarch::python-gil-3.11.13-hd8ed1ab_0 \n",
            "  python-tzdata      conda-forge/noarch::python-tzdata-2025.2-pyhd8ed1ab_0 \n",
            "  python-xxhash      conda-forge/linux-64::python-xxhash-3.5.0-py311h9ecbd09_2 \n",
            "  re2                conda-forge/linux-64::re2-2024.07.02-h9925aae_2 \n",
            "  regex              conda-forge/linux-64::regex-2025.7.34-py311h49ec1c0_0 \n",
            "  s2n                conda-forge/linux-64::s2n-1.5.11-h072c03f_0 \n",
            "  sacremoses         conda-forge/noarch::sacremoses-0.0.53-pyhd8ed1ab_0 \n",
            "  safetensors        conda-forge/linux-64::safetensors-0.6.2-py311hc8fb587_0 \n",
            "  six                conda-forge/noarch::six-1.17.0-pyhe01879c_1 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_0 \n",
            "  tokenizers         conda-forge/linux-64::tokenizers-0.13.3-py311h1b04a43_0 \n",
            "  transformers       conda-forge/noarch::transformers-4.32.1-pyhd8ed1ab_0 \n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.14.1-h4440ef1_0 \n",
            "  xxhash             conda-forge/linux-64::xxhash-0.8.3-hb47aa4a_0 \n",
            "  yarl               conda-forge/linux-64::yarl-1.20.1-py311h2dc5d0c_0 \n",
            "  zipp               conda-forge/noarch::zipp-3.23.0-pyhd8ed1ab_0 \n",
            "  zlib               conda-forge/linux-64::zlib-1.3.1-hb9d3cd8_2 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pandas-2.3.1         | 14.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libarrow-19.0.1      | 8.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  16% 0.15776762023685262/1 [00:00<00:00,  1.56it/s]\n",
            "libarrow-19.0.1      | 8.6 MB    | :   5% 0.04750145241703381/1 [00:00<00:02,  2.11s/it]\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :   8% 0.07999839846956189/1 [00:00<00:01,  1.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | :  38% 0.3777678592204155/1 [00:00<00:00,  3.76it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  37% 0.3699011096093774/1 [00:00<00:00,  1.85it/s] \n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :  73% 0.7299853860347523/1 [00:00<00:00,  4.05it/s] \u001b[A\u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | :  48% 0.4804954609876882/1 [00:00<00:00,  2.59it/s] \u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.12it/s]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.12it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.99it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  70% 0.6960963244234105/1 [00:00<00:00,  2.40it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  99% 0.9892456187824271/1 [00:00<00:00,  2.57it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.05it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | :   1% 0.006298219784190638/1 [00:00<01:15, 76.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.01it/s]               \u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.01it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.51it/s]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | :   1% 0.012491622820694435/1 [00:00<00:42, 43.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:00<00:00, 76.30s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | :   1% 0.013023485038174614/1 [00:00<00:41, 42.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:00<00:00, 43.52s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:00<00:00, 42.39s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | :   1% 0.013781026023630624/1 [00:00<00:45, 45.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | : 100% 1.0/1 [00:00<00:00,  2.57it/s]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:00<00:00, 39.66s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 45.87s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | :   2% 0.020430787340992386/1 [00:00<00:33, 34.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | :   2% 0.02085069937145017/1 [00:00<00:33, 34.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:00<00:00, 34.27s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | :   3% 0.025678077404106863/1 [00:00<00:27, 28.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:00<00:00, 34.48s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | :   3% 0.02710339123242349/1 [00:00<00:27, 28.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:00<00:00, 28.32s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :   1% 0.00614833611404443/1 [00:00<02:06, 126.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | : 100% 1.0/1 [00:00<00:00, 28.19s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | :   3% 0.029824772181992275/1 [00:00<00:26, 27.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:00<00:00, 27.00s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :  25% 0.24593344456177718/1 [00:00<00:01,  2.65s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | :   1% 0.013162493000596907/1 [00:00<01:06, 67.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:00<00:00, 67.37s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :  51% 0.5103118974656877/1 [00:00<00:00,  1.29s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :  77% 0.7685420142555537/1 [00:01<00:00,  1.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:01<00:00,  1.28it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:01<00:00,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | : 100% 1.0/1 [00:01<00:00,  4.12it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | : 100% 1.0/1 [00:02<00:00,  3.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | : 100% 1.0/1 [00:02<00:00,  4.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:02<00:00,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | : 100% 1.0/1 [00:02<00:00,  2.01it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:03<00:00,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:03<00:00,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:03<00:00,  3.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:03<00:00,  3.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:03<00:00,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:03<00:00,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:03<00:00,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:03<00:00,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | : 100% 1.0/1 [00:03<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | : 100% 1.0/1 [00:03<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:03<00:00,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:03<00:00,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | : 100% 1.0/1 [00:05<00:00,  2.57it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:05<00:00,  5.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:05<00:00,  5.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:07<00:00,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.32.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (2.1.2)\n",
            "Collecting torchvision (from sentence-transformers==2.2.2)\n",
            "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.26.3)\n",
            "Collecting scikit-learn (from sentence-transformers==2.2.2)\n",
            "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence-transformers==2.2.2)\n",
            "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "Collecting nltk (from sentence-transformers==2.2.2)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
            "  Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.1.7)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (1.5.1)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==2.2.2)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch>=1.6.0 (from sentence-transformers==2.2.2)\n",
            "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers==2.2.2)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.6.0->sentence-transformers==2.2.2) (65.6.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.8.3)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m171.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m180.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=7ed603ba2b58fdc97104b90a1f2faa5276c5c988f9415b2ee624838d3996d2ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: nvidia-cusparselt-cu12, triton, threadpoolctl, sentencepiece, scipy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, sentence-transformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "Successfully installed nltk-3.9.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pillow-11.3.0 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-2.2.2 sentencepiece-0.2.1 threadpoolctl-3.6.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "df683fea361b472cbb908019a4e94caf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda-forge::accelerate=0.25.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    accelerate-0.25.0          |     pyhd8ed1ab_0         175 KB  conda-forge\n",
            "    psutil-7.0.0               |  py311h9ecbd09_0         473 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         648 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  accelerate         conda-forge/noarch::accelerate-0.25.0-pyhd8ed1ab_0 \n",
            "  psutil             conda-forge/linux-64::psutil-7.0.0-py311h9ecbd09_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "psutil-7.0.0         | 473 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "accelerate-0.25.0    | 175 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "psutil-7.0.0         | 473 KB    | : 100% 1.0/1 [00:00<00:00, 10.02it/s]\n",
            "accelerate-0.25.0    | 175 KB    | : 100% 1.0/1 [00:00<00:00,  7.34it/s]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda-forge::bitsandbytes=0.42.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bitsandbytes-0.42.0        |  py311hccbc8e4_0         272 KB  conda-forge\n",
            "    scipy-1.16.0               |  py311h2d3ef60_0        16.1 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        16.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  bitsandbytes       conda-forge/linux-64::bitsandbytes-0.42.0-py311hccbc8e4_0 \n",
            "  scipy              conda-forge/linux-64::scipy-1.16.0-py311h2d3ef60_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "scipy-1.16.0         | 16.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "bitsandbytes-0.42.0  | 272 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "scipy-1.16.0         | 16.1 MB   | :  24% 0.23814265856436717/1 [00:00<00:00,  2.38it/s]\n",
            "bitsandbytes-0.42.0  | 272 KB    | : 100% 1.0/1 [00:00<00:00,  5.34it/s]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\bdone\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/site-packages (2.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (65.6.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
            "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, sentence-transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.32.1\n",
            "    Uninstalling transformers-4.32.1:\n",
            "      Successfully uninstalled transformers-4.32.1\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.2.2\n",
            "    Uninstalling sentence-transformers-2.2.2:\n",
            "      Successfully uninstalled sentence-transformers-2.2.2\n",
            "Successfully installed sentence-transformers-5.1.0 tokenizers-0.21.4 transformers-4.55.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movies_and_TV Dataset\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/Movies_and_TV.json.gz\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_Movies_and_TV.json.gz\n",
        "\n",
        "with gzip.open('/content/Movies_and_TV.json.gz', 'rb') as f_in:\n",
        "    with open('/content/Movies_and_TV.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "with gzip.open('/content/meta_Movies_and_TV.json.gz', 'rb') as f_in:\n",
        "    with open('/content/meta_Movies_and_TV.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "metadata": {
        "id": "vNtW7yMW9QV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All_Beauty Dataset\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/All_Beauty.json.gz\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_All_Beauty.json.gz\n",
        "\n",
        "with gzip.open('/content/All_Beauty.json.gz', 'rb') as f_in:\n",
        "    with open('/content/All_Beauty.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "with gzip.open('/content/meta_All_Beauty.json.gz', 'rb') as f_in:\n",
        "    with open('/content/meta_All_Beauty.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OjMIf1en9Nx7",
        "outputId": "9382bb81-256f-4731-cdd9-cb24ee584556"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-17 17:43:51--  https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/All_Beauty.json.gz\n",
            "Resolving mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)... 169.228.63.88\n",
            "Connecting to mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)|169.228.63.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46650072 (44M) [application/gzip]\n",
            "Saving to: All_Beauty.json.gz\n",
            "\n",
            "All_Beauty.json.gz  100%[===================>]  44.49M  12.9MB/s    in 3.6s    \n",
            "\n",
            "2025-08-17 17:43:56 (12.3 MB/s) - All_Beauty.json.gz saved [46650072/46650072]\n",
            "\n",
            "--2025-08-17 17:43:56--  https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_All_Beauty.json.gz\n",
            "Resolving mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)... 169.228.63.88\n",
            "Connecting to mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)|169.228.63.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10349695 (9.9M) [application/gzip]\n",
            "Saving to: meta_All_Beauty.json.gz\n",
            "\n",
            "meta_All_Beauty.jso 100%[===================>]   9.87M  5.42MB/s    in 1.8s    \n",
            "\n",
            "2025-08-17 17:43:59 (5.42 MB/s) - meta_All_Beauty.json.gz saved [10349695/10349695]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA device count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMYAmHUv_uZ3",
        "outputId": "9049643c-b87c-4a43-c396-bc16b2626393"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA device count: 1\n",
            "Current CUDA device: 0\n",
            "CUDA device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Rec_Proj_DL/pre_train/sasrec/main.py --device=cuda --dataset All_Beauty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du-3ugMSSQUb",
        "outputId": "097588c0-36da-4365-ee26-064bc4093c2b",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371345it [00:04, 89840.65it/s] \n",
            "371345it [00:03, 106364.33it/s]\n",
            "2169 1854\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "  0% 0/1 [00:00<?, ?it/s]loss in epoch 1 iteration 0: 1.3666472434997559\n",
            "Evaluating........................................\n",
            "\n",
            "epoch:1, time: 1.884776(s), valid (NDCG@10: 0.5228, HR@10: 0.5650), test (NDCG@10: 0.3378, HR@10: 0.3378)\n",
            "(0.5228105891213498, 0.5650309671272035) (0.33777989518818485, 0.33777989518818485)\n",
            "\n",
            "Saving model to: /content/All_Beauty/SASRec.epoch=1.lr=0.001.layer=2.head=1.hidden=50.maxlen=50.pth\n",
            "100% 1/1 [00:18<00:00, 18.89s/it]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train stage1\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --pretrain_stage1 --rec_pre_trained_data All_Beauty"
      ],
      "metadata": {
        "id": "adWqS5QoSzWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603a8c6f-0d85-43f7-9631-5bf32ebf481b",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec start train phase-1\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2169\n",
            "  0% 0/20 [00:00<?, ?it/s]loss in epoch 1/21 iteration 0/67: 1.5866392850875854 / BPR loss: 1.3866043090820312 / Matching loss: 0.008662793785333633 / Item reconstruction: 0.15345421433448792 / Text reconstruction: 0.5732250213623047\n",
            "loss in epoch 1/21 iteration 1/67: 1.5560789108276367 / BPR loss: 1.3867192268371582 / Matching loss: 0.0055673932656645775 / Item reconstruction: 0.14500011503696442 / Text reconstruction: 0.4564608633518219\n",
            "loss in epoch 1/21 iteration 2/67: 1.5422492027282715 / BPR loss: 1.3867180347442627 / Matching loss: 0.005663213320076466 / Item reconstruction: 0.13950960338115692 / Text reconstruction: 0.40056556463241577\n",
            "loss in epoch 1/21 iteration 3/67: 1.5342463254928589 / BPR loss: 1.3869372606277466 / Matching loss: 0.004424444865435362 / Item reconstruction: 0.13256371021270752 / Text reconstruction: 0.38301384449005127\n",
            "loss in epoch 1/21 iteration 4/67: 1.5202789306640625 / BPR loss: 1.386674165725708 / Matching loss: 0.0032908879220485687 / Item reconstruction: 0.12709471583366394 / Text reconstruction: 0.3338327705860138\n",
            "loss in epoch 1/21 iteration 5/67: 1.5118634700775146 / BPR loss: 1.3867878913879395 / Matching loss: 0.0027517806738615036 / Item reconstruction: 0.12194045633077621 / Text reconstruction: 0.3067678213119507\n",
            "loss in epoch 1/21 iteration 6/67: 1.5057556629180908 / BPR loss: 1.3868242502212524 / Matching loss: 0.002408053493127227 / Item reconstruction: 0.11848045885562897 / Text reconstruction: 0.2864157557487488\n",
            "loss in epoch 1/21 iteration 7/67: 1.5015088319778442 / BPR loss: 1.3868669271469116 / Matching loss: 0.0022597103379666805 / Item reconstruction: 0.11362159252166748 / Text reconstruction: 0.27785709500312805\n",
            "loss in epoch 1/21 iteration 8/67: 1.4957796335220337 / BPR loss: 1.386852741241455 / Matching loss: 0.002095635049045086 / Item reconstruction: 0.1081061065196991 / Text reconstruction: 0.26389119029045105\n",
            "loss in epoch 1/21 iteration 9/67: 1.4914002418518066 / BPR loss: 1.386749267578125 / Matching loss: 0.001981060253456235 / Item reconstruction: 0.10386142134666443 / Text reconstruction: 0.2536967396736145\n",
            "loss in epoch 1/21 iteration 10/67: 1.486368179321289 / BPR loss: 1.3865840435028076 / Matching loss: 0.0018140985630452633 / Item reconstruction: 0.09998954832553864 / Text reconstruction: 0.239875927567482\n",
            "loss in epoch 1/21 iteration 11/67: 1.4819036722183228 / BPR loss: 1.38683021068573 / Matching loss: 0.0016921446658670902 / Item reconstruction: 0.09443396329879761 / Text reconstruction: 0.23082122206687927\n",
            "loss in epoch 1/21 iteration 12/67: 1.4798275232315063 / BPR loss: 1.386594533920288 / Matching loss: 0.0016617061337456107 / Item reconstruction: 0.0925009474158287 / Text reconstruction: 0.22660431265830994\n",
            "loss in epoch 1/21 iteration 13/67: 1.4763119220733643 / BPR loss: 1.3865714073181152 / Matching loss: 0.001565045677125454 / Item reconstruction: 0.08836314082145691 / Text reconstruction: 0.21996945142745972\n",
            "loss in epoch 1/21 iteration 14/67: 1.4736249446868896 / BPR loss: 1.3866169452667236 / Matching loss: 0.001496003125794232 / Item reconstruction: 0.08497734367847443 / Text reconstruction: 0.2151165008544922\n",
            "loss in epoch 1/21 iteration 15/67: 1.4715945720672607 / BPR loss: 1.3867084980010986 / Matching loss: 0.0014479112578555942 / Item reconstruction: 0.08263346552848816 / Text reconstruction: 0.21060694754123688\n",
            "loss in epoch 1/21 iteration 16/67: 1.467431902885437 / BPR loss: 1.3865612745285034 / Matching loss: 0.0013189419405534863 / Item reconstruction: 0.07820966839790344 / Text reconstruction: 0.20223411917686462\n",
            "loss in epoch 1/21 iteration 17/67: 1.4647105932235718 / BPR loss: 1.3865883350372314 / Matching loss: 0.0012188476976007223 / Item reconstruction: 0.07535625994205475 / Text reconstruction: 0.19612647593021393\n",
            "loss in epoch 1/21 iteration 18/67: 1.4648795127868652 / BPR loss: 1.3864624500274658 / Matching loss: 0.001262319041416049 / Item reconstruction: 0.07626575231552124 / Text reconstruction: 0.19510947167873383\n",
            "loss in epoch 1/21 iteration 19/67: 1.4634255170822144 / BPR loss: 1.3864498138427734 / Matching loss: 0.001229161280207336 / Item reconstruction: 0.07504522800445557 / Text reconstruction: 0.19111917912960052\n",
            "loss in epoch 1/21 iteration 20/67: 1.460570216178894 / BPR loss: 1.3865180015563965 / Matching loss: 0.001127308583818376 / Item reconstruction: 0.07070405781269073 / Text reconstruction: 0.18786409497261047\n",
            "loss in epoch 1/21 iteration 21/67: 1.4583650827407837 / BPR loss: 1.3864644765853882 / Matching loss: 0.001061745104379952 / Item reconstruction: 0.06866838037967682 / Text reconstruction: 0.18252339959144592\n",
            "loss in epoch 1/21 iteration 22/67: 1.4563013315200806 / BPR loss: 1.3866462707519531 / Matching loss: 0.000987364212051034 / Item reconstruction: 0.06680665910243988 / Text reconstruction: 0.17632213234901428\n",
            "loss in epoch 1/21 iteration 23/67: 1.4532923698425293 / BPR loss: 1.3864104747772217 / Matching loss: 0.0009145762305706739 / Item reconstruction: 0.06324368715286255 / Text reconstruction: 0.1717275083065033\n",
            "loss in epoch 1/21 iteration 24/67: 1.451887607574463 / BPR loss: 1.3864854574203491 / Matching loss: 0.0008728108950890601 / Item reconstruction: 0.06171662360429764 / Text reconstruction: 0.16835540533065796\n",
            "loss in epoch 1/21 iteration 25/67: 1.4497402906417847 / BPR loss: 1.3865147829055786 / Matching loss: 0.0008107272442430258 / Item reconstruction: 0.05936234071850777 / Text reconstruction: 0.1636679768562317\n",
            "loss in epoch 1/21 iteration 26/67: 1.4478145837783813 / BPR loss: 1.3865132331848145 / Matching loss: 0.0007698782719671726 / Item reconstruction: 0.05695195496082306 / Text reconstruction: 0.16027748584747314\n",
            "loss in epoch 1/21 iteration 27/67: 1.445730447769165 / BPR loss: 1.3864738941192627 / Matching loss: 0.0007383798947557807 / Item reconstruction: 0.05478659272193909 / Text reconstruction: 0.15562421083450317\n",
            "loss in epoch 1/21 iteration 28/67: 1.4443742036819458 / BPR loss: 1.386550784111023 / Matching loss: 0.0007034537266008556 / Item reconstruction: 0.053396500647068024 / Text reconstruction: 0.15210846066474915\n",
            "loss in epoch 1/21 iteration 29/67: 1.4424630403518677 / BPR loss: 1.3865201473236084 / Matching loss: 0.0006670109578408301 / Item reconstruction: 0.05128481984138489 / Text reconstruction: 0.14816787838935852\n",
            "loss in epoch 1/21 iteration 30/67: 1.440375804901123 / BPR loss: 1.3864223957061768 / Matching loss: 0.0006442872690968215 / Item reconstruction: 0.04875445365905762 / Text reconstruction: 0.14465901255607605\n",
            "loss in epoch 1/21 iteration 31/67: 1.438839077949524 / BPR loss: 1.3863275051116943 / Matching loss: 0.0006380426348187029 / Item reconstruction: 0.04762449860572815 / Text reconstruction: 0.1403064727783203\n",
            "loss in epoch 1/21 iteration 32/67: 1.4374693632125854 / BPR loss: 1.3863872289657593 / Matching loss: 0.000620389124378562 / Item reconstruction: 0.04613161459565163 / Text reconstruction: 0.13697963953018188\n",
            "loss in epoch 1/21 iteration 33/67: 1.4347758293151855 / BPR loss: 1.3864259719848633 / Matching loss: 0.0005821596132591367 / Item reconstruction: 0.042449891567230225 / Text reconstruction: 0.1327131688594818\n",
            "loss in epoch 1/21 iteration 34/67: 1.4337173700332642 / BPR loss: 1.386185646057129 / Matching loss: 0.000551525445189327 / Item reconstruction: 0.04151264578104019 / Text reconstruction: 0.13111908733844757\n",
            "loss in epoch 1/21 iteration 35/67: 1.4322494268417358 / BPR loss: 1.3863359689712524 / Matching loss: 0.000516625412274152 / Item reconstruction: 0.039738669991493225 / Text reconstruction: 0.1276375949382782\n",
            "loss in epoch 1/21 iteration 36/67: 1.4312056303024292 / BPR loss: 1.386322259902954 / Matching loss: 0.0005282824859023094 / Item reconstruction: 0.03902263194322586 / Text reconstruction: 0.12421870976686478\n",
            "loss in epoch 1/21 iteration 37/67: 1.4301226139068604 / BPR loss: 1.386399507522583 / Matching loss: 0.0005150117794983089 / Item reconstruction: 0.03824838250875473 / Text reconstruction: 0.12041958421468735\n",
            "loss in epoch 1/21 iteration 38/67: 1.4291115999221802 / BPR loss: 1.3864538669586182 / Matching loss: 0.0004890752024948597 / Item reconstruction: 0.03699593245983124 / Text reconstruction: 0.11835360527038574\n",
            "loss in epoch 1/21 iteration 39/67: 1.4280049800872803 / BPR loss: 1.386415958404541 / Matching loss: 0.0004594989586621523 / Item reconstruction: 0.03584422171115875 / Text reconstruction: 0.11603659391403198\n",
            "loss in epoch 1/21 iteration 40/67: 1.4265172481536865 / BPR loss: 1.3864147663116455 / Matching loss: 0.0004377808654680848 / Item reconstruction: 0.03374915570020676 / Text reconstruction: 0.11395108699798584\n",
            "loss in epoch 1/21 iteration 41/67: 1.4244681596755981 / BPR loss: 1.38634192943573 / Matching loss: 0.000410907348850742 / Item reconstruction: 0.03157291188836098 / Text reconstruction: 0.10964466631412506\n",
            "loss in epoch 1/21 iteration 42/67: 1.422690510749817 / BPR loss: 1.3863335847854614 / Matching loss: 0.00038511224556714296 / Item reconstruction: 0.029507294297218323 / Text reconstruction: 0.10609034448862076\n",
            "loss in epoch 1/21 iteration 43/67: 1.4213528633117676 / BPR loss: 1.3862460851669312 / Matching loss: 0.00037235626950860023 / Item reconstruction: 0.028196105733513832 / Text reconstruction: 0.10318168997764587\n",
            "loss in epoch 1/21 iteration 44/67: 1.4217438697814941 / BPR loss: 1.3863160610198975 / Matching loss: 0.00040151402936317027 / Item reconstruction: 0.0293688103556633 / Text reconstruction: 0.10170946270227432\n",
            "loss in epoch 1/21 iteration 45/67: 1.420972466468811 / BPR loss: 1.386277437210083 / Matching loss: 0.0003686940763145685 / Item reconstruction: 0.02865649200975895 / Text reconstruction: 0.09999023377895355\n",
            "loss in epoch 1/21 iteration 46/67: 1.419834017753601 / BPR loss: 1.3864569664001465 / Matching loss: 0.0003592123684938997 / Item reconstruction: 0.027049219235777855 / Text reconstruction: 0.09746597707271576\n",
            "loss in epoch 1/21 iteration 47/67: 1.4188034534454346 / BPR loss: 1.386380672454834 / Matching loss: 0.000345622596796602 / Item reconstruction: 0.0261138416826725 / Text reconstruction: 0.0951014906167984\n",
            "loss in epoch 1/21 iteration 48/67: 1.4180628061294556 / BPR loss: 1.3862831592559814 / Matching loss: 0.00033125714980997145 / Item reconstruction: 0.025677766650915146 / Text reconstruction: 0.09304782748222351\n",
            "loss in epoch 1/21 iteration 49/67: 1.4168846607208252 / BPR loss: 1.3864483833312988 / Matching loss: 0.0003054793050978333 / Item reconstruction: 0.02423819713294506 / Text reconstruction: 0.09005828201770782\n",
            "loss in epoch 1/21 iteration 50/67: 1.415948748588562 / BPR loss: 1.3863798379898071 / Matching loss: 0.0002942314022220671 / Item reconstruction: 0.02328409254550934 / Text reconstruction: 0.08816312253475189\n",
            "loss in epoch 1/21 iteration 51/67: 1.4155064821243286 / BPR loss: 1.386288046836853 / Matching loss: 0.0002872789918910712 / Item reconstruction: 0.02333362028002739 / Text reconstruction: 0.08632158488035202\n",
            "loss in epoch 1/21 iteration 52/67: 1.414467215538025 / BPR loss: 1.3863062858581543 / Matching loss: 0.00028945913072675467 / Item reconstruction: 0.02206725999712944 / Text reconstruction: 0.08418931812047958\n",
            "loss in epoch 1/21 iteration 53/67: 1.4139690399169922 / BPR loss: 1.386364221572876 / Matching loss: 0.0002762574004009366 / Item reconstruction: 0.021484464406967163 / Text reconstruction: 0.08293218165636063\n",
            "loss in epoch 1/21 iteration 54/67: 1.412988543510437 / BPR loss: 1.3863062858581543 / Matching loss: 0.0002642538456711918 / Item reconstruction: 0.02049591951072216 / Text reconstruction: 0.08085036277770996\n",
            "loss in epoch 1/21 iteration 55/67: 1.4123759269714355 / BPR loss: 1.386373519897461 / Matching loss: 0.00026209987117908895 / Item reconstruction: 0.019678186625242233 / Text reconstruction: 0.07950587570667267\n",
            "loss in epoch 1/21 iteration 56/67: 1.4114230871200562 / BPR loss: 1.3863236904144287 / Matching loss: 0.00025545331300236285 / Item reconstruction: 0.01862788386642933 / Text reconstruction: 0.07765006273984909\n",
            "loss in epoch 1/21 iteration 57/67: 1.4110639095306396 / BPR loss: 1.3863747119903564 / Matching loss: 0.00025093392468988895 / Item reconstruction: 0.018351782113313675 / Text reconstruction: 0.07631182670593262\n",
            "loss in epoch 1/21 iteration 58/67: 1.4101709127426147 / BPR loss: 1.3862671852111816 / Matching loss: 0.00024193228455260396 / Item reconstruction: 0.01750151813030243 / Text reconstruction: 0.0745554193854332\n",
            "loss in epoch 1/21 iteration 59/67: 1.4095790386199951 / BPR loss: 1.386293649673462 / Matching loss: 0.00023494221386499703 / Item reconstruction: 0.0169614739716053 / Text reconstruction: 0.0728481113910675\n",
            "loss in epoch 1/21 iteration 60/67: 1.4089441299438477 / BPR loss: 1.3863320350646973 / Matching loss: 0.0002352466544834897 / Item reconstruction: 0.016410881653428078 / Text reconstruction: 0.07085710763931274\n",
            "loss in epoch 1/21 iteration 61/67: 1.4082748889923096 / BPR loss: 1.3863704204559326 / Matching loss: 0.0002273717400385067 / Item reconstruction: 0.015599273145198822 / Text reconstruction: 0.06938765943050385\n",
            "loss in epoch 1/21 iteration 62/67: 1.4075632095336914 / BPR loss: 1.3863334655761719 / Matching loss: 0.00021884262969251722 / Item reconstruction: 0.014659831300377846 / Text reconstruction: 0.06840445846319199\n",
            "loss in epoch 1/21 iteration 63/67: 1.4074182510375977 / BPR loss: 1.3863248825073242 / Matching loss: 0.0002192195097450167 / Item reconstruction: 0.015187965705990791 / Text reconstruction: 0.0664009153842926\n",
            "loss in epoch 1/21 iteration 64/67: 1.4066643714904785 / BPR loss: 1.3863551616668701 / Matching loss: 0.00020817558106500655 / Item reconstruction: 0.014195375144481659 / Text reconstruction: 0.06501681357622147\n",
            "loss in epoch 1/21 iteration 65/67: 1.4062031507492065 / BPR loss: 1.3863086700439453 / Matching loss: 0.00019707177125383168 / Item reconstruction: 0.013894915580749512 / Text reconstruction: 0.06374996900558472\n",
            "loss in epoch 1/21 iteration 66/67: 1.405609369277954 / BPR loss: 1.3862630128860474 / Matching loss: 0.00018931736121885478 / Item reconstruction: 0.013183007016777992 / Text reconstruction: 0.0628277063369751\n",
            "loss in epoch 1/21 iteration 67/67: 1.4051835536956787 / BPR loss: 1.3863450288772583 / Matching loss: 0.00018154257850255817 / Item reconstruction: 0.012741560116410255 / Text reconstruction: 0.061430931091308594\n",
            "  5% 1/20 [01:54<36:09, 114.21s/it]loss in epoch 2/21 iteration 0/67: 1.404860019683838 / BPR loss: 1.3863226175308228 / Matching loss: 0.0002035006182268262 / Item reconstruction: 0.012856030836701393 / Text reconstruction: 0.059529244899749756\n",
            "loss in epoch 2/21 iteration 1/67: 1.4038584232330322 / BPR loss: 1.3862054347991943 / Matching loss: 0.0001962471433216706 / Item reconstruction: 0.011619873344898224 / Text reconstruction: 0.0582343265414238\n",
            "loss in epoch 2/21 iteration 2/67: 1.4035449028015137 / BPR loss: 1.3861761093139648 / Matching loss: 0.00019032045383937657 / Item reconstruction: 0.011571517214179039 / Text reconstruction: 0.056963834911584854\n",
            "loss in epoch 2/21 iteration 3/67: 1.4027196168899536 / BPR loss: 1.386149287223816 / Matching loss: 0.00017928970919456333 / Item reconstruction: 0.010528999380767345 / Text reconstruction: 0.05563275143504143\n",
            "loss in epoch 2/21 iteration 4/67: 1.4022783041000366 / BPR loss: 1.386152982711792 / Matching loss: 0.00017902599938679487 / Item reconstruction: 0.010126335546374321 / Text reconstruction: 0.054415248334407806\n",
            "loss in epoch 2/21 iteration 5/67: 1.4020007848739624 / BPR loss: 1.3862476348876953 / Matching loss: 0.00017582744476385415 / Item reconstruction: 0.009800986386835575 / Text reconstruction: 0.05338415130972862\n",
            "loss in epoch 2/21 iteration 6/67: 1.4016022682189941 / BPR loss: 1.3861849308013916 / Matching loss: 0.00017533483332954347 / Item reconstruction: 0.009503841400146484 / Text reconstruction: 0.05245053395628929\n",
            "loss in epoch 2/21 iteration 7/67: 1.4013628959655762 / BPR loss: 1.3862264156341553 / Matching loss: 0.00017313275020569563 / Item reconstruction: 0.009370528161525726 / Text reconstruction: 0.05139049142599106\n",
            "loss in epoch 2/21 iteration 8/67: 1.4007598161697388 / BPR loss: 1.3861517906188965 / Matching loss: 0.00016925706586334854 / Item reconstruction: 0.008762774057686329 / Text reconstruction: 0.05028644576668739\n",
            "loss in epoch 2/21 iteration 9/67: 1.4004690647125244 / BPR loss: 1.386173963546753 / Matching loss: 0.0001658753608353436 / Item reconstruction: 0.008508672006428242 / Text reconstruction: 0.049374449998140335\n",
            "loss in epoch 2/21 iteration 10/67: 1.400071620941162 / BPR loss: 1.386236310005188 / Matching loss: 0.00016387301729992032 / Item reconstruction: 0.0080302394926548 / Text reconstruction: 0.04828168451786041\n",
            "loss in epoch 2/21 iteration 11/67: 1.3996566534042358 / BPR loss: 1.3861212730407715 / Matching loss: 0.00015693940804339945 / Item reconstruction: 0.00781027227640152 / Text reconstruction: 0.047366078943014145\n",
            "loss in epoch 2/21 iteration 12/67: 1.3994063138961792 / BPR loss: 1.3861910104751587 / Matching loss: 0.00014996380195952952 / Item reconstruction: 0.0074838087894022465 / Text reconstruction: 0.04661719128489494\n",
            "loss in epoch 2/21 iteration 13/67: 1.3992011547088623 / BPR loss: 1.3861680030822754 / Matching loss: 0.0001478631456848234 / Item reconstruction: 0.007431861478835344 / Text reconstruction: 0.045847270637750626\n",
            "loss in epoch 2/21 iteration 14/67: 1.3989466428756714 / BPR loss: 1.386220932006836 / Matching loss: 0.0001462560030631721 / Item reconstruction: 0.007162333466112614 / Text reconstruction: 0.04499165713787079\n",
            "loss in epoch 2/21 iteration 15/67: 1.398635745048523 / BPR loss: 1.3861193656921387 / Matching loss: 0.00014308159006759524 / Item reconstruction: 0.007048838771879673 / Text reconstruction: 0.04424475133419037\n",
            "loss in epoch 2/21 iteration 16/67: 1.3982055187225342 / BPR loss: 1.3861095905303955 / Matching loss: 0.00014281924813985825 / Item reconstruction: 0.006593545898795128 / Text reconstruction: 0.043281715363264084\n",
            "loss in epoch 2/21 iteration 17/67: 1.3978971242904663 / BPR loss: 1.3861565589904785 / Matching loss: 0.00014208235370460898 / Item reconstruction: 0.006158190313726664 / Text reconstruction: 0.04259716346859932\n",
            "loss in epoch 2/21 iteration 18/67: 1.3988075256347656 / BPR loss: 1.3863433599472046 / Matching loss: 0.0001555686758365482 / Item reconstruction: 0.0077251046895980835 / Text reconstruction: 0.042230457067489624\n",
            "loss in epoch 2/21 iteration 19/67: 1.3987616300582886 / BPR loss: 1.3863158226013184 / Matching loss: 0.00015496081323362887 / Item reconstruction: 0.007893294095993042 / Text reconstruction: 0.04172089695930481\n",
            "loss in epoch 2/21 iteration 20/67: 1.398537278175354 / BPR loss: 1.3863117694854736 / Matching loss: 0.0001446341339033097 / Item reconstruction: 0.007716530933976173 / Text reconstruction: 0.041113290935754776\n",
            "loss in epoch 2/21 iteration 21/67: 1.3983299732208252 / BPR loss: 1.3863288164138794 / Matching loss: 0.0001478743797633797 / Item reconstruction: 0.0075609274208545685 / Text reconstruction: 0.04036427661776543\n",
            "loss in epoch 2/21 iteration 22/67: 1.3979413509368896 / BPR loss: 1.386151909828186 / Matching loss: 0.0001539866061648354 / Item reconstruction: 0.0074663469567894936 / Text reconstruction: 0.03951115533709526\n",
            "loss in epoch 2/21 iteration 23/67: 1.3975945711135864 / BPR loss: 1.3861767053604126 / Matching loss: 0.00014352420112118125 / Item reconstruction: 0.0070113567635416985 / Text reconstruction: 0.03884332627058029\n",
            "loss in epoch 2/21 iteration 24/67: 1.3974195718765259 / BPR loss: 1.3862226009368896 / Matching loss: 0.00013845026842318475 / Item reconstruction: 0.006859431974589825 / Text reconstruction: 0.038143787533044815\n",
            "loss in epoch 2/21 iteration 25/67: 1.3973060846328735 / BPR loss: 1.3862775564193726 / Matching loss: 0.0001391746918670833 / Item reconstruction: 0.0067832814529538155 / Text reconstruction: 0.03748885169625282\n",
            "loss in epoch 2/21 iteration 26/67: 1.397225260734558 / BPR loss: 1.3862427473068237 / Matching loss: 0.00013716385001316667 / Item reconstruction: 0.006914054974913597 / Text reconstruction: 0.03694123402237892\n",
            "loss in epoch 2/21 iteration 27/67: 1.3966379165649414 / BPR loss: 1.3861404657363892 / Matching loss: 0.0001388847886119038 / Item reconstruction: 0.006171646062284708 / Text reconstruction: 0.036363761872053146\n",
            "loss in epoch 2/21 iteration 28/67: 1.3964316844940186 / BPR loss: 1.3860630989074707 / Matching loss: 0.0001448351686121896 / Item reconstruction: 0.0061717769131064415 / Text reconstruction: 0.035689592361450195\n",
            "loss in epoch 2/21 iteration 29/67: 1.3963321447372437 / BPR loss: 1.386151671409607 / Matching loss: 0.00014050262689124793 / Item reconstruction: 0.006031600758433342 / Text reconstruction: 0.035120975226163864\n",
            "loss in epoch 2/21 iteration 30/67: 1.3961225748062134 / BPR loss: 1.3861457109451294 / Matching loss: 0.00013594501069746912 / Item reconstruction: 0.005820784717798233 / Text reconstruction: 0.03465304523706436\n",
            "loss in epoch 2/21 iteration 31/67: 1.3958942890167236 / BPR loss: 1.3860976696014404 / Matching loss: 0.00013138481881469488 / Item reconstruction: 0.005694095976650715 / Text reconstruction: 0.03409063071012497\n",
            "loss in epoch 2/21 iteration 32/67: 1.3957008123397827 / BPR loss: 1.3860973119735718 / Matching loss: 0.0001239952107425779 / Item reconstruction: 0.005474753212183714 / Text reconstruction: 0.03371064364910126\n",
            "loss in epoch 2/21 iteration 33/67: 1.3955061435699463 / BPR loss: 1.3860310316085815 / Matching loss: 0.00011938739771721885 / Item reconstruction: 0.0054440912790596485 / Text reconstruction: 0.03316876292228699\n",
            "loss in epoch 2/21 iteration 34/67: 1.3954495191574097 / BPR loss: 1.3859996795654297 / Matching loss: 0.0001222810533363372 / Item reconstruction: 0.005611455999314785 / Text reconstruction: 0.03260895237326622\n",
            "loss in epoch 2/21 iteration 35/67: 1.3953578472137451 / BPR loss: 1.3860453367233276 / Matching loss: 0.0001162895787274465 / Item reconstruction: 0.005510721355676651 / Text reconstruction: 0.03220396861433983\n",
            "loss in epoch 2/21 iteration 36/67: 1.3955157995224 / BPR loss: 1.3862800598144531 / Matching loss: 0.0001369686797261238 / Item reconstruction: 0.005468250252306461 / Text reconstruction: 0.031823113560676575\n",
            "loss in epoch 2/21 iteration 37/67: 1.3954229354858398 / BPR loss: 1.3863457441329956 / Matching loss: 0.0001381345500703901 / Item reconstruction: 0.005320263095200062 / Text reconstruction: 0.03139445185661316\n",
            "loss in epoch 2/21 iteration 38/67: 1.3952842950820923 / BPR loss: 1.3862648010253906 / Matching loss: 0.00013693893561139703 / Item reconstruction: 0.005355190485715866 / Text reconstruction: 0.031024668365716934\n",
            "loss in epoch 2/21 iteration 39/67: 1.395087480545044 / BPR loss: 1.38624906539917 / Matching loss: 0.0001268832857022062 / Item reconstruction: 0.005084286443889141 / Text reconstruction: 0.030847258865833282\n",
            "loss in epoch 2/21 iteration 40/67: 1.3950129747390747 / BPR loss: 1.3863019943237305 / Matching loss: 0.00012725753185804933 / Item reconstruction: 0.00504254549741745 / Text reconstruction: 0.030311843380331993\n",
            "loss in epoch 2/21 iteration 41/67: 1.3946678638458252 / BPR loss: 1.3862025737762451 / Matching loss: 0.00012199767661513761 / Item reconstruction: 0.004653883166611195 / Text reconstruction: 0.030081871896982193\n",
            "loss in epoch 2/21 iteration 42/67: 1.3942022323608398 / BPR loss: 1.3860416412353516 / Matching loss: 0.0001082850358216092 / Item reconstruction: 0.004059731028974056 / Text reconstruction: 0.030112354084849358\n",
            "loss in epoch 2/21 iteration 43/67: 1.3939905166625977 / BPR loss: 1.3860032558441162 / Matching loss: 0.0001033617154462263 / Item reconstruction: 0.003978464286774397 / Text reconstruction: 0.029473263770341873\n",
            "loss in epoch 2/21 iteration 44/67: 1.3944038152694702 / BPR loss: 1.3862435817718506 / Matching loss: 0.00012367338058538735 / Item reconstruction: 0.004582330584526062 / Text reconstruction: 0.028727179393172264\n",
            "loss in epoch 2/21 iteration 45/67: 1.3942883014678955 / BPR loss: 1.386293888092041 / Matching loss: 0.00011870681191794574 / Item reconstruction: 0.004411492496728897 / Text reconstruction: 0.028349777683615685\n",
            "loss in epoch 2/21 iteration 46/67: 1.3940916061401367 / BPR loss: 1.3862860202789307 / Matching loss: 0.0001241481804754585 / Item reconstruction: 0.004233997315168381 / Text reconstruction: 0.027822110801935196\n",
            "loss in epoch 2/21 iteration 47/67: 1.3939776420593262 / BPR loss: 1.3862794637680054 / Matching loss: 0.00012197594332974404 / Item reconstruction: 0.004151705652475357 / Text reconstruction: 0.027501529082655907\n",
            "loss in epoch 2/21 iteration 48/67: 1.3938956260681152 / BPR loss: 1.3862652778625488 / Matching loss: 0.0001223536382894963 / Item reconstruction: 0.00410233810544014 / Text reconstruction: 0.02728484943509102\n",
            "loss in epoch 2/21 iteration 49/67: 1.3939316272735596 / BPR loss: 1.386466383934021 / Matching loss: 0.00011763378279283643 / Item reconstruction: 0.003832050133496523 / Text reconstruction: 0.02715795859694481\n",
            "loss in epoch 2/21 iteration 50/67: 1.3938592672348022 / BPR loss: 1.386420726776123 / Matching loss: 0.00012037278793286532 / Item reconstruction: 0.003947521559894085 / Text reconstruction: 0.026721758767962456\n",
            "loss in epoch 2/21 iteration 51/67: 1.3936389684677124 / BPR loss: 1.3862993717193604 / Matching loss: 0.00012140214676037431 / Item reconstruction: 0.003829128574579954 / Text reconstruction: 0.026518017053604126\n",
            "loss in epoch 2/21 iteration 52/67: 1.3934776782989502 / BPR loss: 1.3862594366073608 / Matching loss: 0.00011707905650837347 / Item reconstruction: 0.0037822099402546883 / Text reconstruction: 0.026050163432955742\n",
            "loss in epoch 2/21 iteration 53/67: 1.3933265209197998 / BPR loss: 1.3862496614456177 / Matching loss: 0.00010754347022157162 / Item reconstruction: 0.0035962960682809353 / Text reconstruction: 0.025855857878923416\n",
            "loss in epoch 2/21 iteration 54/67: 1.3932377099990845 / BPR loss: 1.386267900466919 / Matching loss: 0.00011308598914183676 / Item reconstruction: 0.003461167449131608 / Text reconstruction: 0.025630682706832886\n",
            "loss in epoch 2/21 iteration 55/67: 1.3932214975357056 / BPR loss: 1.3862946033477783 / Matching loss: 0.0001090498044504784 / Item reconstruction: 0.003476677695289254 / Text reconstruction: 0.025397635996341705\n",
            "loss in epoch 2/21 iteration 56/67: 1.3931587934494019 / BPR loss: 1.3862855434417725 / Matching loss: 0.00011158559937030077 / Item reconstruction: 0.0034777605906128883 / Text reconstruction: 0.025113757699728012\n",
            "loss in epoch 2/21 iteration 57/67: 1.3930672407150269 / BPR loss: 1.3862919807434082 / Matching loss: 0.0001103598769987002 / Item reconstruction: 0.0033171263057738543 / Text reconstruction: 0.025031641125679016\n",
            "loss in epoch 2/21 iteration 58/67: 1.393051266670227 / BPR loss: 1.3863773345947266 / Matching loss: 0.00010659512190613896 / Item reconstruction: 0.0032330816611647606 / Text reconstruction: 0.02475358545780182\n",
            "loss in epoch 2/21 iteration 59/67: 1.3928725719451904 / BPR loss: 1.3862943649291992 / Matching loss: 0.00011020863894373178 / Item reconstruction: 0.0032075359486043453 / Text reconstruction: 0.024321559816598892\n",
            "loss in epoch 2/21 iteration 60/67: 1.3927522897720337 / BPR loss: 1.38627290725708 / Matching loss: 0.00010535297042224556 / Item reconstruction: 0.0030721458606421947 / Text reconstruction: 0.02418912574648857\n",
            "loss in epoch 2/21 iteration 61/67: 1.3926359415054321 / BPR loss: 1.3862826824188232 / Matching loss: 0.00010127226414624602 / Item reconstruction: 0.0029537330847233534 / Text reconstruction: 0.023875292390584946\n",
            "loss in epoch 2/21 iteration 62/67: 1.3923133611679077 / BPR loss: 1.3861812353134155 / Matching loss: 9.419721027370542e-05 / Item reconstruction: 0.002632874995470047 / Text reconstruction: 0.023607397451996803\n",
            "loss in epoch 2/21 iteration 63/67: 1.392553687095642 / BPR loss: 1.3862268924713135 / Matching loss: 0.00010610741446726024 / Item reconstruction: 0.003164886496961117 / Text reconstruction: 0.023191845044493675\n",
            "loss in epoch 2/21 iteration 64/67: 1.392555594444275 / BPR loss: 1.3863682746887207 / Matching loss: 0.00010334981925552711 / Item reconstruction: 0.002915211021900177 / Text reconstruction: 0.02313179336488247\n",
            "loss in epoch 2/21 iteration 65/67: 1.39254891872406 / BPR loss: 1.3863885402679443 / Matching loss: 0.00010100976942339912 / Item reconstruction: 0.0028788787312805653 / Text reconstruction: 0.02309967577457428\n",
            "loss in epoch 2/21 iteration 66/67: 1.3921513557434082 / BPR loss: 1.3862392902374268 / Matching loss: 9.010003122966737e-05 / Item reconstruction: 0.0024269279092550278 / Text reconstruction: 0.023042671382427216\n",
            "loss in epoch 2/21 iteration 67/67: 1.3920918703079224 / BPR loss: 1.3862967491149902 / Matching loss: 8.530987543053925e-05 / Item reconstruction: 0.0022395863197743893 / Text reconstruction: 0.022949792444705963\n",
            " 10% 2/20 [03:52<34:58, 116.59s/it]loss in epoch 3/21 iteration 0/67: 1.3923916816711426 / BPR loss: 1.386320948600769 / Matching loss: 0.00010928832489298657 / Item reconstruction: 0.003065346274524927 / Text reconstruction: 0.0221437718719244\n",
            "loss in epoch 3/21 iteration 1/67: 1.3922293186187744 / BPR loss: 1.3861876726150513 / Matching loss: 9.508836956229061e-05 / Item reconstruction: 0.0030168567318469286 / Text reconstruction: 0.022190328687429428\n",
            "loss in epoch 3/21 iteration 2/67: 1.3920403718948364 / BPR loss: 1.385892629623413 / Matching loss: 9.218492778018117e-05 / Item reconstruction: 0.003288453444838524 / Text reconstruction: 0.02205696515738964\n",
            "loss in epoch 3/21 iteration 3/67: 1.3919614553451538 / BPR loss: 1.3859050273895264 / Matching loss: 8.415836055064574e-05 / Item reconstruction: 0.0031158048659563065 / Text reconstruction: 0.022071726620197296\n",
            "loss in epoch 3/21 iteration 4/67: 1.3919650316238403 / BPR loss: 1.3859515190124512 / Matching loss: 8.90088194864802e-05 / Item reconstruction: 0.0030662144999951124 / Text reconstruction: 0.021956387907266617\n",
            "loss in epoch 3/21 iteration 5/67: 1.3917608261108398 / BPR loss: 1.3858990669250488 / Matching loss: 9.085908823180944e-05 / Item reconstruction: 0.002824237570166588 / Text reconstruction: 0.021793564781546593\n",
            "loss in epoch 3/21 iteration 6/67: 1.3917267322540283 / BPR loss: 1.3859601020812988 / Matching loss: 9.059398871613666e-05 / Item reconstruction: 0.0027635344304144382 / Text reconstruction: 0.021471450105309486\n",
            "loss in epoch 3/21 iteration 7/67: 1.3917114734649658 / BPR loss: 1.385962963104248 / Matching loss: 9.173149010166526e-05 / Item reconstruction: 0.002823429647833109 / Text reconstruction: 0.021225642412900925\n",
            "loss in epoch 3/21 iteration 8/67: 1.3914512395858765 / BPR loss: 1.3858386278152466 / Matching loss: 8.578278357163072e-05 / Item reconstruction: 0.002638585399836302 / Text reconstruction: 0.02103731408715248\n",
            "loss in epoch 3/21 iteration 9/67: 1.3914357423782349 / BPR loss: 1.3859232664108276 / Matching loss: 7.740238652331755e-05 / Item reconstruction: 0.0025078325998038054 / Text reconstruction: 0.02090596780180931\n",
            "loss in epoch 3/21 iteration 10/67: 1.3913207054138184 / BPR loss: 1.3859069347381592 / Matching loss: 7.743389869574457e-05 / Item reconstruction: 0.0023701051250100136 / Text reconstruction: 0.02075617015361786\n",
            "loss in epoch 3/21 iteration 11/67: 1.3912937641143799 / BPR loss: 1.385879397392273 / Matching loss: 7.715549145359546e-05 / Item reconstruction: 0.0024141217581927776 / Text reconstruction: 0.02065075933933258\n",
            "loss in epoch 3/21 iteration 12/67: 1.3912756443023682 / BPR loss: 1.385909080505371 / Matching loss: 7.808601367287338e-05 / Item reconstruction: 0.0024161934852600098 / Text reconstruction: 0.02040180191397667\n",
            "loss in epoch 3/21 iteration 13/67: 1.391239881515503 / BPR loss: 1.3859074115753174 / Matching loss: 8.163554593920708e-05 / Item reconstruction: 0.0023736695293337107 / Text reconstruction: 0.02031955122947693\n",
            "loss in epoch 3/21 iteration 14/67: 1.3910614252090454 / BPR loss: 1.385810136795044 / Matching loss: 8.042308036237955e-05 / Item reconstruction: 0.00224898848682642 / Text reconstruction: 0.02023143321275711\n",
            "loss in epoch 3/21 iteration 15/67: 1.391006350517273 / BPR loss: 1.3857848644256592 / Matching loss: 7.802489562891424e-05 / Item reconstruction: 0.0022008728701621294 / Text reconstruction: 0.02021469920873642\n",
            "loss in epoch 3/21 iteration 16/67: 1.3910109996795654 / BPR loss: 1.3858575820922852 / Matching loss: 7.909916166681796e-05 / Item reconstruction: 0.0021867540199309587 / Text reconstruction: 0.019904647022485733\n",
            "loss in epoch 3/21 iteration 17/67: 1.3909885883331299 / BPR loss: 1.3858305215835571 / Matching loss: 7.636348891537637e-05 / Item reconstruction: 0.0022364577744156122 / Text reconstruction: 0.019817225635051727\n",
            "loss in epoch 3/21 iteration 18/67: 1.3916913270950317 / BPR loss: 1.3861563205718994 / Matching loss: 8.842378156259656e-05 / Item reconstruction: 0.0028908499516546726 / Text reconstruction: 0.020005952566862106\n",
            "loss in epoch 3/21 iteration 19/67: 1.3919837474822998 / BPR loss: 1.386317491531372 / Matching loss: 8.794612949714065e-05 / Item reconstruction: 0.003100356087088585 / Text reconstruction: 0.020140424370765686\n",
            "loss in epoch 3/21 iteration 20/67: 1.3918447494506836 / BPR loss: 1.3862426280975342 / Matching loss: 9.076303103938699e-05 / Item reconstruction: 0.003110544290393591 / Text reconstruction: 0.019780687987804413\n",
            "loss in epoch 3/21 iteration 21/67: 1.3919329643249512 / BPR loss: 1.386357069015503 / Matching loss: 9.713895269669592e-05 / Item reconstruction: 0.003199708880856633 / Text reconstruction: 0.01939440332353115\n",
            "loss in epoch 3/21 iteration 22/67: 1.3915247917175293 / BPR loss: 1.3859400749206543 / Matching loss: 9.835372475208715e-05 / Item reconstruction: 0.0032673636451363564 / Text reconstruction: 0.019263576716184616\n",
            "loss in epoch 3/21 iteration 23/67: 1.3913527727127075 / BPR loss: 1.3859022855758667 / Matching loss: 8.911611803341657e-05 / Item reconstruction: 0.0030579217709600925 / Text reconstruction: 0.019161881878972054\n",
            "loss in epoch 3/21 iteration 24/67: 1.3912761211395264 / BPR loss: 1.3858590126037598 / Matching loss: 8.525732846464962e-05 / Item reconstruction: 0.003027746919542551 / Text reconstruction: 0.019090035930275917\n",
            "loss in epoch 3/21 iteration 25/67: 1.3912334442138672 / BPR loss: 1.3858973979949951 / Matching loss: 8.584692113799974e-05 / Item reconstruction: 0.002945362590253353 / Text reconstruction: 0.01888742297887802\n",
            "loss in epoch 3/21 iteration 26/67: 1.391143798828125 / BPR loss: 1.3859156370162964 / Matching loss: 8.357089245691895e-05 / Item reconstruction: 0.002839121501892805 / Text reconstruction: 0.018625298514962196\n",
            "loss in epoch 3/21 iteration 27/67: 1.3910938501358032 / BPR loss: 1.3858954906463623 / Matching loss: 8.811664883978665e-05 / Item reconstruction: 0.0028700875118374825 / Text reconstruction: 0.018376067280769348\n",
            "loss in epoch 3/21 iteration 28/67: 1.3910961151123047 / BPR loss: 1.3859741687774658 / Matching loss: 9.172270074486732e-05 / Item reconstruction: 0.002754172310233116 / Text reconstruction: 0.018265848979353905\n",
            "loss in epoch 3/21 iteration 29/67: 1.3909071683883667 / BPR loss: 1.385885238647461 / Matching loss: 8.534522203262895e-05 / Item reconstruction: 0.0026143398135900497 / Text reconstruction: 0.01814703643321991\n",
            "loss in epoch 3/21 iteration 30/67: 1.3907407522201538 / BPR loss: 1.3857872486114502 / Matching loss: 8.028697629924864e-05 / Item reconstruction: 0.0025050744879990816 / Text reconstruction: 0.01810365542769432\n",
            "loss in epoch 3/21 iteration 31/67: 1.3908374309539795 / BPR loss: 1.3859245777130127 / Matching loss: 7.846043445169926e-05 / Item reconstruction: 0.0024737929925322533 / Text reconstruction: 0.017987674102187157\n",
            "loss in epoch 3/21 iteration 32/67: 1.390830159187317 / BPR loss: 1.3859717845916748 / Matching loss: 7.554530748166144e-05 / Item reconstruction: 0.0024168831296265125 / Text reconstruction: 0.01787184178829193\n",
            "loss in epoch 3/21 iteration 33/67: 1.390766978263855 / BPR loss: 1.3858462572097778 / Matching loss: 8.068847091635689e-05 / Item reconstruction: 0.0025919259060174227 / Text reconstruction: 0.017720337957143784\n",
            "loss in epoch 3/21 iteration 34/67: 1.3908010721206665 / BPR loss: 1.3858590126037598 / Matching loss: 8.84666369529441e-05 / Item reconstruction: 0.002809793222695589 / Text reconstruction: 0.017243869602680206\n",
            "loss in epoch 3/21 iteration 35/67: 1.3908016681671143 / BPR loss: 1.3858774900436401 / Matching loss: 7.949583959998563e-05 / Item reconstruction: 0.0027719640638679266 / Text reconstruction: 0.017293749377131462\n",
            "loss in epoch 3/21 iteration 36/67: 1.3911041021347046 / BPR loss: 1.3861685991287231 / Matching loss: 0.0001009616898954846 / Item reconstruction: 0.002756691537797451 / Text reconstruction: 0.017281439155340195\n",
            "loss in epoch 3/21 iteration 37/67: 1.3912301063537598 / BPR loss: 1.3863234519958496 / Matching loss: 0.00010066899267258123 / Item reconstruction: 0.0027017618995159864 / Text reconstruction: 0.017276056110858917\n",
            "loss in epoch 3/21 iteration 38/67: 1.3912074565887451 / BPR loss: 1.386286735534668 / Matching loss: 9.244483953807503e-05 / Item reconstruction: 0.002824957948178053 / Text reconstruction: 0.01707918383181095\n",
            "loss in epoch 3/21 iteration 39/67: 1.3910545110702515 / BPR loss: 1.3862406015396118 / Matching loss: 8.743668149691075e-05 / Item reconstruction: 0.0026060668751597404 / Text reconstruction: 0.017117269337177277\n",
            "loss in epoch 3/21 iteration 40/67: 1.3911486864089966 / BPR loss: 1.3863334655761719 / Matching loss: 9.52421105466783e-05 / Item reconstruction: 0.0026813996955752373 / Text reconstruction: 0.016896190121769905\n",
            "loss in epoch 3/21 iteration 41/67: 1.3909056186676025 / BPR loss: 1.3860927820205688 / Matching loss: 8.663692278787494e-05 / Item reconstruction: 0.0026360461488366127 / Text reconstruction: 0.017040781676769257\n",
            "loss in epoch 3/21 iteration 42/67: 1.390566349029541 / BPR loss: 1.3856830596923828 / Matching loss: 7.200604886747897e-05 / Item reconstruction: 0.002573614474385977 / Text reconstruction: 0.017621954903006554\n",
            "loss in epoch 3/21 iteration 43/67: 1.390578031539917 / BPR loss: 1.3857239484786987 / Matching loss: 7.141559763113037e-05 / Item reconstruction: 0.0025232143234461546 / Text reconstruction: 0.017605707049369812\n",
            "loss in epoch 3/21 iteration 44/67: 1.3908451795578003 / BPR loss: 1.3862574100494385 / Matching loss: 9.581753693055362e-05 / Item reconstruction: 0.002387064741924405 / Text reconstruction: 0.016491724178195\n",
            "loss in epoch 3/21 iteration 45/67: 1.3907750844955444 / BPR loss: 1.3863098621368408 / Matching loss: 9.269991278415546e-05 / Item reconstruction: 0.0022159237414598465 / Text reconstruction: 0.016322962939739227\n",
            "loss in epoch 3/21 iteration 46/67: 1.390697956085205 / BPR loss: 1.3862242698669434 / Matching loss: 9.428831981495023e-05 / Item reconstruction: 0.0022896635346114635 / Text reconstruction: 0.01617254689335823\n",
            "loss in epoch 3/21 iteration 47/67: 1.3906854391098022 / BPR loss: 1.3862402439117432 / Matching loss: 8.881509711500257e-05 / Item reconstruction: 0.0022860895842313766 / Text reconstruction: 0.01606624759733677\n",
            "loss in epoch 3/21 iteration 48/67: 1.3906339406967163 / BPR loss: 1.3862171173095703 / Matching loss: 8.756833267398179e-05 / Item reconstruction: 0.002262976486235857 / Text reconstruction: 0.01598864048719406\n",
            "loss in epoch 3/21 iteration 49/67: 1.3908568620681763 / BPR loss: 1.386403203010559 / Matching loss: 8.73305689310655e-05 / Item reconstruction: 0.0023125912994146347 / Text reconstruction: 0.016050007194280624\n",
            "loss in epoch 3/21 iteration 50/67: 1.3907643556594849 / BPR loss: 1.3863496780395508 / Matching loss: 8.529771002940834e-05 / Item reconstruction: 0.002308250404894352 / Text reconstruction: 0.0158759206533432\n",
            "loss in epoch 3/21 iteration 51/67: 1.3905688524246216 / BPR loss: 1.3862597942352295 / Matching loss: 9.069532825378701e-05 / Item reconstruction: 0.0021406253799796104 / Text reconstruction: 0.01574036106467247\n",
            "loss in epoch 3/21 iteration 52/67: 1.390579342842102 / BPR loss: 1.3862299919128418 / Matching loss: 9.063267498277128e-05 / Item reconstruction: 0.0022464003413915634 / Text reconstruction: 0.015677906572818756\n",
            "loss in epoch 3/21 iteration 53/67: 1.3905601501464844 / BPR loss: 1.3862295150756836 / Matching loss: 9.086591308005154e-05 / Item reconstruction: 0.0021676640026271343 / Text reconstruction: 0.015779506415128708\n",
            "loss in epoch 3/21 iteration 54/67: 1.3905556201934814 / BPR loss: 1.386333703994751 / Matching loss: 9.174534352496266e-05 / Item reconstruction: 0.0020096134394407272 / Text reconstruction: 0.015626315027475357\n",
            "loss in epoch 3/21 iteration 55/67: 1.3904470205307007 / BPR loss: 1.3862346410751343 / Matching loss: 9.017858246807009e-05 / Item reconstruction: 0.002013855380937457 / Text reconstruction: 0.015576292760670185\n",
            "loss in epoch 3/21 iteration 56/67: 1.390472412109375 / BPR loss: 1.3862367868423462 / Matching loss: 8.475211507175118e-05 / Item reconstruction: 0.0021359678357839584 / Text reconstruction: 0.015414601191878319\n",
            "loss in epoch 3/21 iteration 57/67: 1.3904943466186523 / BPR loss: 1.3862853050231934 / Matching loss: 8.32453224575147e-05 / Item reconstruction: 0.0020496249198913574 / Text reconstruction: 0.015504742041230202\n",
            "loss in epoch 3/21 iteration 58/67: 1.3904132843017578 / BPR loss: 1.3863074779510498 / Matching loss: 7.55772489355877e-05 / Item reconstruction: 0.0019132099114358425 / Text reconstruction: 0.015368017368018627\n",
            "loss in epoch 3/21 iteration 59/67: 1.3903789520263672 / BPR loss: 1.3862717151641846 / Matching loss: 8.133066876325756e-05 / Item reconstruction: 0.0019945227541029453 / Text reconstruction: 0.015142912045121193\n",
            "loss in epoch 3/21 iteration 60/67: 1.3902541399002075 / BPR loss: 1.3861987590789795 / Matching loss: 8.097863610601053e-05 / Item reconstruction: 0.0019112691516056657 / Text reconstruction: 0.015093987807631493\n",
            "loss in epoch 3/21 iteration 61/67: 1.3903194665908813 / BPR loss: 1.3862801790237427 / Matching loss: 8.33127778605558e-05 / Item reconstruction: 0.0018984172493219376 / Text reconstruction: 0.015033569186925888\n",
            "loss in epoch 3/21 iteration 62/67: 1.3901026248931885 / BPR loss: 1.3861515522003174 / Matching loss: 7.842059130780399e-05 / Item reconstruction: 0.0017654343973845243 / Text reconstruction: 0.014949553646147251\n",
            "loss in epoch 3/21 iteration 63/67: 1.390408992767334 / BPR loss: 1.3862768411636353 / Matching loss: 9.130255784839392e-05 / Item reconstruction: 0.0021793232299387455 / Text reconstruction: 0.01475561410188675\n",
            "loss in epoch 3/21 iteration 64/67: 1.3903063535690308 / BPR loss: 1.3862955570220947 / Matching loss: 8.270111720776185e-05 / Item reconstruction: 0.0019924375228583813 / Text reconstruction: 0.014659225940704346\n",
            "loss in epoch 3/21 iteration 65/67: 1.3902994394302368 / BPR loss: 1.3862950801849365 / Matching loss: 8.212824468500912e-05 / Item reconstruction: 0.001979989465326071 / Text reconstruction: 0.014661013148725033\n",
            "loss in epoch 3/21 iteration 66/67: 1.390036702156067 / BPR loss: 1.3862714767456055 / Matching loss: 6.792900967411697e-05 / Item reconstruction: 0.0014751198468729854 / Text reconstruction: 0.014798504300415516\n",
            "loss in epoch 3/21 iteration 67/67: 1.390023946762085 / BPR loss: 1.3863189220428467 / Matching loss: 6.260503141675144e-05 / Item reconstruction: 0.001372313592582941 / Text reconstruction: 0.014781545847654343\n",
            " 15% 3/20 [05:51<33:24, 117.89s/it]loss in epoch 4/21 iteration 0/67: 1.390364170074463 / BPR loss: 1.3862435817718506 / Matching loss: 8.553866064175963e-05 / Item reconstruction: 0.002364122774451971 / Text reconstruction: 0.014264597557485104\n",
            "loss in epoch 4/21 iteration 1/67: 1.3903383016586304 / BPR loss: 1.386035680770874 / Matching loss: 7.507720147259533e-05 / Item reconstruction: 0.002497133333235979 / Text reconstruction: 0.014894692227244377\n",
            "loss in epoch 4/21 iteration 2/67: 1.3902708292007446 / BPR loss: 1.3857237100601196 / Matching loss: 7.226690649986267e-05 / Item reconstruction: 0.0028050679247826338 / Text reconstruction: 0.015361681580543518\n",
            "loss in epoch 4/21 iteration 3/67: 1.390112280845642 / BPR loss: 1.385632872581482 / Matching loss: 6.824942101957276e-05 / Item reconstruction: 0.0026844008825719357 / Text reconstruction: 0.015344899147748947\n",
            "loss in epoch 4/21 iteration 4/67: 1.3901187181472778 / BPR loss: 1.3856877088546753 / Matching loss: 6.689557631034404e-05 / Item reconstruction: 0.002706032246351242 / Text reconstruction: 0.015055806376039982\n",
            "loss in epoch 4/21 iteration 5/67: 1.3899667263031006 / BPR loss: 1.3856141567230225 / Matching loss: 6.794519140385091e-05 / Item reconstruction: 0.0026019555516541004 / Text reconstruction: 0.014918539673089981\n",
            "loss in epoch 4/21 iteration 6/67: 1.3898329734802246 / BPR loss: 1.3855769634246826 / Matching loss: 6.586330709978938e-05 / Item reconstruction: 0.0024787774309515953 / Text reconstruction: 0.014753492549061775\n",
            "loss in epoch 4/21 iteration 7/67: 1.389870285987854 / BPR loss: 1.385664463043213 / Matching loss: 6.65883781039156e-05 / Item reconstruction: 0.0024642457719892263 / Text reconstruction: 0.014535014517605305\n",
            "loss in epoch 4/21 iteration 8/67: 1.3897316455841064 / BPR loss: 1.3856000900268555 / Matching loss: 6.126100925030187e-05 / Item reconstruction: 0.0023252638056874275 / Text reconstruction: 0.014538202434778214\n",
            "loss in epoch 4/21 iteration 9/67: 1.3895882368087769 / BPR loss: 1.3855611085891724 / Matching loss: 6.056195707060397e-05 / Item reconstruction: 0.002197656547650695 / Text reconstruction: 0.014338783919811249\n",
            "loss in epoch 4/21 iteration 10/67: 1.3896522521972656 / BPR loss: 1.3856018781661987 / Matching loss: 6.0447149735409766e-05 / Item reconstruction: 0.0022737449035048485 / Text reconstruction: 0.01426502875983715\n",
            "loss in epoch 4/21 iteration 11/67: 1.3894822597503662 / BPR loss: 1.3855233192443848 / Matching loss: 6.0524595028255135e-05 / Item reconstruction: 0.0021545474883168936 / Text reconstruction: 0.014105263166129589\n",
            "loss in epoch 4/21 iteration 12/67: 1.3896123170852661 / BPR loss: 1.3856810331344604 / Matching loss: 6.43592793494463e-05 / Item reconstruction: 0.002121579833328724 / Text reconstruction: 0.01403006911277771\n",
            "loss in epoch 4/21 iteration 13/67: 1.3895100355148315 / BPR loss: 1.3855862617492676 / Matching loss: 6.338847015285864e-05 / Item reconstruction: 0.002115898299962282 / Text reconstruction: 0.014011567458510399\n",
            "loss in epoch 4/21 iteration 14/67: 1.3895089626312256 / BPR loss: 1.3856005668640137 / Matching loss: 6.396167009370402e-05 / Item reconstruction: 0.002110445639118552 / Text reconstruction: 0.01394568756222725\n",
            "loss in epoch 4/21 iteration 15/67: 1.3894306421279907 / BPR loss: 1.3855271339416504 / Matching loss: 6.119140743976459e-05 / Item reconstruction: 0.0021169809624552727 / Text reconstruction: 0.013919606804847717\n",
            "loss in epoch 4/21 iteration 16/67: 1.389278531074524 / BPR loss: 1.3854540586471558 / Matching loss: 6.172979192342609e-05 / Item reconstruction: 0.002006014110520482 / Text reconstruction: 0.013798190280795097\n",
            "loss in epoch 4/21 iteration 17/67: 1.3893482685089111 / BPR loss: 1.3855417966842651 / Matching loss: 6.0654976550722495e-05 / Item reconstruction: 0.002010995289310813 / Text reconstruction: 0.013701410964131355\n",
            "loss in epoch 4/21 iteration 18/67: 1.3903981447219849 / BPR loss: 1.3862278461456299 / Matching loss: 7.424581417581066e-05 / Item reconstruction: 0.0026190890930593014 / Text reconstruction: 0.013932568952441216\n",
            "loss in epoch 4/21 iteration 19/67: 1.3905664682388306 / BPR loss: 1.3862121105194092 / Matching loss: 7.848028326407075e-05 / Item reconstruction: 0.0029174615629017353 / Text reconstruction: 0.014085670001804829\n",
            "loss in epoch 4/21 iteration 20/67: 1.390505075454712 / BPR loss: 1.3862786293029785 / Matching loss: 7.569607987534255e-05 / Item reconstruction: 0.0026969497557729483 / Text reconstruction: 0.014011168852448463\n",
            "loss in epoch 4/21 iteration 21/67: 1.3905558586120605 / BPR loss: 1.3862848281860352 / Matching loss: 8.034837082959712e-05 / Item reconstruction: 0.0028897495940327644 / Text reconstruction: 0.013729432597756386\n",
            "loss in epoch 4/21 iteration 22/67: 1.3899366855621338 / BPR loss: 1.3856276273727417 / Matching loss: 6.65627303533256e-05 / Item reconstruction: 0.0029290011152625084 / Text reconstruction: 0.013890537433326244\n",
            "loss in epoch 4/21 iteration 23/67: 1.3899884223937988 / BPR loss: 1.3857388496398926 / Matching loss: 6.806811143178493e-05 / Item reconstruction: 0.002809569239616394 / Text reconstruction: 0.013883581385016441\n",
            "loss in epoch 4/21 iteration 24/67: 1.3899099826812744 / BPR loss: 1.3857038021087646 / Matching loss: 6.672330346191302e-05 / Item reconstruction: 0.0027932876255363226 / Text reconstruction: 0.013713868334889412\n",
            "loss in epoch 4/21 iteration 25/67: 1.389816164970398 / BPR loss: 1.3856360912322998 / Matching loss: 6.87858191668056e-05 / Item reconstruction: 0.002811543643474579 / Text reconstruction: 0.013527624309062958\n",
            "loss in epoch 4/21 iteration 26/67: 1.3897333145141602 / BPR loss: 1.3856611251831055 / Matching loss: 6.439450953621417e-05 / Item reconstruction: 0.0026559862308204174 / Text reconstruction: 0.013399221003055573\n",
            "loss in epoch 4/21 iteration 27/67: 1.3896136283874512 / BPR loss: 1.3856065273284912 / Matching loss: 6.228071288205683e-05 / Item reconstruction: 0.0025325599126517773 / Text reconstruction: 0.013393132016062737\n",
            "loss in epoch 4/21 iteration 28/67: 1.3897514343261719 / BPR loss: 1.385742425918579 / Matching loss: 6.336059595923871e-05 / Item reconstruction: 0.002558935433626175 / Text reconstruction: 0.013330765999853611\n",
            "loss in epoch 4/21 iteration 29/67: 1.3894728422164917 / BPR loss: 1.385569453239441 / Matching loss: 6.206124817254022e-05 / Item reconstruction: 0.002418090356513858 / Text reconstruction: 0.013161404058337212\n",
            "loss in epoch 4/21 iteration 30/67: 1.3894065618515015 / BPR loss: 1.3855628967285156 / Matching loss: 6.0227466747164726e-05 / Item reconstruction: 0.0023316589649766684 / Text reconstruction: 0.013087727129459381\n",
            "loss in epoch 4/21 iteration 31/67: 1.3895304203033447 / BPR loss: 1.3857641220092773 / Matching loss: 5.9039237385150045e-05 / Item reconstruction: 0.0022175090853124857 / Text reconstruction: 0.012992342002689838\n",
            "loss in epoch 4/21 iteration 32/67: 1.3893189430236816 / BPR loss: 1.3855845928192139 / Matching loss: 5.876453360542655e-05 / Item reconstruction: 0.0021814038045704365 / Text reconstruction: 0.012924833223223686\n",
            "loss in epoch 4/21 iteration 33/67: 1.3896015882492065 / BPR loss: 1.385682463645935 / Matching loss: 7.143699622247368e-05 / Item reconstruction: 0.0025418675504624844 / Text reconstruction: 0.012884354218840599\n",
            "loss in epoch 4/21 iteration 34/67: 1.3895655870437622 / BPR loss: 1.3857132196426392 / Matching loss: 7.281229773070663e-05 / Item reconstruction: 0.0026508211158216 / Text reconstruction: 0.012270929291844368\n",
            "loss in epoch 4/21 iteration 35/67: 1.3896089792251587 / BPR loss: 1.385748028755188 / Matching loss: 6.703291728626937e-05 / Item reconstruction: 0.0026168692857027054 / Text reconstruction: 0.01242786180227995\n",
            "loss in epoch 4/21 iteration 36/67: 1.3900206089019775 / BPR loss: 1.3861020803451538 / Matching loss: 8.69619834702462e-05 / Item reconstruction: 0.0027048620395362377 / Text reconstruction: 0.012396177276968956\n",
            "loss in epoch 4/21 iteration 37/67: 1.3902337551116943 / BPR loss: 1.3863024711608887 / Matching loss: 7.981929229572415e-05 / Item reconstruction: 0.0027270889841020107 / Text reconstruction: 0.01243951078504324\n",
            "loss in epoch 4/21 iteration 38/67: 1.3901289701461792 / BPR loss: 1.3862240314483643 / Matching loss: 7.838915917091072e-05 / Item reconstruction: 0.002720384392887354 / Text reconstruction: 0.012331889942288399\n",
            "loss in epoch 4/21 iteration 39/67: 1.3899871110916138 / BPR loss: 1.3861697912216187 / Matching loss: 7.705896132392809e-05 / Item reconstruction: 0.002610278781503439 / Text reconstruction: 0.012175862677395344\n",
            "loss in epoch 4/21 iteration 40/67: 1.390067219734192 / BPR loss: 1.3863131999969482 / Matching loss: 8.821365190669894e-05 / Item reconstruction: 0.002564640250056982 / Text reconstruction: 0.011917554773390293\n",
            "loss in epoch 4/21 iteration 41/67: 1.3898005485534668 / BPR loss: 1.3859745264053345 / Matching loss: 8.16487445263192e-05 / Item reconstruction: 0.002619183622300625 / Text reconstruction: 0.012173505499958992\n",
            "loss in epoch 4/21 iteration 42/67: 1.389402985572815 / BPR loss: 1.3854987621307373 / Matching loss: 6.36198092252016e-05 / Item reconstruction: 0.0025221374817192554 / Text reconstruction: 0.012897329404950142\n",
            "loss in epoch 4/21 iteration 43/67: 1.389303207397461 / BPR loss: 1.3853142261505127 / Matching loss: 6.205363024491817e-05 / Item reconstruction: 0.0026099563110619783 / Text reconstruction: 0.013109270483255386\n",
            "loss in epoch 4/21 iteration 44/67: 1.389696717262268 / BPR loss: 1.3861351013183594 / Matching loss: 8.132661605486646e-05 / Item reconstruction: 0.0022913904394954443 / Text reconstruction: 0.011672927998006344\n",
            "loss in epoch 4/21 iteration 45/67: 1.3896442651748657 / BPR loss: 1.3862438201904297 / Matching loss: 7.313130481634289e-05 / Item reconstruction: 0.00206321501173079 / Text reconstruction: 0.011478867381811142\n",
            "loss in epoch 4/21 iteration 46/67: 1.389695405960083 / BPR loss: 1.3861896991729736 / Matching loss: 8.239215094363317e-05 / Item reconstruction: 0.002338648308068514 / Text reconstruction: 0.011270198971033096\n",
            "loss in epoch 4/21 iteration 47/67: 1.3897340297698975 / BPR loss: 1.386297583580017 / Matching loss: 7.655014633201063e-05 / Item reconstruction: 0.002248567994683981 / Text reconstruction: 0.0111785177141428\n",
            "loss in epoch 4/21 iteration 48/67: 1.3895410299301147 / BPR loss: 1.3861422538757324 / Matching loss: 7.714862294960767e-05 / Item reconstruction: 0.0021666944958269596 / Text reconstruction: 0.011191188357770443\n",
            "loss in epoch 4/21 iteration 49/67: 1.389723539352417 / BPR loss: 1.3862507343292236 / Matching loss: 7.816986908437684e-05 / Item reconstruction: 0.0022993753664195538 / Text reconstruction: 0.011224960908293724\n",
            "loss in epoch 4/21 iteration 50/67: 1.3896992206573486 / BPR loss: 1.3862617015838623 / Matching loss: 7.877174357417971e-05 / Item reconstruction: 0.002273701597005129 / Text reconstruction: 0.011108852922916412\n",
            "loss in epoch 4/21 iteration 51/67: 1.3896509408950806 / BPR loss: 1.3862824440002441 / Matching loss: 8.291083213407546e-05 / Item reconstruction: 0.002119948621839285 / Text reconstruction: 0.011127575300633907\n",
            "loss in epoch 4/21 iteration 52/67: 1.38947331905365 / BPR loss: 1.3861252069473267 / Matching loss: 7.863294740673155e-05 / Item reconstruction: 0.0021791872568428516 / Text reconstruction: 0.010899046435952187\n",
            "loss in epoch 4/21 iteration 53/67: 1.3895654678344727 / BPR loss: 1.3862037658691406 / Matching loss: 7.812313560862094e-05 / Item reconstruction: 0.0021419404074549675 / Text reconstruction: 0.0110631687566638\n",
            "loss in epoch 4/21 iteration 54/67: 1.3895890712738037 / BPR loss: 1.3863474130630493 / Matching loss: 7.742062007309869e-05 / Item reconstruction: 0.0019490576814860106 / Text reconstruction: 0.010948536917567253\n",
            "loss in epoch 4/21 iteration 55/67: 1.389639973640442 / BPR loss: 1.386357069015503 / Matching loss: 7.605009886901826e-05 / Item reconstruction: 0.0020107640884816647 / Text reconstruction: 0.011007123626768589\n",
            "loss in epoch 4/21 iteration 56/67: 1.3895050287246704 / BPR loss: 1.3862030506134033 / Matching loss: 7.346703205257654e-05 / Item reconstruction: 0.002116687595844269 / Text reconstruction: 0.010851267725229263\n",
            "loss in epoch 4/21 iteration 57/67: 1.3894866704940796 / BPR loss: 1.386231780052185 / Matching loss: 7.266255852300674e-05 / Item reconstruction: 0.0020365857053548098 / Text reconstruction: 0.010819308459758759\n",
            "loss in epoch 4/21 iteration 58/67: 1.389507532119751 / BPR loss: 1.38631010055542 / Matching loss: 7.057607581373304e-05 / Item reconstruction: 0.0019409367814660072 / Text reconstruction: 0.010781900957226753\n",
            "loss in epoch 4/21 iteration 59/67: 1.3894680738449097 / BPR loss: 1.3862698078155518 / Matching loss: 7.636229565832764e-05 / Item reconstruction: 0.0019835683051496744 / Text reconstruction: 0.010649880394339561\n",
            "loss in epoch 4/21 iteration 60/67: 1.3894482851028442 / BPR loss: 1.3862736225128174 / Matching loss: 7.567883585579693e-05 / Item reconstruction: 0.0019500049529597163 / Text reconstruction: 0.010619486682116985\n",
            "loss in epoch 4/21 iteration 61/67: 1.389412760734558 / BPR loss: 1.3862957954406738 / Matching loss: 7.228396134451032e-05 / Item reconstruction: 0.001875746645964682 / Text reconstruction: 0.010534550994634628\n",
            "loss in epoch 4/21 iteration 62/67: 1.3891961574554443 / BPR loss: 1.3861111402511597 / Matching loss: 6.361280975397676e-05 / Item reconstruction: 0.0018129078671336174 / Text reconstruction: 0.01057430449873209\n",
            "loss in epoch 4/21 iteration 63/67: 1.3894538879394531 / BPR loss: 1.3862199783325195 / Matching loss: 7.927567639853805e-05 / Item reconstruction: 0.002167265862226486 / Text reconstruction: 0.0103549063205719\n",
            "loss in epoch 4/21 iteration 64/67: 1.3893952369689941 / BPR loss: 1.3862988948822021 / Matching loss: 7.357537106145173e-05 / Item reconstruction: 0.001928321085870266 / Text reconstruction: 0.0102929025888443\n",
            "loss in epoch 4/21 iteration 65/67: 1.3894257545471191 / BPR loss: 1.3863394260406494 / Matching loss: 7.193064811872318e-05 / Item reconstruction: 0.0018919873982667923 / Text reconstruction: 0.0103420065715909\n",
            "loss in epoch 4/21 iteration 66/67: 1.389229655265808 / BPR loss: 1.386298418045044 / Matching loss: 6.369926268234849e-05 / Item reconstruction: 0.0015939853619784117 / Text reconstruction: 0.010352713987231255\n",
            "loss in epoch 4/21 iteration 67/67: 1.3890414237976074 / BPR loss: 1.3862731456756592 / Matching loss: 5.723705544369295e-05 / Item reconstruction: 0.0012942318571731448 / Text reconstruction: 0.010319789871573448\n",
            " 20% 4/20 [07:54<31:55, 119.71s/it]loss in epoch 5/21 iteration 0/67: 1.3895435333251953 / BPR loss: 1.3862950801849365 / Matching loss: 7.961357187014073e-05 / Item reconstruction: 0.002339543541893363 / Text reconstruction: 0.00999487191438675\n",
            "loss in epoch 5/21 iteration 1/67: 1.3893530368804932 / BPR loss: 1.3858697414398193 / Matching loss: 6.57403506920673e-05 / Item reconstruction: 0.0024818952661007643 / Text reconstruction: 0.010883273556828499\n",
            "loss in epoch 5/21 iteration 2/67: 1.3891972303390503 / BPR loss: 1.3854553699493408 / Matching loss: 6.37376942904666e-05 / Item reconstruction: 0.002746765036135912 / Text reconstruction: 0.011523662135004997\n",
            "loss in epoch 5/21 iteration 3/67: 1.3889541625976562 / BPR loss: 1.385326623916626 / Matching loss: 6.122184277046472e-05 / Item reconstruction: 0.0026468101423233747 / Text reconstruction: 0.011213753372430801\n",
            "loss in epoch 5/21 iteration 4/67: 1.3889048099517822 / BPR loss: 1.3853065967559814 / Matching loss: 6.21577346464619e-05 / Item reconstruction: 0.002711996901780367 / Text reconstruction: 0.010900282301008701\n",
            "loss in epoch 5/21 iteration 5/67: 1.3888062238693237 / BPR loss: 1.385329008102417 / Matching loss: 5.912676715524867e-05 / Item reconstruction: 0.0025157411582767963 / Text reconstruction: 0.010800901800394058\n",
            "loss in epoch 5/21 iteration 6/67: 1.3888967037200928 / BPR loss: 1.3854448795318604 / Matching loss: 6.0450140153989196e-05 / Item reconstruction: 0.0024695578031241894 / Text reconstruction: 0.010783189907670021\n",
            "loss in epoch 5/21 iteration 7/67: 1.3886427879333496 / BPR loss: 1.3852295875549316 / Matching loss: 5.956031964160502e-05 / Item reconstruction: 0.002428849460557103 / Text reconstruction: 0.01069581788033247\n",
            "loss in epoch 5/21 iteration 8/67: 1.3883968591690063 / BPR loss: 1.385133981704712 / Matching loss: 5.542306462302804e-05 / Item reconstruction: 0.0022432045079767704 / Text reconstruction: 0.010428998619318008\n",
            "loss in epoch 5/21 iteration 9/67: 1.388495683670044 / BPR loss: 1.385329246520996 / Matching loss: 5.569432323682122e-05 / Item reconstruction: 0.0021497351117432117 / Text reconstruction: 0.01017957367002964\n",
            "loss in epoch 5/21 iteration 10/67: 1.3882694244384766 / BPR loss: 1.3851101398468018 / Matching loss: 5.308574691298418e-05 / Item reconstruction: 0.0021262113004922867 / Text reconstruction: 0.010215820744633675\n",
            "loss in epoch 5/21 iteration 11/67: 1.3884071111679077 / BPR loss: 1.3852514028549194 / Matching loss: 5.711818812415004e-05 / Item reconstruction: 0.002094084629788995 / Text reconstruction: 0.01025802455842495\n",
            "loss in epoch 5/21 iteration 12/67: 1.38833487033844 / BPR loss: 1.3852250576019287 / Matching loss: 5.858447912032716e-05 / Item reconstruction: 0.0020394851453602314 / Text reconstruction: 0.010157923214137554\n",
            "loss in epoch 5/21 iteration 13/67: 1.3882821798324585 / BPR loss: 1.3851861953735352 / Matching loss: 5.510656046681106e-05 / Item reconstruction: 0.002032260177657008 / Text reconstruction: 0.010124079883098602\n",
            "loss in epoch 5/21 iteration 14/67: 1.388356328010559 / BPR loss: 1.3852331638336182 / Matching loss: 5.8775538491318e-05 / Item reconstruction: 0.0020529101602733135 / Text reconstruction: 0.010189559310674667\n",
            "loss in epoch 5/21 iteration 15/67: 1.3882859945297241 / BPR loss: 1.3852025270462036 / Matching loss: 5.301309283822775e-05 / Item reconstruction: 0.0019792914390563965 / Text reconstruction: 0.010203790850937366\n",
            "loss in epoch 5/21 iteration 16/67: 1.388012170791626 / BPR loss: 1.384972333908081 / Matching loss: 5.147521733306348e-05 / Item reconstruction: 0.0019816251005977392 / Text reconstruction: 0.009987285360693932\n",
            "loss in epoch 5/21 iteration 17/67: 1.3883823156356812 / BPR loss: 1.3853788375854492 / Matching loss: 5.267629603622481e-05 / Item reconstruction: 0.0019457918824627995 / Text reconstruction: 0.009889347478747368\n",
            "loss in epoch 5/21 iteration 18/67: 1.389413833618164 / BPR loss: 1.3859405517578125 / Matching loss: 6.733674672432244e-05 / Item reconstruction: 0.0026643495075404644 / Text reconstruction: 0.010368721559643745\n",
            "loss in epoch 5/21 iteration 19/67: 1.3899589776992798 / BPR loss: 1.386275053024292 / Matching loss: 7.157645450206473e-05 / Item reconstruction: 0.0029913638718426228 / Text reconstruction: 0.010583588853478432\n",
            "loss in epoch 5/21 iteration 20/67: 1.3897885084152222 / BPR loss: 1.3862669467926025 / Matching loss: 6.930150266271085e-05 / Item reconstruction: 0.0027715396136045456 / Text reconstruction: 0.0103325005620718\n",
            "loss in epoch 5/21 iteration 21/67: 1.3897836208343506 / BPR loss: 1.3862545490264893 / Matching loss: 7.35500143491663e-05 / Item reconstruction: 0.002884447108954191 / Text reconstruction: 0.010066449642181396\n",
            "loss in epoch 5/21 iteration 22/67: 1.389007329940796 / BPR loss: 1.385274887084961 / Matching loss: 6.187499820953235e-05 / Item reconstruction: 0.0031741084530949593 / Text reconstruction: 0.010417550802230835\n",
            "loss in epoch 5/21 iteration 23/67: 1.388897180557251 / BPR loss: 1.3853750228881836 / Matching loss: 5.945906013948843e-05 / Item reconstruction: 0.0028888958040624857 / Text reconstruction: 0.010091036558151245\n",
            "loss in epoch 5/21 iteration 24/67: 1.388945460319519 / BPR loss: 1.3854460716247559 / Matching loss: 5.8928759244736284e-05 / Item reconstruction: 0.0029015582986176014 / Text reconstruction: 0.009948554448783398\n",
            "loss in epoch 5/21 iteration 25/67: 1.3887691497802734 / BPR loss: 1.3853709697723389 / Matching loss: 5.697310189134441e-05 / Item reconstruction: 0.0027317095082253218 / Text reconstruction: 0.009876243770122528\n",
            "loss in epoch 5/21 iteration 26/67: 1.3887052536010742 / BPR loss: 1.38539719581604 / Matching loss: 5.348114063963294e-05 / Item reconstruction: 0.0026013157330453396 / Text reconstruction: 0.00976899266242981\n",
            "loss in epoch 5/21 iteration 27/67: 1.3884106874465942 / BPR loss: 1.3851895332336426 / Matching loss: 5.417308784672059e-05 / Item reconstruction: 0.0024849551264196634 / Text reconstruction: 0.009622488170862198\n",
            "loss in epoch 5/21 iteration 28/67: 1.3885380029678345 / BPR loss: 1.3853771686553955 / Matching loss: 5.541097925743088e-05 / Item reconstruction: 0.002416976960375905 / Text reconstruction: 0.009484484791755676\n",
            "loss in epoch 5/21 iteration 29/67: 1.3885691165924072 / BPR loss: 1.3854221105575562 / Matching loss: 5.697779852198437e-05 / Item reconstruction: 0.0023794067092239857 / Text reconstruction: 0.009501848369836807\n",
            "loss in epoch 5/21 iteration 30/67: 1.3883869647979736 / BPR loss: 1.385330080986023 / Matching loss: 5.215923738433048e-05 / Item reconstruction: 0.0021954067051410675 / Text reconstruction: 0.009535038843750954\n",
            "loss in epoch 5/21 iteration 31/67: 1.3881494998931885 / BPR loss: 1.3851553201675415 / Matching loss: 5.111346035846509e-05 / Item reconstruction: 0.002177717862650752 / Text reconstruction: 0.009270859882235527\n",
            "loss in epoch 5/21 iteration 32/67: 1.3881109952926636 / BPR loss: 1.3851897716522217 / Matching loss: 5.186864291317761e-05 / Item reconstruction: 0.0020792214199900627 / Text reconstruction: 0.009148972108960152\n",
            "loss in epoch 5/21 iteration 33/67: 1.3887197971343994 / BPR loss: 1.3853816986083984 / Matching loss: 6.508793740067631e-05 / Item reconstruction: 0.0027317123021930456 / Text reconstruction: 0.009535842575132847\n",
            "loss in epoch 5/21 iteration 34/67: 1.388661503791809 / BPR loss: 1.3854947090148926 / Matching loss: 6.233715248527005e-05 / Item reconstruction: 0.002703495789319277 / Text reconstruction: 0.008763527497649193\n",
            "loss in epoch 5/21 iteration 35/67: 1.3886762857437134 / BPR loss: 1.3854796886444092 / Matching loss: 5.846924977959134e-05 / Item reconstruction: 0.002676224336028099 / Text reconstruction: 0.009000526741147041\n",
            "loss in epoch 5/21 iteration 36/67: 1.3892955780029297 / BPR loss: 1.3860571384429932 / Matching loss: 7.279377314262092e-05 / Item reconstruction: 0.002781990449875593 / Text reconstruction: 0.008872779086232185\n",
            "loss in epoch 5/21 iteration 37/67: 1.3894108533859253 / BPR loss: 1.3862197399139404 / Matching loss: 6.789108738303185e-05 / Item reconstruction: 0.002691984409466386 / Text reconstruction: 0.008886130526661873\n",
            "loss in epoch 5/21 iteration 38/67: 1.3892505168914795 / BPR loss: 1.3860723972320557 / Matching loss: 6.614239100599661e-05 / Item reconstruction: 0.0027653765864670277 / Text reconstruction: 0.008646437898278236\n",
            "loss in epoch 5/21 iteration 39/67: 1.3892441987991333 / BPR loss: 1.3861613273620605 / Matching loss: 6.946115172468126e-05 / Item reconstruction: 0.002572151366621256 / Text reconstruction: 0.00863691046833992\n",
            "loss in epoch 5/21 iteration 40/67: 1.3893059492111206 / BPR loss: 1.3862643241882324 / Matching loss: 8.319660992128775e-05 / Item reconstruction: 0.002549031050875783 / Text reconstruction: 0.008420048281550407\n",
            "loss in epoch 5/21 iteration 41/67: 1.3890290260314941 / BPR loss: 1.3858375549316406 / Matching loss: 7.746242044959217e-05 / Item reconstruction: 0.0026995008811354637 / Text reconstruction: 0.008820723742246628\n",
            "loss in epoch 5/21 iteration 42/67: 1.3883304595947266 / BPR loss: 1.3851196765899658 / Matching loss: 5.331553620635532e-05 / Item reconstruction: 0.0025551598519086838 / Text reconstruction: 0.009399646893143654\n",
            "loss in epoch 5/21 iteration 43/67: 1.3881967067718506 / BPR loss: 1.3849176168441772 / Matching loss: 5.555660754907876e-05 / Item reconstruction: 0.0026986575685441494 / Text reconstruction: 0.009371280670166016\n",
            "loss in epoch 5/21 iteration 44/67: 1.388917326927185 / BPR loss: 1.3860734701156616 / Matching loss: 7.12368855602108e-05 / Item reconstruction: 0.002365824533626437 / Text reconstruction: 0.007948044687509537\n",
            "loss in epoch 5/21 iteration 45/67: 1.3889491558074951 / BPR loss: 1.3862533569335938 / Matching loss: 6.862601003376767e-05 / Item reconstruction: 0.0021212331485003233 / Text reconstruction: 0.007832702249288559\n",
            "loss in epoch 5/21 iteration 46/67: 1.3888717889785767 / BPR loss: 1.38612961769104 / Matching loss: 7.277479744516313e-05 / Item reconstruction: 0.0022791028022766113 / Text reconstruction: 0.007649713195860386\n",
            "loss in epoch 5/21 iteration 47/67: 1.3887970447540283 / BPR loss: 1.3860965967178345 / Matching loss: 6.803528231102973e-05 / Item reconstruction: 0.0022216560319066048 / Text reconstruction: 0.007608037441968918\n",
            "loss in epoch 5/21 iteration 48/67: 1.3888285160064697 / BPR loss: 1.3861314058303833 / Matching loss: 6.895478873047978e-05 / Item reconstruction: 0.0021982400212436914 / Text reconstruction: 0.007645436096936464\n",
            "loss in epoch 5/21 iteration 49/67: 1.3889352083206177 / BPR loss: 1.386216640472412 / Matching loss: 6.516159191960469e-05 / Item reconstruction: 0.002212800784036517 / Text reconstruction: 0.007734779268503189\n",
            "loss in epoch 5/21 iteration 50/67: 1.3888490200042725 / BPR loss: 1.386115312576294 / Matching loss: 6.937638681847602e-05 / Item reconstruction: 0.002269407734274864 / Text reconstruction: 0.007647748105227947\n",
            "loss in epoch 5/21 iteration 51/67: 1.3888598680496216 / BPR loss: 1.386215329170227 / Matching loss: 7.343832112383097e-05 / Item reconstruction: 0.002109637251123786 / Text reconstruction: 0.007581626530736685\n",
            "loss in epoch 5/21 iteration 52/67: 1.388898253440857 / BPR loss: 1.3862452507019043 / Matching loss: 7.02458928572014e-05 / Item reconstruction: 0.002206389792263508 / Text reconstruction: 0.0073978654108941555\n",
            "loss in epoch 5/21 iteration 53/67: 1.3886797428131104 / BPR loss: 1.3860752582550049 / Matching loss: 6.743408448528498e-05 / Item reconstruction: 0.0020667759235948324 / Text reconstruction: 0.007518201135098934\n",
            "loss in epoch 5/21 iteration 54/67: 1.3888884782791138 / BPR loss: 1.3863110542297363 / Matching loss: 7.036468014121056e-05 / Item reconstruction: 0.002043143380433321 / Text reconstruction: 0.007427209056913853\n",
            "loss in epoch 5/21 iteration 55/67: 1.3888112306594849 / BPR loss: 1.3862448930740356 / Matching loss: 6.599583139177412e-05 / Item reconstruction: 0.0020113312639296055 / Text reconstruction: 0.007473322097212076\n",
            "loss in epoch 5/21 iteration 56/67: 1.388800024986267 / BPR loss: 1.386230230331421 / Matching loss: 6.538339948747307e-05 / Item reconstruction: 0.0020941095426678658 / Text reconstruction: 0.007287179585546255\n",
            "loss in epoch 5/21 iteration 57/67: 1.3887181282043457 / BPR loss: 1.3862049579620361 / Matching loss: 6.234000466065481e-05 / Item reconstruction: 0.0019692331552505493 / Text reconstruction: 0.007330574095249176\n",
            "loss in epoch 5/21 iteration 58/67: 1.3887141942977905 / BPR loss: 1.386230707168579 / Matching loss: 6.321308319456875e-05 / Item reconstruction: 0.0019290170166641474 / Text reconstruction: 0.007279045879840851\n",
            "loss in epoch 5/21 iteration 59/67: 1.3888227939605713 / BPR loss: 1.3862824440002441 / Matching loss: 7.029641710687429e-05 / Item reconstruction: 0.002073324518278241 / Text reconstruction: 0.007166898809373379\n",
            "loss in epoch 5/21 iteration 60/67: 1.388683795928955 / BPR loss: 1.386247158050537 / Matching loss: 6.601840141229331e-05 / Item reconstruction: 0.001905590295791626 / Text reconstruction: 0.007088567595928907\n",
            "loss in epoch 5/21 iteration 61/67: 1.3886185884475708 / BPR loss: 1.3862576484680176 / Matching loss: 6.272713653743267e-05 / Item reconstruction: 0.0017763671930879354 / Text reconstruction: 0.007049985229969025\n",
            "loss in epoch 5/21 iteration 62/67: 1.3883692026138306 / BPR loss: 1.3859772682189941 / Matching loss: 5.472667908179574e-05 / Item reconstruction: 0.0018060359871014953 / Text reconstruction: 0.0071711172349750996\n",
            "loss in epoch 5/21 iteration 63/67: 1.3886911869049072 / BPR loss: 1.3862056732177734 / Matching loss: 6.665132968919352e-05 / Item reconstruction: 0.0020841537043452263 / Text reconstruction: 0.00688379118219018\n",
            "loss in epoch 5/21 iteration 64/67: 1.3887029886245728 / BPR loss: 1.3862870931625366 / Matching loss: 6.335712532745674e-05 / Item reconstruction: 0.0019707586616277695 / Text reconstruction: 0.006835948675870895\n",
            "loss in epoch 5/21 iteration 65/67: 1.3887473344802856 / BPR loss: 1.3863717317581177 / Matching loss: 6.388171459548175e-05 / Item reconstruction: 0.0018794725183397532 / Text reconstruction: 0.0068598417565226555\n",
            "loss in epoch 5/21 iteration 66/67: 1.3885010480880737 / BPR loss: 1.3863139152526855 / Matching loss: 5.616137423203327e-05 / Item reconstruction: 0.0014927645679563284 / Text reconstruction: 0.00692308833822608\n",
            "loss in epoch 5/21 iteration 67/67: 1.388385534286499 / BPR loss: 1.3863000869750977 / Matching loss: 5.103761941427365e-05 / Item reconstruction: 0.0013207111041992903 / Text reconstruction: 0.006870540790259838\n",
            " 25% 5/20 [09:54<29:55, 119.71s/it]loss in epoch 6/21 iteration 0/67: 1.388794183731079 / BPR loss: 1.3862113952636719 / Matching loss: 6.785393634345382e-05 / Item reconstruction: 0.002356116659939289 / Text reconstruction: 0.006684369873255491\n",
            "loss in epoch 6/21 iteration 1/67: 1.3883893489837646 / BPR loss: 1.3855617046356201 / Matching loss: 5.582606536336243e-05 / Item reconstruction: 0.0025224084965884686 / Text reconstruction: 0.007553010247647762\n",
            "loss in epoch 6/21 iteration 2/67: 1.388206958770752 / BPR loss: 1.385153889656067 / Matching loss: 5.2799619879806414e-05 / Item reconstruction: 0.0027378899976611137 / Text reconstruction: 0.00815640389919281\n",
            "loss in epoch 6/21 iteration 3/67: 1.3878958225250244 / BPR loss: 1.3849070072174072 / Matching loss: 5.265121581032872e-05 / Item reconstruction: 0.0026419837959110737 / Text reconstruction: 0.008075669407844543\n",
            "loss in epoch 6/21 iteration 4/67: 1.3879042863845825 / BPR loss: 1.384962797164917 / Matching loss: 5.5112886911956593e-05 / Item reconstruction: 0.0026219086721539497 / Text reconstruction: 0.00787755660712719\n",
            "loss in epoch 6/21 iteration 5/67: 1.3877160549163818 / BPR loss: 1.3848497867584229 / Matching loss: 5.599471114692278e-05 / Item reconstruction: 0.0025439411401748657 / Text reconstruction: 0.007691657170653343\n",
            "loss in epoch 6/21 iteration 6/67: 1.3877962827682495 / BPR loss: 1.3850858211517334 / Matching loss: 5.170282383915037e-05 / Item reconstruction: 0.002323226071894169 / Text reconstruction: 0.007485631387680769\n",
            "loss in epoch 6/21 iteration 7/67: 1.3876512050628662 / BPR loss: 1.38498055934906 / Matching loss: 5.032074841437861e-05 / Item reconstruction: 0.002291790209710598 / Text reconstruction: 0.007372346241027117\n",
            "loss in epoch 6/21 iteration 8/67: 1.3874646425247192 / BPR loss: 1.3848621845245361 / Matching loss: 4.7031400754349306e-05 / Item reconstruction: 0.002171966712921858 / Text reconstruction: 0.0073470063507556915\n",
            "loss in epoch 6/21 iteration 9/67: 1.3873531818389893 / BPR loss: 1.3848381042480469 / Matching loss: 4.6577188186347485e-05 / Item reconstruction: 0.002101380843669176 / Text reconstruction: 0.007088666781783104\n",
            "loss in epoch 6/21 iteration 10/67: 1.3872073888778687 / BPR loss: 1.384730577468872 / Matching loss: 4.561073728837073e-05 / Item reconstruction: 0.002046595560386777 / Text reconstruction: 0.00703921914100647\n",
            "loss in epoch 6/21 iteration 11/67: 1.3871084451675415 / BPR loss: 1.3846769332885742 / Matching loss: 4.663752770284191e-05 / Item reconstruction: 0.0019634361378848553 / Text reconstruction: 0.007015777751803398\n",
            "loss in epoch 6/21 iteration 12/67: 1.3875117301940918 / BPR loss: 1.3850502967834473 / Matching loss: 5.1601607992779464e-05 / Item reconstruction: 0.002014369238168001 / Text reconstruction: 0.007012989837676287\n",
            "loss in epoch 6/21 iteration 13/67: 1.3873032331466675 / BPR loss: 1.3848910331726074 / Matching loss: 5.286550003802404e-05 / Item reconstruction: 0.0019485538359731436 / Text reconstruction: 0.006925365421921015\n",
            "loss in epoch 6/21 iteration 14/67: 1.3870868682861328 / BPR loss: 1.3846962451934814 / Matching loss: 5.1830582378897816e-05 / Item reconstruction: 0.0019508550176396966 / Text reconstruction: 0.006817059125751257\n",
            "loss in epoch 6/21 iteration 15/67: 1.3870843648910522 / BPR loss: 1.384674310684204 / Matching loss: 4.874129081144929e-05 / Item reconstruction: 0.0019991742447018623 / Text reconstruction: 0.006808869075030088\n",
            "loss in epoch 6/21 iteration 16/67: 1.3869749307632446 / BPR loss: 1.3846607208251953 / Matching loss: 4.538780194707215e-05 / Item reconstruction: 0.0018488778732717037 / Text reconstruction: 0.006721634417772293\n",
            "loss in epoch 6/21 iteration 17/67: 1.387237548828125 / BPR loss: 1.384962558746338 / Matching loss: 4.189696483081207e-05 / Item reconstruction: 0.0018048067577183247 / Text reconstruction: 0.006653684191405773\n",
            "loss in epoch 6/21 iteration 18/67: 1.3888745307922363 / BPR loss: 1.3860126733779907 / Matching loss: 5.85688540013507e-05 / Item reconstruction: 0.00273907370865345 / Text reconstruction: 0.0071688322350382805\n",
            "loss in epoch 6/21 iteration 19/67: 1.3893487453460693 / BPR loss: 1.3862628936767578 / Matching loss: 6.175076123327017e-05 / Item reconstruction: 0.0029900255613029003 / Text reconstruction: 0.0076457429677248\n",
            "loss in epoch 6/21 iteration 20/67: 1.389101266860962 / BPR loss: 1.386143445968628 / Matching loss: 6.471600499935448e-05 / Item reconstruction: 0.002800930757075548 / Text reconstruction: 0.007462996989488602\n",
            "loss in epoch 6/21 iteration 21/67: 1.3890222311019897 / BPR loss: 1.3861126899719238 / Matching loss: 6.8111032305751e-05 / Item reconstruction: 0.0029382240027189255 / Text reconstruction: 0.006861510220915079\n",
            "loss in epoch 6/21 iteration 22/67: 1.3881349563598633 / BPR loss: 1.3850817680358887 / Matching loss: 5.253595008980483e-05 / Item reconstruction: 0.0030992641113698483 / Text reconstruction: 0.007255013566464186\n",
            "loss in epoch 6/21 iteration 23/67: 1.3878837823867798 / BPR loss: 1.3849592208862305 / Matching loss: 5.064898869022727e-05 / Item reconstruction: 0.002841761102899909 / Text reconstruction: 0.007265379186719656\n",
            "loss in epoch 6/21 iteration 24/67: 1.3878470659255981 / BPR loss: 1.3849575519561768 / Matching loss: 5.02782131661661e-05 / Item reconstruction: 0.002843031892552972 / Text reconstruction: 0.007088053971529007\n",
            "loss in epoch 6/21 iteration 25/67: 1.3877580165863037 / BPR loss: 1.3850146532058716 / Matching loss: 4.8538837290834635e-05 / Item reconstruction: 0.0026521305553615093 / Text reconstruction: 0.00684386258944869\n",
            "loss in epoch 6/21 iteration 26/67: 1.387819528579712 / BPR loss: 1.385098934173584 / Matching loss: 5.0470967835281044e-05 / Item reconstruction: 0.002628093119710684 / Text reconstruction: 0.006780372001230717\n",
            "loss in epoch 6/21 iteration 27/67: 1.3874324560165405 / BPR loss: 1.384778618812561 / Matching loss: 4.8172434617299587e-05 / Item reconstruction: 0.002499396214261651 / Text reconstruction: 0.006780274212360382\n",
            "loss in epoch 6/21 iteration 28/67: 1.3874711990356445 / BPR loss: 1.3849557638168335 / Matching loss: 4.438840915099718e-05 / Item reconstruction: 0.0023310512769967318 / Text reconstruction: 0.006527815014123917\n",
            "loss in epoch 6/21 iteration 29/67: 1.3874484300613403 / BPR loss: 1.3849618434906006 / Matching loss: 4.6870285586919636e-05 / Item reconstruction: 0.0023262607865035534 / Text reconstruction: 0.006382847670465708\n",
            "loss in epoch 6/21 iteration 30/67: 1.3873183727264404 / BPR loss: 1.384901762008667 / Matching loss: 4.742559394799173e-05 / Item reconstruction: 0.002209392376244068 / Text reconstruction: 0.006322350353002548\n",
            "loss in epoch 6/21 iteration 31/67: 1.387308955192566 / BPR loss: 1.384973168373108 / Matching loss: 4.667188477469608e-05 / Item reconstruction: 0.0020902655087411404 / Text reconstruction: 0.006219873204827309\n",
            "loss in epoch 6/21 iteration 32/67: 1.3871312141418457 / BPR loss: 1.3848531246185303 / Matching loss: 4.6965644287411124e-05 / Item reconstruction: 0.0020381715148687363 / Text reconstruction: 0.006060237996280193\n",
            "loss in epoch 6/21 iteration 33/67: 1.3875665664672852 / BPR loss: 1.384909987449646 / Matching loss: 5.2143383072689176e-05 / Item reconstruction: 0.0026799854822456837 / Text reconstruction: 0.006322196684777737\n",
            "loss in epoch 6/21 iteration 34/67: 1.387790560722351 / BPR loss: 1.3852020502090454 / Matching loss: 5.1630864618346095e-05 / Item reconstruction: 0.002695414237678051 / Text reconstruction: 0.005946305580437183\n",
            "loss in epoch 6/21 iteration 35/67: 1.3876433372497559 / BPR loss: 1.3849537372589111 / Matching loss: 4.973476461600512e-05 / Item reconstruction: 0.002831435762345791 / Text reconstruction: 0.006121066864579916\n",
            "loss in epoch 6/21 iteration 36/67: 1.3887121677398682 / BPR loss: 1.3860396146774292 / Matching loss: 6.286456482484937e-05 / Item reconstruction: 0.0027917081024497747 / Text reconstruction: 0.00606961827725172\n",
            "loss in epoch 6/21 iteration 37/67: 1.388620376586914 / BPR loss: 1.3860434293746948 / Matching loss: 6.06155808782205e-05 / Item reconstruction: 0.002635420998558402 / Text reconstruction: 0.00599303562194109\n",
            "loss in epoch 6/21 iteration 38/67: 1.3886585235595703 / BPR loss: 1.386120319366455 / Matching loss: 5.885857535758987e-05 / Item reconstruction: 0.0026758136227726936 / Text reconstruction: 0.005707332864403725\n",
            "loss in epoch 6/21 iteration 39/67: 1.3886724710464478 / BPR loss: 1.3861887454986572 / Matching loss: 5.908820094191469e-05 / Item reconstruction: 0.0025762133300304413 / Text reconstruction: 0.005682975985109806\n",
            "loss in epoch 6/21 iteration 40/67: 1.388639211654663 / BPR loss: 1.3861291408538818 / Matching loss: 7.26579746697098e-05 / Item reconstruction: 0.0026623555459082127 / Text reconstruction: 0.005531531758606434\n",
            "loss in epoch 6/21 iteration 41/67: 1.3882007598876953 / BPR loss: 1.3856663703918457 / Matching loss: 6.28649431746453e-05 / Item reconstruction: 0.0025721974670886993 / Text reconstruction: 0.005927138030529022\n",
            "loss in epoch 6/21 iteration 42/67: 1.3873463869094849 / BPR loss: 1.384750247001648 / Matching loss: 4.50697225460317e-05 / Item reconstruction: 0.002486070152372122 / Text reconstruction: 0.006540372967720032\n",
            "loss in epoch 6/21 iteration 43/67: 1.3873652219772339 / BPR loss: 1.3847434520721436 / Matching loss: 4.7093159082578495e-05 / Item reconstruction: 0.0025731606874614954 / Text reconstruction: 0.006440102122724056\n",
            "loss in epoch 6/21 iteration 44/67: 1.3882169723510742 / BPR loss: 1.3860350847244263 / Matching loss: 6.027200652169995e-05 / Item reconstruction: 0.0021920856088399887 / Text reconstruction: 0.005127615295350552\n",
            "loss in epoch 6/21 iteration 45/67: 1.3882240056991577 / BPR loss: 1.3861310482025146 / Matching loss: 5.8598932810127735e-05 / Item reconstruction: 0.0020880992524325848 / Text reconstruction: 0.004951514303684235\n",
            "loss in epoch 6/21 iteration 46/67: 1.38826584815979 / BPR loss: 1.3860540390014648 / Matching loss: 6.231307634152472e-05 / Item reconstruction: 0.002335340017452836 / Text reconstruction: 0.004908798262476921\n",
            "loss in epoch 6/21 iteration 47/67: 1.3881429433822632 / BPR loss: 1.3859838247299194 / Matching loss: 6.005925388308242e-05 / Item reconstruction: 0.0022333767265081406 / Text reconstruction: 0.004911945201456547\n",
            "loss in epoch 6/21 iteration 48/67: 1.3882334232330322 / BPR loss: 1.3860313892364502 / Matching loss: 6.093757110647857e-05 / Item reconstruction: 0.002280020620673895 / Text reconstruction: 0.005005418322980404\n",
            "loss in epoch 6/21 iteration 49/67: 1.388497233390808 / BPR loss: 1.386300802230835 / Matching loss: 5.600648728432134e-05 / Item reconstruction: 0.0022834064438939095 / Text reconstruction: 0.0049933805130422115\n",
            "loss in epoch 6/21 iteration 50/67: 1.3883945941925049 / BPR loss: 1.3861989974975586 / Matching loss: 5.972037251922302e-05 / Item reconstruction: 0.002303909743204713 / Text reconstruction: 0.004919945728033781\n",
            "loss in epoch 6/21 iteration 51/67: 1.3884038925170898 / BPR loss: 1.3862895965576172 / Matching loss: 6.678973295493051e-05 / Item reconstruction: 0.0021576862782239914 / Text reconstruction: 0.004843397997319698\n",
            "loss in epoch 6/21 iteration 52/67: 1.3883020877838135 / BPR loss: 1.3862178325653076 / Matching loss: 5.827682252856903e-05 / Item reconstruction: 0.002172228181734681 / Text reconstruction: 0.004699486307799816\n",
            "loss in epoch 6/21 iteration 53/67: 1.3883631229400635 / BPR loss: 1.3863108158111572 / Matching loss: 5.35226208739914e-05 / Item reconstruction: 0.002092263661324978 / Text reconstruction: 0.004763215780258179\n",
            "loss in epoch 6/21 iteration 54/67: 1.3883554935455322 / BPR loss: 1.3863061666488647 / Matching loss: 6.389288319041952e-05 / Item reconstruction: 0.002081639599055052 / Text reconstruction: 0.004723271355032921\n",
            "loss in epoch 6/21 iteration 55/67: 1.3884050846099854 / BPR loss: 1.3863537311553955 / Matching loss: 6.118715100456029e-05 / Item reconstruction: 0.002053016796708107 / Text reconstruction: 0.004818513989448547\n",
            "loss in epoch 6/21 iteration 56/67: 1.3883475065231323 / BPR loss: 1.3863279819488525 / Matching loss: 5.720918852603063e-05 / Item reconstruction: 0.0020845416001975536 / Text reconstruction: 0.004600225482136011\n",
            "loss in epoch 6/21 iteration 57/67: 1.388251543045044 / BPR loss: 1.3862688541412354 / Matching loss: 5.365224205888808e-05 / Item reconstruction: 0.0020199157297611237 / Text reconstruction: 0.004595703911036253\n",
            "loss in epoch 6/21 iteration 58/67: 1.388137936592102 / BPR loss: 1.3862098455429077 / Matching loss: 5.326836617314257e-05 / Item reconstruction: 0.0019439435563981533 / Text reconstruction: 0.004514693282544613\n",
            "loss in epoch 6/21 iteration 59/67: 1.3882273435592651 / BPR loss: 1.3862744569778442 / Matching loss: 5.818226782139391e-05 / Item reconstruction: 0.002007779199630022 / Text reconstruction: 0.004454244859516621\n",
            "loss in epoch 6/21 iteration 60/67: 1.3881264925003052 / BPR loss: 1.3862175941467285 / Matching loss: 5.761200372944586e-05 / Item reconstruction: 0.0019375425763428211 / Text reconstruction: 0.0044127837754786015\n",
            "loss in epoch 6/21 iteration 61/67: 1.3881257772445679 / BPR loss: 1.3862982988357544 / Matching loss: 5.542561848415062e-05 / Item reconstruction: 0.0018089922377839684 / Text reconstruction: 0.0043380665592849255\n",
            "loss in epoch 6/21 iteration 62/67: 1.3879830837249756 / BPR loss: 1.3860960006713867 / Matching loss: 4.58769645774737e-05 / Item reconstruction: 0.0018375851213932037 / Text reconstruction: 0.004612024407833815\n",
            "loss in epoch 6/21 iteration 63/67: 1.3882684707641602 / BPR loss: 1.3862683773040771 / Matching loss: 6.254029722185805e-05 / Item reconstruction: 0.0021813763305544853 / Text reconstruction: 0.0042343745008111\n",
            "loss in epoch 6/21 iteration 64/67: 1.388182520866394 / BPR loss: 1.386322259902954 / Matching loss: 5.504646469489671e-05 / Item reconstruction: 0.0019403428304940462 / Text reconstruction: 0.004175448324531317\n",
            "loss in epoch 6/21 iteration 65/67: 1.3882992267608643 / BPR loss: 1.3864541053771973 / Matching loss: 5.625719131785445e-05 / Item reconstruction: 0.001902847085148096 / Text reconstruction: 0.004187355749309063\n",
            "loss in epoch 6/21 iteration 66/67: 1.3878849744796753 / BPR loss: 1.3862547874450684 / Matching loss: 4.548801007331349e-05 / Item reconstruction: 0.0014977087266743183 / Text reconstruction: 0.004178795963525772\n",
            "loss in epoch 6/21 iteration 67/67: 1.3877549171447754 / BPR loss: 1.3862193822860718 / Matching loss: 4.0353017539018765e-05 / Item reconstruction: 0.0013072711881250143 / Text reconstruction: 0.00420739222317934\n",
            " 30% 6/20 [11:56<28:07, 120.54s/it]loss in epoch 7/21 iteration 0/67: 1.3882111310958862 / BPR loss: 1.3861732482910156 / Matching loss: 5.882328696316108e-05 / Item reconstruction: 0.0023145414888858795 / Text reconstruction: 0.00410922896116972\n",
            "loss in epoch 7/21 iteration 1/67: 1.387529730796814 / BPR loss: 1.385259985923767 / Matching loss: 4.998445001547225e-05 / Item reconstruction: 0.0024548303335905075 / Text reconstruction: 0.004962028935551643\n",
            "loss in epoch 7/21 iteration 2/67: 1.3871623277664185 / BPR loss: 1.3846755027770996 / Matching loss: 4.8073776270030066e-05 / Item reconstruction: 0.0027220486663281918 / Text reconstruction: 0.005388577468693256\n",
            "loss in epoch 7/21 iteration 3/67: 1.3868284225463867 / BPR loss: 1.3844434022903442 / Matching loss: 4.635284858522937e-05 / Item reconstruction: 0.0025418319273740053 / Text reconstruction: 0.0053387656807899475\n",
            "loss in epoch 7/21 iteration 4/67: 1.3868300914764404 / BPR loss: 1.384425163269043 / Matching loss: 4.431250272318721e-05 / Item reconstruction: 0.002552073448896408 / Text reconstruction: 0.005422587506473064\n",
            "loss in epoch 7/21 iteration 5/67: 1.3867934942245483 / BPR loss: 1.38450288772583 / Matching loss: 4.601144974003546e-05 / Item reconstruction: 0.002376381540670991 / Text reconstruction: 0.005281892139464617\n",
            "loss in epoch 7/21 iteration 6/67: 1.3867543935775757 / BPR loss: 1.384608268737793 / Matching loss: 4.16455150116235e-05 / Item reconstruction: 0.0022174688056111336 / Text reconstruction: 0.0049787480384111404\n",
            "loss in epoch 7/21 iteration 7/67: 1.3865617513656616 / BPR loss: 1.3844337463378906 / Matching loss: 4.370901297079399e-05 / Item reconstruction: 0.0022544702515006065 / Text reconstruction: 0.004785164259374142\n",
            "loss in epoch 7/21 iteration 8/67: 1.3862731456756592 / BPR loss: 1.3842355012893677 / Matching loss: 4.1470098949503154e-05 / Item reconstruction: 0.0021330788731575012 / Text reconstruction: 0.004647885449230671\n",
            "loss in epoch 7/21 iteration 9/67: 1.38645339012146 / BPR loss: 1.3844983577728271 / Matching loss: 3.986908996012062e-05 / Item reconstruction: 0.001984929433092475 / Text reconstruction: 0.004614057019352913\n",
            "loss in epoch 7/21 iteration 10/67: 1.3860870599746704 / BPR loss: 1.3842062950134277 / Matching loss: 4.059652565047145e-05 / Item reconstruction: 0.001895452500320971 / Text reconstruction: 0.004461971577256918\n",
            "loss in epoch 7/21 iteration 11/67: 1.3860591650009155 / BPR loss: 1.384188175201416 / Matching loss: 4.169197563896887e-05 / Item reconstruction: 0.00192231684923172 / Text reconstruction: 0.004340495448559523\n",
            "loss in epoch 7/21 iteration 12/67: 1.386491298675537 / BPR loss: 1.3845871686935425 / Matching loss: 4.371575414552353e-05 / Item reconstruction: 0.0019890593830496073 / Text reconstruction: 0.004329349845647812\n",
            "loss in epoch 7/21 iteration 13/67: 1.3862558603286743 / BPR loss: 1.3843462467193604 / Matching loss: 4.316798731451854e-05 / Item reconstruction: 0.0019930745474994183 / Text reconstruction: 0.004349462687969208\n",
            "loss in epoch 7/21 iteration 14/67: 1.3860279321670532 / BPR loss: 1.3841571807861328 / Matching loss: 4.3807867768919095e-05 / Item reconstruction: 0.0019184406846761703 / Text reconstruction: 0.004338401835411787\n",
            "loss in epoch 7/21 iteration 15/67: 1.3862392902374268 / BPR loss: 1.3843462467193604 / Matching loss: 4.0272421756526455e-05 / Item reconstruction: 0.0018913778476417065 / Text reconstruction: 0.004535404033958912\n",
            "loss in epoch 7/21 iteration 16/67: 1.3859184980392456 / BPR loss: 1.384063959121704 / Matching loss: 3.9137143176048994e-05 / Item reconstruction: 0.0018445050809532404 / Text reconstruction: 0.004466081503778696\n",
            "loss in epoch 7/21 iteration 17/67: 1.3864638805389404 / BPR loss: 1.3846256732940674 / Matching loss: 3.7424597394419834e-05 / Item reconstruction: 0.0018671073485165834 / Text reconstruction: 0.00433622719720006\n",
            "loss in epoch 7/21 iteration 18/67: 1.3880583047866821 / BPR loss: 1.3856947422027588 / Matching loss: 5.1635091949719936e-05 / Item reconstruction: 0.002702073659747839 / Text reconstruction: 0.004804661497473717\n",
            "loss in epoch 7/21 iteration 19/67: 1.3887125253677368 / BPR loss: 1.3861842155456543 / Matching loss: 5.23533126397524e-05 / Item reconstruction: 0.0029746112413704395 / Text reconstruction: 0.004943493288010359\n",
            "loss in epoch 7/21 iteration 20/67: 1.3886231184005737 / BPR loss: 1.3862003087997437 / Matching loss: 5.480617983266711e-05 / Item reconstruction: 0.002829338889569044 / Text reconstruction: 0.00476630637422204\n",
            "loss in epoch 7/21 iteration 21/67: 1.388472080230713 / BPR loss: 1.3860595226287842 / Matching loss: 5.772137956228107e-05 / Item reconstruction: 0.0029252960812300444 / Text reconstruction: 0.004460903815925121\n",
            "loss in epoch 7/21 iteration 22/67: 1.3870996236801147 / BPR loss: 1.3845536708831787 / Matching loss: 4.436530434759334e-05 / Item reconstruction: 0.0030284239910542965 / Text reconstruction: 0.0049370587803423405\n",
            "loss in epoch 7/21 iteration 23/67: 1.387056589126587 / BPR loss: 1.3846685886383057 / Matching loss: 4.16375114582479e-05 / Item reconstruction: 0.0028352662920951843 / Text reconstruction: 0.004643926862627268\n",
            "loss in epoch 7/21 iteration 24/67: 1.3867557048797607 / BPR loss: 1.3844621181488037 / Matching loss: 4.150535096414387e-05 / Item reconstruction: 0.0026966521982103586 / Text reconstruction: 0.004518497735261917\n",
            "loss in epoch 7/21 iteration 25/67: 1.3867770433425903 / BPR loss: 1.3844966888427734 / Matching loss: 4.344091212260537e-05 / Item reconstruction: 0.0027171634137630463 / Text reconstruction: 0.004391444381326437\n",
            "loss in epoch 7/21 iteration 26/67: 1.3867555856704712 / BPR loss: 1.384535789489746 / Matching loss: 4.3975953303743154e-05 / Item reconstruction: 0.0025781868025660515 / Text reconstruction: 0.0044336868450045586\n",
            "loss in epoch 7/21 iteration 27/67: 1.3867181539535522 / BPR loss: 1.3846304416656494 / Matching loss: 4.0504313801648095e-05 / Item reconstruction: 0.002364026615396142 / Text reconstruction: 0.004326238762587309\n",
            "loss in epoch 7/21 iteration 28/67: 1.3865374326705933 / BPR loss: 1.3845266103744507 / Matching loss: 4.146443825447932e-05 / Item reconstruction: 0.002276510000228882 / Text reconstruction: 0.004155515227466822\n",
            "loss in epoch 7/21 iteration 29/67: 1.386533498764038 / BPR loss: 1.3845560550689697 / Matching loss: 3.97477597289253e-05 / Item reconstruction: 0.0022075253073126078 / Text reconstruction: 0.004169851541519165\n",
            "loss in epoch 7/21 iteration 30/67: 1.3865283727645874 / BPR loss: 1.3845727443695068 / Matching loss: 3.631438812590204e-05 / Item reconstruction: 0.0021129681263118982 / Text reconstruction: 0.004314383491873741\n",
            "loss in epoch 7/21 iteration 31/67: 1.3863316774368286 / BPR loss: 1.384413719177246 / Matching loss: 3.76285970560275e-05 / Item reconstruction: 0.002127069281414151 / Text reconstruction: 0.004083604551851749\n",
            "loss in epoch 7/21 iteration 32/67: 1.38621187210083 / BPR loss: 1.3843915462493896 / Matching loss: 3.800229751504958e-05 / Item reconstruction: 0.0020332462154328823 / Text reconstruction: 0.003828659188002348\n",
            "loss in epoch 7/21 iteration 33/67: 1.386894941329956 / BPR loss: 1.3846652507781982 / Matching loss: 4.394193092593923e-05 / Item reconstruction: 0.002709601540118456 / Text reconstruction: 0.004154423251748085\n",
            "loss in epoch 7/21 iteration 34/67: 1.3871071338653564 / BPR loss: 1.3849831819534302 / Matching loss: 4.5727436372544616e-05 / Item reconstruction: 0.0026623113080859184 / Text reconstruction: 0.003734918776899576\n",
            "loss in epoch 7/21 iteration 35/67: 1.3869976997375488 / BPR loss: 1.384773850440979 / Matching loss: 4.1902283555828035e-05 / Item reconstruction: 0.0027939537540078163 / Text reconstruction: 0.003924104385077953\n",
            "loss in epoch 7/21 iteration 36/67: 1.388182282447815 / BPR loss: 1.3859895467758179 / Matching loss: 4.9923699407372624e-05 / Item reconstruction: 0.00270252488553524 / Text reconstruction: 0.0039575109258294106\n",
            "loss in epoch 7/21 iteration 37/67: 1.388360857963562 / BPR loss: 1.3862258195877075 / Matching loss: 5.118761691846885e-05 / Item reconstruction: 0.0026671732775866985 / Text reconstruction: 0.003751650219783187\n",
            "loss in epoch 7/21 iteration 38/67: 1.388087272644043 / BPR loss: 1.3860031366348267 / Matching loss: 5.1562576118158177e-05 / Item reconstruction: 0.0027073549572378397 / Text reconstruction: 0.003394355531781912\n",
            "loss in epoch 7/21 iteration 39/67: 1.3880506753921509 / BPR loss: 1.386063575744629 / Matching loss: 5.257371230982244e-05 / Item reconstruction: 0.0025264823343604803 / Text reconstruction: 0.0033564483746886253\n",
            "loss in epoch 7/21 iteration 40/67: 1.3882951736450195 / BPR loss: 1.3863141536712646 / Matching loss: 5.771179712610319e-05 / Item reconstruction: 0.002524592448025942 / Text reconstruction: 0.00330499280244112\n",
            "loss in epoch 7/21 iteration 41/67: 1.387544870376587 / BPR loss: 1.3855301141738892 / Matching loss: 5.419042281573638e-05 / Item reconstruction: 0.002515302039682865 / Text reconstruction: 0.0035140595864504576\n",
            "loss in epoch 7/21 iteration 42/67: 1.3864063024520874 / BPR loss: 1.3843233585357666 / Matching loss: 3.659824869828299e-05 / Item reconstruction: 0.0024254578165709972 / Text reconstruction: 0.004168050829321146\n",
            "loss in epoch 7/21 iteration 43/67: 1.3861867189407349 / BPR loss: 1.384061574935913 / Matching loss: 3.924551128875464e-05 / Item reconstruction: 0.002508386503905058 / Text reconstruction: 0.004158606752753258\n",
            "loss in epoch 7/21 iteration 44/67: 1.3877266645431519 / BPR loss: 1.3859567642211914 / Matching loss: 5.341028736438602e-05 / Item reconstruction: 0.002237398875877261 / Text reconstruction: 0.00298890913836658\n",
            "loss in epoch 7/21 iteration 45/67: 1.3879308700561523 / BPR loss: 1.3862255811691284 / Matching loss: 5.279364631860517e-05 / Item reconstruction: 0.0021298653446137905 / Text reconstruction: 0.0029379790648818016\n",
            "loss in epoch 7/21 iteration 46/67: 1.387772798538208 / BPR loss: 1.3859913349151611 / Matching loss: 5.3781201131641865e-05 / Item reconstruction: 0.002314130775630474 / Text reconstruction: 0.002853238955140114\n",
            "loss in epoch 7/21 iteration 47/67: 1.3876420259475708 / BPR loss: 1.3858927488327026 / Matching loss: 5.09417150169611e-05 / Item reconstruction: 0.0022479798644781113 / Text reconstruction: 0.0028716325759887695\n",
            "loss in epoch 7/21 iteration 48/67: 1.3878912925720215 / BPR loss: 1.386160969734192 / Matching loss: 5.3104533435544e-05 / Item reconstruction: 0.002203636337071657 / Text reconstruction: 0.0028772444929927588\n",
            "loss in epoch 7/21 iteration 49/67: 1.3879518508911133 / BPR loss: 1.3861846923828125 / Matching loss: 4.925212124362588e-05 / Item reconstruction: 0.002235857304185629 / Text reconstruction: 0.0029996749944984913\n",
            "loss in epoch 7/21 iteration 50/67: 1.3878881931304932 / BPR loss: 1.386107087135315 / Matching loss: 5.205548950470984e-05 / Item reconstruction: 0.0022975155152380466 / Text reconstruction: 0.002901733387261629\n",
            "loss in epoch 7/21 iteration 51/67: 1.3881031274795532 / BPR loss: 1.3864121437072754 / Matching loss: 6.140662299003452e-05 / Item reconstruction: 0.00215481361374259 / Text reconstruction: 0.0027610589750111103\n",
            "loss in epoch 7/21 iteration 52/67: 1.3877755403518677 / BPR loss: 1.3860706090927124 / Matching loss: 5.268814493319951e-05 / Item reconstruction: 0.0022445153445005417 / Text reconstruction: 0.002649999689310789\n",
            "loss in epoch 7/21 iteration 53/67: 1.3877650499343872 / BPR loss: 1.3860844373703003 / Matching loss: 5.105713353259489e-05 / Item reconstruction: 0.0021399722900241613 / Text reconstruction: 0.0027978301513940096\n",
            "loss in epoch 7/21 iteration 54/67: 1.3880600929260254 / BPR loss: 1.3864338397979736 / Matching loss: 5.0645241572055966e-05 / Item reconstruction: 0.0020550915505737066 / Text reconstruction: 0.0027401004917919636\n",
            "loss in epoch 7/21 iteration 55/67: 1.3878977298736572 / BPR loss: 1.3862590789794922 / Matching loss: 5.1452825573505834e-05 / Item reconstruction: 0.0020504645071923733 / Text reconstruction: 0.0028097894974052906\n",
            "loss in epoch 7/21 iteration 56/67: 1.3878881931304932 / BPR loss: 1.3862478733062744 / Matching loss: 5.31121768290177e-05 / Item reconstruction: 0.002125322353094816 / Text reconstruction: 0.002622830681502819\n",
            "loss in epoch 7/21 iteration 57/67: 1.3877476453781128 / BPR loss: 1.3861900568008423 / Matching loss: 4.839224857278168e-05 / Item reconstruction: 0.0019856332801282406 / Text reconstruction: 0.0025822720490396023\n",
            "loss in epoch 7/21 iteration 58/67: 1.3877605199813843 / BPR loss: 1.3862321376800537 / Matching loss: 4.9911814130609855e-05 / Item reconstruction: 0.0019454066641628742 / Text reconstruction: 0.0025283314753323793\n",
            "loss in epoch 7/21 iteration 59/67: 1.3877692222595215 / BPR loss: 1.3862240314483643 / Matching loss: 5.583171878242865e-05 / Item reconstruction: 0.0019959183409810066 / Text reconstruction: 0.002457426395267248\n",
            "loss in epoch 7/21 iteration 60/67: 1.3877266645431519 / BPR loss: 1.3862260580062866 / Matching loss: 4.875382364843972e-05 / Item reconstruction: 0.0019184506963938475 / Text reconstruction: 0.002462799893692136\n",
            "loss in epoch 7/21 iteration 61/67: 1.3878254890441895 / BPR loss: 1.3863835334777832 / Matching loss: 4.9577010940993205e-05 / Item reconstruction: 0.0018221554346382618 / Text reconstruction: 0.002406052313745022\n",
            "loss in epoch 7/21 iteration 62/67: 1.3874056339263916 / BPR loss: 1.3858914375305176 / Matching loss: 4.2077721445821226e-05 / Item reconstruction: 0.0018462399020791054 / Text reconstruction: 0.0027447715401649475\n",
            "loss in epoch 7/21 iteration 63/67: 1.387919306755066 / BPR loss: 1.3863229751586914 / Matching loss: 5.4923497373238206e-05 / Item reconstruction: 0.002125159604474902 / Text reconstruction: 0.002393928822129965\n",
            "loss in epoch 7/21 iteration 64/67: 1.3877731561660767 / BPR loss: 1.386296272277832 / Matching loss: 4.9765170842874795e-05 / Item reconstruction: 0.0019294379744678736 / Text reconstruction: 0.002312297699972987\n",
            "loss in epoch 7/21 iteration 65/67: 1.3878437280654907 / BPR loss: 1.3863756656646729 / Matching loss: 4.9703165132086724e-05 / Item reconstruction: 0.0019302431028336287 / Text reconstruction: 0.002266195137053728\n",
            "loss in epoch 7/21 iteration 66/67: 1.3875229358673096 / BPR loss: 1.386253833770752 / Matching loss: 3.932942126994021e-05 / Item reconstruction: 0.0015047520864754915 / Text reconstruction: 0.002386930165812373\n",
            "loss in epoch 7/21 iteration 67/67: 1.3874952793121338 / BPR loss: 1.3863474130630493 / Matching loss: 3.497295256238431e-05 / Item reconstruction: 0.0013022713828831911 / Text reconstruction: 0.002308872062712908\n",
            " 35% 7/20 [13:49<25:35, 118.15s/it]loss in epoch 8/21 iteration 0/67: 1.3878173828125 / BPR loss: 1.3861026763916016 / Matching loss: 5.7286586525151506e-05 / Item reconstruction: 0.0023907311260700226 / Text reconstruction: 0.002310473006218672\n",
            "loss in epoch 8/21 iteration 1/67: 1.3870600461959839 / BPR loss: 1.3851661682128906 / Matching loss: 4.9937771109398454e-05 / Item reconstruction: 0.0024790363386273384 / Text reconstruction: 0.003021895419806242\n",
            "loss in epoch 8/21 iteration 2/67: 1.3862345218658447 / BPR loss: 1.384141206741333 / Matching loss: 4.577537765726447e-05 / Item reconstruction: 0.0026857778429985046 / Text reconstruction: 0.0035233167000114918\n",
            "loss in epoch 8/21 iteration 3/67: 1.3857762813568115 / BPR loss: 1.3837599754333496 / Matching loss: 4.568519216263667e-05 / Item reconstruction: 0.0025488545652478933 / Text reconstruction: 0.003480801358819008\n",
            "loss in epoch 8/21 iteration 4/67: 1.3859018087387085 / BPR loss: 1.3839067220687866 / Matching loss: 4.217193054500967e-05 / Item reconstruction: 0.002454449888318777 / Text reconstruction: 0.0036280546337366104\n",
            "loss in epoch 8/21 iteration 5/67: 1.3859034776687622 / BPR loss: 1.3840662240982056 / Matching loss: 3.992172423750162e-05 / Item reconstruction: 0.0022493680007755756 / Text reconstruction: 0.0033626907970756292\n",
            "loss in epoch 8/21 iteration 6/67: 1.3856585025787354 / BPR loss: 1.3838918209075928 / Matching loss: 4.12178342230618e-05 / Item reconstruction: 0.0021877328399568796 / Text reconstruction: 0.0031580105423927307\n",
            "loss in epoch 8/21 iteration 7/67: 1.3857882022857666 / BPR loss: 1.3840687274932861 / Matching loss: 3.8358055462595075e-05 / Item reconstruction: 0.002111753448843956 / Text reconstruction: 0.0031261956319212914\n",
            "loss in epoch 8/21 iteration 8/67: 1.3855969905853271 / BPR loss: 1.3838858604431152 / Matching loss: 3.7085024814587086e-05 / Item reconstruction: 0.0020565977320075035 / Text reconstruction: 0.0032289025839418173\n",
            "loss in epoch 8/21 iteration 9/67: 1.3855862617492676 / BPR loss: 1.3840066194534302 / Matching loss: 3.613544686231762e-05 / Item reconstruction: 0.0019624968990683556 / Text reconstruction: 0.0028117382898926735\n",
            "loss in epoch 8/21 iteration 10/67: 1.3849657773971558 / BPR loss: 1.383470892906189 / Matching loss: 3.664182440843433e-05 / Item reconstruction: 0.0018735845806077123 / Text reconstruction: 0.0026077041402459145\n",
            "loss in epoch 8/21 iteration 11/67: 1.3851832151412964 / BPR loss: 1.3836994171142578 / Matching loss: 3.7183734093559906e-05 / Item reconstruction: 0.0018463676096871495 / Text reconstruction: 0.002617513295263052\n",
            "loss in epoch 8/21 iteration 12/67: 1.3854866027832031 / BPR loss: 1.383866786956787 / Matching loss: 4.163068297202699e-05 / Item reconstruction: 0.002082128543406725 / Text reconstruction: 0.002685891930013895\n",
            "loss in epoch 8/21 iteration 13/67: 1.3854635953903198 / BPR loss: 1.3839566707611084 / Matching loss: 3.904235200025141e-05 / Item reconstruction: 0.0018691809382289648 / Text reconstruction: 0.0026662328746169806\n",
            "loss in epoch 8/21 iteration 14/67: 1.385196566581726 / BPR loss: 1.383683681488037 / Matching loss: 3.660978836705908e-05 / Item reconstruction: 0.0018697413615882397 / Text reconstruction: 0.002707360079512\n",
            "loss in epoch 8/21 iteration 15/67: 1.385408878326416 / BPR loss: 1.3839038610458374 / Matching loss: 3.755859870580025e-05 / Item reconstruction: 0.0018507580971345305 / Text reconstruction: 0.0027102576568722725\n",
            "loss in epoch 8/21 iteration 16/67: 1.3851261138916016 / BPR loss: 1.383666753768921 / Matching loss: 3.664487667265348e-05 / Item reconstruction: 0.0017760931514203548 / Text reconstruction: 0.002673824317753315\n",
            "loss in epoch 8/21 iteration 17/67: 1.3853707313537598 / BPR loss: 1.3839037418365479 / Matching loss: 3.328168168081902e-05 / Item reconstruction: 0.0018011394422501326 / Text reconstruction: 0.0026656021364033222\n",
            "loss in epoch 8/21 iteration 18/67: 1.3876664638519287 / BPR loss: 1.3855916261672974 / Matching loss: 4.855865699937567e-05 / Item reconstruction: 0.0027644429355859756 / Text reconstruction: 0.003220669459551573\n",
            "loss in epoch 8/21 iteration 19/67: 1.3883846998214722 / BPR loss: 1.3862330913543701 / Matching loss: 4.721972072729841e-05 / Item reconstruction: 0.0028908345848321915 / Text reconstruction: 0.003294861875474453\n",
            "loss in epoch 8/21 iteration 20/67: 1.388132929801941 / BPR loss: 1.3860971927642822 / Matching loss: 4.8183483158936724e-05 / Item reconstruction: 0.0027894428931176662 / Text reconstruction: 0.002964121988043189\n",
            "loss in epoch 8/21 iteration 21/67: 1.3882441520690918 / BPR loss: 1.3861336708068848 / Matching loss: 5.21268775628414e-05 / Item reconstruction: 0.0029735746793448925 / Text reconstruction: 0.0028578732162714005\n",
            "loss in epoch 8/21 iteration 22/67: 1.3864012956619263 / BPR loss: 1.384245753288269 / Matching loss: 4.154490670771338e-05 / Item reconstruction: 0.003010971238836646 / Text reconstruction: 0.0030420618131756783\n",
            "loss in epoch 8/21 iteration 23/67: 1.3860496282577515 / BPR loss: 1.3840444087982178 / Matching loss: 3.957712760893628e-05 / Item reconstruction: 0.0027174712158739567 / Text reconstruction: 0.003034198423847556\n",
            "loss in epoch 8/21 iteration 24/67: 1.3862544298171997 / BPR loss: 1.3842277526855469 / Matching loss: 3.887256025336683e-05 / Item reconstruction: 0.0026981262490153313 / Text reconstruction: 0.003193721640855074\n",
            "loss in epoch 8/21 iteration 25/67: 1.3859386444091797 / BPR loss: 1.3839802742004395 / Matching loss: 3.875858601531945e-05 / Item reconstruction: 0.0025647850707173347 / Text reconstruction: 0.0031866575591266155\n",
            "loss in epoch 8/21 iteration 26/67: 1.3858909606933594 / BPR loss: 1.3840522766113281 / Matching loss: 3.8406033127103e-05 / Item reconstruction: 0.0024766698479652405 / Text reconstruction: 0.0028100390918552876\n",
            "loss in epoch 8/21 iteration 27/67: 1.3857816457748413 / BPR loss: 1.3840408325195312 / Matching loss: 3.313801425974816e-05 / Item reconstruction: 0.0022999283391982317 / Text reconstruction: 0.0027880205307155848\n",
            "loss in epoch 8/21 iteration 28/67: 1.385850191116333 / BPR loss: 1.3841652870178223 / Matching loss: 3.418327105464414e-05 / Item reconstruction: 0.0021746947895735502 / Text reconstruction: 0.0028167134150862694\n",
            "loss in epoch 8/21 iteration 29/67: 1.385704755783081 / BPR loss: 1.3840718269348145 / Matching loss: 3.6772602470591664e-05 / Item reconstruction: 0.002178307855501771 / Text reconstruction: 0.0025358342099934816\n",
            "loss in epoch 8/21 iteration 30/67: 1.385611891746521 / BPR loss: 1.383981704711914 / Matching loss: 3.7065736250951886e-05 / Item reconstruction: 0.002170221647247672 / Text reconstruction: 0.002539557870477438\n",
            "loss in epoch 8/21 iteration 31/67: 1.3855555057525635 / BPR loss: 1.3839882612228394 / Matching loss: 3.3717027690727264e-05 / Item reconstruction: 0.0020449338480830193 / Text reconstruction: 0.002554995007812977\n",
            "loss in epoch 8/21 iteration 32/67: 1.3854318857192993 / BPR loss: 1.3838729858398438 / Matching loss: 3.689913501148112e-05 / Item reconstruction: 0.002010311931371689 / Text reconstruction: 0.0025840336456894875\n",
            "loss in epoch 8/21 iteration 33/67: 1.3862202167510986 / BPR loss: 1.3842263221740723 / Matching loss: 4.098106364835985e-05 / Item reconstruction: 0.0027598459273576736 / Text reconstruction: 0.002864812035113573\n",
            "loss in epoch 8/21 iteration 34/67: 1.3865535259246826 / BPR loss: 1.3846145868301392 / Matching loss: 4.1482318920316175e-05 / Item reconstruction: 0.0027918245177716017 / Text reconstruction: 0.0025074488949030638\n",
            "loss in epoch 8/21 iteration 35/67: 1.3863556385040283 / BPR loss: 1.384429693222046 / Matching loss: 4.0083810745272785e-05 / Item reconstruction: 0.0027434350922703743 / Text reconstruction: 0.002570534823462367\n",
            "loss in epoch 8/21 iteration 36/67: 1.387807011604309 / BPR loss: 1.3859219551086426 / Matching loss: 4.829618046642281e-05 / Item reconstruction: 0.002744972938671708 / Text reconstruction: 0.0023217396810650826\n",
            "loss in epoch 8/21 iteration 37/67: 1.3880451917648315 / BPR loss: 1.3861782550811768 / Matching loss: 4.8932932259049267e-05 / Item reconstruction: 0.0026914032641798258 / Text reconstruction: 0.002361803315579891\n",
            "loss in epoch 8/21 iteration 38/67: 1.387736439704895 / BPR loss: 1.3858602046966553 / Matching loss: 4.5369419240159914e-05 / Item reconstruction: 0.0027574803680181503 / Text reconstruction: 0.0022604709956794977\n",
            "loss in epoch 8/21 iteration 39/67: 1.387703537940979 / BPR loss: 1.385990023612976 / Matching loss: 4.852755955653265e-05 / Item reconstruction: 0.002429164946079254 / Text reconstruction: 0.002251571509987116\n",
            "loss in epoch 8/21 iteration 40/67: 1.3877925872802734 / BPR loss: 1.386036992073059 / Matching loss: 5.945603334112093e-05 / Item reconstruction: 0.0026015136390924454 / Text reconstruction: 0.0019763903692364693\n",
            "loss in epoch 8/21 iteration 41/67: 1.3869045972824097 / BPR loss: 1.385148048400879 / Matching loss: 5.00655805808492e-05 / Item reconstruction: 0.0025772368535399437 / Text reconstruction: 0.002089024055749178\n",
            "loss in epoch 8/21 iteration 42/67: 1.385578989982605 / BPR loss: 1.3838088512420654 / Matching loss: 3.568789907149039e-05 / Item reconstruction: 0.00240316241979599 / Text reconstruction: 0.0026643096935003996\n",
            "loss in epoch 8/21 iteration 43/67: 1.3856384754180908 / BPR loss: 1.3837863206863403 / Matching loss: 3.7277226510923356e-05 / Item reconstruction: 0.00246978085488081 / Text reconstruction: 0.0028997142799198627\n",
            "loss in epoch 8/21 iteration 44/67: 1.3873567581176758 / BPR loss: 1.385839819908142 / Matching loss: 4.982277823728509e-05 / Item reconstruction: 0.0022712484933435917 / Text reconstruction: 0.0016578166978433728\n",
            "loss in epoch 8/21 iteration 45/67: 1.3876616954803467 / BPR loss: 1.386231780052185 / Matching loss: 4.9555856094229966e-05 / Item reconstruction: 0.002149304375052452 / Text reconstruction: 0.0015284044202417135\n",
            "loss in epoch 8/21 iteration 46/67: 1.387401819229126 / BPR loss: 1.3858838081359863 / Matching loss: 4.5753444283036515e-05 / Item reconstruction: 0.0023098131641745567 / Text reconstruction: 0.0015869096387177706\n",
            "loss in epoch 8/21 iteration 47/67: 1.387382984161377 / BPR loss: 1.3859186172485352 / Matching loss: 4.286429611966014e-05 / Item reconstruction: 0.00220479560084641 / Text reconstruction: 0.0015948740765452385\n",
            "loss in epoch 8/21 iteration 48/67: 1.387353539466858 / BPR loss: 1.3859021663665771 / Matching loss: 4.5401153329294175e-05 / Item reconstruction: 0.0021684430539608 / Text reconstruction: 0.0016084762755781412\n",
            "loss in epoch 8/21 iteration 49/67: 1.3876632452011108 / BPR loss: 1.386134147644043 / Matching loss: 3.9892787754070014e-05 / Item reconstruction: 0.0022704200819134712 / Text reconstruction: 0.0017695784335955977\n",
            "loss in epoch 8/21 iteration 50/67: 1.387704849243164 / BPR loss: 1.3861565589904785 / Matching loss: 4.4907697883900255e-05 / Item reconstruction: 0.0022952151484787464 / Text reconstruction: 0.0017783655785024166\n",
            "loss in epoch 8/21 iteration 51/67: 1.3877466917037964 / BPR loss: 1.3862826824188232 / Matching loss: 5.389027501223609e-05 / Item reconstruction: 0.0021477846894413233 / Text reconstruction: 0.0016811772948130965\n",
            "loss in epoch 8/21 iteration 52/67: 1.387518286705017 / BPR loss: 1.3860284090042114 / Matching loss: 5.010415043216199e-05 / Item reconstruction: 0.0022230027243494987 / Text reconstruction: 0.0016413230914622545\n",
            "loss in epoch 8/21 iteration 53/67: 1.3874762058258057 / BPR loss: 1.3860689401626587 / Matching loss: 4.668359906645492e-05 / Item reconstruction: 0.0020574615336954594 / Text reconstruction: 0.0016588354483246803\n",
            "loss in epoch 8/21 iteration 54/67: 1.3877202272415161 / BPR loss: 1.3863235712051392 / Matching loss: 5.066060111857951e-05 / Item reconstruction: 0.0020992669742554426 / Text reconstruction: 0.0014818112831562757\n",
            "loss in epoch 8/21 iteration 55/67: 1.3877209424972534 / BPR loss: 1.3863099813461304 / Matching loss: 4.597078441292979e-05 / Item reconstruction: 0.002055936958640814 / Text reconstruction: 0.0016852119006216526\n",
            "loss in epoch 8/21 iteration 56/67: 1.3876490592956543 / BPR loss: 1.3862403631210327 / Matching loss: 4.947443085256964e-05 / Item reconstruction: 0.0021232403814792633 / Text reconstruction: 0.0014876938657835126\n",
            "loss in epoch 8/21 iteration 57/67: 1.3875596523284912 / BPR loss: 1.3862264156341553 / Matching loss: 4.5983833842910826e-05 / Item reconstruction: 0.0019952685106545687 / Text reconstruction: 0.0014479230158030987\n",
            "loss in epoch 8/21 iteration 58/67: 1.3875606060028076 / BPR loss: 1.3862824440002441 / Matching loss: 4.301347871660255e-05 / Item reconstruction: 0.0019172634929418564 / Text reconstruction: 0.0013823806075379252\n",
            "loss in epoch 8/21 iteration 59/67: 1.3875784873962402 / BPR loss: 1.3862762451171875 / Matching loss: 4.51416963187512e-05 / Item reconstruction: 0.002017783001065254 / Text reconstruction: 0.0012410366907715797\n",
            "loss in epoch 8/21 iteration 60/67: 1.3873624801635742 / BPR loss: 1.3861308097839355 / Matching loss: 4.3566920794546604e-05 / Item reconstruction: 0.0018739611841738224 / Text reconstruction: 0.0012558475136756897\n",
            "loss in epoch 8/21 iteration 61/67: 1.3874891996383667 / BPR loss: 1.3862841129302979 / Matching loss: 4.140743112657219e-05 / Item reconstruction: 0.0018423693254590034 / Text reconstruction: 0.0012128448579460382\n",
            "loss in epoch 8/21 iteration 62/67: 1.3872175216674805 / BPR loss: 1.3859692811965942 / Matching loss: 3.629823186201975e-05 / Item reconstruction: 0.0018212387803941965 / Text reconstruction: 0.0015069665387272835\n",
            "loss in epoch 8/21 iteration 63/67: 1.3875598907470703 / BPR loss: 1.3862028121948242 / Matching loss: 5.1595437980722636e-05 / Item reconstruction: 0.0021274674218147993 / Text reconstruction: 0.0012086548376828432\n",
            "loss in epoch 8/21 iteration 64/67: 1.387697696685791 / BPR loss: 1.386383295059204 / Matching loss: 4.825251380680129e-05 / Item reconstruction: 0.0020478537771850824 / Text reconstruction: 0.0012111988617107272\n",
            "loss in epoch 8/21 iteration 65/67: 1.3876612186431885 / BPR loss: 1.3864210844039917 / Matching loss: 4.581849498208612e-05 / Item reconstruction: 0.001919698202982545 / Text reconstruction: 0.0011722182389348745\n",
            "loss in epoch 8/21 iteration 66/67: 1.3873177766799927 / BPR loss: 1.3862942457199097 / Matching loss: 3.5162705898983404e-05 / Item reconstruction: 0.0014969401527196169 / Text reconstruction: 0.0011994497617706656\n",
            "loss in epoch 8/21 iteration 67/67: 1.387242078781128 / BPR loss: 1.3862903118133545 / Matching loss: 2.9069829906802624e-05 / Item reconstruction: 0.0013465973315760493 / Text reconstruction: 0.001247048145160079\n",
            " 40% 8/20 [15:49<23:44, 118.73s/it]loss in epoch 9/21 iteration 0/67: 1.3875013589859009 / BPR loss: 1.3860235214233398 / Matching loss: 4.946479748468846e-05 / Item reconstruction: 0.002331077354028821 / Text reconstruction: 0.0013145522680133581\n",
            "loss in epoch 9/21 iteration 1/67: 1.3866571187973022 / BPR loss: 1.3849842548370361 / Matching loss: 4.2586965719237924e-05 / Item reconstruction: 0.002388409338891506 / Text reconstruction: 0.002180488081648946\n",
            "loss in epoch 9/21 iteration 2/67: 1.3855913877487183 / BPR loss: 1.3837758302688599 / Matching loss: 3.7193392927292734e-05 / Item reconstruction: 0.0024904124438762665 / Text reconstruction: 0.002665608888491988\n",
            "loss in epoch 9/21 iteration 3/67: 1.3850172758102417 / BPR loss: 1.383232593536377 / Matching loss: 3.729144373210147e-05 / Item reconstruction: 0.00244238693267107 / Text reconstruction: 0.00263101770542562\n",
            "loss in epoch 9/21 iteration 4/67: 1.3848631381988525 / BPR loss: 1.3831522464752197 / Matching loss: 3.9023874705890194e-05 / Item reconstruction: 0.0023609395138919353 / Text reconstruction: 0.002457517897710204\n",
            "loss in epoch 9/21 iteration 5/67: 1.385039210319519 / BPR loss: 1.3834196329116821 / Matching loss: 3.684543480630964e-05 / Item reconstruction: 0.0022597189527004957 / Text reconstruction: 0.0022645825520157814\n",
            "loss in epoch 9/21 iteration 6/67: 1.3849660158157349 / BPR loss: 1.3834339380264282 / Matching loss: 3.281380486441776e-05 / Item reconstruction: 0.0021040255669504404 / Text reconstruction: 0.0022365362383425236\n",
            "loss in epoch 9/21 iteration 7/67: 1.3845914602279663 / BPR loss: 1.3831229209899902 / Matching loss: 3.202190782758407e-05 / Item reconstruction: 0.0020080211106687784 / Text reconstruction: 0.0021624299697577953\n",
            "loss in epoch 9/21 iteration 8/67: 1.3845375776290894 / BPR loss: 1.383124828338623 / Matching loss: 3.3752614399418235e-05 / Item reconstruction: 0.0019573261961340904 / Text reconstruction: 0.002001415006816387\n",
            "loss in epoch 9/21 iteration 9/67: 1.3844413757324219 / BPR loss: 1.3831074237823486 / Matching loss: 3.3280197385465726e-05 / Item reconstruction: 0.0018773332703858614 / Text reconstruction: 0.001809896668419242\n",
            "loss in epoch 9/21 iteration 10/67: 1.3843255043029785 / BPR loss: 1.3830204010009766 / Matching loss: 3.387301694601774e-05 / Item reconstruction: 0.001857222756370902 / Text reconstruction: 0.0017129778861999512\n",
            "loss in epoch 9/21 iteration 11/67: 1.3843415975570679 / BPR loss: 1.3830831050872803 / Matching loss: 3.12086267513223e-05 / Item reconstruction: 0.0017835572361946106 / Text reconstruction: 0.00167742557823658\n",
            "loss in epoch 9/21 iteration 12/67: 1.3846863508224487 / BPR loss: 1.383380651473999 / Matching loss: 3.3555359550518915e-05 / Item reconstruction: 0.0018477963749319315 / Text reconstruction: 0.0017417706549167633\n",
            "loss in epoch 9/21 iteration 13/67: 1.3846399784088135 / BPR loss: 1.3833329677581787 / Matching loss: 3.425917020649649e-05 / Item reconstruction: 0.0018636340973898768 / Text reconstruction: 0.0017043977277353406\n",
            "loss in epoch 9/21 iteration 14/67: 1.3843432664871216 / BPR loss: 1.3830260038375854 / Matching loss: 3.45584521710407e-05 / Item reconstruction: 0.0018726747948676348 / Text reconstruction: 0.0017314094584435225\n",
            "loss in epoch 9/21 iteration 15/67: 1.3842617273330688 / BPR loss: 1.3829431533813477 / Matching loss: 3.214920434402302e-05 / Item reconstruction: 0.0018549642991274595 / Text reconstruction: 0.0017946783918887377\n",
            "loss in epoch 9/21 iteration 16/67: 1.3842023611068726 / BPR loss: 1.3829460144042969 / Matching loss: 3.204610038665123e-05 / Item reconstruction: 0.0017544000875204802 / Text reconstruction: 0.00173598260153085\n",
            "loss in epoch 9/21 iteration 17/67: 1.3841193914413452 / BPR loss: 1.3828649520874023 / Matching loss: 3.091562757617794e-05 / Item reconstruction: 0.0017095335060730577 / Text reconstruction: 0.0018442865693941712\n",
            "loss in epoch 9/21 iteration 18/67: 1.3874902725219727 / BPR loss: 1.385683298110962 / Matching loss: 4.070163413416594e-05 / Item reconstruction: 0.00262833503074944 / Text reconstruction: 0.0022605317644774914\n",
            "loss in epoch 9/21 iteration 19/67: 1.3880653381347656 / BPR loss: 1.3860819339752197 / Matching loss: 4.2266055970685557e-05 / Item reconstruction: 0.0029160580597817898 / Text reconstruction: 0.002415355993434787\n",
            "loss in epoch 9/21 iteration 20/67: 1.3880996704101562 / BPR loss: 1.3862264156341553 / Matching loss: 4.188408638583496e-05 / Item reconstruction: 0.002775126602500677 / Text reconstruction: 0.0022191600874066353\n",
            "loss in epoch 9/21 iteration 21/67: 1.387698769569397 / BPR loss: 1.385802984237671 / Matching loss: 4.602302942657843e-05 / Item reconstruction: 0.0028925875667482615 / Text reconstruction: 0.0020173441153019667\n",
            "loss in epoch 9/21 iteration 22/67: 1.3858338594436646 / BPR loss: 1.3839045763015747 / Matching loss: 3.178237966494635e-05 / Item reconstruction: 0.002827826188877225 / Text reconstruction: 0.0024178274907171726\n",
            "loss in epoch 9/21 iteration 23/67: 1.3854321241378784 / BPR loss: 1.383638858795166 / Matching loss: 3.4831864468287677e-05 / Item reconstruction: 0.0027330510783940554 / Text reconstruction: 0.0019596004858613014\n",
            "loss in epoch 9/21 iteration 24/67: 1.3854039907455444 / BPR loss: 1.3836944103240967 / Matching loss: 3.3186974178534e-05 / Item reconstruction: 0.0026356265880167484 / Text reconstruction: 0.0017931853653863072\n",
            "loss in epoch 9/21 iteration 25/67: 1.3852261304855347 / BPR loss: 1.3835735321044922 / Matching loss: 3.0826518923277035e-05 / Item reconstruction: 0.002472146414220333 / Text reconstruction: 0.001928031095303595\n",
            "loss in epoch 9/21 iteration 26/67: 1.3849754333496094 / BPR loss: 1.3833115100860596 / Matching loss: 3.177316102664918e-05 / Item reconstruction: 0.0024217518512159586 / Text reconstruction: 0.0021058828569948673\n",
            "loss in epoch 9/21 iteration 27/67: 1.3850353956222534 / BPR loss: 1.383551836013794 / Matching loss: 2.8655467758653685e-05 / Item reconstruction: 0.0021819407120347023 / Text reconstruction: 0.0018196487799286842\n",
            "loss in epoch 9/21 iteration 28/67: 1.3852108716964722 / BPR loss: 1.3837404251098633 / Matching loss: 3.060376548091881e-05 / Item reconstruction: 0.0021506024058908224 / Text reconstruction: 0.0018229903653264046\n",
            "loss in epoch 9/21 iteration 29/67: 1.3848828077316284 / BPR loss: 1.3834011554718018 / Matching loss: 3.230939546483569e-05 / Item reconstruction: 0.0020792903378605843 / Text reconstruction: 0.0020486831199377775\n",
            "loss in epoch 9/21 iteration 30/67: 1.384901762008667 / BPR loss: 1.38344407081604 / Matching loss: 3.1042676710058004e-05 / Item reconstruction: 0.002102963160723448 / Text reconstruction: 0.0018763813422992826\n",
            "loss in epoch 9/21 iteration 31/67: 1.3849482536315918 / BPR loss: 1.3836127519607544 / Matching loss: 3.0890227208146825e-05 / Item reconstruction: 0.0019597867503762245 / Text reconstruction: 0.0016238047974184155\n",
            "loss in epoch 9/21 iteration 32/67: 1.3847483396530151 / BPR loss: 1.383439064025879 / Matching loss: 3.0012433853698894e-05 / Item reconstruction: 0.0019352955278009176 / Text reconstruction: 0.0015582757769152522\n",
            "loss in epoch 9/21 iteration 33/67: 1.3854094743728638 / BPR loss: 1.3836970329284668 / Matching loss: 3.307126826257445e-05 / Item reconstruction: 0.002588610863313079 / Text reconstruction: 0.0019258738029748201\n",
            "loss in epoch 9/21 iteration 34/67: 1.3859461545944214 / BPR loss: 1.3842194080352783 / Matching loss: 3.290069798822515e-05 / Item reconstruction: 0.002657477045431733 / Text reconstruction: 0.0018255007453262806\n",
            "loss in epoch 9/21 iteration 35/67: 1.3859413862228394 / BPR loss: 1.384110450744629 / Matching loss: 3.2439016649732366e-05 / Item reconstruction: 0.0027477892581373453 / Text reconstruction: 0.002123379847034812\n",
            "loss in epoch 9/21 iteration 36/67: 1.387607216835022 / BPR loss: 1.385810375213623 / Matching loss: 4.236658787704073e-05 / Item reconstruction: 0.0027814500499516726 / Text reconstruction: 0.0018193143187090755\n",
            "loss in epoch 9/21 iteration 37/67: 1.3874659538269043 / BPR loss: 1.3857688903808594 / Matching loss: 4.9184702220372856e-05 / Item reconstruction: 0.00269137741997838 / Text reconstruction: 0.0015110443346202374\n",
            "loss in epoch 9/21 iteration 38/67: 1.387416958808899 / BPR loss: 1.3857567310333252 / Matching loss: 3.996139275841415e-05 / Item reconstruction: 0.002705405466258526 / Text reconstruction: 0.001338369445875287\n",
            "loss in epoch 9/21 iteration 39/67: 1.3875503540039062 / BPR loss: 1.3859305381774902 / Matching loss: 4.290421202313155e-05 / Item reconstruction: 0.002554334467276931 / Text reconstruction: 0.0014984195586293936\n",
            "loss in epoch 9/21 iteration 40/67: 1.387664794921875 / BPR loss: 1.3861039876937866 / Matching loss: 4.6725755964871496e-05 / Item reconstruction: 0.0025502750650048256 / Text reconstruction: 0.0011943017598241568\n",
            "loss in epoch 9/21 iteration 41/67: 1.3866539001464844 / BPR loss: 1.385055422782898 / Matching loss: 4.361590254120529e-05 / Item reconstruction: 0.002460962627083063 / Text reconstruction: 0.0016220682300627232\n",
            "loss in epoch 9/21 iteration 42/67: 1.3850483894348145 / BPR loss: 1.3834530115127563 / Matching loss: 2.6874047762248665e-05 / Item reconstruction: 0.0022947839461266994 / Text reconstruction: 0.00210579507984221\n",
            "loss in epoch 9/21 iteration 43/67: 1.3846683502197266 / BPR loss: 1.3830785751342773 / Matching loss: 3.46731576428283e-05 / Item reconstruction: 0.0023944727145135403 / Text reconstruction: 0.0017891025636345148\n",
            "loss in epoch 9/21 iteration 44/67: 1.3870368003845215 / BPR loss: 1.385648250579834 / Matching loss: 4.3125965021317825e-05 / Item reconstruction: 0.002300678053870797 / Text reconstruction: 0.0009752932819537818\n",
            "loss in epoch 9/21 iteration 45/67: 1.38735032081604 / BPR loss: 1.3860957622528076 / Matching loss: 4.4862514187116176e-05 / Item reconstruction: 0.0021034879609942436 / Text reconstruction: 0.0007896645693108439\n",
            "loss in epoch 9/21 iteration 46/67: 1.3871996402740479 / BPR loss: 1.3858113288879395 / Matching loss: 3.9286136598093435e-05 / Item reconstruction: 0.0023264186456799507 / Text reconstruction: 0.0009287007269449532\n",
            "loss in epoch 9/21 iteration 47/67: 1.3872015476226807 / BPR loss: 1.3858497142791748 / Matching loss: 3.7245743442326784e-05 / Item reconstruction: 0.0022325445897877216 / Text reconstruction: 0.0009915933478623629\n",
            "loss in epoch 9/21 iteration 48/67: 1.3872358798980713 / BPR loss: 1.3858747482299805 / Matching loss: 4.4149801396997645e-05 / Item reconstruction: 0.002240236848592758 / Text reconstruction: 0.0009846334578469396\n",
            "loss in epoch 9/21 iteration 49/67: 1.387597918510437 / BPR loss: 1.3861987590789795 / Matching loss: 3.606169775594026e-05 / Item reconstruction: 0.00230413768440485 / Text reconstruction: 0.0010551994200795889\n",
            "loss in epoch 9/21 iteration 50/67: 1.3875977993011475 / BPR loss: 1.386162519454956 / Matching loss: 4.3538399040699005e-05 / Item reconstruction: 0.0023757489398121834 / Text reconstruction: 0.0010190195171162486\n",
            "loss in epoch 9/21 iteration 51/67: 1.3875871896743774 / BPR loss: 1.3863399028778076 / Matching loss: 4.629112663678825e-05 / Item reconstruction: 0.0020897414069622755 / Text reconstruction: 0.0007810688111931086\n",
            "loss in epoch 9/21 iteration 52/67: 1.3874093294143677 / BPR loss: 1.38608717918396 / Matching loss: 4.390707181300968e-05 / Item reconstruction: 0.00215225201100111 / Text reconstruction: 0.001010777079500258\n",
            "loss in epoch 9/21 iteration 53/67: 1.3872826099395752 / BPR loss: 1.3860334157943726 / Matching loss: 4.065788380103186e-05 / Item reconstruction: 0.002038099803030491 / Text reconstruction: 0.0009474493563175201\n",
            "loss in epoch 9/21 iteration 54/67: 1.387664556503296 / BPR loss: 1.3864421844482422 / Matching loss: 4.692142101703212e-05 / Item reconstruction: 0.002073204843327403 / Text reconstruction: 0.000693884096108377\n",
            "loss in epoch 9/21 iteration 55/67: 1.3874796628952026 / BPR loss: 1.3862800598144531 / Matching loss: 4.448606341611594e-05 / Item reconstruction: 0.0020288038067519665 / Text reconstruction: 0.0007036419119685888\n",
            "loss in epoch 9/21 iteration 56/67: 1.3874428272247314 / BPR loss: 1.3862199783325195 / Matching loss: 4.3112129787914455e-05 / Item reconstruction: 0.0020950273610651493 / Text reconstruction: 0.0006607823306694627\n",
            "loss in epoch 9/21 iteration 57/67: 1.3873755931854248 / BPR loss: 1.3861773014068604 / Matching loss: 4.1803887143032625e-05 / Item reconstruction: 0.002021107356995344 / Text reconstruction: 0.0007293869857676327\n",
            "loss in epoch 9/21 iteration 58/67: 1.3873674869537354 / BPR loss: 1.386237621307373 / Matching loss: 3.866889892378822e-05 / Item reconstruction: 0.0019105947576463223 / Text reconstruction: 0.0006793159991502762\n",
            "loss in epoch 9/21 iteration 59/67: 1.3875237703323364 / BPR loss: 1.3863458633422852 / Matching loss: 4.428190732141957e-05 / Item reconstruction: 0.002014563884586096 / Text reconstruction: 0.0006318505620583892\n",
            "loss in epoch 9/21 iteration 60/67: 1.387345552444458 / BPR loss: 1.3862078189849854 / Matching loss: 4.111414455110207e-05 / Item reconstruction: 0.0019264186266809702 / Text reconstruction: 0.0006669176509603858\n",
            "loss in epoch 9/21 iteration 61/67: 1.387347936630249 / BPR loss: 1.3862441778182983 / Matching loss: 4.09882704843767e-05 / Item reconstruction: 0.0018824688158929348 / Text reconstruction: 0.00060742546338588\n",
            "loss in epoch 9/21 iteration 62/67: 1.386924147605896 / BPR loss: 1.3858139514923096 / Matching loss: 3.193024531356059e-05 / Item reconstruction: 0.0017753285355865955 / Text reconstruction: 0.0009530683164484799\n",
            "loss in epoch 9/21 iteration 63/67: 1.3874425888061523 / BPR loss: 1.3862452507019043 / Matching loss: 4.616195656126365e-05 / Item reconstruction: 0.0021007198374718428 / Text reconstruction: 0.0005041867261752486\n",
            "loss in epoch 9/21 iteration 64/67: 1.387470006942749 / BPR loss: 1.3863592147827148 / Matching loss: 4.215822264086455e-05 / Item reconstruction: 0.0019415300339460373 / Text reconstruction: 0.0004893287550657988\n",
            "loss in epoch 9/21 iteration 65/67: 1.3874313831329346 / BPR loss: 1.38633131980896 / Matching loss: 4.2235886212438345e-05 / Item reconstruction: 0.0019003378693014383 / Text reconstruction: 0.0005382293602451682\n",
            "loss in epoch 9/21 iteration 66/67: 1.3871588706970215 / BPR loss: 1.386262059211731 / Matching loss: 3.138524334644899e-05 / Item reconstruction: 0.0014775714371353388 / Text reconstruction: 0.0006337465019896626\n",
            "loss in epoch 9/21 iteration 67/67: 1.3871952295303345 / BPR loss: 1.3863842487335205 / Matching loss: 2.8718561225105077e-05 / Item reconstruction: 0.0013088008854538202 / Text reconstruction: 0.0006388651672750711\n",
            " 45% 9/20 [17:47<21:43, 118.46s/it]loss in epoch 10/21 iteration 0/67: 1.3874289989471436 / BPR loss: 1.3860607147216797 / Matching loss: 5.040335963713005e-05 / Item reconstruction: 0.0023540291003882885 / Text reconstruction: 0.0007040806231088936\n",
            "loss in epoch 10/21 iteration 1/67: 1.3861953020095825 / BPR loss: 1.38460111618042 / Matching loss: 4.044399975100532e-05 / Item reconstruction: 0.0023760399781167507 / Text reconstruction: 0.0018289632862433791\n",
            "loss in epoch 10/21 iteration 2/67: 1.3850274085998535 / BPR loss: 1.3832728862762451 / Matching loss: 3.682021997519769e-05 / Item reconstruction: 0.0024600252509117126 / Text reconstruction: 0.002438299125060439\n",
            "loss in epoch 10/21 iteration 3/67: 1.3841054439544678 / BPR loss: 1.3825405836105347 / Matching loss: 3.585094236768782e-05 / Item reconstruction: 0.0023191142827272415 / Text reconstruction: 0.0018473734380677342\n",
            "loss in epoch 10/21 iteration 4/67: 1.3840510845184326 / BPR loss: 1.3825095891952515 / Matching loss: 3.930601087631658e-05 / Item reconstruction: 0.0023479382507503033 / Text reconstruction: 0.0016407223884016275\n",
            "loss in epoch 10/21 iteration 5/67: 1.3839868307113647 / BPR loss: 1.3825052976608276 / Matching loss: 3.267664578743279e-05 / Item reconstruction: 0.0021817758679389954 / Text reconstruction: 0.0017898149089887738\n",
            "loss in epoch 10/21 iteration 6/67: 1.3842804431915283 / BPR loss: 1.3828608989715576 / Matching loss: 2.9596460080938414e-05 / Item reconstruction: 0.0020087631419301033 / Text reconstruction: 0.00192819454241544\n",
            "loss in epoch 10/21 iteration 7/67: 1.3841099739074707 / BPR loss: 1.382685661315918 / Matching loss: 3.0948493076721206e-05 / Item reconstruction: 0.0020653873216360807 / Text reconstruction: 0.0018029678612947464\n",
            "loss in epoch 10/21 iteration 8/67: 1.3839080333709717 / BPR loss: 1.3826048374176025 / Matching loss: 3.1995150493457913e-05 / Item reconstruction: 0.001890793559141457 / Text reconstruction: 0.0016290510538965464\n",
            "loss in epoch 10/21 iteration 9/67: 1.3839770555496216 / BPR loss: 1.3827390670776367 / Matching loss: 3.179264967911877e-05 / Item reconstruction: 0.001813829643651843 / Text reconstruction: 0.0014958151150494814\n",
            "loss in epoch 10/21 iteration 10/67: 1.3836933374404907 / BPR loss: 1.382480263710022 / Matching loss: 2.8462356567615643e-05 / Item reconstruction: 0.0017890348099172115 / Text reconstruction: 0.0014501409605145454\n",
            "loss in epoch 10/21 iteration 11/67: 1.3836783170700073 / BPR loss: 1.3825106620788574 / Matching loss: 2.732630309765227e-05 / Item reconstruction: 0.0017404775135219097 / Text reconstruction: 0.0013506769901141524\n",
            "loss in epoch 10/21 iteration 12/67: 1.3840528726577759 / BPR loss: 1.3828154802322388 / Matching loss: 3.277458745287731e-05 / Item reconstruction: 0.0018856325186789036 / Text reconstruction: 0.0013086615363135934\n",
            "loss in epoch 10/21 iteration 13/67: 1.3835482597351074 / BPR loss: 1.3823275566101074 / Matching loss: 3.329929677420296e-05 / Item reconstruction: 0.0018622726202011108 / Text reconstruction: 0.0012813331559300423\n",
            "loss in epoch 10/21 iteration 14/67: 1.3835728168487549 / BPR loss: 1.3823914527893066 / Matching loss: 2.9921608074801043e-05 / Item reconstruction: 0.0017862197710201144 / Text reconstruction: 0.0012917101848870516\n",
            "loss in epoch 10/21 iteration 15/67: 1.383444905281067 / BPR loss: 1.3822638988494873 / Matching loss: 2.867588773369789e-05 / Item reconstruction: 0.0017309340182691813 / Text reconstruction: 0.0014338935725390911\n",
            "loss in epoch 10/21 iteration 16/67: 1.3835060596466064 / BPR loss: 1.3823915719985962 / Matching loss: 2.780788236123044e-05 / Item reconstruction: 0.0015821149572730064 / Text reconstruction: 0.0014780331403017044\n",
            "loss in epoch 10/21 iteration 17/67: 1.3841559886932373 / BPR loss: 1.3829824924468994 / Matching loss: 2.815930565702729e-05 / Item reconstruction: 0.0016573546454310417 / Text reconstruction: 0.0015836686361581087\n",
            "loss in epoch 10/21 iteration 18/67: 1.3874211311340332 / BPR loss: 1.3855912685394287 / Matching loss: 4.087098204763606e-05 / Item reconstruction: 0.00268612545914948 / Text reconstruction: 0.0022296791430562735\n",
            "loss in epoch 10/21 iteration 19/67: 1.3879176378250122 / BPR loss: 1.3860671520233154 / Matching loss: 3.98634365410544e-05 / Item reconstruction: 0.002747494727373123 / Text reconstruction: 0.0021847037132829428\n",
            "loss in epoch 10/21 iteration 20/67: 1.3880456686019897 / BPR loss: 1.3863246440887451 / Matching loss: 3.96051473217085e-05 / Item reconstruction: 0.002662344602867961 / Text reconstruction: 0.0017512212507426739\n",
            "loss in epoch 10/21 iteration 21/67: 1.3875916004180908 / BPR loss: 1.3857877254486084 / Matching loss: 4.2881365516223013e-05 / Item reconstruction: 0.0028815099503844976 / Text reconstruction: 0.001601146999746561\n",
            "loss in epoch 10/21 iteration 22/67: 1.3846646547317505 / BPR loss: 1.3828121423721313 / Matching loss: 3.0035986128496006e-05 / Item reconstruction: 0.0028287116438150406 / Text reconstruction: 0.002040799707174301\n",
            "loss in epoch 10/21 iteration 23/67: 1.3846242427825928 / BPR loss: 1.3828752040863037 / Matching loss: 3.3682586945360526e-05 / Item reconstruction: 0.0026788064278662205 / Text reconstruction: 0.0018793013878166676\n",
            "loss in epoch 10/21 iteration 24/67: 1.3846728801727295 / BPR loss: 1.3829705715179443 / Matching loss: 3.2390107662649825e-05 / Item reconstruction: 0.0026127302553504705 / Text reconstruction: 0.0018174932338297367\n",
            "loss in epoch 10/21 iteration 25/67: 1.3848261833190918 / BPR loss: 1.3831512928009033 / Matching loss: 3.3251679269596934e-05 / Item reconstruction: 0.0025654113851487637 / Text reconstruction: 0.0017944176215678453\n",
            "loss in epoch 10/21 iteration 26/67: 1.384305715560913 / BPR loss: 1.3827546834945679 / Matching loss: 2.9538903618231416e-05 / Item reconstruction: 0.0023382529616355896 / Text reconstruction: 0.001761717488989234\n",
            "loss in epoch 10/21 iteration 27/67: 1.3842463493347168 / BPR loss: 1.3827202320098877 / Matching loss: 2.9598271794384345e-05 / Item reconstruction: 0.0023068306036293507 / Text reconstruction: 0.001715285936370492\n",
            "loss in epoch 10/21 iteration 28/67: 1.3844683170318604 / BPR loss: 1.3830407857894897 / Matching loss: 2.9986051231389865e-05 / Item reconstruction: 0.002161981537938118 / Text reconstruction: 0.0015823876019567251\n",
            "loss in epoch 10/21 iteration 29/67: 1.384117841720581 / BPR loss: 1.3827141523361206 / Matching loss: 2.7254794986220077e-05 / Item reconstruction: 0.002100656507536769 / Text reconstruction: 0.0016302638687193394\n",
            "loss in epoch 10/21 iteration 30/67: 1.3840034008026123 / BPR loss: 1.3826279640197754 / Matching loss: 2.802084964059759e-05 / Item reconstruction: 0.0020426674745976925 / Text reconstruction: 0.0016299248673021793\n",
            "loss in epoch 10/21 iteration 31/67: 1.384298324584961 / BPR loss: 1.3829586505889893 / Matching loss: 2.7536583729670383e-05 / Item reconstruction: 0.0020008892752230167 / Text reconstruction: 0.0015584076754748821\n",
            "loss in epoch 10/21 iteration 32/67: 1.3840409517288208 / BPR loss: 1.3827784061431885 / Matching loss: 2.947062239400111e-05 / Item reconstruction: 0.0019032113486900926 / Text reconstruction: 0.0014070685720071197\n",
            "loss in epoch 10/21 iteration 33/67: 1.3848938941955566 / BPR loss: 1.3831732273101807 / Matching loss: 3.12843440042343e-05 / Item reconstruction: 0.0026074987836182117 / Text reconstruction: 0.001928161014802754\n",
            "loss in epoch 10/21 iteration 34/67: 1.3856936693191528 / BPR loss: 1.3840371370315552 / Matching loss: 2.980082354042679e-05 / Item reconstruction: 0.0026117092929780483 / Text reconstruction: 0.0016045067459344864\n",
            "loss in epoch 10/21 iteration 35/67: 1.3854674100875854 / BPR loss: 1.3838468790054321 / Matching loss: 2.8500293410615996e-05 / Item reconstruction: 0.002533351071178913 / Text reconstruction: 0.0016266611637547612\n",
            "loss in epoch 10/21 iteration 36/67: 1.3871392011642456 / BPR loss: 1.3855366706848145 / Matching loss: 3.897532951668836e-05 / Item reconstruction: 0.002599563915282488 / Text reconstruction: 0.0013190738391131163\n",
            "loss in epoch 10/21 iteration 37/67: 1.3875571489334106 / BPR loss: 1.3859748840332031 / Matching loss: 3.962812479585409e-05 / Item reconstruction: 0.002599524799734354 / Text reconstruction: 0.0012147075030952692\n",
            "loss in epoch 10/21 iteration 38/67: 1.3872214555740356 / BPR loss: 1.3856348991394043 / Matching loss: 3.7041445466456935e-05 / Item reconstruction: 0.0026302968617528677 / Text reconstruction: 0.0011721099726855755\n",
            "loss in epoch 10/21 iteration 39/67: 1.387428879737854 / BPR loss: 1.3859065771102905 / Matching loss: 3.7360114220064133e-05 / Item reconstruction: 0.002491968683898449 / Text reconstruction: 0.0011952528730034828\n",
            "loss in epoch 10/21 iteration 40/67: 1.3875858783721924 / BPR loss: 1.3861032724380493 / Matching loss: 4.1316900023957714e-05 / Item reconstruction: 0.0024907500483095646 / Text reconstruction: 0.0009794225916266441\n",
            "loss in epoch 10/21 iteration 41/67: 1.3862371444702148 / BPR loss: 1.3846943378448486 / Matching loss: 3.939568705391139e-05 / Item reconstruction: 0.002473915461450815 / Text reconstruction: 0.0013329583453014493\n",
            "loss in epoch 10/21 iteration 42/67: 1.3841018676757812 / BPR loss: 1.3825688362121582 / Matching loss: 2.5863806513370946e-05 / Item reconstruction: 0.002223010640591383 / Text reconstruction: 0.0019782271701842546\n",
            "loss in epoch 10/21 iteration 43/67: 1.3837522268295288 / BPR loss: 1.3821797370910645 / Matching loss: 3.080893657170236e-05 / Item reconstruction: 0.002359999343752861 / Text reconstruction: 0.001808233791962266\n",
            "loss in epoch 10/21 iteration 44/67: 1.387076735496521 / BPR loss: 1.3857903480529785 / Matching loss: 3.9048929465934634e-05 / Item reconstruction: 0.002181186806410551 / Text reconstruction: 0.0007829808164387941\n",
            "loss in epoch 10/21 iteration 45/67: 1.3872932195663452 / BPR loss: 1.3861126899719238 / Matching loss: 4.09415370086208e-05 / Item reconstruction: 0.002062716521322727 / Text reconstruction: 0.0005413969629444182\n",
            "loss in epoch 10/21 iteration 46/67: 1.3871588706970215 / BPR loss: 1.385764718055725 / Matching loss: 3.770071634789929e-05 / Item reconstruction: 0.0023750802502036095 / Text reconstruction: 0.0008445960702374578\n",
            "loss in epoch 10/21 iteration 47/67: 1.3869221210479736 / BPR loss: 1.3856394290924072 / Matching loss: 3.2405132515123114e-05 / Item reconstruction: 0.00214033923111856 / Text reconstruction: 0.0009006927139125764\n",
            "loss in epoch 10/21 iteration 48/67: 1.387085199356079 / BPR loss: 1.3858013153076172 / Matching loss: 3.8388250686693937e-05 / Item reconstruction: 0.002154809422791004 / Text reconstruction: 0.0008401891100220382\n",
            "loss in epoch 10/21 iteration 49/67: 1.387228012084961 / BPR loss: 1.3858983516693115 / Matching loss: 3.2363001082558185e-05 / Item reconstruction: 0.0022371953818947077 / Text reconstruction: 0.0008941414998844266\n",
            "loss in epoch 10/21 iteration 50/67: 1.3872184753417969 / BPR loss: 1.3859416246414185 / Matching loss: 3.6523822927847505e-05 / Item reconstruction: 0.002174601424485445 / Text reconstruction: 0.0007655429653823376\n",
            "loss in epoch 10/21 iteration 51/67: 1.3875151872634888 / BPR loss: 1.3863145112991333 / Matching loss: 4.2199597373837605e-05 / Item reconstruction: 0.002116590738296509 / Text reconstruction: 0.0005006039282307029\n",
            "loss in epoch 10/21 iteration 52/67: 1.3873156309127808 / BPR loss: 1.3860392570495605 / Matching loss: 4.072747833561152e-05 / Item reconstruction: 0.0021649268455803394 / Text reconstruction: 0.0007658389513380826\n",
            "loss in epoch 10/21 iteration 53/67: 1.3872590065002441 / BPR loss: 1.385982632637024 / Matching loss: 3.8114994822535664e-05 / Item reconstruction: 0.0021388321183621883 / Text reconstruction: 0.0008442932739853859\n",
            "loss in epoch 10/21 iteration 54/67: 1.3874858617782593 / BPR loss: 1.3863074779510498 / Matching loss: 4.35277761425823e-05 / Item reconstruction: 0.0020294771529734135 / Text reconstruction: 0.0006009041680954397\n",
            "loss in epoch 10/21 iteration 55/67: 1.3874188661575317 / BPR loss: 1.386236310005188 / Matching loss: 4.033012373838574e-05 / Item reconstruction: 0.0020313565619289875 / Text reconstruction: 0.0006330792675726116\n",
            "loss in epoch 10/21 iteration 56/67: 1.3873530626296997 / BPR loss: 1.3861684799194336 / Matching loss: 4.2484101868467405e-05 / Item reconstruction: 0.0020819343626499176 / Text reconstruction: 0.0005057933158241212\n",
            "loss in epoch 10/21 iteration 57/67: 1.3875154256820679 / BPR loss: 1.3863332271575928 / Matching loss: 3.760923937079497e-05 / Item reconstruction: 0.0020421231165528297 / Text reconstruction: 0.0006181527860462666\n",
            "loss in epoch 10/21 iteration 58/67: 1.3873705863952637 / BPR loss: 1.3862773180007935 / Matching loss: 3.68189430446364e-05 / Item reconstruction: 0.001891881925985217 / Text reconstruction: 0.0005526861641556025\n",
            "loss in epoch 10/21 iteration 59/67: 1.3874330520629883 / BPR loss: 1.386300802230835 / Matching loss: 4.083432941115461e-05 / Item reconstruction: 0.0020005544647574425 / Text reconstruction: 0.0004555745981633663\n",
            "loss in epoch 10/21 iteration 60/67: 1.387263536453247 / BPR loss: 1.3862037658691406 / Matching loss: 3.794645090238191e-05 / Item reconstruction: 0.0018523572944104671 / Text reconstruction: 0.0004789026570506394\n",
            "loss in epoch 10/21 iteration 61/67: 1.3874934911727905 / BPR loss: 1.3864675760269165 / Matching loss: 3.618224582169205e-05 / Item reconstruction: 0.001810781890526414 / Text reconstruction: 0.00042143804603256285\n",
            "loss in epoch 10/21 iteration 62/67: 1.3867766857147217 / BPR loss: 1.3856985569000244 / Matching loss: 2.8592030503205024e-05 / Item reconstruction: 0.0017429213039577007 / Text reconstruction: 0.00089029292576015\n",
            "loss in epoch 10/21 iteration 63/67: 1.3872157335281372 / BPR loss: 1.3860249519348145 / Matching loss: 4.6089699026197195e-05 / Item reconstruction: 0.0021138438023626804 / Text reconstruction: 0.00043848855420947075\n",
            "loss in epoch 10/21 iteration 64/67: 1.387603521347046 / BPR loss: 1.386482834815979 / Matching loss: 4.2154202674282715e-05 / Item reconstruction: 0.002004047390073538 / Text reconstruction: 0.00038228643825277686\n",
            "loss in epoch 10/21 iteration 65/67: 1.3875908851623535 / BPR loss: 1.3864853382110596 / Matching loss: 4.148983134655282e-05 / Item reconstruction: 0.0019558684434741735 / Text reconstruction: 0.0004306384944356978\n",
            "loss in epoch 10/21 iteration 66/67: 1.38712477684021 / BPR loss: 1.386248230934143 / Matching loss: 2.865846545319073e-05 / Item reconstruction: 0.0015005628811195493 / Text reconstruction: 0.0004882687935605645\n",
            "loss in epoch 10/21 iteration 67/67: 1.387121558189392 / BPR loss: 1.3863329887390137 / Matching loss: 2.514412517484743e-05 / Item reconstruction: 0.001317179063335061 / Text reconstruction: 0.0005237279692664742\n",
            " 50% 10/20 [19:42<19:33, 117.32s/it]loss in epoch 11/21 iteration 0/67: 1.3875092267990112 / BPR loss: 1.3861560821533203 / Matching loss: 4.611518670571968e-05 / Item reconstruction: 0.002382494043558836 / Text reconstruction: 0.0005785489920526743\n",
            "loss in epoch 11/21 iteration 1/67: 1.3857067823410034 / BPR loss: 1.3841910362243652 / Matching loss: 4.1023762605618685e-05 / Item reconstruction: 0.002371399663388729 / Text reconstruction: 0.0014456534991040826\n",
            "loss in epoch 11/21 iteration 2/67: 1.3838789463043213 / BPR loss: 1.3822038173675537 / Matching loss: 3.650060898507945e-05 / Item reconstruction: 0.0023618079721927643 / Text reconstruction: 0.0022889936808496714\n",
            "loss in epoch 11/21 iteration 3/67: 1.3832777738571167 / BPR loss: 1.3816313743591309 / Matching loss: 3.485247725620866e-05 / Item reconstruction: 0.0023213978856801987 / Text reconstruction: 0.0022541149519383907\n",
            "loss in epoch 11/21 iteration 4/67: 1.3834304809570312 / BPR loss: 1.381791591644287 / Matching loss: 3.578745236154646e-05 / Item reconstruction: 0.0022640926763415337 / Text reconstruction: 0.00235529663041234\n",
            "loss in epoch 11/21 iteration 5/67: 1.3833955526351929 / BPR loss: 1.3818626403808594 / Matching loss: 3.153522266075015e-05 / Item reconstruction: 0.002102744299918413 / Text reconstruction: 0.002249747049063444\n",
            "loss in epoch 11/21 iteration 6/67: 1.383537769317627 / BPR loss: 1.382081151008606 / Matching loss: 2.980594763357658e-05 / Item reconstruction: 0.001998934429138899 / Text reconstruction: 0.002136681228876114\n",
            "loss in epoch 11/21 iteration 7/67: 1.3831744194030762 / BPR loss: 1.3817589282989502 / Matching loss: 3.0227653041947633e-05 / Item reconstruction: 0.0020044902339577675 / Text reconstruction: 0.0019149064319208264\n",
            "loss in epoch 11/21 iteration 8/67: 1.3829848766326904 / BPR loss: 1.381697177886963 / Matching loss: 2.918246536864899e-05 / Item reconstruction: 0.0018914450192824006 / Text reconstruction: 0.001563796540722251\n",
            "loss in epoch 11/21 iteration 9/67: 1.383151650428772 / BPR loss: 1.3819023370742798 / Matching loss: 3.0909155611880124e-05 / Item reconstruction: 0.0018700999207794666 / Text reconstruction: 0.0014169001951813698\n",
            "loss in epoch 11/21 iteration 10/67: 1.3828599452972412 / BPR loss: 1.38169527053833 / Matching loss: 3.0630239052698016e-05 / Item reconstruction: 0.0017329603433609009 / Text reconstruction: 0.0013373233377933502\n",
            "loss in epoch 11/21 iteration 11/67: 1.3825693130493164 / BPR loss: 1.3814716339111328 / Matching loss: 3.1033043342176825e-05 / Item reconstruction: 0.0016470423433929682 / Text reconstruction: 0.0012160693295300007\n",
            "loss in epoch 11/21 iteration 12/67: 1.3832210302352905 / BPR loss: 1.3820197582244873 / Matching loss: 3.1053732527652755e-05 / Item reconstruction: 0.0018220398342236876 / Text reconstruction: 0.0012962775072082877\n",
            "loss in epoch 11/21 iteration 13/67: 1.382851481437683 / BPR loss: 1.3816578388214111 / Matching loss: 3.1108284019865096e-05 / Item reconstruction: 0.001752121257595718 / Text reconstruction: 0.0014320660848170519\n",
            "loss in epoch 11/21 iteration 14/67: 1.3826229572296143 / BPR loss: 1.381464958190918 / Matching loss: 2.781669536489062e-05 / Item reconstruction: 0.0016536945477128029 / Text reconstruction: 0.001516980119049549\n",
            "loss in epoch 11/21 iteration 15/67: 1.3827967643737793 / BPR loss: 1.3815832138061523 / Matching loss: 2.8721438866341487e-05 / Item reconstruction: 0.0017366185784339905 / Text reconstruction: 0.0015825678128749132\n",
            "loss in epoch 11/21 iteration 16/67: 1.3820819854736328 / BPR loss: 1.3808729648590088 / Matching loss: 2.9119662940502167e-05 / Item reconstruction: 0.001698375795967877 / Text reconstruction: 0.0016534090973436832\n",
            "loss in epoch 11/21 iteration 17/67: 1.383236289024353 / BPR loss: 1.3820582628250122 / Matching loss: 2.7460180717753246e-05 / Item reconstruction: 0.0016645980067551136 / Text reconstruction: 0.0015912845265120268\n",
            "loss in epoch 11/21 iteration 18/67: 1.3869036436080933 / BPR loss: 1.38515305519104 / Matching loss: 3.841143916361034e-05 / Item reconstruction: 0.0025148936547338963 / Text reconstruction: 0.002273841295391321\n",
            "loss in epoch 11/21 iteration 19/67: 1.38814377784729 / BPR loss: 1.3862758874893188 / Matching loss: 4.094180985703133e-05 / Item reconstruction: 0.002814135979861021 / Text reconstruction: 0.002099908422678709\n",
            "loss in epoch 11/21 iteration 20/67: 1.3877569437026978 / BPR loss: 1.3860641717910767 / Matching loss: 4.0776259993435815e-05 / Item reconstruction: 0.002633100375533104 / Text reconstruction: 0.0016772793605923653\n",
            "loss in epoch 11/21 iteration 21/67: 1.3873860836029053 / BPR loss: 1.385630488395691 / Matching loss: 4.2617972212610766e-05 / Item reconstruction: 0.0027625402435660362 / Text reconstruction: 0.0016581629170104861\n",
            "loss in epoch 11/21 iteration 22/67: 1.3840080499649048 / BPR loss: 1.38219153881073 / Matching loss: 3.327814192743972e-05 / Item reconstruction: 0.002860790118575096 / Text reconstruction: 0.0017640484729781747\n",
            "loss in epoch 11/21 iteration 23/67: 1.383866786956787 / BPR loss: 1.382150411605835 / Matching loss: 3.1298848625738174e-05 / Item reconstruction: 0.0025939939077943563 / Text reconstruction: 0.0019399432931095362\n",
            "loss in epoch 11/21 iteration 24/67: 1.3839223384857178 / BPR loss: 1.3822147846221924 / Matching loss: 3.3516593248350546e-05 / Item reconstruction: 0.002499750815331936 / Text reconstruction: 0.0021210256963968277\n",
            "loss in epoch 11/21 iteration 25/67: 1.383863925933838 / BPR loss: 1.3822581768035889 / Matching loss: 3.130961340502836e-05 / Item reconstruction: 0.002433846239000559 / Text reconstruction: 0.001787584275007248\n",
            "loss in epoch 11/21 iteration 26/67: 1.3836108446121216 / BPR loss: 1.3820804357528687 / Matching loss: 3.155968079227023e-05 / Item reconstruction: 0.002324711764231324 / Text reconstruction: 0.0016820200253278017\n",
            "loss in epoch 11/21 iteration 27/67: 1.383315086364746 / BPR loss: 1.381859540939331 / Matching loss: 2.884781497414224e-05 / Item reconstruction: 0.0021344940178096294 / Text reconstruction: 0.0017971729394048452\n",
            "loss in epoch 11/21 iteration 28/67: 1.383426308631897 / BPR loss: 1.3819913864135742 / Matching loss: 2.937981298600789e-05 / Item reconstruction: 0.002100312849506736 / Text reconstruction: 0.0017776403110474348\n",
            "loss in epoch 11/21 iteration 29/67: 1.3837116956710815 / BPR loss: 1.3823286294937134 / Matching loss: 2.826468880812172e-05 / Item reconstruction: 0.002069738693535328 / Text reconstruction: 0.0015997402369976044\n",
            "loss in epoch 11/21 iteration 30/67: 1.3835551738739014 / BPR loss: 1.3821909427642822 / Matching loss: 3.341447882121429e-05 / Item reconstruction: 0.0020693717524409294 / Text reconstruction: 0.0014804009115323424\n",
            "loss in epoch 11/21 iteration 31/67: 1.3833034038543701 / BPR loss: 1.3820462226867676 / Matching loss: 2.6387226171209477e-05 / Item reconstruction: 0.001838131109252572 / Text reconstruction: 0.001558384159579873\n",
            "loss in epoch 11/21 iteration 32/67: 1.3836920261383057 / BPR loss: 1.3824396133422852 / Matching loss: 2.806775773933623e-05 / Item reconstruction: 0.00181095814332366 / Text reconstruction: 0.0015943904872983694\n",
            "loss in epoch 11/21 iteration 33/67: 1.383817195892334 / BPR loss: 1.3820562362670898 / Matching loss: 3.427905176067725e-05 / Item reconstruction: 0.002651162911206484 / Text reconstruction: 0.002004982903599739\n",
            "loss in epoch 11/21 iteration 34/67: 1.3852108716964722 / BPR loss: 1.3835344314575195 / Matching loss: 3.0202692869352177e-05 / Item reconstruction: 0.002612621057778597 / Text reconstruction: 0.001700074877589941\n",
            "loss in epoch 11/21 iteration 35/67: 1.384857416152954 / BPR loss: 1.3831679821014404 / Matching loss: 3.1298797694034874e-05 / Item reconstruction: 0.002571305725723505 / Text reconstruction: 0.0018620432820171118\n",
            "loss in epoch 11/21 iteration 36/67: 1.3871400356292725 / BPR loss: 1.3854676485061646 / Matching loss: 4.1389965190319344e-05 / Item reconstruction: 0.0026511824689805508 / Text reconstruction: 0.0015271384036168456\n",
            "loss in epoch 11/21 iteration 37/67: 1.387292504310608 / BPR loss: 1.385772466659546 / Matching loss: 4.1848918044706807e-05 / Item reconstruction: 0.002511736936867237 / Text reconstruction: 0.0011117157991975546\n",
            "loss in epoch 11/21 iteration 38/67: 1.3872838020324707 / BPR loss: 1.3857238292694092 / Matching loss: 3.701166497194208e-05 / Item reconstruction: 0.0026195747777819633 / Text reconstruction: 0.0010665907757356763\n",
            "loss in epoch 11/21 iteration 39/67: 1.3872265815734863 / BPR loss: 1.3857407569885254 / Matching loss: 3.818215191131458e-05 / Item reconstruction: 0.0024491730146110058 / Text reconstruction: 0.001115195918828249\n",
            "loss in epoch 11/21 iteration 40/67: 1.3874053955078125 / BPR loss: 1.3859732151031494 / Matching loss: 4.200458715786226e-05 / Item reconstruction: 0.0024016876704990864 / Text reconstruction: 0.0009469002252444625\n",
            "loss in epoch 11/21 iteration 41/67: 1.3860212564468384 / BPR loss: 1.3845112323760986 / Matching loss: 3.923860640497878e-05 / Item reconstruction: 0.0023756404407322407 / Text reconstruction: 0.0014151415089145303\n",
            "loss in epoch 11/21 iteration 42/67: 1.3835275173187256 / BPR loss: 1.3820102214813232 / Matching loss: 2.588846291473601e-05 / Item reconstruction: 0.0021648588590323925 / Text reconstruction: 0.0020450609736144543\n",
            "loss in epoch 11/21 iteration 43/67: 1.3828868865966797 / BPR loss: 1.38131844997406 / Matching loss: 2.9069635274936445e-05 / Item reconstruction: 0.002281729131937027 / Text reconstruction: 0.001992408186197281\n",
            "loss in epoch 11/21 iteration 44/67: 1.386898159980774 / BPR loss: 1.385626196861267 / Matching loss: 3.5331937397131696e-05 / Item reconstruction: 0.0021446370519697666 / Text reconstruction: 0.0008221722673624754\n",
            "loss in epoch 11/21 iteration 45/67: 1.3872802257537842 / BPR loss: 1.3860708475112915 / Matching loss: 4.015792364953086e-05 / Item reconstruction: 0.0020408378913998604 / Text reconstruction: 0.0007435836596414447\n",
            "loss in epoch 11/21 iteration 46/67: 1.3867018222808838 / BPR loss: 1.3853678703308105 / Matching loss: 3.255829869885929e-05 / Item reconstruction: 0.0022428506053984165 / Text reconstruction: 0.0008999982965178788\n",
            "loss in epoch 11/21 iteration 47/67: 1.387036681175232 / BPR loss: 1.3856885433197021 / Matching loss: 3.134080907329917e-05 / Item reconstruction: 0.0022421074099838734 / Text reconstruction: 0.000978758791461587\n",
            "loss in epoch 11/21 iteration 48/67: 1.3872674703598022 / BPR loss: 1.3859820365905762 / Matching loss: 3.652232408057898e-05 / Item reconstruction: 0.0021721255034208298 / Text reconstruction: 0.0008144346065819263\n",
            "loss in epoch 11/21 iteration 49/67: 1.387164831161499 / BPR loss: 1.385836124420166 / Matching loss: 3.127989111817442e-05 / Item reconstruction: 0.0022568744607269764 / Text reconstruction: 0.000845440779812634\n",
            "loss in epoch 11/21 iteration 50/67: 1.387446403503418 / BPR loss: 1.3860785961151123 / Matching loss: 3.7816942494828254e-05 / Item reconstruction: 0.002345990389585495 / Text reconstruction: 0.0007849297253414989\n",
            "loss in epoch 11/21 iteration 51/67: 1.387451171875 / BPR loss: 1.3862369060516357 / Matching loss: 4.036322934553027e-05 / Item reconstruction: 0.002146128099411726 / Text reconstruction: 0.0005038699600845575\n",
            "loss in epoch 11/21 iteration 52/67: 1.3873414993286133 / BPR loss: 1.3860658407211304 / Matching loss: 3.7420293665491045e-05 / Item reconstruction: 0.002216293942183256 / Text reconstruction: 0.000650098838377744\n",
            "loss in epoch 11/21 iteration 53/67: 1.387044072151184 / BPR loss: 1.3858349323272705 / Matching loss: 3.52782808477059e-05 / Item reconstruction: 0.0020795457530766726 / Text reconstruction: 0.0006705765845254064\n",
            "loss in epoch 11/21 iteration 54/67: 1.3876862525939941 / BPR loss: 1.3865410089492798 / Matching loss: 4.008311952929944e-05 / Item reconstruction: 0.0020104669965803623 / Text reconstruction: 0.0004996073548682034\n",
            "loss in epoch 11/21 iteration 55/67: 1.3873594999313354 / BPR loss: 1.3861982822418213 / Matching loss: 3.7181594962021336e-05 / Item reconstruction: 0.0020367451943457127 / Text reconstruction: 0.0005282581551000476\n",
            "loss in epoch 11/21 iteration 56/67: 1.3873064517974854 / BPR loss: 1.3861236572265625 / Matching loss: 3.932733307010494e-05 / Item reconstruction: 0.002085927175357938 / Text reconstruction: 0.0005025318823754787\n",
            "loss in epoch 11/21 iteration 57/67: 1.387297511100769 / BPR loss: 1.3861578702926636 / Matching loss: 3.4892022085841745e-05 / Item reconstruction: 0.001979643711820245 / Text reconstruction: 0.0005744730588048697\n",
            "loss in epoch 11/21 iteration 58/67: 1.3873205184936523 / BPR loss: 1.3862248659133911 / Matching loss: 3.2516087230760604e-05 / Item reconstruction: 0.0018861433491110802 / Text reconstruction: 0.0006000382709316909\n",
            "loss in epoch 11/21 iteration 59/67: 1.387520432472229 / BPR loss: 1.3863804340362549 / Matching loss: 3.7877485738135874e-05 / Item reconstruction: 0.002021140418946743 / Text reconstruction: 0.00045756902545690536\n",
            "loss in epoch 11/21 iteration 60/67: 1.3869742155075073 / BPR loss: 1.3859119415283203 / Matching loss: 3.60168851329945e-05 / Item reconstruction: 0.0018451674841344357 / Text reconstruction: 0.0005183368339203298\n",
            "loss in epoch 11/21 iteration 61/67: 1.3872431516647339 / BPR loss: 1.3862082958221436 / Matching loss: 3.269652370363474e-05 / Item reconstruction: 0.0018208452966064215 / Text reconstruction: 0.00045893481001257896\n",
            "loss in epoch 11/21 iteration 62/67: 1.3866909742355347 / BPR loss: 1.385610818862915 / Matching loss: 2.7155623683938757e-05 / Item reconstruction: 0.0017520238179713488 / Text reconstruction: 0.0008847757708281279\n",
            "loss in epoch 11/21 iteration 63/67: 1.3875412940979004 / BPR loss: 1.3863525390625 / Matching loss: 4.112489114049822e-05 / Item reconstruction: 0.0021234138403087854 / Text reconstruction: 0.00042972632218152285\n",
            "loss in epoch 11/21 iteration 64/67: 1.3874882459640503 / BPR loss: 1.386357069015503 / Matching loss: 3.955113425035961e-05 / Item reconstruction: 0.0020146712195128202 / Text reconstruction: 0.0004212524218019098\n",
            "loss in epoch 11/21 iteration 65/67: 1.3873330354690552 / BPR loss: 1.3862278461456299 / Matching loss: 3.9253827708307654e-05 / Item reconstruction: 0.0019571157172322273 / Text reconstruction: 0.00043713825289160013\n",
            "loss in epoch 11/21 iteration 66/67: 1.3872511386871338 / BPR loss: 1.3863730430603027 / Matching loss: 2.6566463930066675e-05 / Item reconstruction: 0.0014995583333075047 / Text reconstruction: 0.0005082424031570554\n",
            "loss in epoch 11/21 iteration 67/67: 1.3871227502822876 / BPR loss: 1.386335849761963 / Matching loss: 2.299315747222863e-05 / Item reconstruction: 0.0013189176097512245 / Text reconstruction: 0.0005219792947173119\n",
            " 55% 11/20 [21:45<17:52, 119.15s/it]loss in epoch 12/21 iteration 0/67: 1.387299656867981 / BPR loss: 1.385976791381836 / Matching loss: 4.179492680123076e-05 / Item reconstruction: 0.0022942661307752132 / Text reconstruction: 0.0006690982263535261\n",
            "loss in epoch 12/21 iteration 1/67: 1.3849477767944336 / BPR loss: 1.3834877014160156 / Matching loss: 3.709953307406977e-05 / Item reconstruction: 0.0022415928542613983 / Text reconstruction: 0.0015111754182726145\n",
            "loss in epoch 12/21 iteration 2/67: 1.3835558891296387 / BPR loss: 1.3818788528442383 / Matching loss: 3.604378434829414e-05 / Item reconstruction: 0.00240576034411788 / Text reconstruction: 0.0021908555645495653\n",
            "loss in epoch 12/21 iteration 3/67: 1.3826591968536377 / BPR loss: 1.381043553352356 / Matching loss: 3.332386404508725e-05 / Item reconstruction: 0.002229782287031412 / Text reconstruction: 0.0023371167480945587\n",
            "loss in epoch 12/21 iteration 4/67: 1.3824424743652344 / BPR loss: 1.3807852268218994 / Matching loss: 3.332101186970249e-05 / Item reconstruction: 0.0022588721476495266 / Text reconstruction: 0.0024721736554056406\n",
            "loss in epoch 12/21 iteration 5/67: 1.3826044797897339 / BPR loss: 1.3811376094818115 / Matching loss: 2.7150781534146518e-05 / Item reconstruction: 0.001970123965293169 / Text reconstruction: 0.0022732543293386698\n",
            "loss in epoch 12/21 iteration 6/67: 1.382781982421875 / BPR loss: 1.381326675415039 / Matching loss: 2.8836489946115762e-05 / Item reconstruction: 0.0020143561996519566 / Text reconstruction: 0.0020963444840162992\n",
            "loss in epoch 12/21 iteration 7/67: 1.382392168045044 / BPR loss: 1.3809900283813477 / Matching loss: 2.8715057851513848e-05 / Item reconstruction: 0.0019215322099626064 / Text reconstruction: 0.0020634965039789677\n",
            "loss in epoch 12/21 iteration 8/67: 1.3818883895874023 / BPR loss: 1.3805537223815918 / Matching loss: 3.0195422368706204e-05 / Item reconstruction: 0.0018830863991752267 / Text reconstruction: 0.0018147560767829418\n",
            "loss in epoch 12/21 iteration 9/67: 1.3827424049377441 / BPR loss: 1.3815317153930664 / Matching loss: 2.967950058518909e-05 / Item reconstruction: 0.0017711927648633718 / Text reconstruction: 0.001477158977650106\n",
            "loss in epoch 12/21 iteration 10/67: 1.3819384574890137 / BPR loss: 1.3807874917984009 / Matching loss: 2.9644706955878064e-05 / Item reconstruction: 0.0016911211423575878 / Text reconstruction: 0.0013787811622023582\n",
            "loss in epoch 12/21 iteration 11/67: 1.381410837173462 / BPR loss: 1.38025963306427 / Matching loss: 2.9827484468114562e-05 / Item reconstruction: 0.0016473705181851983 / Text reconstruction: 0.0014880977105349302\n",
            "loss in epoch 12/21 iteration 12/67: 1.382230281829834 / BPR loss: 1.3810431957244873 / Matching loss: 2.7031970603275113e-05 / Item reconstruction: 0.0016612526960670948 / Text reconstruction: 0.0016467263922095299\n",
            "loss in epoch 12/21 iteration 13/67: 1.3818680047988892 / BPR loss: 1.3806359767913818 / Matching loss: 3.139801265206188e-05 / Item reconstruction: 0.0017464010743424296 / Text reconstruction: 0.0016374614788219333\n",
            "loss in epoch 12/21 iteration 14/67: 1.3815914392471313 / BPR loss: 1.3803331851959229 / Matching loss: 3.0466970201814547e-05 / Item reconstruction: 0.0016882391646504402 / Text reconstruction: 0.001918138237670064\n",
            "loss in epoch 12/21 iteration 15/67: 1.3816211223602295 / BPR loss: 1.3803480863571167 / Matching loss: 2.7180800316273235e-05 / Item reconstruction: 0.001687813550233841 / Text reconstruction: 0.0020097310189157724\n",
            "loss in epoch 12/21 iteration 16/67: 1.381118893623352 / BPR loss: 1.3799245357513428 / Matching loss: 2.7669269911712036e-05 / Item reconstruction: 0.0016532791778445244 / Text reconstruction: 0.001700246357358992\n",
            "loss in epoch 12/21 iteration 17/67: 1.3818793296813965 / BPR loss: 1.3807772397994995 / Matching loss: 2.8428263249224983e-05 / Item reconstruction: 0.0015662601217627525 / Text reconstruction: 0.0014529158361256123\n",
            "loss in epoch 12/21 iteration 18/67: 1.3865101337432861 / BPR loss: 1.3847825527191162 / Matching loss: 3.8375645090127364e-05 / Item reconstruction: 0.002514295279979706 / Text reconstruction: 0.002160258125513792\n",
            "loss in epoch 12/21 iteration 19/67: 1.387917399406433 / BPR loss: 1.3859583139419556 / Matching loss: 3.9855360228102654e-05 / Item reconstruction: 0.002727752085775137 / Text reconstruction: 0.002776704728603363\n",
            "loss in epoch 12/21 iteration 20/67: 1.3878161907196045 / BPR loss: 1.3860304355621338 / Matching loss: 3.732725599547848e-05 / Item reconstruction: 0.002594880759716034 / Text reconstruction: 0.0022546115797013044\n",
            "loss in epoch 12/21 iteration 21/67: 1.3871660232543945 / BPR loss: 1.3854758739471436 / Matching loss: 4.353107578936033e-05 / Item reconstruction: 0.0026703549083322287 / Text reconstruction: 0.001557648996822536\n",
            "loss in epoch 12/21 iteration 22/67: 1.382873773574829 / BPR loss: 1.3810979127883911 / Matching loss: 3.433128586038947e-05 / Item reconstruction: 0.0027275155298411846 / Text reconstruction: 0.0018886011093854904\n",
            "loss in epoch 12/21 iteration 23/67: 1.383100986480713 / BPR loss: 1.381469964981079 / Matching loss: 3.184071829309687e-05 / Item reconstruction: 0.0025017964653670788 / Text reconstruction: 0.001741514541208744\n",
            "loss in epoch 12/21 iteration 24/67: 1.383008360862732 / BPR loss: 1.3813447952270508 / Matching loss: 3.0343029720825143e-05 / Item reconstruction: 0.0024915658868849277 / Text reconstruction: 0.00193693395704031\n",
            "loss in epoch 12/21 iteration 25/67: 1.3832283020019531 / BPR loss: 1.3815932273864746 / Matching loss: 3.136995655950159e-05 / Item reconstruction: 0.0023722518235445023 / Text reconstruction: 0.0020877751521766186\n",
            "loss in epoch 12/21 iteration 26/67: 1.3830230236053467 / BPR loss: 1.3814630508422852 / Matching loss: 2.8900973120471463e-05 / Item reconstruction: 0.002261238405480981 / Text reconstruction: 0.0020026909187436104\n",
            "loss in epoch 12/21 iteration 27/67: 1.382613182067871 / BPR loss: 1.3811264038085938 / Matching loss: 2.9419828933896497e-05 / Item reconstruction: 0.0021459334529936314 / Text reconstruction: 0.001921630697324872\n",
            "loss in epoch 12/21 iteration 28/67: 1.3825684785842896 / BPR loss: 1.3811665773391724 / Matching loss: 2.9730033929808997e-05 / Item reconstruction: 0.0020505015272647142 / Text reconstruction: 0.0017352106515318155\n",
            "loss in epoch 12/21 iteration 29/67: 1.382764220237732 / BPR loss: 1.3814431428909302 / Matching loss: 2.6845555112231523e-05 / Item reconstruction: 0.0019502486102283 / Text reconstruction: 0.001595359412021935\n",
            "loss in epoch 12/21 iteration 30/67: 1.382575511932373 / BPR loss: 1.3812596797943115 / Matching loss: 2.714694528549444e-05 / Item reconstruction: 0.0019491328857839108 / Text reconstruction: 0.0015708308201283216\n",
            "loss in epoch 12/21 iteration 31/67: 1.3826764822006226 / BPR loss: 1.3814318180084229 / Matching loss: 2.8090424166293815e-05 / Item reconstruction: 0.0018579678144305944 / Text reconstruction: 0.0014378719497472048\n",
            "loss in epoch 12/21 iteration 32/67: 1.3818720579147339 / BPR loss: 1.3806476593017578 / Matching loss: 2.9284561605891213e-05 / Item reconstruction: 0.001819557510316372 / Text reconstruction: 0.0014264292549341917\n",
            "loss in epoch 12/21 iteration 33/67: 1.383562684059143 / BPR loss: 1.3818771839141846 / Matching loss: 3.158764957333915e-05 / Item reconstruction: 0.0025065047666430473 / Text reconstruction: 0.0020033312030136585\n",
            "loss in epoch 12/21 iteration 34/67: 1.384628176689148 / BPR loss: 1.3830039501190186 / Matching loss: 3.058528091059998e-05 / Item reconstruction: 0.0026010966394096613 / Text reconstruction: 0.0014652200043201447\n",
            "loss in epoch 12/21 iteration 35/67: 1.3840471506118774 / BPR loss: 1.3824516534805298 / Matching loss: 3.0903913284419104e-05 / Item reconstruction: 0.002504487056285143 / Text reconstruction: 0.001561796641908586\n",
            "loss in epoch 12/21 iteration 36/67: 1.3867671489715576 / BPR loss: 1.3851282596588135 / Matching loss: 3.816582466242835e-05 / Item reconstruction: 0.002597304992377758 / Text reconstruction: 0.0015103372279554605\n",
            "loss in epoch 12/21 iteration 37/67: 1.3872772455215454 / BPR loss: 1.3857686519622803 / Matching loss: 4.172179978922941e-05 / Item reconstruction: 0.0024858196265995502 / Text reconstruction: 0.0011198713909834623\n",
            "loss in epoch 12/21 iteration 38/67: 1.387008547782898 / BPR loss: 1.3854596614837646 / Matching loss: 3.6976111005060375e-05 / Item reconstruction: 0.0025664358399808407 / Text reconstruction: 0.0011435567867010832\n",
            "loss in epoch 12/21 iteration 39/67: 1.3871418237686157 / BPR loss: 1.3856287002563477 / Matching loss: 3.713537080329843e-05 / Item reconstruction: 0.0024936844129115343 / Text reconstruction: 0.001145782065577805\n",
            "loss in epoch 12/21 iteration 40/67: 1.387329339981079 / BPR loss: 1.3859137296676636 / Matching loss: 3.948872472392395e-05 / Item reconstruction: 0.0023333942517638206 / Text reconstruction: 0.001047156983986497\n",
            "loss in epoch 12/21 iteration 41/67: 1.3854374885559082 / BPR loss: 1.3839788436889648 / Matching loss: 3.705472045112401e-05 / Item reconstruction: 0.0023300296161323786 / Text reconstruction: 0.0012828484177589417\n",
            "loss in epoch 12/21 iteration 42/67: 1.3825464248657227 / BPR loss: 1.3810441493988037 / Matching loss: 2.6491819880902767e-05 / Item reconstruction: 0.0021748344879597425 / Text reconstruction: 0.0019419998861849308\n",
            "loss in epoch 12/21 iteration 43/67: 1.3821064233779907 / BPR loss: 1.3805339336395264 / Matching loss: 3.0351255190907978e-05 / Item reconstruction: 0.0022277990356087685 / Text reconstruction: 0.002140905475243926\n",
            "loss in epoch 12/21 iteration 44/67: 1.3867918252944946 / BPR loss: 1.3854458332061768 / Matching loss: 3.463974280748516e-05 / Item reconstruction: 0.00226385286077857 / Text reconstruction: 0.0008969257469289005\n",
            "loss in epoch 12/21 iteration 45/67: 1.387075424194336 / BPR loss: 1.3858414888381958 / Matching loss: 3.7094920116942376e-05 / Item reconstruction: 0.002112356713041663 / Text reconstruction: 0.000703432597219944\n",
            "loss in epoch 12/21 iteration 46/67: 1.3867560625076294 / BPR loss: 1.3854070901870728 / Matching loss: 3.483791078906506e-05 / Item reconstruction: 0.0022265450097620487 / Text reconstruction: 0.0010041318600997329\n",
            "loss in epoch 12/21 iteration 47/67: 1.386966586112976 / BPR loss: 1.3856648206710815 / Matching loss: 2.8733684303006157e-05 / Item reconstruction: 0.002153645269572735 / Text reconstruction: 0.0009809830226004124\n",
            "loss in epoch 12/21 iteration 48/67: 1.3870158195495605 / BPR loss: 1.3857272863388062 / Matching loss: 3.377674147486687e-05 / Item reconstruction: 0.0021755872294306755 / Text reconstruction: 0.000834861071780324\n",
            "loss in epoch 12/21 iteration 49/67: 1.387105941772461 / BPR loss: 1.3857966661453247 / Matching loss: 3.093912891927175e-05 / Item reconstruction: 0.0021987268701195717 / Text reconstruction: 0.0008945456356741488\n",
            "loss in epoch 12/21 iteration 50/67: 1.3872582912445068 / BPR loss: 1.385923981666565 / Matching loss: 3.4896151191787794e-05 / Item reconstruction: 0.002276062499731779 / Text reconstruction: 0.0008073307108134031\n",
            "loss in epoch 12/21 iteration 51/67: 1.387593388557434 / BPR loss: 1.386373519897461 / Matching loss: 3.858649142784998e-05 / Item reconstruction: 0.0021192231215536594 / Text reconstruction: 0.0006079571321606636\n",
            "loss in epoch 12/21 iteration 52/67: 1.3872979879379272 / BPR loss: 1.3860383033752441 / Matching loss: 3.333282802486792e-05 / Item reconstruction: 0.0021584592759609222 / Text reconstruction: 0.0007352989632636309\n",
            "loss in epoch 12/21 iteration 53/67: 1.3870134353637695 / BPR loss: 1.3857929706573486 / Matching loss: 3.549230677890591e-05 / Item reconstruction: 0.0020576613023877144 / Text reconstruction: 0.0007808439549989998\n",
            "loss in epoch 12/21 iteration 54/67: 1.3876177072525024 / BPR loss: 1.3864679336547852 / Matching loss: 3.8988735468592495e-05 / Item reconstruction: 0.002000995445996523 / Text reconstruction: 0.0005513284122571349\n",
            "loss in epoch 12/21 iteration 55/67: 1.3873307704925537 / BPR loss: 1.3861901760101318 / Matching loss: 3.7581008655251935e-05 / Item reconstruction: 0.0020029915031045675 / Text reconstruction: 0.0005077215610072017\n",
            "loss in epoch 12/21 iteration 56/67: 1.3872318267822266 / BPR loss: 1.3860552310943604 / Matching loss: 3.965540963690728e-05 / Item reconstruction: 0.0020691233221441507 / Text reconstruction: 0.0005111870123073459\n",
            "loss in epoch 12/21 iteration 57/67: 1.3871186971664429 / BPR loss: 1.3859721422195435 / Matching loss: 3.435745384194888e-05 / Item reconstruction: 0.0019777549896389246 / Text reconstruction: 0.0006170739652588964\n",
            "loss in epoch 12/21 iteration 58/67: 1.3872206211090088 / BPR loss: 1.3861173391342163 / Matching loss: 3.3709497074596584e-05 / Item reconstruction: 0.00191351561807096 / Text reconstruction: 0.0005641535972245038\n",
            "loss in epoch 12/21 iteration 59/67: 1.3872073888778687 / BPR loss: 1.3860695362091064 / Matching loss: 3.7820656871190295e-05 / Item reconstruction: 0.0020245721098035574 / Text reconstruction: 0.00043853529496118426\n",
            "loss in epoch 12/21 iteration 60/67: 1.3871134519577026 / BPR loss: 1.386081576347351 / Matching loss: 3.2347114029107615e-05 / Item reconstruction: 0.0017742931377142668 / Text reconstruction: 0.0005620765732601285\n",
            "loss in epoch 12/21 iteration 61/67: 1.3872816562652588 / BPR loss: 1.386230707168579 / Matching loss: 3.5693199606612325e-05 / Item reconstruction: 0.0018538788426667452 / Text reconstruction: 0.0004414026625454426\n",
            "loss in epoch 12/21 iteration 62/67: 1.3867567777633667 / BPR loss: 1.3856464624404907 / Matching loss: 2.799073263304308e-05 / Item reconstruction: 0.001793130999431014 / Text reconstruction: 0.000928819237742573\n",
            "loss in epoch 12/21 iteration 63/67: 1.3872482776641846 / BPR loss: 1.3860691785812378 / Matching loss: 4.320574953453615e-05 / Item reconstruction: 0.0020780807826668024 / Text reconstruction: 0.0004844782524742186\n",
            "loss in epoch 12/21 iteration 64/67: 1.387405276298523 / BPR loss: 1.3862884044647217 / Matching loss: 3.7309702747734264e-05 / Item reconstruction: 0.0019941264763474464 / Text reconstruction: 0.00041244117892347276\n",
            "loss in epoch 12/21 iteration 65/67: 1.387712836265564 / BPR loss: 1.3866477012634277 / Matching loss: 3.762624692171812e-05 / Item reconstruction: 0.0018800643738359213 / Text reconstruction: 0.00043713871855288744\n",
            "loss in epoch 12/21 iteration 66/67: 1.3871262073516846 / BPR loss: 1.3862388134002686 / Matching loss: 2.8951602871529758e-05 / Item reconstruction: 0.001505768857896328 / Text reconstruction: 0.0005277935415506363\n",
            "loss in epoch 12/21 iteration 67/67: 1.3871060609817505 / BPR loss: 1.3863482475280762 / Matching loss: 2.2088566765887663e-05 / Item reconstruction: 0.0012582062045112252 / Text reconstruction: 0.0005332758883014321\n",
            " 60% 12/20 [23:44<15:52, 119.01s/it]loss in epoch 13/21 iteration 0/67: 1.3870950937271118 / BPR loss: 1.3857356309890747 / Matching loss: 3.890250809490681e-05 / Item reconstruction: 0.00235242722555995 / Text reconstruction: 0.000721879187040031\n",
            "loss in epoch 13/21 iteration 1/67: 1.3852272033691406 / BPR loss: 1.3836581707000732 / Matching loss: 3.4583637898322195e-05 / Item reconstruction: 0.0022550206631422043 / Text reconstruction: 0.0020347447134554386\n",
            "loss in epoch 13/21 iteration 2/67: 1.3824787139892578 / BPR loss: 1.3807358741760254 / Matching loss: 3.1858249712968245e-05 / Item reconstruction: 0.002234609331935644 / Text reconstruction: 0.0029680996667593718\n",
            "loss in epoch 13/21 iteration 3/67: 1.3817260265350342 / BPR loss: 1.3800400495529175 / Matching loss: 3.339059549034573e-05 / Item reconstruction: 0.002232168335467577 / Text reconstruction: 0.002682717749848962\n",
            "loss in epoch 13/21 iteration 4/67: 1.3813616037368774 / BPR loss: 1.3797590732574463 / Matching loss: 3.316315996926278e-05 / Item reconstruction: 0.0021407967433333397 / Text reconstruction: 0.0024949279613792896\n",
            "loss in epoch 13/21 iteration 5/67: 1.381258249282837 / BPR loss: 1.3797671794891357 / Matching loss: 3.074355481658131e-05 / Item reconstruction: 0.0020017384085804224 / Text reconstruction: 0.0022973923478275537\n",
            "loss in epoch 13/21 iteration 6/67: 1.3816972970962524 / BPR loss: 1.380294680595398 / Matching loss: 2.710218177526258e-05 / Item reconstruction: 0.0019006083020940423 / Text reconstruction: 0.00212584575638175\n",
            "loss in epoch 13/21 iteration 7/67: 1.3808178901672363 / BPR loss: 1.3794262409210205 / Matching loss: 2.9150543923606165e-05 / Item reconstruction: 0.0018901170697063208 / Text reconstruction: 0.0020866328850388527\n",
            "loss in epoch 13/21 iteration 8/67: 1.3805497884750366 / BPR loss: 1.3792400360107422 / Matching loss: 2.739285810093861e-05 / Item reconstruction: 0.0017830815631896257 / Text reconstruction: 0.0019537133630365133\n",
            "loss in epoch 13/21 iteration 9/67: 1.3813550472259521 / BPR loss: 1.3801287412643433 / Matching loss: 2.604982364573516e-05 / Item reconstruction: 0.0016445521032437682 / Text reconstruction: 0.0018897493137046695\n",
            "loss in epoch 13/21 iteration 10/67: 1.3809795379638672 / BPR loss: 1.379762887954712 / Matching loss: 2.7591104299062863e-05 / Item reconstruction: 0.0016586664132773876 / Text reconstruction: 0.001798892393708229\n",
            "loss in epoch 13/21 iteration 11/67: 1.3804162740707397 / BPR loss: 1.3792064189910889 / Matching loss: 2.7828829843201675e-05 / Item reconstruction: 0.0016543500823900104 / Text reconstruction: 0.0017742847558110952\n",
            "loss in epoch 13/21 iteration 12/67: 1.3813869953155518 / BPR loss: 1.3801510334014893 / Matching loss: 2.747502912825439e-05 / Item reconstruction: 0.0017359030898660421 / Text reconstruction: 0.0017030761810019612\n",
            "loss in epoch 13/21 iteration 13/67: 1.381205439567566 / BPR loss: 1.3800251483917236 / Matching loss: 2.9234135581646115e-05 / Item reconstruction: 0.0016509746201336384 / Text reconstruction: 0.0016276226378977299\n",
            "loss in epoch 13/21 iteration 14/67: 1.3806309700012207 / BPR loss: 1.3793786764144897 / Matching loss: 3.02836033370113e-05 / Item reconstruction: 0.0017515941290184855 / Text reconstruction: 0.0017311256378889084\n",
            "loss in epoch 13/21 iteration 15/67: 1.3803961277008057 / BPR loss: 1.3792465925216675 / Matching loss: 2.673881135706324e-05 / Item reconstruction: 0.0015530490782111883 / Text reconstruction: 0.0017318071331828833\n",
            "loss in epoch 13/21 iteration 16/67: 1.380315899848938 / BPR loss: 1.3791109323501587 / Matching loss: 2.7603386115515605e-05 / Item reconstruction: 0.0015876423567533493 / Text reconstruction: 0.0019177626818418503\n",
            "loss in epoch 13/21 iteration 17/67: 1.381016492843628 / BPR loss: 1.3798489570617676 / Matching loss: 2.798796231218148e-05 / Item reconstruction: 0.0015451189829036593 / Text reconstruction: 0.0018346752040088177\n",
            "loss in epoch 13/21 iteration 18/67: 1.3865598440170288 / BPR loss: 1.3848034143447876 / Matching loss: 3.873682362609543e-05 / Item reconstruction: 0.002478271257132292 / Text reconstruction: 0.0023924019187688828\n",
            "loss in epoch 13/21 iteration 19/67: 1.3882094621658325 / BPR loss: 1.3862736225128174 / Matching loss: 4.1147657611873e-05 / Item reconstruction: 0.0027622247580438852 / Text reconstruction: 0.0025677948724478483\n",
            "loss in epoch 13/21 iteration 20/67: 1.3874902725219727 / BPR loss: 1.385652780532837 / Matching loss: 3.714707418112084e-05 / Item reconstruction: 0.002577777486294508 / Text reconstruction: 0.0025568741839379072\n",
            "loss in epoch 13/21 iteration 21/67: 1.3872129917144775 / BPR loss: 1.3853304386138916 / Matching loss: 4.207265010336414e-05 / Item reconstruction: 0.002705307910218835 / Text reconstruction: 0.0024392567574977875\n",
            "loss in epoch 13/21 iteration 22/67: 1.3816558122634888 / BPR loss: 1.3798339366912842 / Matching loss: 3.0329907531267963e-05 / Item reconstruction: 0.002763120923191309 / Text reconstruction: 0.002050227951258421\n",
            "loss in epoch 13/21 iteration 23/67: 1.3821738958358765 / BPR loss: 1.3805229663848877 / Matching loss: 3.1000770832179114e-05 / Item reconstruction: 0.002481447532773018 / Text reconstruction: 0.0018961294554173946\n",
            "loss in epoch 13/21 iteration 24/67: 1.3823634386062622 / BPR loss: 1.3807685375213623 / Matching loss: 2.9513330446206965e-05 / Item reconstruction: 0.002366643399000168 / Text reconstruction: 0.0019105959217995405\n",
            "loss in epoch 13/21 iteration 25/67: 1.38215172290802 / BPR loss: 1.3805365562438965 / Matching loss: 3.130848199361935e-05 / Item reconstruction: 0.0023997309617698193 / Text reconstruction: 0.0019196851644665003\n",
            "loss in epoch 13/21 iteration 26/67: 1.3821035623550415 / BPR loss: 1.3805415630340576 / Matching loss: 2.9086844733683392e-05 / Item reconstruction: 0.002254148479551077 / Text reconstruction: 0.0020290017127990723\n",
            "loss in epoch 13/21 iteration 27/67: 1.381571888923645 / BPR loss: 1.3800790309906006 / Matching loss: 2.8577473131008446e-05 / Item reconstruction: 0.0021174876019358635 / Text reconstruction: 0.002027633599936962\n",
            "loss in epoch 13/21 iteration 28/67: 1.3817578554153442 / BPR loss: 1.3803383111953735 / Matching loss: 2.9080099920975044e-05 / Item reconstruction: 0.002025485970079899 / Text reconstruction: 0.001888226019218564\n",
            "loss in epoch 13/21 iteration 29/67: 1.3816999197006226 / BPR loss: 1.3803001642227173 / Matching loss: 2.9272168831084855e-05 / Item reconstruction: 0.0020036608912050724 / Text reconstruction: 0.0018427877221256495\n",
            "loss in epoch 13/21 iteration 30/67: 1.3814969062805176 / BPR loss: 1.38010835647583 / Matching loss: 2.778250018309336e-05 / Item reconstruction: 0.0019856670405715704 / Text reconstruction: 0.001839946722611785\n",
            "loss in epoch 13/21 iteration 31/67: 1.3817219734191895 / BPR loss: 1.38045334815979 / Matching loss: 2.7427611712482758e-05 / Item reconstruction: 0.0017986227758228779 / Text reconstruction: 0.0017092585330829024\n",
            "loss in epoch 13/21 iteration 32/67: 1.3816032409667969 / BPR loss: 1.3804116249084473 / Matching loss: 2.795552063616924e-05 / Item reconstruction: 0.0017332074930891395 / Text reconstruction: 0.0014848022256046534\n",
            "loss in epoch 13/21 iteration 33/67: 1.3830125331878662 / BPR loss: 1.3812711238861084 / Matching loss: 3.236178963561542e-05 / Item reconstruction: 0.0026355842128396034 / Text reconstruction: 0.0019566104747354984\n",
            "loss in epoch 13/21 iteration 34/67: 1.3837735652923584 / BPR loss: 1.382096290588379 / Matching loss: 3.082104740315117e-05 / Item reconstruction: 0.0026208804920315742 / Text reconstruction: 0.0016797077842056751\n",
            "loss in epoch 13/21 iteration 35/67: 1.3836233615875244 / BPR loss: 1.3820054531097412 / Matching loss: 2.8117130568716675e-05 / Item reconstruction: 0.0025127469561994076 / Text reconstruction: 0.0016673970967531204\n",
            "loss in epoch 13/21 iteration 36/67: 1.3869764804840088 / BPR loss: 1.3853850364685059 / Matching loss: 3.830288915196434e-05 / Item reconstruction: 0.002529939403757453 / Text reconstruction: 0.0014409482246264815\n",
            "loss in epoch 13/21 iteration 37/67: 1.3871184587478638 / BPR loss: 1.385493278503418 / Matching loss: 3.7347141187638044e-05 / Item reconstruction: 0.002515817526727915 / Text reconstruction: 0.0016496384050697088\n",
            "loss in epoch 13/21 iteration 38/67: 1.386397361755371 / BPR loss: 1.3847646713256836 / Matching loss: 3.4381591831333935e-05 / Item reconstruction: 0.002618328435346484 / Text reconstruction: 0.0014457217184826732\n",
            "loss in epoch 13/21 iteration 39/67: 1.3871395587921143 / BPR loss: 1.3856899738311768 / Matching loss: 3.482124884612858e-05 / Item reconstruction: 0.0023224574979394674 / Text reconstruction: 0.0012678736820816994\n",
            "loss in epoch 13/21 iteration 40/67: 1.387165904045105 / BPR loss: 1.3856778144836426 / Matching loss: 4.103611718164757e-05 / Item reconstruction: 0.0024196491576731205 / Text reconstruction: 0.001186123350635171\n",
            "loss in epoch 13/21 iteration 41/67: 1.385094165802002 / BPR loss: 1.3835132122039795 / Matching loss: 3.78310214728117e-05 / Item reconstruction: 0.0024705305695533752 / Text reconstruction: 0.0015394754009321332\n",
            "loss in epoch 13/21 iteration 42/67: 1.381601095199585 / BPR loss: 1.3800287246704102 / Matching loss: 2.7796249923994765e-05 / Item reconstruction: 0.002157696522772312 / Text reconstruction: 0.0023286391515284777\n",
            "loss in epoch 13/21 iteration 43/67: 1.3807612657546997 / BPR loss: 1.379142165184021 / Matching loss: 3.0307292036013678e-05 / Item reconstruction: 0.0022582607343792915 / Text reconstruction: 0.0022982172667980194\n",
            "loss in epoch 13/21 iteration 44/67: 1.386788249015808 / BPR loss: 1.3854129314422607 / Matching loss: 3.24343127431348e-05 / Item reconstruction: 0.002227922435849905 / Text reconstruction: 0.0011444874107837677\n",
            "loss in epoch 13/21 iteration 45/67: 1.3871409893035889 / BPR loss: 1.3859574794769287 / Matching loss: 3.743890192708932e-05 / Item reconstruction: 0.0020218791905790567 / Text reconstruction: 0.0006760807009413838\n",
            "loss in epoch 13/21 iteration 46/67: 1.3866088390350342 / BPR loss: 1.385254144668579 / Matching loss: 3.131467383354902e-05 / Item reconstruction: 0.0022406543139368296 / Text reconstruction: 0.0010153206530958414\n",
            "loss in epoch 13/21 iteration 47/67: 1.3866385221481323 / BPR loss: 1.3852812051773071 / Matching loss: 2.8708791433018632e-05 / Item reconstruction: 0.002227707067504525 / Text reconstruction: 0.0010735215619206429\n",
            "loss in epoch 13/21 iteration 48/67: 1.3867100477218628 / BPR loss: 1.385381817817688 / Matching loss: 3.2966199796646833e-05 / Item reconstruction: 0.0022004619240760803 / Text reconstruction: 0.0009751549223437905\n",
            "loss in epoch 13/21 iteration 49/67: 1.386988878250122 / BPR loss: 1.3856656551361084 / Matching loss: 2.790906000882387e-05 / Item reconstruction: 0.002178380498662591 / Text reconstruction: 0.0010307147167623043\n",
            "loss in epoch 13/21 iteration 50/67: 1.3870588541030884 / BPR loss: 1.3857108354568481 / Matching loss: 3.2959556847345084e-05 / Item reconstruction: 0.0022522173821926117 / Text reconstruction: 0.0009454407845623791\n",
            "loss in epoch 13/21 iteration 51/67: 1.3872623443603516 / BPR loss: 1.3860458135604858 / Matching loss: 3.599494812078774e-05 / Item reconstruction: 0.002100472804158926 / Text reconstruction: 0.0006514833075925708\n",
            "loss in epoch 13/21 iteration 52/67: 1.387001872062683 / BPR loss: 1.385710597038269 / Matching loss: 3.310523970867507e-05 / Item reconstruction: 0.002205359283834696 / Text reconstruction: 0.0007775251287966967\n",
            "loss in epoch 13/21 iteration 53/67: 1.387052059173584 / BPR loss: 1.3858221769332886 / Matching loss: 3.207678673788905e-05 / Item reconstruction: 0.0020641041919589043 / Text reconstruction: 0.0008292208658531308\n",
            "loss in epoch 13/21 iteration 54/67: 1.3879257440567017 / BPR loss: 1.3867017030715942 / Matching loss: 4.0140501369023696e-05 / Item reconstruction: 0.0020919525995850563 / Text reconstruction: 0.0006897426792420447\n",
            "loss in epoch 13/21 iteration 55/67: 1.3876436948776245 / BPR loss: 1.3864754438400269 / Matching loss: 3.53668219759129e-05 / Item reconstruction: 0.001990223303437233 / Text reconstruction: 0.0006882413872517645\n",
            "loss in epoch 13/21 iteration 56/67: 1.3873217105865479 / BPR loss: 1.3861327171325684 / Matching loss: 3.778088648687117e-05 / Item reconstruction: 0.002045260276645422 / Text reconstruction: 0.0006431671790778637\n",
            "loss in epoch 13/21 iteration 57/67: 1.38716721534729 / BPR loss: 1.3860218524932861 / Matching loss: 3.436674160184339e-05 / Item reconstruction: 0.0019398233853280544 / Text reconstruction: 0.0007058749906718731\n",
            "loss in epoch 13/21 iteration 58/67: 1.3870604038238525 / BPR loss: 1.3859620094299316 / Matching loss: 3.3099018764914945e-05 / Item reconstruction: 0.0019061036873608828 / Text reconstruction: 0.0005611705128103495\n",
            "loss in epoch 13/21 iteration 59/67: 1.3872650861740112 / BPR loss: 1.38615882396698 / Matching loss: 3.524154089973308e-05 / Item reconstruction: 0.0019406209466978908 / Text reconstruction: 0.0005029262974858284\n",
            "loss in epoch 13/21 iteration 60/67: 1.3870329856872559 / BPR loss: 1.3859467506408691 / Matching loss: 3.2520190870855004e-05 / Item reconstruction: 0.0018600431503728032 / Text reconstruction: 0.0006178702460601926\n",
            "loss in epoch 13/21 iteration 61/67: 1.3875542879104614 / BPR loss: 1.3864779472351074 / Matching loss: 3.3630902180448174e-05 / Item reconstruction: 0.0018857114482671022 / Text reconstruction: 0.0004995112540200353\n",
            "loss in epoch 13/21 iteration 62/67: 1.3865301609039307 / BPR loss: 1.3854446411132812 / Matching loss: 2.7927817427553236e-05 / Item reconstruction: 0.0018125956412404776 / Text reconstruction: 0.0007561504608020186\n",
            "loss in epoch 13/21 iteration 63/67: 1.3873165845870972 / BPR loss: 1.3861124515533447 / Matching loss: 4.078573692822829e-05 / Item reconstruction: 0.002102179452776909 / Text reconstruction: 0.0005612127715721726\n",
            "loss in epoch 13/21 iteration 64/67: 1.3877887725830078 / BPR loss: 1.3866711854934692 / Matching loss: 3.6867633752990514e-05 / Item reconstruction: 0.001954686129465699 / Text reconstruction: 0.0005168456118553877\n",
            "loss in epoch 13/21 iteration 65/67: 1.387526512145996 / BPR loss: 1.3863872289657593 / Matching loss: 3.9223417843459174e-05 / Item reconstruction: 0.002010060241445899 / Text reconstruction: 0.0004751529486384243\n",
            "loss in epoch 13/21 iteration 66/67: 1.387484073638916 / BPR loss: 1.3866195678710938 / Matching loss: 2.5673220079625025e-05 / Item reconstruction: 0.0014246746432036161 / Text reconstruction: 0.0006321283290162683\n",
            "loss in epoch 13/21 iteration 67/67: 1.387148380279541 / BPR loss: 1.3863542079925537 / Matching loss: 2.1849533368367702e-05 / Item reconstruction: 0.001318804221227765 / Text reconstruction: 0.0005648377700708807\n",
            " 65% 13/20 [25:44<13:55, 119.37s/it]loss in epoch 14/21 iteration 0/67: 1.386858344078064 / BPR loss: 1.3855016231536865 / Matching loss: 4.131165042053908e-05 / Item reconstruction: 0.0023004752583801746 / Text reconstruction: 0.0008253401611000299\n",
            "loss in epoch 14/21 iteration 1/67: 1.3839536905288696 / BPR loss: 1.3823539018630981 / Matching loss: 3.8928217691136524e-05 / Item reconstruction: 0.0022059795446693897 / Text reconstruction: 0.0022887808736413717\n",
            "loss in epoch 14/21 iteration 2/67: 1.3815702199935913 / BPR loss: 1.3798222541809082 / Matching loss: 3.387374454177916e-05 / Item reconstruction: 0.0022651380859315395 / Text reconstruction: 0.0029074312187731266\n",
            "loss in epoch 14/21 iteration 3/67: 1.3799431324005127 / BPR loss: 1.378259301185608 / Matching loss: 3.696209023473784e-05 / Item reconstruction: 0.002229111734777689 / Text reconstruction: 0.002661065896973014\n",
            "loss in epoch 14/21 iteration 4/67: 1.3802603483200073 / BPR loss: 1.3786262273788452 / Matching loss: 3.222277155146003e-05 / Item reconstruction: 0.0021281843073666096 / Text reconstruction: 0.0026892542373389006\n",
            "loss in epoch 14/21 iteration 5/67: 1.3799176216125488 / BPR loss: 1.3783543109893799 / Matching loss: 2.9198621632531285e-05 / Item reconstruction: 0.0019726960454136133 / Text reconstruction: 0.0027390688192099333\n",
            "loss in epoch 14/21 iteration 6/67: 1.3804054260253906 / BPR loss: 1.3788760900497437 / Matching loss: 3.0365550628630444e-05 / Item reconstruction: 0.0019693116191774607 / Text reconstruction: 0.0025716170202940702\n",
            "loss in epoch 14/21 iteration 7/67: 1.3804066181182861 / BPR loss: 1.3789825439453125 / Matching loss: 3.127383388346061e-05 / Item reconstruction: 0.0018823354039341211 / Text reconstruction: 0.002258694265037775\n",
            "loss in epoch 14/21 iteration 8/67: 1.3799479007720947 / BPR loss: 1.3786288499832153 / Matching loss: 2.8803915483877063e-05 / Item reconstruction: 0.0017209432553499937 / Text reconstruction: 0.0021487860940396786\n",
            "loss in epoch 14/21 iteration 9/67: 1.3792957067489624 / BPR loss: 1.3779728412628174 / Matching loss: 3.0387742299353704e-05 / Item reconstruction: 0.0017882043030112982 / Text reconstruction: 0.0019922114443033934\n",
            "loss in epoch 14/21 iteration 10/67: 1.379154086112976 / BPR loss: 1.3778846263885498 / Matching loss: 2.9935767088318244e-05 / Item reconstruction: 0.001707401592284441 / Text reconstruction: 0.0019296390237286687\n",
            "loss in epoch 14/21 iteration 11/67: 1.3788151741027832 / BPR loss: 1.3775767087936401 / Matching loss: 3.098658999078907e-05 / Item reconstruction: 0.0016579527873545885 / Text reconstruction: 0.001892151078209281\n",
            "loss in epoch 14/21 iteration 12/67: 1.3805938959121704 / BPR loss: 1.3792895078659058 / Matching loss: 3.0299626814667135e-05 / Item reconstruction: 0.0017721937038004398 / Text reconstruction: 0.0019403495825827122\n",
            "loss in epoch 14/21 iteration 13/67: 1.3797576427459717 / BPR loss: 1.378458857536316 / Matching loss: 3.076426946790889e-05 / Item reconstruction: 0.0017604471649974585 / Text reconstruction: 0.001938813948072493\n",
            "loss in epoch 14/21 iteration 14/67: 1.3788949251174927 / BPR loss: 1.3776397705078125 / Matching loss: 2.965353814943228e-05 / Item reconstruction: 0.001692523481324315 / Text reconstruction: 0.0018962475005537271\n",
            "loss in epoch 14/21 iteration 15/67: 1.3792786598205566 / BPR loss: 1.3780391216278076 / Matching loss: 2.682612648641225e-05 / Item reconstruction: 0.001664046081714332 / Text reconstruction: 0.001903400057926774\n",
            "loss in epoch 14/21 iteration 16/67: 1.3782267570495605 / BPR loss: 1.3769835233688354 / Matching loss: 2.967021100630518e-05 / Item reconstruction: 0.0016147037968039513 / Text reconstruction: 0.0020304806530475616\n",
            "loss in epoch 14/21 iteration 17/67: 1.379536747932434 / BPR loss: 1.3782751560211182 / Matching loss: 2.8876072974526323e-05 / Item reconstruction: 0.001684064045548439 / Text reconstruction: 0.001954007428139448\n",
            "loss in epoch 14/21 iteration 18/67: 1.3859091997146606 / BPR loss: 1.384117841720581 / Matching loss: 3.6054523661732674e-05 / Item reconstruction: 0.002496755449101329 / Text reconstruction: 0.002535174135118723\n",
            "loss in epoch 14/21 iteration 19/67: 1.3880311250686646 / BPR loss: 1.3860565423965454 / Matching loss: 3.5570446925703436e-05 / Item reconstruction: 0.002694063587114215 / Text reconstruction: 0.0029601729474961758\n",
            "loss in epoch 14/21 iteration 20/67: 1.3876415491104126 / BPR loss: 1.3857841491699219 / Matching loss: 3.719791129697114e-05 / Item reconstruction: 0.002612345153465867 / Text reconstruction: 0.0025701201520860195\n",
            "loss in epoch 14/21 iteration 21/67: 1.3872543573379517 / BPR loss: 1.3854460716247559 / Matching loss: 4.133720358368009e-05 / Item reconstruction: 0.002754002343863249 / Text reconstruction: 0.0019497958710417151\n",
            "loss in epoch 14/21 iteration 22/67: 1.3810193538665771 / BPR loss: 1.3792030811309814 / Matching loss: 3.572287823772058e-05 / Item reconstruction: 0.0028062094934284687 / Text reconstruction: 0.0018873552326112986\n",
            "loss in epoch 14/21 iteration 23/67: 1.3805153369903564 / BPR loss: 1.3787801265716553 / Matching loss: 3.2390784326707944e-05 / Item reconstruction: 0.002571951597929001 / Text reconstruction: 0.0020835166797041893\n",
            "loss in epoch 14/21 iteration 24/67: 1.3810136318206787 / BPR loss: 1.3793351650238037 / Matching loss: 3.108383680228144e-05 / Item reconstruction: 0.0024477653205394745 / Text reconstruction: 0.002116952557116747\n",
            "loss in epoch 14/21 iteration 25/67: 1.3808388710021973 / BPR loss: 1.3791998624801636 / Matching loss: 3.046052370336838e-05 / Item reconstruction: 0.002321619540452957 / Text reconstruction: 0.0022382535971701145\n",
            "loss in epoch 14/21 iteration 26/67: 1.381005883216858 / BPR loss: 1.3794612884521484 / Matching loss: 2.870816933864262e-05 / Item reconstruction: 0.0021536077838391066 / Text reconstruction: 0.0021951436065137386\n",
            "loss in epoch 14/21 iteration 27/67: 1.380241870880127 / BPR loss: 1.378734827041626 / Matching loss: 2.776739165710751e-05 / Item reconstruction: 0.002057925797998905 / Text reconstruction: 0.0022514245938509703\n",
            "loss in epoch 14/21 iteration 28/67: 1.381201148033142 / BPR loss: 1.3798155784606934 / Matching loss: 2.7746289561036974e-05 / Item reconstruction: 0.0019180120434612036 / Text reconstruction: 0.0019935567397624254\n",
            "loss in epoch 14/21 iteration 29/67: 1.3806158304214478 / BPR loss: 1.3792040348052979 / Matching loss: 2.915978984674439e-05 / Item reconstruction: 0.0020218603312969208 / Text reconstruction: 0.0018582285847514868\n",
            "loss in epoch 14/21 iteration 30/67: 1.3808016777038574 / BPR loss: 1.3794814348220825 / Matching loss: 2.750818384811282e-05 / Item reconstruction: 0.0018786826403811574 / Text reconstruction: 0.001766752451658249\n",
            "loss in epoch 14/21 iteration 31/67: 1.3801888227462769 / BPR loss: 1.378917932510376 / Matching loss: 2.78490042546764e-05 / Item reconstruction: 0.0018301343079656363 / Text reconstruction: 0.0016398315783590078\n",
            "loss in epoch 14/21 iteration 32/67: 1.3806456327438354 / BPR loss: 1.3794281482696533 / Matching loss: 2.6819310733117163e-05 / Item reconstruction: 0.001711050164885819 / Text reconstruction: 0.0016754441894590855\n",
            "loss in epoch 14/21 iteration 33/67: 1.3812758922576904 / BPR loss: 1.3795530796051025 / Matching loss: 2.8567726985784248e-05 / Item reconstruction: 0.002556030172854662 / Text reconstruction: 0.002080710371956229\n",
            "loss in epoch 14/21 iteration 34/67: 1.383616328239441 / BPR loss: 1.3819217681884766 / Matching loss: 2.686107109184377e-05 / Item reconstruction: 0.002613578224554658 / Text reconstruction: 0.0018048349302262068\n",
            "loss in epoch 14/21 iteration 35/67: 1.3830795288085938 / BPR loss: 1.3813989162445068 / Matching loss: 2.986527579196263e-05 / Item reconstruction: 0.0025725080631673336 / Text reconstruction: 0.0018220285419374704\n",
            "loss in epoch 14/21 iteration 36/67: 1.3867193460464478 / BPR loss: 1.3851215839385986 / Matching loss: 3.7007372156949714e-05 / Item reconstruction: 0.00247140321880579 / Text reconstruction: 0.0016252518398687243\n",
            "loss in epoch 14/21 iteration 37/67: 1.3871159553527832 / BPR loss: 1.3855094909667969 / Matching loss: 3.707476571435109e-05 / Item reconstruction: 0.002564767375588417 / Text reconstruction: 0.0014354548184201121\n",
            "loss in epoch 14/21 iteration 38/67: 1.386858344078064 / BPR loss: 1.385296106338501 / Matching loss: 3.191819996573031e-05 / Item reconstruction: 0.002545017749071121 / Text reconstruction: 0.0012887788470834494\n",
            "loss in epoch 14/21 iteration 39/67: 1.386716604232788 / BPR loss: 1.3852801322937012 / Matching loss: 3.4794851671904325e-05 / Item reconstruction: 0.002357331570237875 / Text reconstruction: 0.001115285325795412\n",
            "loss in epoch 14/21 iteration 40/67: 1.386916995048523 / BPR loss: 1.3854312896728516 / Matching loss: 3.971625483245589e-05 / Item reconstruction: 0.0024586287327110767 / Text reconstruction: 0.0010839049937203526\n",
            "loss in epoch 14/21 iteration 41/67: 1.3846076726913452 / BPR loss: 1.3830301761627197 / Matching loss: 3.837052281596698e-05 / Item reconstruction: 0.00242064893245697 / Text reconstruction: 0.001643856056034565\n",
            "loss in epoch 14/21 iteration 42/67: 1.3808588981628418 / BPR loss: 1.3793387413024902 / Matching loss: 2.4639035473228432e-05 / Item reconstruction: 0.002099699340760708 / Text reconstruction: 0.0022280034609138966\n",
            "loss in epoch 14/21 iteration 43/67: 1.3801275491714478 / BPR loss: 1.3784618377685547 / Matching loss: 2.8530175768537447e-05 / Item reconstruction: 0.0022703194990754128 / Text reconstruction: 0.00251055508852005\n",
            "loss in epoch 14/21 iteration 44/67: 1.3860622644424438 / BPR loss: 1.3847397565841675 / Matching loss: 3.13174314214848e-05 / Item reconstruction: 0.0021389899775385857 / Text reconstruction: 0.001107922988012433\n",
            "loss in epoch 14/21 iteration 45/67: 1.3869978189468384 / BPR loss: 1.3857536315917969 / Matching loss: 3.673813625937328e-05 / Item reconstruction: 0.002066353103145957 / Text reconstruction: 0.0008713479619473219\n",
            "loss in epoch 14/21 iteration 46/67: 1.385841965675354 / BPR loss: 1.3844754695892334 / Matching loss: 2.9747250664513558e-05 / Item reconstruction: 0.0022441507317125797 / Text reconstruction: 0.0010726801119744778\n",
            "loss in epoch 14/21 iteration 47/67: 1.3862659931182861 / BPR loss: 1.384913682937622 / Matching loss: 2.9623988666571677e-05 / Item reconstruction: 0.002205814002081752 / Text reconstruction: 0.0010987024288624525\n",
            "loss in epoch 14/21 iteration 48/67: 1.3865851163864136 / BPR loss: 1.3852934837341309 / Matching loss: 3.172468132106587e-05 / Item reconstruction: 0.0021477811969816685 / Text reconstruction: 0.0009303160477429628\n",
            "loss in epoch 14/21 iteration 49/67: 1.3868573904037476 / BPR loss: 1.3855526447296143 / Matching loss: 2.8156824555480853e-05 / Item reconstruction: 0.0021820180118083954 / Text reconstruction: 0.0009281038073822856\n",
            "loss in epoch 14/21 iteration 50/67: 1.3868560791015625 / BPR loss: 1.3855531215667725 / Matching loss: 3.120681503787637e-05 / Item reconstruction: 0.0021961615420877934 / Text reconstruction: 0.0008684288477525115\n",
            "loss in epoch 14/21 iteration 51/67: 1.3876758813858032 / BPR loss: 1.3864686489105225 / Matching loss: 3.6284101952333e-05 / Item reconstruction: 0.002099959645420313 / Text reconstruction: 0.0006049537332728505\n",
            "loss in epoch 14/21 iteration 52/67: 1.3871288299560547 / BPR loss: 1.385860562324524 / Matching loss: 3.06485453620553e-05 / Item reconstruction: 0.0021509001962840557 / Text reconstruction: 0.0008108027977868915\n",
            "loss in epoch 14/21 iteration 53/67: 1.3867533206939697 / BPR loss: 1.385495662689209 / Matching loss: 3.372846913407557e-05 / Item reconstruction: 0.002098478376865387 / Text reconstruction: 0.0008733869181014597\n",
            "loss in epoch 14/21 iteration 54/67: 1.3876686096191406 / BPR loss: 1.3864967823028564 / Matching loss: 3.772435593418777e-05 / Item reconstruction: 0.002009166404604912 / Text reconstruction: 0.000647674547508359\n",
            "loss in epoch 14/21 iteration 55/67: 1.3874891996383667 / BPR loss: 1.3863685131072998 / Matching loss: 3.363293581060134e-05 / Item reconstruction: 0.00192109530325979 / Text reconstruction: 0.0006322060362435877\n",
            "loss in epoch 14/21 iteration 56/67: 1.3872733116149902 / BPR loss: 1.3861002922058105 / Matching loss: 3.580077463993803e-05 / Item reconstruction: 0.0020091405604034662 / Text reconstruction: 0.0006632962031289935\n",
            "loss in epoch 14/21 iteration 57/67: 1.3871996402740479 / BPR loss: 1.386064052581787 / Matching loss: 3.2203835871769115e-05 / Item reconstruction: 0.0019305788446217775 / Text reconstruction: 0.0006905272603034973\n",
            "loss in epoch 14/21 iteration 58/67: 1.3873215913772583 / BPR loss: 1.3862125873565674 / Matching loss: 3.496208228170872e-05 / Item reconstruction: 0.0018900553695857525 / Text reconstruction: 0.0006455386755988002\n",
            "loss in epoch 14/21 iteration 59/67: 1.3876559734344482 / BPR loss: 1.38653564453125 / Matching loss: 3.328423190396279e-05 / Item reconstruction: 0.0019530163845047355 / Text reconstruction: 0.000552342040464282\n",
            "loss in epoch 14/21 iteration 60/67: 1.386984944343567 / BPR loss: 1.3858578205108643 / Matching loss: 3.310029933345504e-05 / Item reconstruction: 0.0019085003295913339 / Text reconstruction: 0.0006983083439990878\n",
            "loss in epoch 14/21 iteration 61/67: 1.3873406648635864 / BPR loss: 1.3862745761871338 / Matching loss: 3.14919016091153e-05 / Item reconstruction: 0.0018408647738397121 / Text reconstruction: 0.0005712572019547224\n",
            "loss in epoch 14/21 iteration 62/67: 1.3863730430603027 / BPR loss: 1.3852823972702026 / Matching loss: 2.788837991829496e-05 / Item reconstruction: 0.0017655412666499615 / Text reconstruction: 0.0009000172140076756\n",
            "loss in epoch 14/21 iteration 63/67: 1.3868061304092407 / BPR loss: 1.3856136798858643 / Matching loss: 3.952894621761516e-05 / Item reconstruction: 0.0020944979041814804 / Text reconstruction: 0.0005278359749354422\n",
            "loss in epoch 14/21 iteration 64/67: 1.3877699375152588 / BPR loss: 1.386660099029541 / Matching loss: 3.5557328374125063e-05 / Item reconstruction: 0.0019393468974158168 / Text reconstruction: 0.000523098511621356\n",
            "loss in epoch 14/21 iteration 65/67: 1.3874845504760742 / BPR loss: 1.3863939046859741 / Matching loss: 3.547052256180905e-05 / Item reconstruction: 0.0018992472905665636 / Text reconstruction: 0.0005275894654914737\n",
            "loss in epoch 14/21 iteration 66/67: 1.3870326280593872 / BPR loss: 1.3861639499664307 / Matching loss: 2.4663891963427886e-05 / Item reconstruction: 0.0014610192738473415 / Text reconstruction: 0.0005672350525856018\n",
            "loss in epoch 14/21 iteration 67/67: 1.3872089385986328 / BPR loss: 1.3864381313323975 / Matching loss: 1.9636807337519713e-05 / Item reconstruction: 0.0012630806304514408 / Text reconstruction: 0.0005977463442832232\n",
            " 70% 14/20 [27:44<11:58, 119.77s/it]loss in epoch 15/21 iteration 0/67: 1.3868755102157593 / BPR loss: 1.3855342864990234 / Matching loss: 3.980533074354753e-05 / Item reconstruction: 0.002265326213091612 / Text reconstruction: 0.0008437576470896602\n",
            "loss in epoch 15/21 iteration 1/67: 1.3831785917282104 / BPR loss: 1.3816795349121094 / Matching loss: 3.4194643376395106e-05 / Item reconstruction: 0.002162102609872818 / Text reconstruction: 0.0019185955170542002\n",
            "loss in epoch 15/21 iteration 2/67: 1.3799914121627808 / BPR loss: 1.3782262802124023 / Matching loss: 3.474163531791419e-05 / Item reconstruction: 0.002266352064907551 / Text reconstruction: 0.0029859759379178286\n",
            "loss in epoch 15/21 iteration 3/67: 1.3790837526321411 / BPR loss: 1.377327561378479 / Matching loss: 3.371993079781532e-05 / Item reconstruction: 0.0022234306670725346 / Text reconstruction: 0.0030535648111253977\n",
            "loss in epoch 15/21 iteration 4/67: 1.3791272640228271 / BPR loss: 1.3773651123046875 / Matching loss: 3.336406371090561e-05 / Item reconstruction: 0.002181839896366 / Text reconstruction: 0.0031891940161585808\n",
            "loss in epoch 15/21 iteration 5/67: 1.379224419593811 / BPR loss: 1.3776127099990845 / Matching loss: 3.221854422008619e-05 / Item reconstruction: 0.0019749884959310293 / Text reconstruction: 0.0029599855188280344\n",
            "loss in epoch 15/21 iteration 6/67: 1.3790720701217651 / BPR loss: 1.377474069595337 / Matching loss: 3.0369859814527445e-05 / Item reconstruction: 0.002010791562497616 / Text reconstruction: 0.0028106800746172667\n",
            "loss in epoch 15/21 iteration 7/67: 1.3791329860687256 / BPR loss: 1.3776741027832031 / Matching loss: 2.7999521989841014e-05 / Item reconstruction: 0.0018742748070508242 / Text reconstruction: 0.002469068393111229\n",
            "loss in epoch 15/21 iteration 8/67: 1.3787561655044556 / BPR loss: 1.3774003982543945 / Matching loss: 2.9554605134762824e-05 / Item reconstruction: 0.0017777476459741592 / Text reconstruction: 0.0021866238676011562\n",
            "loss in epoch 15/21 iteration 9/67: 1.3786479234695435 / BPR loss: 1.3773212432861328 / Matching loss: 2.9548398742917925e-05 / Item reconstruction: 0.0017754993168637156 / Text reconstruction: 0.002046799287199974\n",
            "loss in epoch 15/21 iteration 10/67: 1.3786447048187256 / BPR loss: 1.3773584365844727 / Matching loss: 2.8602495149243623e-05 / Item reconstruction: 0.00175576435867697 / Text reconstruction: 0.0018991881515830755\n",
            "loss in epoch 15/21 iteration 11/67: 1.377982497215271 / BPR loss: 1.3766977787017822 / Matching loss: 2.921161831181962e-05 / Item reconstruction: 0.0017077699303627014 / Text reconstruction: 0.0020080246031284332\n",
            "loss in epoch 15/21 iteration 12/67: 1.3790936470031738 / BPR loss: 1.3777074813842773 / Matching loss: 3.081134855165146e-05 / Item reconstruction: 0.001790858805179596 / Text reconstruction: 0.002299903193488717\n",
            "loss in epoch 15/21 iteration 13/67: 1.3780276775360107 / BPR loss: 1.376672387123108 / Matching loss: 2.7661217245622538e-05 / Item reconstruction: 0.0016966484254226089 / Text reconstruction: 0.002396542578935623\n",
            "loss in epoch 15/21 iteration 14/67: 1.377800703048706 / BPR loss: 1.3764972686767578 / Matching loss: 2.9075554266455583e-05 / Item reconstruction: 0.0017032346222549677 / Text reconstruction: 0.002113874303176999\n",
            "loss in epoch 15/21 iteration 15/67: 1.3779038190841675 / BPR loss: 1.376619815826416 / Matching loss: 2.8143267627456225e-05 / Item reconstruction: 0.001652348437346518 / Text reconstruction: 0.0021486564073711634\n",
            "loss in epoch 15/21 iteration 16/67: 1.3772612810134888 / BPR loss: 1.3759393692016602 / Matching loss: 2.952494651253801e-05 / Item reconstruction: 0.0017672849353402853 / Text reconstruction: 0.0020432230085134506\n",
            "loss in epoch 15/21 iteration 17/67: 1.3795140981674194 / BPR loss: 1.3782806396484375 / Matching loss: 2.7210129701416008e-05 / Item reconstruction: 0.0016351434169337153 / Text reconstruction: 0.0019438270246610045\n",
            "loss in epoch 15/21 iteration 18/67: 1.3855700492858887 / BPR loss: 1.383766531944275 / Matching loss: 3.655811815406196e-05 / Item reconstruction: 0.0024692045990377665 / Text reconstruction: 0.0026612484361976385\n",
            "loss in epoch 15/21 iteration 19/67: 1.3881422281265259 / BPR loss: 1.386016845703125 / Matching loss: 4.051868381793611e-05 / Item reconstruction: 0.002872333163395524 / Text reconstruction: 0.0032434435561299324\n",
            "loss in epoch 15/21 iteration 20/67: 1.3877040147781372 / BPR loss: 1.3857166767120361 / Matching loss: 3.6976896808482707e-05 / Item reconstruction: 0.002686020452529192 / Text reconstruction: 0.003036599839106202\n",
            "loss in epoch 15/21 iteration 21/67: 1.3871419429779053 / BPR loss: 1.3853166103363037 / Matching loss: 3.585298691177741e-05 / Item reconstruction: 0.0026268968358635902 / Text reconstruction: 0.002379986457526684\n",
            "loss in epoch 15/21 iteration 22/67: 1.379888653755188 / BPR loss: 1.3781238794326782 / Matching loss: 2.894862336688675e-05 / Item reconstruction: 0.0026662247255444527 / Text reconstruction: 0.0020137163810431957\n",
            "loss in epoch 15/21 iteration 23/67: 1.3795411586761475 / BPR loss: 1.3778634071350098 / Matching loss: 3.1214662158163264e-05 / Item reconstruction: 0.0024941253941506147 / Text reconstruction: 0.001997380517423153\n",
            "loss in epoch 15/21 iteration 24/67: 1.3798621892929077 / BPR loss: 1.3782448768615723 / Matching loss: 3.023284261871595e-05 / Item reconstruction: 0.0023337381426244974 / Text reconstruction: 0.0021008378826081753\n",
            "loss in epoch 15/21 iteration 25/67: 1.3802533149719238 / BPR loss: 1.3786544799804688 / Matching loss: 2.9692855605389923e-05 / Item reconstruction: 0.0022110596764832735 / Text reconstruction: 0.0023179147392511368\n",
            "loss in epoch 15/21 iteration 26/67: 1.379688024520874 / BPR loss: 1.378124475479126 / Matching loss: 2.7432781280367635e-05 / Item reconstruction: 0.0021408768370747566 / Text reconstruction: 0.002328927395865321\n",
            "loss in epoch 15/21 iteration 27/67: 1.3801071643829346 / BPR loss: 1.3785828351974487 / Matching loss: 2.7827547455672175e-05 / Item reconstruction: 0.002138856565579772 / Text reconstruction: 0.002135602058842778\n",
            "loss in epoch 15/21 iteration 28/67: 1.3792965412139893 / BPR loss: 1.3778671026229858 / Matching loss: 2.723242505453527e-05 / Item reconstruction: 0.001989588141441345 / Text reconstruction: 0.002037089318037033\n",
            "loss in epoch 15/21 iteration 29/67: 1.3792994022369385 / BPR loss: 1.3778982162475586 / Matching loss: 2.8468522941693664e-05 / Item reconstruction: 0.0019901010673493147 / Text reconstruction: 0.0018881699070334435\n",
            "loss in epoch 15/21 iteration 30/67: 1.3784172534942627 / BPR loss: 1.377032995223999 / Matching loss: 2.801512528094463e-05 / Item reconstruction: 0.0019191959872841835 / Text reconstruction: 0.0019833091646432877\n",
            "loss in epoch 15/21 iteration 31/67: 1.379227638244629 / BPR loss: 1.3778681755065918 / Matching loss: 2.7454374503577128e-05 / Item reconstruction: 0.001889738254249096 / Text reconstruction: 0.001935911481268704\n",
            "loss in epoch 15/21 iteration 32/67: 1.3791683912277222 / BPR loss: 1.3778886795043945 / Matching loss: 2.76266218861565e-05 / Item reconstruction: 0.0017628362402319908 / Text reconstruction: 0.001852876041084528\n",
            "loss in epoch 15/21 iteration 33/67: 1.3803194761276245 / BPR loss: 1.3786208629608154 / Matching loss: 2.937164026661776e-05 / Item reconstruction: 0.0025013175327330828 / Text reconstruction: 0.0020932727493345737\n",
            "loss in epoch 15/21 iteration 34/67: 1.3824423551559448 / BPR loss: 1.380810022354126 / Matching loss: 2.7450354536995292e-05 / Item reconstruction: 0.002529451623558998 / Text reconstruction: 0.0017013100441545248\n",
            "loss in epoch 15/21 iteration 35/67: 1.3821120262145996 / BPR loss: 1.3804675340652466 / Matching loss: 2.736137503234204e-05 / Item reconstruction: 0.0025069713592529297 / Text reconstruction: 0.0018180551705881953\n",
            "loss in epoch 15/21 iteration 36/67: 1.386324167251587 / BPR loss: 1.3846434354782104 / Matching loss: 3.5259836295153946e-05 / Item reconstruction: 0.0026436932384967804 / Text reconstruction: 0.0016182268736883998\n",
            "loss in epoch 15/21 iteration 37/67: 1.3872812986373901 / BPR loss: 1.3856337070465088 / Matching loss: 3.438474959693849e-05 / Item reconstruction: 0.002570131327956915 / Text reconstruction: 0.001640803413465619\n",
            "loss in epoch 15/21 iteration 38/67: 1.386244773864746 / BPR loss: 1.3846731185913086 / Matching loss: 3.1006162316771224e-05 / Item reconstruction: 0.0025101313367486 / Text reconstruction: 0.0014283275231719017\n",
            "loss in epoch 15/21 iteration 39/67: 1.3871378898620605 / BPR loss: 1.3856990337371826 / Matching loss: 3.2723699405323714e-05 / Item reconstruction: 0.0023791752755641937 / Text reconstruction: 0.0010824105702340603\n",
            "loss in epoch 15/21 iteration 40/67: 1.3873964548110962 / BPR loss: 1.3859796524047852 / Matching loss: 3.629600541898981e-05 / Item reconstruction: 0.0023731915280222893 / Text reconstruction: 0.0009697782224975526\n",
            "loss in epoch 15/21 iteration 41/67: 1.3840779066085815 / BPR loss: 1.3824880123138428 / Matching loss: 3.851233486784622e-05 / Item reconstruction: 0.0024394632782787085 / Text reconstruction: 0.0016583373071625829\n",
            "loss in epoch 15/21 iteration 42/67: 1.3788093328475952 / BPR loss: 1.3772090673446655 / Matching loss: 2.938171019195579e-05 / Item reconstruction: 0.0022528055123984814 / Text reconstruction: 0.002222895622253418\n",
            "loss in epoch 15/21 iteration 43/67: 1.37821626663208 / BPR loss: 1.3764573335647583 / Matching loss: 3.076677967328578e-05 / Item reconstruction: 0.0023616563994437456 / Text reconstruction: 0.0027364627458155155\n",
            "loss in epoch 15/21 iteration 44/67: 1.3862025737762451 / BPR loss: 1.3848376274108887 / Matching loss: 3.255220508435741e-05 / Item reconstruction: 0.002175484085455537 / Text reconstruction: 0.0012233208399266005\n",
            "loss in epoch 15/21 iteration 45/67: 1.3872284889221191 / BPR loss: 1.3859915733337402 / Matching loss: 3.2338633900508285e-05 / Item reconstruction: 0.0020636601839214563 / Text reconstruction: 0.0008636842831037939\n",
            "loss in epoch 15/21 iteration 46/67: 1.386055827140808 / BPR loss: 1.384606122970581 / Matching loss: 3.4535565646365285e-05 / Item reconstruction: 0.0023140781559050083 / Text reconstruction: 0.0012906428892165422\n",
            "loss in epoch 15/21 iteration 47/67: 1.3860398530960083 / BPR loss: 1.38469660282135 / Matching loss: 2.9735443604295142e-05 / Item reconstruction: 0.002169530838727951 / Text reconstruction: 0.0011439700610935688\n",
            "loss in epoch 15/21 iteration 48/67: 1.3865678310394287 / BPR loss: 1.385190725326538 / Matching loss: 3.8604433939326555e-05 / Item reconstruction: 0.002265636809170246 / Text reconstruction: 0.0010284571908414364\n",
            "loss in epoch 15/21 iteration 49/67: 1.3868556022644043 / BPR loss: 1.3854970932006836 / Matching loss: 2.8830498195020482e-05 / Item reconstruction: 0.0022506248205900192 / Text reconstruction: 0.0010217721574008465\n",
            "loss in epoch 15/21 iteration 50/67: 1.3868207931518555 / BPR loss: 1.3854634761810303 / Matching loss: 3.4251974284416065e-05 / Item reconstruction: 0.0022252476774156094 / Text reconstruction: 0.0010526427067816257\n",
            "loss in epoch 15/21 iteration 51/67: 1.387839913368225 / BPR loss: 1.3866055011749268 / Matching loss: 3.311270847916603e-05 / Item reconstruction: 0.0020798593759536743 / Text reconstruction: 0.000806157011538744\n",
            "loss in epoch 15/21 iteration 52/67: 1.3870477676391602 / BPR loss: 1.385759949684143 / Matching loss: 3.6664725485024974e-05 / Item reconstruction: 0.002143237041309476 / Text reconstruction: 0.0008979288395494223\n",
            "loss in epoch 15/21 iteration 53/67: 1.386847734451294 / BPR loss: 1.3856111764907837 / Matching loss: 3.1612573366146535e-05 / Item reconstruction: 0.002051925053820014 / Text reconstruction: 0.0008954013464972377\n",
            "loss in epoch 15/21 iteration 54/67: 1.387786626815796 / BPR loss: 1.3865779638290405 / Matching loss: 3.8966769352555275e-05 / Item reconstruction: 0.0020215664990246296 / Text reconstruction: 0.0007944582030177116\n",
            "loss in epoch 15/21 iteration 55/67: 1.3876055479049683 / BPR loss: 1.3864192962646484 / Matching loss: 3.3673568395897746e-05 / Item reconstruction: 0.002031868789345026 / Text reconstruction: 0.000683482619933784\n",
            "loss in epoch 15/21 iteration 56/67: 1.3871221542358398 / BPR loss: 1.3859381675720215 / Matching loss: 3.6370962334331125e-05 / Item reconstruction: 0.0020347475074231625 / Text reconstruction: 0.000651522830594331\n",
            "loss in epoch 15/21 iteration 57/67: 1.3870843648910522 / BPR loss: 1.3859636783599854 / Matching loss: 3.159766492899507e-05 / Item reconstruction: 0.0019055362790822983 / Text reconstruction: 0.000682170270010829\n",
            "loss in epoch 15/21 iteration 58/67: 1.3870614767074585 / BPR loss: 1.3859883546829224 / Matching loss: 3.0996139685157686e-05 / Item reconstruction: 0.0018440280109643936 / Text reconstruction: 0.0006006310577504337\n",
            "loss in epoch 15/21 iteration 59/67: 1.3876625299453735 / BPR loss: 1.386526107788086 / Matching loss: 3.377077518962324e-05 / Item reconstruction: 0.0019727288745343685 / Text reconstruction: 0.0005816060001961887\n",
            "loss in epoch 15/21 iteration 60/67: 1.3866852521896362 / BPR loss: 1.3856024742126465 / Matching loss: 3.4012740798061714e-05 / Item reconstruction: 0.0018396786181256175 / Text reconstruction: 0.0006448483327403665\n",
            "loss in epoch 15/21 iteration 61/67: 1.387482762336731 / BPR loss: 1.386412262916565 / Matching loss: 3.080909664276987e-05 / Item reconstruction: 0.001831256435252726 / Text reconstruction: 0.0006203775410540402\n",
            "loss in epoch 15/21 iteration 62/67: 1.386085867881775 / BPR loss: 1.384995460510254 / Matching loss: 2.7446032618172467e-05 / Item reconstruction: 0.00178069481626153 / Text reconstruction: 0.000863055232912302\n",
            "loss in epoch 15/21 iteration 63/67: 1.3870526552200317 / BPR loss: 1.3858616352081299 / Matching loss: 3.559704782674089e-05 / Item reconstruction: 0.002088043373078108 / Text reconstruction: 0.0005569973727688193\n",
            "loss in epoch 15/21 iteration 64/67: 1.3877508640289307 / BPR loss: 1.386654257774353 / Matching loss: 3.478830331005156e-05 / Item reconstruction: 0.0019088522531092167 / Text reconstruction: 0.00053693592781201\n",
            "loss in epoch 15/21 iteration 65/67: 1.388121247291565 / BPR loss: 1.387010097503662 / Matching loss: 3.4032902476610616e-05 / Item reconstruction: 0.0019117509946227074 / Text reconstruction: 0.0006066281930543482\n",
            "loss in epoch 15/21 iteration 66/67: 1.387492299079895 / BPR loss: 1.3865752220153809 / Matching loss: 2.709058389882557e-05 / Item reconstruction: 0.0015162532217800617 / Text reconstruction: 0.0006594164879061282\n",
            "loss in epoch 15/21 iteration 67/67: 1.3872061967849731 / BPR loss: 1.3864152431488037 / Matching loss: 2.1535841369768605e-05 / Item reconstruction: 0.0012679231585934758 / Text reconstruction: 0.0006770658073946834\n",
            " 75% 15/20 [29:47<10:03, 120.68s/it]loss in epoch 16/21 iteration 0/67: 1.386729121208191 / BPR loss: 1.3853485584259033 / Matching loss: 3.781820123549551e-05 / Item reconstruction: 0.00233967206440866 / Text reconstruction: 0.0008646076312288642\n",
            "loss in epoch 16/21 iteration 1/67: 1.3833831548690796 / BPR loss: 1.3816590309143066 / Matching loss: 4.025258749607019e-05 / Item reconstruction: 0.002156547037884593 / Text reconstruction: 0.0030277513433247805\n",
            "loss in epoch 16/21 iteration 2/67: 1.3788034915924072 / BPR loss: 1.376856803894043 / Matching loss: 3.5965909773949534e-05 / Item reconstruction: 0.002313995501026511 / Text reconstruction: 0.0037682889960706234\n",
            "loss in epoch 16/21 iteration 3/67: 1.3784304857254028 / BPR loss: 1.3765851259231567 / Matching loss: 3.53183968400117e-05 / Item reconstruction: 0.002265186980366707 / Text reconstruction: 0.0033874157816171646\n",
            "loss in epoch 16/21 iteration 4/67: 1.3772878646850586 / BPR loss: 1.3755526542663574 / Matching loss: 4.000276021542959e-05 / Item reconstruction: 0.002220077672973275 / Text reconstruction: 0.002925439737737179\n",
            "loss in epoch 16/21 iteration 5/67: 1.3773486614227295 / BPR loss: 1.375731348991394 / Matching loss: 3.508820736897178e-05 / Item reconstruction: 0.0020828181877732277 / Text reconstruction: 0.0027043826412409544\n",
            "loss in epoch 16/21 iteration 6/67: 1.37740957736969 / BPR loss: 1.3758031129837036 / Matching loss: 3.3046631870092824e-05 / Item reconstruction: 0.0020397757180035114 / Text reconstruction: 0.002768075093626976\n",
            "loss in epoch 16/21 iteration 7/67: 1.376941442489624 / BPR loss: 1.3753929138183594 / Matching loss: 2.8975418899790384e-05 / Item reconstruction: 0.001928605604916811 / Text reconstruction: 0.0027765249833464622\n",
            "loss in epoch 16/21 iteration 8/67: 1.377260684967041 / BPR loss: 1.375758409500122 / Matching loss: 3.060930976062082e-05 / Item reconstruction: 0.0018513198010623455 / Text reconstruction: 0.0027299351058900356\n",
            "loss in epoch 16/21 iteration 9/67: 1.3774042129516602 / BPR loss: 1.3759653568267822 / Matching loss: 2.773651431198232e-05 / Item reconstruction: 0.0018020130228251219 / Text reconstruction: 0.002550435485318303\n",
            "loss in epoch 16/21 iteration 10/67: 1.3758482933044434 / BPR loss: 1.3743901252746582 / Matching loss: 3.0297660487121902e-05 / Item reconstruction: 0.0017852166201919317 / Text reconstruction: 0.0026763416826725006\n",
            "loss in epoch 16/21 iteration 11/67: 1.3762495517730713 / BPR loss: 1.374873161315918 / Matching loss: 2.7754662369261496e-05 / Item reconstruction: 0.0017394997412338853 / Text reconstruction: 0.00239450391381979\n",
            "loss in epoch 16/21 iteration 12/67: 1.3776694536209106 / BPR loss: 1.3762627840042114 / Matching loss: 2.8668235245277174e-05 / Item reconstruction: 0.0018582488410174847 / Text reconstruction: 0.00224451906979084\n",
            "loss in epoch 16/21 iteration 13/67: 1.3765594959259033 / BPR loss: 1.3752186298370361 / Matching loss: 3.1016956199891865e-05 / Item reconstruction: 0.0017777122557163239 / Text reconstruction: 0.002105348976328969\n",
            "loss in epoch 16/21 iteration 14/67: 1.3762143850326538 / BPR loss: 1.3748517036437988 / Matching loss: 2.939232399512548e-05 / Item reconstruction: 0.0017983911093324423 / Text reconstruction: 0.00217020814307034\n",
            "loss in epoch 16/21 iteration 15/67: 1.3773807287216187 / BPR loss: 1.376076579093933 / Matching loss: 2.599498475319706e-05 / Item reconstruction: 0.001717632869258523 / Text reconstruction: 0.0020969142206013203\n",
            "loss in epoch 16/21 iteration 16/67: 1.3755888938903809 / BPR loss: 1.3742578029632568 / Matching loss: 2.735280395427253e-05 / Item reconstruction: 0.001608199207112193 / Text reconstruction: 0.002498531248420477\n",
            "loss in epoch 16/21 iteration 17/67: 1.377568006515503 / BPR loss: 1.3762483596801758 / Matching loss: 2.822683018166572e-05 / Item reconstruction: 0.0016784834442660213 / Text reconstruction: 0.0022610449232161045\n",
            "loss in epoch 16/21 iteration 18/67: 1.3860552310943604 / BPR loss: 1.3839824199676514 / Matching loss: 3.776964149437845e-05 / Item reconstruction: 0.0026699919253587723 / Text reconstruction: 0.0035002590157091618\n",
            "loss in epoch 16/21 iteration 19/67: 1.3878709077835083 / BPR loss: 1.385732889175415 / Matching loss: 3.637111876741983e-05 / Item reconstruction: 0.0028510703705251217 / Text reconstruction: 0.0033806227147579193\n",
            "loss in epoch 16/21 iteration 20/67: 1.3877527713775635 / BPR loss: 1.3857976198196411 / Matching loss: 3.305084101157263e-05 / Item reconstruction: 0.002695986069738865 / Text reconstruction: 0.0028702772688120604\n",
            "loss in epoch 16/21 iteration 21/67: 1.3870832920074463 / BPR loss: 1.3851255178451538 / Matching loss: 3.9840622775955126e-05 / Item reconstruction: 0.002792858751490712 / Text reconstruction: 0.0026074142660945654\n",
            "loss in epoch 16/21 iteration 22/67: 1.3790099620819092 / BPR loss: 1.3771483898162842 / Matching loss: 3.1212472094921395e-05 / Item reconstruction: 0.0026875967159867287 / Text reconstruction: 0.002432607812806964\n",
            "loss in epoch 16/21 iteration 23/67: 1.378631591796875 / BPR loss: 1.3769643306732178 / Matching loss: 2.6599655029713176e-05 / Item reconstruction: 0.0023723882623016834 / Text reconstruction: 0.00227231252938509\n",
            "loss in epoch 16/21 iteration 24/67: 1.379409909248352 / BPR loss: 1.377763032913208 / Matching loss: 2.929833317466546e-05 / Item reconstruction: 0.002378718461841345 / Text reconstruction: 0.0021409322507679462\n",
            "loss in epoch 16/21 iteration 25/67: 1.3789608478546143 / BPR loss: 1.377375602722168 / Matching loss: 2.931370363512542e-05 / Item reconstruction: 0.0022339755669236183 / Text reconstruction: 0.002194827888160944\n",
            "loss in epoch 16/21 iteration 26/67: 1.378735065460205 / BPR loss: 1.3771086931228638 / Matching loss: 2.8202799512655474e-05 / Item reconstruction: 0.0022757756523787975 / Text reconstruction: 0.002301071537658572\n",
            "loss in epoch 16/21 iteration 27/67: 1.3782646656036377 / BPR loss: 1.376746416091919 / Matching loss: 2.75584970950149e-05 / Item reconstruction: 0.0020920634269714355 / Text reconstruction: 0.0022233836352825165\n",
            "loss in epoch 16/21 iteration 28/67: 1.378204345703125 / BPR loss: 1.3767263889312744 / Matching loss: 2.7126301574753597e-05 / Item reconstruction: 0.0020517827942967415 / Text reconstruction: 0.002124345861375332\n",
            "loss in epoch 16/21 iteration 29/67: 1.3780931234359741 / BPR loss: 1.3766189813613892 / Matching loss: 2.6052863177028485e-05 / Item reconstruction: 0.001988380216062069 / Text reconstruction: 0.002269321121275425\n",
            "loss in epoch 16/21 iteration 30/67: 1.3784427642822266 / BPR loss: 1.376990556716919 / Matching loss: 2.5055702280951664e-05 / Item reconstruction: 0.0019501701463013887 / Text reconstruction: 0.0022599578369408846\n",
            "loss in epoch 16/21 iteration 31/67: 1.3780910968780518 / BPR loss: 1.3767389059066772 / Matching loss: 2.549331111367792e-05 / Item reconstruction: 0.0017963279969990253 / Text reconstruction: 0.002142819343134761\n",
            "loss in epoch 16/21 iteration 32/67: 1.3777514696121216 / BPR loss: 1.3765236139297485 / Matching loss: 2.3323304048972204e-05 / Item reconstruction: 0.0016397908329963684 / Text reconstruction: 0.001922857016324997\n",
            "loss in epoch 16/21 iteration 33/67: 1.379323124885559 / BPR loss: 1.3776041269302368 / Matching loss: 2.999218304466922e-05 / Item reconstruction: 0.0025164014659821987 / Text reconstruction: 0.0021535041742026806\n",
            "loss in epoch 16/21 iteration 34/67: 1.3814754486083984 / BPR loss: 1.3798508644104004 / Matching loss: 2.8601865778909996e-05 / Item reconstruction: 0.002573841717094183 / Text reconstruction: 0.001545498613268137\n",
            "loss in epoch 16/21 iteration 35/67: 1.3816455602645874 / BPR loss: 1.379944086074829 / Matching loss: 2.7837908419314772e-05 / Item reconstruction: 0.0025808624923229218 / Text reconstruction: 0.0019154788460582495\n",
            "loss in epoch 16/21 iteration 36/67: 1.3864086866378784 / BPR loss: 1.384675145149231 / Matching loss: 3.4075470466632396e-05 / Item reconstruction: 0.0026471083983778954 / Text reconstruction: 0.0018796223448589444\n",
            "loss in epoch 16/21 iteration 37/67: 1.387089490890503 / BPR loss: 1.3853753805160522 / Matching loss: 3.895896952599287e-05 / Item reconstruction: 0.002586767775937915 / Text reconstruction: 0.0019088295521214604\n",
            "loss in epoch 16/21 iteration 38/67: 1.3856821060180664 / BPR loss: 1.384061574935913 / Matching loss: 3.214720345567912e-05 / Item reconstruction: 0.0025765178725123405 / Text reconstruction: 0.0015003560110926628\n",
            "loss in epoch 16/21 iteration 39/67: 1.3868263959884644 / BPR loss: 1.385372281074524 / Matching loss: 3.3778895158320665e-05 / Item reconstruction: 0.002412975998595357 / Text reconstruction: 0.0010695084929466248\n",
            "loss in epoch 16/21 iteration 40/67: 1.3868827819824219 / BPR loss: 1.3854197263717651 / Matching loss: 3.671698868856765e-05 / Item reconstruction: 0.00241115246899426 / Text reconstruction: 0.0011038233060389757\n",
            "loss in epoch 16/21 iteration 41/67: 1.3831220865249634 / BPR loss: 1.381495714187622 / Matching loss: 3.587094761314802e-05 / Item reconstruction: 0.0023858060594648123 / Text reconstruction: 0.0019876384176313877\n",
            "loss in epoch 16/21 iteration 42/67: 1.3776524066925049 / BPR loss: 1.3759773969650269 / Matching loss: 2.6290741516277194e-05 / Item reconstruction: 0.00227311160415411 / Text reconstruction: 0.0025604693219065666\n",
            "loss in epoch 16/21 iteration 43/67: 1.377682089805603 / BPR loss: 1.3758819103240967 / Matching loss: 2.6872667149291374e-05 / Item reconstruction: 0.0023649418726563454 / Text reconstruction: 0.0029546532314270735\n",
            "loss in epoch 16/21 iteration 44/67: 1.386062741279602 / BPR loss: 1.3846588134765625 / Matching loss: 3.154969454044476e-05 / Item reconstruction: 0.0022542355582118034 / Text reconstruction: 0.0012259443756192923\n",
            "loss in epoch 16/21 iteration 45/67: 1.386928677558899 / BPR loss: 1.3856613636016846 / Matching loss: 3.182553336955607e-05 / Item reconstruction: 0.0021319356746971607 / Text reconstruction: 0.0008474269416183233\n",
            "loss in epoch 16/21 iteration 46/67: 1.385485291481018 / BPR loss: 1.3840866088867188 / Matching loss: 3.03652705042623e-05 / Item reconstruction: 0.0022487081587314606 / Text reconstruction: 0.0012196259340271354\n",
            "loss in epoch 16/21 iteration 47/67: 1.3862260580062866 / BPR loss: 1.3848953247070312 / Matching loss: 2.9523251214413904e-05 / Item reconstruction: 0.0021385331638157368 / Text reconstruction: 0.0011591736692935228\n",
            "loss in epoch 16/21 iteration 48/67: 1.386153221130371 / BPR loss: 1.3848283290863037 / Matching loss: 3.0250565032474697e-05 / Item reconstruction: 0.0021661813370883465 / Text reconstruction: 0.0010571887250989676\n",
            "loss in epoch 16/21 iteration 49/67: 1.386499285697937 / BPR loss: 1.3851896524429321 / Matching loss: 2.899540777434595e-05 / Item reconstruction: 0.002113675232976675 / Text reconstruction: 0.0011195375118404627\n",
            "loss in epoch 16/21 iteration 50/67: 1.386763572692871 / BPR loss: 1.3854389190673828 / Matching loss: 2.719943950069137e-05 / Item reconstruction: 0.0021985038183629513 / Text reconstruction: 0.0009912734385579824\n",
            "loss in epoch 16/21 iteration 51/67: 1.3870604038238525 / BPR loss: 1.3858017921447754 / Matching loss: 3.331433254061267e-05 / Item reconstruction: 0.002058254089206457 / Text reconstruction: 0.000980847398750484\n",
            "loss in epoch 16/21 iteration 52/67: 1.3868458271026611 / BPR loss: 1.3855189085006714 / Matching loss: 2.783034142339602e-05 / Item reconstruction: 0.0021830813493579626 / Text reconstruction: 0.0010379233863204718\n",
            "loss in epoch 16/21 iteration 53/67: 1.3867216110229492 / BPR loss: 1.385498285293579 / Matching loss: 3.16224577545654e-05 / Item reconstruction: 0.0020047700963914394 / Text reconstruction: 0.0009464513277634978\n",
            "loss in epoch 16/21 iteration 54/67: 1.3875529766082764 / BPR loss: 1.3863956928253174 / Matching loss: 3.389710036572069e-05 / Item reconstruction: 0.0019695330411195755 / Text reconstruction: 0.0006930386298336089\n",
            "loss in epoch 16/21 iteration 55/67: 1.3876527547836304 / BPR loss: 1.3865094184875488 / Matching loss: 3.143666617688723e-05 / Item reconstruction: 0.0019314049277454615 / Text reconstruction: 0.0007308737258426845\n",
            "loss in epoch 16/21 iteration 56/67: 1.3876924514770508 / BPR loss: 1.386488914489746 / Matching loss: 3.3994438126683235e-05 / Item reconstruction: 0.00205871369689703 / Text reconstruction: 0.0007008507382124662\n",
            "loss in epoch 16/21 iteration 57/67: 1.3872401714324951 / BPR loss: 1.386110544204712 / Matching loss: 2.9519713280024007e-05 / Item reconstruction: 0.001911722356453538 / Text reconstruction: 0.0007209519972093403\n",
            "loss in epoch 16/21 iteration 58/67: 1.387297511100769 / BPR loss: 1.386183261871338 / Matching loss: 3.0455905289272778e-05 / Item reconstruction: 0.001883676741272211 / Text reconstruction: 0.0007099133799783885\n",
            "loss in epoch 16/21 iteration 59/67: 1.387637734413147 / BPR loss: 1.386502981185913 / Matching loss: 3.278851727372967e-05 / Item reconstruction: 0.0019624833948910236 / Text reconstruction: 0.0006036158883944154\n",
            "loss in epoch 16/21 iteration 60/67: 1.3869961500167847 / BPR loss: 1.3859102725982666 / Matching loss: 3.2172465580515563e-05 / Item reconstruction: 0.0018321778625249863 / Text reconstruction: 0.0006876534316688776\n",
            "loss in epoch 16/21 iteration 61/67: 1.3872005939483643 / BPR loss: 1.3861563205718994 / Matching loss: 2.871489414246753e-05 / Item reconstruction: 0.001783071318641305 / Text reconstruction: 0.0006200067582540214\n",
            "loss in epoch 16/21 iteration 62/67: 1.3862340450286865 / BPR loss: 1.385148286819458 / Matching loss: 2.441374999762047e-05 / Item reconstruction: 0.0017835922772064805 / Text reconstruction: 0.0008474617497995496\n",
            "loss in epoch 16/21 iteration 63/67: 1.3872522115707397 / BPR loss: 1.3859987258911133 / Matching loss: 4.191622792859562e-05 / Item reconstruction: 0.0021522226743400097 / Text reconstruction: 0.000677101023029536\n",
            "loss in epoch 16/21 iteration 64/67: 1.387466549873352 / BPR loss: 1.3863229751586914 / Matching loss: 3.205968823749572e-05 / Item reconstruction: 0.0019689088221639395 / Text reconstruction: 0.0006356184021569788\n",
            "loss in epoch 16/21 iteration 65/67: 1.3875383138656616 / BPR loss: 1.3864097595214844 / Matching loss: 3.621676660259254e-05 / Item reconstruction: 0.0019243350252509117 / Text reconstruction: 0.0006508615333586931\n",
            "loss in epoch 16/21 iteration 66/67: 1.3870407342910767 / BPR loss: 1.386176347732544 / Matching loss: 2.5606983399484307e-05 / Item reconstruction: 0.0014416896738111973 / Text reconstruction: 0.0005897337105125189\n",
            "loss in epoch 16/21 iteration 67/67: 1.3869175910949707 / BPR loss: 1.3861265182495117 / Matching loss: 1.9564969989005476e-05 / Item reconstruction: 0.0012934088008478284 / Text reconstruction: 0.0006238178466446698\n",
            " 80% 16/20 [31:48<08:03, 120.80s/it]loss in epoch 17/21 iteration 0/67: 1.386501431465149 / BPR loss: 1.3851443529129028 / Matching loss: 3.83667902497109e-05 / Item reconstruction: 0.0023254964035004377 / Text reconstruction: 0.0007799236918799579\n",
            "loss in epoch 17/21 iteration 1/67: 1.3827183246612549 / BPR loss: 1.380954623222351 / Matching loss: 3.5099859815090895e-05 / Item reconstruction: 0.0023484835401177406 / Text reconstruction: 0.002771976636722684\n",
            "loss in epoch 17/21 iteration 2/67: 1.3767037391662598 / BPR loss: 1.3746545314788818 / Matching loss: 3.6698260373668745e-05 / Item reconstruction: 0.0025001552421599627 / Text reconstruction: 0.0038122988771647215\n",
            "loss in epoch 17/21 iteration 3/67: 1.3762638568878174 / BPR loss: 1.3742189407348633 / Matching loss: 3.407763142604381e-05 / Item reconstruction: 0.0024726337287575006 / Text reconstruction: 0.0038723726756870747\n",
            "loss in epoch 17/21 iteration 4/67: 1.3758448362350464 / BPR loss: 1.373788833618164 / Matching loss: 3.3918498957064e-05 / Item reconstruction: 0.002466375706717372 / Text reconstruction: 0.003944038413465023\n",
            "loss in epoch 17/21 iteration 5/67: 1.3763996362686157 / BPR loss: 1.3745396137237549 / Matching loss: 3.296896466054022e-05 / Item reconstruction: 0.0021685915999114513 / Text reconstruction: 0.003713516518473625\n",
            "loss in epoch 17/21 iteration 6/67: 1.3759706020355225 / BPR loss: 1.3742036819458008 / Matching loss: 2.7729334760806523e-05 / Item reconstruction: 0.002106773667037487 / Text reconstruction: 0.0034293250646442175\n",
            "loss in epoch 17/21 iteration 7/67: 1.3753910064697266 / BPR loss: 1.37369966506958 / Matching loss: 2.8372842280077748e-05 / Item reconstruction: 0.0020785874221473932 / Text reconstruction: 0.0031183366663753986\n",
            "loss in epoch 17/21 iteration 8/67: 1.374563217163086 / BPR loss: 1.3729894161224365 / Matching loss: 2.9641312721651047e-05 / Item reconstruction: 0.001947026583366096 / Text reconstruction: 0.0028535579331219196\n",
            "loss in epoch 17/21 iteration 9/67: 1.3758559226989746 / BPR loss: 1.37434720993042 / Matching loss: 2.8315687814028934e-05 / Item reconstruction: 0.0019271881319582462 / Text reconstruction: 0.002584020607173443\n",
            "loss in epoch 17/21 iteration 10/67: 1.3746005296707153 / BPR loss: 1.3730711936950684 / Matching loss: 2.8511671189335175e-05 / Item reconstruction: 0.0019334128592163324 / Text reconstruction: 0.0026708589866757393\n",
            "loss in epoch 17/21 iteration 11/67: 1.3744308948516846 / BPR loss: 1.3729758262634277 / Matching loss: 2.677869633771479e-05 / Item reconstruction: 0.001770667964592576 / Text reconstruction: 0.0027141892351210117\n",
            "loss in epoch 17/21 iteration 12/67: 1.376367449760437 / BPR loss: 1.3748279809951782 / Matching loss: 2.617094651213847e-05 / Item reconstruction: 0.0019334445241838694 / Text reconstruction: 0.0027327777352184057\n",
            "loss in epoch 17/21 iteration 13/67: 1.3752126693725586 / BPR loss: 1.3737543821334839 / Matching loss: 2.6685011107474566e-05 / Item reconstruction: 0.0018081131856888533 / Text reconstruction: 0.002637662459164858\n",
            "loss in epoch 17/21 iteration 14/67: 1.3749696016311646 / BPR loss: 1.3734607696533203 / Matching loss: 2.7122110623167828e-05 / Item reconstruction: 0.0018879120470955968 / Text reconstruction: 0.0026888325810432434\n",
            "loss in epoch 17/21 iteration 15/67: 1.3747159242630005 / BPR loss: 1.373244285583496 / Matching loss: 2.7405993023421615e-05 / Item reconstruction: 0.0018906628247350454 / Text reconstruction: 0.0024945500772446394\n",
            "loss in epoch 17/21 iteration 16/67: 1.3739091157913208 / BPR loss: 1.3724305629730225 / Matching loss: 2.742951619438827e-05 / Item reconstruction: 0.0018359661335125566 / Text reconstruction: 0.002665497362613678\n",
            "loss in epoch 17/21 iteration 17/67: 1.3754674196243286 / BPR loss: 1.3739385604858398 / Matching loss: 2.9390976123977453e-05 / Item reconstruction: 0.0019110417924821377 / Text reconstruction: 0.0027198598254472017\n",
            "loss in epoch 17/21 iteration 18/67: 1.3850479125976562 / BPR loss: 1.3827760219573975 / Matching loss: 3.4476946893846616e-05 / Item reconstruction: 0.0029000199865549803 / Text reconstruction: 0.003936923108994961\n",
            "loss in epoch 17/21 iteration 19/67: 1.3877208232879639 / BPR loss: 1.385378360748291 / Matching loss: 3.833493610727601e-05 / Item reconstruction: 0.0030911113135516644 / Text reconstruction: 0.0037926898803561926\n",
            "loss in epoch 17/21 iteration 20/67: 1.3879880905151367 / BPR loss: 1.3858840465545654 / Matching loss: 3.460500738583505e-05 / Item reconstruction: 0.0028142803348600864 / Text reconstruction: 0.0033119183499366045\n",
            "loss in epoch 17/21 iteration 21/67: 1.3875329494476318 / BPR loss: 1.3855078220367432 / Matching loss: 3.5089688026346266e-05 / Item reconstruction: 0.0028691478073596954 / Text reconstruction: 0.0027773305773735046\n",
            "loss in epoch 17/21 iteration 22/67: 1.3774982690811157 / BPR loss: 1.3755675554275513 / Matching loss: 3.178803308401257e-05 / Item reconstruction: 0.0027094660326838493 / Text reconstruction: 0.0027211459819227457\n",
            "loss in epoch 17/21 iteration 23/67: 1.3774845600128174 / BPR loss: 1.3756530284881592 / Matching loss: 2.9984421416884288e-05 / Item reconstruction: 0.0025181712117046118 / Text reconstruction: 0.0027121957391500473\n",
            "loss in epoch 17/21 iteration 24/67: 1.3768879175186157 / BPR loss: 1.3751327991485596 / Matching loss: 3.210515933460556e-05 / Item reconstruction: 0.0024850997142493725 / Text reconstruction: 0.002402416430413723\n",
            "loss in epoch 17/21 iteration 25/67: 1.3772740364074707 / BPR loss: 1.375573992729187 / Matching loss: 2.8123362426413223e-05 / Item reconstruction: 0.0023264652118086815 / Text reconstruction: 0.0025431320536881685\n",
            "loss in epoch 17/21 iteration 26/67: 1.376861572265625 / BPR loss: 1.3752079010009766 / Matching loss: 2.9386415917542763e-05 / Item reconstruction: 0.0022504106163978577 / Text reconstruction: 0.0024952110834419727\n",
            "loss in epoch 17/21 iteration 27/67: 1.3769346475601196 / BPR loss: 1.3753528594970703 / Matching loss: 2.6782578061101958e-05 / Item reconstruction: 0.00214429572224617 / Text reconstruction: 0.0024141953326761723\n",
            "loss in epoch 17/21 iteration 28/67: 1.3768526315689087 / BPR loss: 1.3753042221069336 / Matching loss: 2.9893057217122987e-05 / Item reconstruction: 0.002091601025313139 / Text reconstruction: 0.0023633770179003477\n",
            "loss in epoch 17/21 iteration 29/67: 1.3766989707946777 / BPR loss: 1.3751784563064575 / Matching loss: 2.776989458652679e-05 / Item reconstruction: 0.0019859683234244585 / Text reconstruction: 0.0024986511562019587\n",
            "loss in epoch 17/21 iteration 30/67: 1.3770149946212769 / BPR loss: 1.3754479885101318 / Matching loss: 2.5170525987050496e-05 / Item reconstruction: 0.002060818485915661 / Text reconstruction: 0.002557324944064021\n",
            "loss in epoch 17/21 iteration 31/67: 1.3771718740463257 / BPR loss: 1.3756908178329468 / Matching loss: 2.6290668756701052e-05 / Item reconstruction: 0.0019291755743324757 / Text reconstruction: 0.0024501888547092676\n",
            "loss in epoch 17/21 iteration 32/67: 1.3770912885665894 / BPR loss: 1.3757569789886475 / Matching loss: 2.759377093752846e-05 / Item reconstruction: 0.0017624050378799438 / Text reconstruction: 0.0021277363412082195\n",
            "loss in epoch 17/21 iteration 33/67: 1.379138708114624 / BPR loss: 1.3773212432861328 / Matching loss: 2.7930320356972516e-05 / Item reconstruction: 0.0026064030826091766 / Text reconstruction: 0.002431649249047041\n",
            "loss in epoch 17/21 iteration 34/67: 1.3806201219558716 / BPR loss: 1.3788678646087646 / Matching loss: 2.6003714083344676e-05 / Item reconstruction: 0.0025945433881133795 / Text reconstruction: 0.0021450775675475597\n",
            "loss in epoch 17/21 iteration 35/67: 1.3792767524719238 / BPR loss: 1.3775897026062012 / Matching loss: 2.4912369553931057e-05 / Item reconstruction: 0.0025365687906742096 / Text reconstruction: 0.0019693586509674788\n",
            "loss in epoch 17/21 iteration 36/67: 1.3859056234359741 / BPR loss: 1.3842227458953857 / Matching loss: 3.169599949615076e-05 / Item reconstruction: 0.002639989834278822 / Text reconstruction: 0.0016560927033424377\n",
            "loss in epoch 17/21 iteration 37/67: 1.3867037296295166 / BPR loss: 1.3850510120391846 / Matching loss: 3.1268398743122816e-05 / Item reconstruction: 0.0025757949333637953 / Text reconstruction: 0.0016675597289577127\n",
            "loss in epoch 17/21 iteration 38/67: 1.3857779502868652 / BPR loss: 1.3840806484222412 / Matching loss: 3.3355452615069225e-05 / Item reconstruction: 0.0026295012794435024 / Text reconstruction: 0.0017459634691476822\n",
            "loss in epoch 17/21 iteration 39/67: 1.3863961696624756 / BPR loss: 1.384889841079712 / Matching loss: 3.0409715691348538e-05 / Item reconstruction: 0.002380340825766325 / Text reconstruction: 0.001428601797670126\n",
            "loss in epoch 17/21 iteration 40/67: 1.3869359493255615 / BPR loss: 1.3854330778121948 / Matching loss: 3.387543256394565e-05 / Item reconstruction: 0.002437758492305875 / Text reconstruction: 0.0012506789062172174\n",
            "loss in epoch 17/21 iteration 41/67: 1.3834258317947388 / BPR loss: 1.3817882537841797 / Matching loss: 3.635850589489564e-05 / Item reconstruction: 0.0025017450097948313 / Text reconstruction: 0.0017516587395220995\n",
            "loss in epoch 17/21 iteration 42/67: 1.376001000404358 / BPR loss: 1.3741834163665771 / Matching loss: 2.7071004296885803e-05 / Item reconstruction: 0.0024601444602012634 / Text reconstruction: 0.002802206203341484\n",
            "loss in epoch 17/21 iteration 43/67: 1.3761398792266846 / BPR loss: 1.3741328716278076 / Matching loss: 2.8740008929162286e-05 / Item reconstruction: 0.0026161582209169865 / Text reconstruction: 0.0033508483320474625\n",
            "loss in epoch 17/21 iteration 44/67: 1.386015772819519 / BPR loss: 1.3845763206481934 / Matching loss: 2.8642349207075313e-05 / Item reconstruction: 0.002217461122199893 / Text reconstruction: 0.0015106522478163242\n",
            "loss in epoch 17/21 iteration 45/67: 1.3866777420043945 / BPR loss: 1.3854140043258667 / Matching loss: 3.3026717574102804e-05 / Item reconstruction: 0.0020736814476549625 / Text reconstruction: 0.0009690509177744389\n",
            "loss in epoch 17/21 iteration 46/67: 1.3855406045913696 / BPR loss: 1.3841261863708496 / Matching loss: 2.5509762053843588e-05 / Item reconstruction: 0.002204449847340584 / Text reconstruction: 0.001433718716725707\n",
            "loss in epoch 17/21 iteration 47/67: 1.3858058452606201 / BPR loss: 1.3843891620635986 / Matching loss: 3.100998219451867e-05 / Item reconstruction: 0.0021852022036910057 / Text reconstruction: 0.0014656678540632129\n",
            "loss in epoch 17/21 iteration 48/67: 1.3860599994659424 / BPR loss: 1.3846807479858398 / Matching loss: 3.054813714697957e-05 / Item reconstruction: 0.00218217889778316 / Text reconstruction: 0.0012878996785730124\n",
            "loss in epoch 17/21 iteration 49/67: 1.3860194683074951 / BPR loss: 1.384660005569458 / Matching loss: 2.6066025384352542e-05 / Item reconstruction: 0.002181330230087042 / Text reconstruction: 0.0012137319426983595\n",
            "loss in epoch 17/21 iteration 50/67: 1.386143684387207 / BPR loss: 1.3847935199737549 / Matching loss: 3.034336077689659e-05 / Item reconstruction: 0.0022176799830049276 / Text reconstruction: 0.0010546622797846794\n",
            "loss in epoch 17/21 iteration 51/67: 1.3879578113555908 / BPR loss: 1.3866429328918457 / Matching loss: 3.253643444622867e-05 / Item reconstruction: 0.002136083785444498 / Text reconstruction: 0.001071736216545105\n",
            "loss in epoch 17/21 iteration 52/67: 1.3868343830108643 / BPR loss: 1.385528564453125 / Matching loss: 3.226515764254145e-05 / Item reconstruction: 0.0021846829913556576 / Text reconstruction: 0.0009060004376806319\n",
            "loss in epoch 17/21 iteration 53/67: 1.38690984249115 / BPR loss: 1.3856648206710815 / Matching loss: 2.7296095140627585e-05 / Item reconstruction: 0.0020803925581276417 / Text reconstruction: 0.0008877399377524853\n",
            "loss in epoch 17/21 iteration 54/67: 1.3881251811981201 / BPR loss: 1.38695228099823 / Matching loss: 3.406371979508549e-05 / Item reconstruction: 0.002016740618273616 / Text reconstruction: 0.000652189482934773\n",
            "loss in epoch 17/21 iteration 55/67: 1.3874413967132568 / BPR loss: 1.3862841129302979 / Matching loss: 3.0420251277973875e-05 / Item reconstruction: 0.00198052148334682 / Text reconstruction: 0.0006833549123257399\n",
            "loss in epoch 17/21 iteration 56/67: 1.3874824047088623 / BPR loss: 1.3862743377685547 / Matching loss: 3.4508346288930625e-05 / Item reconstruction: 0.00205134111456573 / Text reconstruction: 0.0007396632572636008\n",
            "loss in epoch 17/21 iteration 57/67: 1.3869456052780151 / BPR loss: 1.3857877254486084 / Matching loss: 2.963203405670356e-05 / Item reconstruction: 0.0019457467133179307 / Text reconstruction: 0.0007766686612740159\n",
            "loss in epoch 17/21 iteration 58/67: 1.3869643211364746 / BPR loss: 1.3858299255371094 / Matching loss: 2.7165478968527168e-05 / Item reconstruction: 0.0019197437213733792 / Text reconstruction: 0.0007364668417721987\n",
            "loss in epoch 17/21 iteration 59/67: 1.386806607246399 / BPR loss: 1.3856476545333862 / Matching loss: 3.2724925404181704e-05 / Item reconstruction: 0.0019693728536367416 / Text reconstruction: 0.000707767263520509\n",
            "loss in epoch 17/21 iteration 60/67: 1.38715660572052 / BPR loss: 1.3860387802124023 / Matching loss: 2.923312240454834e-05 / Item reconstruction: 0.0018552348483353853 / Text reconstruction: 0.0008050976321101189\n",
            "loss in epoch 17/21 iteration 61/67: 1.387094497680664 / BPR loss: 1.385998010635376 / Matching loss: 3.104994902969338e-05 / Item reconstruction: 0.001824212959036231 / Text reconstruction: 0.0007672065403312445\n",
            "loss in epoch 17/21 iteration 62/67: 1.3858442306518555 / BPR loss: 1.3847143650054932 / Matching loss: 2.4388451492995955e-05 / Item reconstruction: 0.0018148507224395871 / Text reconstruction: 0.0009899635333567858\n",
            "loss in epoch 17/21 iteration 63/67: 1.387357473373413 / BPR loss: 1.3860790729522705 / Matching loss: 3.4424887417117134e-05 / Item reconstruction: 0.002165699377655983 / Text reconstruction: 0.0008052544435486197\n",
            "loss in epoch 17/21 iteration 64/67: 1.388285517692566 / BPR loss: 1.3870751857757568 / Matching loss: 3.279071097495034e-05 / Item reconstruction: 0.0020159133709967136 / Text reconstruction: 0.0008481848053634167\n",
            "loss in epoch 17/21 iteration 65/67: 1.3881721496582031 / BPR loss: 1.3870432376861572 / Matching loss: 2.9315024221432395e-05 / Item reconstruction: 0.0019067521207034588 / Text reconstruction: 0.0007314014947041869\n",
            "loss in epoch 17/21 iteration 66/67: 1.386778712272644 / BPR loss: 1.3858821392059326 / Matching loss: 2.374560608586762e-05 / Item reconstruction: 0.001477202051319182 / Text reconstruction: 0.0006709949229843915\n",
            "loss in epoch 17/21 iteration 67/67: 1.3870235681533813 / BPR loss: 1.3862457275390625 / Matching loss: 1.8315036868443713e-05 / Item reconstruction: 0.0012538258451968431 / Text reconstruction: 0.0006628724513575435\n",
            " 85% 17/20 [33:46<05:59, 119.86s/it]loss in epoch 18/21 iteration 0/67: 1.3864498138427734 / BPR loss: 1.3850398063659668 / Matching loss: 3.715683487826027e-05 / Item reconstruction: 0.0023902379907667637 / Text reconstruction: 0.0008886784198693931\n",
            "loss in epoch 18/21 iteration 1/67: 1.381054162979126 / BPR loss: 1.3789761066436768 / Matching loss: 5.1777984481304884e-05 / Item reconstruction: 0.002385542495176196 / Text reconstruction: 0.004167515784502029\n",
            "loss in epoch 18/21 iteration 2/67: 1.3764543533325195 / BPR loss: 1.374164342880249 / Matching loss: 3.585014201235026e-05 / Item reconstruction: 0.002606330905109644 / Text reconstruction: 0.004754482302814722\n",
            "loss in epoch 18/21 iteration 3/67: 1.3750661611557007 / BPR loss: 1.3729171752929688 / Matching loss: 3.9848393498687074e-05 / Item reconstruction: 0.0026384922675788403 / Text reconstruction: 0.003949638921767473\n",
            "loss in epoch 18/21 iteration 4/67: 1.3741637468338013 / BPR loss: 1.3721301555633545 / Matching loss: 4.5443157432600856e-05 / Item reconstruction: 0.002586323767900467 / Text reconstruction: 0.003475024364888668\n",
            "loss in epoch 18/21 iteration 5/67: 1.3747196197509766 / BPR loss: 1.3728110790252686 / Matching loss: 3.63355538866017e-05 / Item reconstruction: 0.0023788362741470337 / Text reconstruction: 0.0034134204033762217\n",
            "loss in epoch 18/21 iteration 6/67: 1.3748970031738281 / BPR loss: 1.3729745149612427 / Matching loss: 3.831869980785996e-05 / Item reconstruction: 0.0023066899739205837 / Text reconstruction: 0.0036544769536703825\n",
            "loss in epoch 18/21 iteration 7/67: 1.373377799987793 / BPR loss: 1.3715202808380127 / Matching loss: 3.520237805787474e-05 / Item reconstruction: 0.0021860101260244846 / Text reconstruction: 0.003646652679890394\n",
            "loss in epoch 18/21 iteration 8/67: 1.373801589012146 / BPR loss: 1.3720203638076782 / Matching loss: 3.2338408345822245e-05 / Item reconstruction: 0.0020705447532236576 / Text reconstruction: 0.0035685200709849596\n",
            "loss in epoch 18/21 iteration 9/67: 1.3736166954040527 / BPR loss: 1.3718130588531494 / Matching loss: 3.812368959188461e-05 / Item reconstruction: 0.0020834505558013916 / Text reconstruction: 0.0036186908837407827\n",
            "loss in epoch 18/21 iteration 10/67: 1.37260103225708 / BPR loss: 1.3709588050842285 / Matching loss: 2.9578537578345276e-05 / Item reconstruction: 0.001878480426967144 / Text reconstruction: 0.003367186291143298\n",
            "loss in epoch 18/21 iteration 11/67: 1.372952938079834 / BPR loss: 1.3713371753692627 / Matching loss: 2.9800041374983266e-05 / Item reconstruction: 0.0019454978173598647 / Text reconstruction: 0.0030658936593681574\n",
            "loss in epoch 18/21 iteration 12/67: 1.3734934329986572 / BPR loss: 1.3718229532241821 / Matching loss: 3.11495823552832e-05 / Item reconstruction: 0.0020864715334028006 / Text reconstruction: 0.002980687189847231\n",
            "loss in epoch 18/21 iteration 13/67: 1.372734785079956 / BPR loss: 1.371065616607666 / Matching loss: 3.066857243538834e-05 / Item reconstruction: 0.0021162345074117184 / Text reconstruction: 0.002901979722082615\n",
            "loss in epoch 18/21 iteration 14/67: 1.3736525774002075 / BPR loss: 1.3720388412475586 / Matching loss: 3.164285953971557e-05 / Item reconstruction: 0.0020265248604118824 / Text reconstruction: 0.0028444710187613964\n",
            "loss in epoch 18/21 iteration 15/67: 1.3737282752990723 / BPR loss: 1.3721253871917725 / Matching loss: 2.8071746783098206e-05 / Item reconstruction: 0.0019444151548668742 / Text reconstruction: 0.003013565670698881\n",
            "loss in epoch 18/21 iteration 16/67: 1.3722598552703857 / BPR loss: 1.3706517219543457 / Matching loss: 2.806296652124729e-05 / Item reconstruction: 0.0019343788735568523 / Text reconstruction: 0.003064938820898533\n",
            "loss in epoch 18/21 iteration 17/67: 1.3738806247711182 / BPR loss: 1.372225284576416 / Matching loss: 3.11592775688041e-05 / Item reconstruction: 0.0019819100853055716 / Text reconstruction: 0.0031659407541155815\n",
            "loss in epoch 18/21 iteration 18/67: 1.384832501411438 / BPR loss: 1.3824840784072876 / Matching loss: 3.889138315571472e-05 / Item reconstruction: 0.003062983974814415 / Text reconstruction: 0.003890144405886531\n",
            "loss in epoch 18/21 iteration 19/67: 1.3886451721191406 / BPR loss: 1.3861544132232666 / Matching loss: 4.1999614040832967e-05 / Item reconstruction: 0.0032369205728173256 / Text reconstruction: 0.004151266999542713\n",
            "loss in epoch 18/21 iteration 20/67: 1.3881336450576782 / BPR loss: 1.3858416080474854 / Matching loss: 3.334002030896954e-05 / Item reconstruction: 0.0030262148939073086 / Text reconstruction: 0.0037279294338077307\n",
            "loss in epoch 18/21 iteration 21/67: 1.3861219882965088 / BPR loss: 1.383826732635498 / Matching loss: 3.7842561141587794e-05 / Item reconstruction: 0.00308117363601923 / Text reconstruction: 0.0035846407990902662\n",
            "loss in epoch 18/21 iteration 22/67: 1.3758203983306885 / BPR loss: 1.3738267421722412 / Matching loss: 2.8264290449442342e-05 / Item reconstruction: 0.002761515323072672 / Text reconstruction: 0.002923212945461273\n",
            "loss in epoch 18/21 iteration 23/67: 1.375058650970459 / BPR loss: 1.3731693029403687 / Matching loss: 2.8837410354753956e-05 / Item reconstruction: 0.0026279957965016365 / Text reconstruction: 0.0027323360554873943\n",
            "loss in epoch 18/21 iteration 24/67: 1.3766940832138062 / BPR loss: 1.374929666519165 / Matching loss: 2.791113729472272e-05 / Item reconstruction: 0.0025308518670499325 / Text reconstruction: 0.0023553872015327215\n",
            "loss in epoch 18/21 iteration 25/67: 1.3754775524139404 / BPR loss: 1.3737401962280273 / Matching loss: 2.7565471100388095e-05 / Item reconstruction: 0.002396873664110899 / Text reconstruction: 0.002556939609348774\n",
            "loss in epoch 18/21 iteration 26/67: 1.3763560056686401 / BPR loss: 1.374610185623169 / Matching loss: 2.4663184376549907e-05 / Item reconstruction: 0.002341459970921278 / Text reconstruction: 0.0027519557625055313\n",
            "loss in epoch 18/21 iteration 27/67: 1.3753197193145752 / BPR loss: 1.3735989332199097 / Matching loss: 2.392777423665393e-05 / Item reconstruction: 0.0022271641064435244 / Text reconstruction: 0.00291625689715147\n",
            "loss in epoch 18/21 iteration 28/67: 1.3757134675979614 / BPR loss: 1.3740074634552002 / Matching loss: 2.6514353521633893e-05 / Item reconstruction: 0.0021818093955516815 / Text reconstruction: 0.002943191444501281\n",
            "loss in epoch 18/21 iteration 29/67: 1.375386357307434 / BPR loss: 1.373722791671753 / Matching loss: 2.6095076464116573e-05 / Item reconstruction: 0.002151092514395714 / Text reconstruction: 0.002809600904583931\n",
            "loss in epoch 18/21 iteration 30/67: 1.3762212991714478 / BPR loss: 1.374588966369629 / Matching loss: 2.5669996830401942e-05 / Item reconstruction: 0.0021395019721239805 / Text reconstruction: 0.002684863982722163\n",
            "loss in epoch 18/21 iteration 31/67: 1.375437617301941 / BPR loss: 1.373897910118103 / Matching loss: 2.8006144930259325e-05 / Item reconstruction: 0.0019964969251304865 / Text reconstruction: 0.002567266346886754\n",
            "loss in epoch 18/21 iteration 32/67: 1.3756054639816284 / BPR loss: 1.3741674423217773 / Matching loss: 2.370875699853059e-05 / Item reconstruction: 0.0018735460471361876 / Text reconstruction: 0.0023877148050814867\n",
            "loss in epoch 18/21 iteration 33/67: 1.3758670091629028 / BPR loss: 1.3739534616470337 / Matching loss: 2.729185507632792e-05 / Item reconstruction: 0.002758537884801626 / Text reconstruction: 0.002534993924200535\n",
            "loss in epoch 18/21 iteration 34/67: 1.37912118434906 / BPR loss: 1.3774113655090332 / Matching loss: 2.5335088139399886e-05 / Item reconstruction: 0.0026069495361298323 / Text reconstruction: 0.0019049084512516856\n",
            "loss in epoch 18/21 iteration 35/67: 1.3790534734725952 / BPR loss: 1.3772966861724854 / Matching loss: 2.4924680474214256e-05 / Item reconstruction: 0.002619020640850067 / Text reconstruction: 0.0021118801087141037\n",
            "loss in epoch 18/21 iteration 36/67: 1.3855093717575073 / BPR loss: 1.3837352991104126 / Matching loss: 3.125799048575573e-05 / Item reconstruction: 0.0026496066711843014 / Text reconstruction: 0.0020906003192067146\n",
            "loss in epoch 18/21 iteration 37/67: 1.3864964246749878 / BPR loss: 1.3846808671951294 / Matching loss: 3.290995300631039e-05 / Item reconstruction: 0.002706399653106928 / Text reconstruction: 0.002147459425032139\n",
            "loss in epoch 18/21 iteration 38/67: 1.3858495950698853 / BPR loss: 1.384117603302002 / Matching loss: 3.0712162697454914e-05 / Item reconstruction: 0.0026869503781199455 / Text reconstruction: 0.0017888640286400914\n",
            "loss in epoch 18/21 iteration 39/67: 1.386247992515564 / BPR loss: 1.384657621383667 / Matching loss: 2.8931790438946337e-05 / Item reconstruction: 0.0025016278959810734 / Text reconstruction: 0.0015528196236118674\n",
            "loss in epoch 18/21 iteration 40/67: 1.3867638111114502 / BPR loss: 1.3851966857910156 / Matching loss: 3.1876388675300404e-05 / Item reconstruction: 0.00246150023303926 / Text reconstruction: 0.001522755715996027\n",
            "loss in epoch 18/21 iteration 41/67: 1.3821426630020142 / BPR loss: 1.3803024291992188 / Matching loss: 3.6975783586967736e-05 / Item reconstruction: 0.002573283389210701 / Text reconstruction: 0.002583236200734973\n",
            "loss in epoch 18/21 iteration 42/67: 1.3758785724639893 / BPR loss: 1.373781442642212 / Matching loss: 2.8824375476688147e-05 / Item reconstruction: 0.00263284076936543 / Text reconstruction: 0.0037592086009681225\n",
            "loss in epoch 18/21 iteration 43/67: 1.3740462064743042 / BPR loss: 1.3718630075454712 / Matching loss: 2.687572305148933e-05 / Item reconstruction: 0.0027923304587602615 / Text reconstruction: 0.003801144426688552\n",
            "loss in epoch 18/21 iteration 44/67: 1.3858519792556763 / BPR loss: 1.3843717575073242 / Matching loss: 2.730775304371491e-05 / Item reconstruction: 0.0022855764254927635 / Text reconstruction: 0.0015509136719629169\n",
            "loss in epoch 18/21 iteration 45/67: 1.3866218328475952 / BPR loss: 1.385335087776184 / Matching loss: 2.9019469366176054e-05 / Item reconstruction: 0.0020630215294659138 / Text reconstruction: 0.0011311676353216171\n",
            "loss in epoch 18/21 iteration 46/67: 1.38504958152771 / BPR loss: 1.383633017539978 / Matching loss: 2.9161705242586322e-05 / Item reconstruction: 0.0023044669069349766 / Text reconstruction: 0.0011751990532502532\n",
            "loss in epoch 18/21 iteration 47/67: 1.3851063251495361 / BPR loss: 1.383783221244812 / Matching loss: 2.5753701265784912e-05 / Item reconstruction: 0.002147040097042918 / Text reconstruction: 0.00111963355448097\n",
            "loss in epoch 18/21 iteration 48/67: 1.3864097595214844 / BPR loss: 1.3850452899932861 / Matching loss: 2.650082387845032e-05 / Item reconstruction: 0.0021959778387099504 / Text reconstruction: 0.0011995536042377353\n",
            "loss in epoch 18/21 iteration 49/67: 1.3860801458358765 / BPR loss: 1.3846951723098755 / Matching loss: 2.5914347133948468e-05 / Item reconstruction: 0.0022512718569487333 / Text reconstruction: 0.0011672996915876865\n",
            "loss in epoch 18/21 iteration 50/67: 1.3867671489715576 / BPR loss: 1.3853776454925537 / Matching loss: 2.8793088858947158e-05 / Item reconstruction: 0.0022816602140665054 / Text reconstruction: 0.0010988743742927909\n",
            "loss in epoch 18/21 iteration 51/67: 1.3875315189361572 / BPR loss: 1.386231780052185 / Matching loss: 3.5199333069613203e-05 / Item reconstruction: 0.002167816972360015 / Text reconstruction: 0.0009034028626047075\n",
            "loss in epoch 18/21 iteration 52/67: 1.386927843093872 / BPR loss: 1.3856098651885986 / Matching loss: 2.8030321118421853e-05 / Item reconstruction: 0.002160646254196763 / Text reconstruction: 0.0010484512895345688\n",
            "loss in epoch 18/21 iteration 53/67: 1.386794090270996 / BPR loss: 1.3854937553405762 / Matching loss: 2.8397207643138245e-05 / Item reconstruction: 0.002115212380886078 / Text reconstruction: 0.0010718427365645766\n",
            "loss in epoch 18/21 iteration 54/67: 1.3878333568572998 / BPR loss: 1.386624813079834 / Matching loss: 2.9343043934204616e-05 / Item reconstruction: 0.001999184023588896 / Text reconstruction: 0.0008985111489892006\n",
            "loss in epoch 18/21 iteration 55/67: 1.3879188299179077 / BPR loss: 1.3867390155792236 / Matching loss: 2.8212845791131258e-05 / Item reconstruction: 0.0019691437482833862 / Text reconstruction: 0.0008350001880899072\n",
            "loss in epoch 18/21 iteration 56/67: 1.386900544166565 / BPR loss: 1.3856604099273682 / Matching loss: 2.978497104777489e-05 / Item reconstruction: 0.0020810766145586967 / Text reconstruction: 0.0008489952888339758\n",
            "loss in epoch 18/21 iteration 57/67: 1.3878536224365234 / BPR loss: 1.3866539001464844 / Matching loss: 2.7561341994442046e-05 / Item reconstruction: 0.0019934019073843956 / Text reconstruction: 0.0008772742585279047\n",
            "loss in epoch 18/21 iteration 58/67: 1.3873589038848877 / BPR loss: 1.3862247467041016 / Matching loss: 2.6431773221702315e-05 / Item reconstruction: 0.0018960745073854923 / Text reconstruction: 0.0007983588147908449\n",
            "loss in epoch 18/21 iteration 59/67: 1.3873534202575684 / BPR loss: 1.3862082958221436 / Matching loss: 2.9765413273707964e-05 / Item reconstruction: 0.0019352334784343839 / Text reconstruction: 0.0007386337965726852\n",
            "loss in epoch 18/21 iteration 60/67: 1.3868026733398438 / BPR loss: 1.3856552839279175 / Matching loss: 2.9998413083376363e-05 / Item reconstruction: 0.0018963351612910628 / Text reconstruction: 0.0008455833303742111\n",
            "loss in epoch 18/21 iteration 61/67: 1.3868772983551025 / BPR loss: 1.3857821226119995 / Matching loss: 2.806880365824327e-05 / Item reconstruction: 0.0018489755457267165 / Text reconstruction: 0.0007135487394407392\n",
            "loss in epoch 18/21 iteration 62/67: 1.3853892087936401 / BPR loss: 1.3842741250991821 / Matching loss: 2.352016235818155e-05 / Item reconstruction: 0.0017862676177173853 / Text reconstruction: 0.0009925144258886576\n",
            "loss in epoch 18/21 iteration 63/67: 1.3874269723892212 / BPR loss: 1.3861415386199951 / Matching loss: 3.196967008989304e-05 / Item reconstruction: 0.0021487518679350615 / Text reconstruction: 0.0008952303323894739\n",
            "loss in epoch 18/21 iteration 64/67: 1.387549638748169 / BPR loss: 1.3864104747772217 / Matching loss: 2.896876867453102e-05 / Item reconstruction: 0.0019305830355733633 / Text reconstruction: 0.0007250468479469419\n",
            "loss in epoch 18/21 iteration 65/67: 1.3882101774215698 / BPR loss: 1.3870482444763184 / Matching loss: 3.078226654906757e-05 / Item reconstruction: 0.001956153428182006 / Text reconstruction: 0.0007653653156012297\n",
            "loss in epoch 18/21 iteration 66/67: 1.3869892358779907 / BPR loss: 1.3860845565795898 / Matching loss: 2.0967818272765726e-05 / Item reconstruction: 0.001462169922888279 / Text reconstruction: 0.0007628059247508645\n",
            "loss in epoch 18/21 iteration 67/67: 1.3868839740753174 / BPR loss: 1.3860448598861694 / Matching loss: 1.6475840311613865e-05 / Item reconstruction: 0.0013343824539333582 / Text reconstruction: 0.0007774516707286239\n",
            " 90% 18/20 [35:41<03:57, 118.53s/it]loss in epoch 19/21 iteration 0/67: 1.386680006980896 / BPR loss: 1.3853046894073486 / Matching loss: 3.8027443224564195e-05 / Item reconstruction: 0.0022622207179665565 / Text reconstruction: 0.0010312163503840566\n",
            "loss in epoch 19/21 iteration 1/67: 1.3810064792633057 / BPR loss: 1.379111886024475 / Matching loss: 4.0303195419255644e-05 / Item reconstruction: 0.002629017923027277 / Text reconstruction: 0.0026990394107997417\n",
            "loss in epoch 19/21 iteration 2/67: 1.3735352754592896 / BPR loss: 1.3712064027786255 / Matching loss: 4.08777232223656e-05 / Item reconstruction: 0.0028693878557533026 / Text reconstruction: 0.004266730509698391\n",
            "loss in epoch 19/21 iteration 3/67: 1.372984528541565 / BPR loss: 1.3704735040664673 / Matching loss: 3.781053965212777e-05 / Item reconstruction: 0.0029462252277880907 / Text reconstruction: 0.005000629927963018\n",
            "loss in epoch 19/21 iteration 4/67: 1.3729397058486938 / BPR loss: 1.370400071144104 / Matching loss: 3.48430585290771e-05 / Item reconstruction: 0.0029314602725207806 / Text reconstruction: 0.005195670761168003\n",
            "loss in epoch 19/21 iteration 5/67: 1.373308539390564 / BPR loss: 1.3709831237792969 / Matching loss: 3.861358345602639e-05 / Item reconstruction: 0.0026631061919033527 / Text reconstruction: 0.004776095040142536\n",
            "loss in epoch 19/21 iteration 6/67: 1.37330961227417 / BPR loss: 1.371098518371582 / Matching loss: 3.7413152313092723e-05 / Item reconstruction: 0.0024826666340231895 / Text reconstruction: 0.00466167600825429\n",
            "loss in epoch 19/21 iteration 7/67: 1.3724219799041748 / BPR loss: 1.370394229888916 / Matching loss: 3.201536674168892e-05 / Item reconstruction: 0.0023609809577465057 / Text reconstruction: 0.004075750708580017\n",
            "loss in epoch 19/21 iteration 8/67: 1.3714916706085205 / BPR loss: 1.3695974349975586 / Matching loss: 3.065751661779359e-05 / Item reconstruction: 0.002274835715070367 / Text reconstruction: 0.003631116356700659\n",
            "loss in epoch 19/21 iteration 9/67: 1.374149203300476 / BPR loss: 1.3724088668823242 / Matching loss: 3.355445369379595e-05 / Item reconstruction: 0.002206579316407442 / Text reconstruction: 0.0030178625602275133\n",
            "loss in epoch 19/21 iteration 10/67: 1.3703348636627197 / BPR loss: 1.3686485290527344 / Matching loss: 3.119814209640026e-05 / Item reconstruction: 0.0021568075753748417 / Text reconstruction: 0.0028836391866207123\n",
            "loss in epoch 19/21 iteration 11/67: 1.370888352394104 / BPR loss: 1.3691235780715942 / Matching loss: 3.277548967162147e-05 / Item reconstruction: 0.0022561331279575825 / Text reconstruction: 0.003019423456862569\n",
            "loss in epoch 19/21 iteration 12/67: 1.3737901449203491 / BPR loss: 1.3719619512557983 / Matching loss: 3.11326002702117e-05 / Item reconstruction: 0.0023545646108686924 / Text reconstruction: 0.0030986350029706955\n",
            "loss in epoch 19/21 iteration 13/67: 1.3719347715377808 / BPR loss: 1.3700692653656006 / Matching loss: 2.7666770620271564e-05 / Item reconstruction: 0.002232525497674942 / Text reconstruction: 0.003607998602092266\n",
            "loss in epoch 19/21 iteration 14/67: 1.3712564706802368 / BPR loss: 1.3693633079528809 / Matching loss: 3.044101504201535e-05 / Item reconstruction: 0.002230266807600856 / Text reconstruction: 0.003738436382263899\n",
            "loss in epoch 19/21 iteration 15/67: 1.3711884021759033 / BPR loss: 1.3693615198135376 / Matching loss: 3.0127232093946077e-05 / Item reconstruction: 0.0021596469450742006 / Text reconstruction: 0.0035843951627612114\n",
            "loss in epoch 19/21 iteration 16/67: 1.3703104257583618 / BPR loss: 1.3685333728790283 / Matching loss: 2.91391734208446e-05 / Item reconstruction: 0.002191167790442705 / Text reconstruction: 0.0032621989957988262\n",
            "loss in epoch 19/21 iteration 17/67: 1.3738033771514893 / BPR loss: 1.3720898628234863 / Matching loss: 2.664636485860683e-05 / Item reconstruction: 0.0022213184274733067 / Text reconstruction: 0.0028804470784962177\n",
            "loss in epoch 19/21 iteration 18/67: 1.3854259252548218 / BPR loss: 1.3829067945480347 / Matching loss: 3.7413235986605287e-05 / Item reconstruction: 0.003434437792748213 / Text reconstruction: 0.0038223995361477137\n",
            "loss in epoch 19/21 iteration 19/67: 1.3882560729980469 / BPR loss: 1.3855643272399902 / Matching loss: 3.831889625871554e-05 / Item reconstruction: 0.0036387289874255657 / Text reconstruction: 0.0041708070784807205\n",
            "loss in epoch 19/21 iteration 20/67: 1.3880635499954224 / BPR loss: 1.3855124711990356 / Matching loss: 3.498596925055608e-05 / Item reconstruction: 0.00335288280621171 / Text reconstruction: 0.00419827364385128\n",
            "loss in epoch 19/21 iteration 21/67: 1.3872073888778687 / BPR loss: 1.3847663402557373 / Matching loss: 3.809736153925769e-05 / Item reconstruction: 0.003231791313737631 / Text reconstruction: 0.003935039974749088\n",
            "loss in epoch 19/21 iteration 22/67: 1.3751189708709717 / BPR loss: 1.3731071949005127 / Matching loss: 3.0691822757944465e-05 / Item reconstruction: 0.002930763643234968 / Text reconstruction: 0.0025785311590880156\n",
            "loss in epoch 19/21 iteration 23/67: 1.3732373714447021 / BPR loss: 1.3712135553359985 / Matching loss: 3.190897768945433e-05 / Item reconstruction: 0.0028124526143074036 / Text reconstruction: 0.0029282765462994576\n",
            "loss in epoch 19/21 iteration 24/67: 1.374424695968628 / BPR loss: 1.3724268674850464 / Matching loss: 2.9854216336389072e-05 / Item reconstruction: 0.0027464572340250015 / Text reconstruction: 0.0029741344042122364\n",
            "loss in epoch 19/21 iteration 25/67: 1.3750325441360474 / BPR loss: 1.37319016456604 / Matching loss: 2.726167076616548e-05 / Item reconstruction: 0.0024999119341373444 / Text reconstruction: 0.002825804753229022\n",
            "loss in epoch 19/21 iteration 26/67: 1.3751198053359985 / BPR loss: 1.373252272605896 / Matching loss: 2.9648512281710282e-05 / Item reconstruction: 0.0025204080156981945 / Text reconstruction: 0.002888299059122801\n",
            "loss in epoch 19/21 iteration 27/67: 1.3734294176101685 / BPR loss: 1.3715488910675049 / Matching loss: 2.812743878166657e-05 / Item reconstruction: 0.0024459133855998516 / Text reconstruction: 0.003147366689518094\n",
            "loss in epoch 19/21 iteration 28/67: 1.3742094039916992 / BPR loss: 1.3723866939544678 / Matching loss: 2.8902830308652483e-05 / Item reconstruction: 0.002420264296233654 / Text reconstruction: 0.0029188627377152443\n",
            "loss in epoch 19/21 iteration 29/67: 1.3734688758850098 / BPR loss: 1.3716955184936523 / Matching loss: 2.560758002800867e-05 / Item reconstruction: 0.0022655613720417023 / Text reconstruction: 0.0030752134043723345\n",
            "loss in epoch 19/21 iteration 30/67: 1.3741613626480103 / BPR loss: 1.3724929094314575 / Matching loss: 2.4386692530242726e-05 / Item reconstruction: 0.002232559025287628 / Text reconstruction: 0.002638907404616475\n",
            "loss in epoch 19/21 iteration 31/67: 1.3737596273422241 / BPR loss: 1.3721550703048706 / Matching loss: 2.6723311748355627e-05 / Item reconstruction: 0.0021357149817049503 / Text reconstruction: 0.0025498319882899523\n",
            "loss in epoch 19/21 iteration 32/67: 1.3741432428359985 / BPR loss: 1.3726176023483276 / Matching loss: 2.4237089746748097e-05 / Item reconstruction: 0.00199180212803185 / Text reconstruction: 0.002527832519263029\n",
            "loss in epoch 19/21 iteration 33/67: 1.374802827835083 / BPR loss: 1.372748613357544 / Matching loss: 3.0160104870446958e-05 / Item reconstruction: 0.0028154836036264896 / Text reconstruction: 0.0030814018100500107\n",
            "loss in epoch 19/21 iteration 34/67: 1.3790713548660278 / BPR loss: 1.3772882223129272 / Matching loss: 2.545181632740423e-05 / Item reconstruction: 0.0025820238515734673 / Text reconstruction: 0.0023329388350248337\n",
            "loss in epoch 19/21 iteration 35/67: 1.37763249874115 / BPR loss: 1.3757522106170654 / Matching loss: 2.6978785172104836e-05 / Item reconstruction: 0.0027998480945825577 / Text reconstruction: 0.002267297822982073\n",
            "loss in epoch 19/21 iteration 36/67: 1.3853379487991333 / BPR loss: 1.3834717273712158 / Matching loss: 3.15024662995711e-05 / Item reconstruction: 0.0028061973862349987 / Text reconstruction: 0.0021582618355751038\n",
            "loss in epoch 19/21 iteration 37/67: 1.3864271640777588 / BPR loss: 1.3846218585968018 / Matching loss: 3.34229989675805e-05 / Item reconstruction: 0.0027854694053530693 / Text reconstruction: 0.0018957405118271708\n",
            "loss in epoch 19/21 iteration 38/67: 1.3854968547821045 / BPR loss: 1.3838183879852295 / Matching loss: 3.1102543289307505e-05 / Item reconstruction: 0.0026843189261853695 / Text reconstruction: 0.0015260967193171382\n",
            "loss in epoch 19/21 iteration 39/67: 1.386743187904358 / BPR loss: 1.3851597309112549 / Matching loss: 2.826937816280406e-05 / Item reconstruction: 0.002519638277590275 / Text reconstruction: 0.001476887846365571\n",
            "loss in epoch 19/21 iteration 40/67: 1.3866710662841797 / BPR loss: 1.3850330114364624 / Matching loss: 3.163234578096308e-05 / Item reconstruction: 0.0025931051932275295 / Text reconstruction: 0.0015498468419536948\n",
            "loss in epoch 19/21 iteration 41/67: 1.3827569484710693 / BPR loss: 1.380893349647522 / Matching loss: 3.144648508168757e-05 / Item reconstruction: 0.002757311798632145 / Text reconstruction: 0.002267215633764863\n",
            "loss in epoch 19/21 iteration 42/67: 1.3728691339492798 / BPR loss: 1.37071692943573 / Matching loss: 2.615920857351739e-05 / Item reconstruction: 0.0028781481087207794 / Text reconstruction: 0.003435267833992839\n",
            "loss in epoch 19/21 iteration 43/67: 1.3720227479934692 / BPR loss: 1.3696573972702026 / Matching loss: 2.9813261789968237e-05 / Item reconstruction: 0.0030700047500431538 / Text reconstruction: 0.004002707544714212\n",
            "loss in epoch 19/21 iteration 44/67: 1.3845585584640503 / BPR loss: 1.3830499649047852 / Matching loss: 2.6037472707685083e-05 / Item reconstruction: 0.0023214598186314106 / Text reconstruction: 0.00160928291734308\n",
            "loss in epoch 19/21 iteration 45/67: 1.3869487047195435 / BPR loss: 1.3856109380722046 / Matching loss: 2.604666951810941e-05 / Item reconstruction: 0.0021052826195955276 / Text reconstruction: 0.0012957964790984988\n",
            "loss in epoch 19/21 iteration 46/67: 1.385376214981079 / BPR loss: 1.3839406967163086 / Matching loss: 2.3797769244993106e-05 / Item reconstruction: 0.0022385097108781338 / Text reconstruction: 0.0014618257991969585\n",
            "loss in epoch 19/21 iteration 47/67: 1.3854619264602661 / BPR loss: 1.3840619325637817 / Matching loss: 2.2887959858053364e-05 / Item reconstruction: 0.002205085940659046 / Text reconstruction: 0.001372840255498886\n",
            "loss in epoch 19/21 iteration 48/67: 1.38538658618927 / BPR loss: 1.3839762210845947 / Matching loss: 2.4981934984680265e-05 / Item reconstruction: 0.0022100978530943394 / Text reconstruction: 0.001401306944899261\n",
            "loss in epoch 19/21 iteration 49/67: 1.386328101158142 / BPR loss: 1.3849215507507324 / Matching loss: 2.3664391846978106e-05 / Item reconstruction: 0.0022665192373096943 / Text reconstruction: 0.0012482160236686468\n",
            "loss in epoch 19/21 iteration 50/67: 1.3859578371047974 / BPR loss: 1.3845422267913818 / Matching loss: 2.5470153559581377e-05 / Item reconstruction: 0.0023176586255431175 / Text reconstruction: 0.001156099489890039\n",
            "loss in epoch 19/21 iteration 51/67: 1.3875031471252441 / BPR loss: 1.3861771821975708 / Matching loss: 2.7197473173146136e-05 / Item reconstruction: 0.0021945354528725147 / Text reconstruction: 0.00100706925150007\n",
            "loss in epoch 19/21 iteration 52/67: 1.386458396911621 / BPR loss: 1.385171890258789 / Matching loss: 2.3688660803600214e-05 / Item reconstruction: 0.002111688256263733 / Text reconstruction: 0.0010348206851631403\n",
            "loss in epoch 19/21 iteration 53/67: 1.3864175081253052 / BPR loss: 1.385119915008545 / Matching loss: 2.407464853604324e-05 / Item reconstruction: 0.002090116962790489 / Text reconstruction: 0.0011420233640819788\n",
            "loss in epoch 19/21 iteration 54/67: 1.3881454467773438 / BPR loss: 1.3869216442108154 / Matching loss: 2.8362754164845683e-05 / Item reconstruction: 0.0020377307664602995 / Text reconstruction: 0.0008827052661217749\n",
            "loss in epoch 19/21 iteration 55/67: 1.3877848386764526 / BPR loss: 1.386542558670044 / Matching loss: 2.8047681553289294e-05 / Item reconstruction: 0.002052753698080778 / Text reconstruction: 0.0009391193743795156\n",
            "loss in epoch 19/21 iteration 56/67: 1.387164831161499 / BPR loss: 1.3859093189239502 / Matching loss: 2.8554310119943693e-05 / Item reconstruction: 0.0020916927605867386 / Text reconstruction: 0.0009053051471710205\n",
            "loss in epoch 19/21 iteration 57/67: 1.3869001865386963 / BPR loss: 1.3856875896453857 / Matching loss: 2.529710764065385e-05 / Item reconstruction: 0.0019875275902450085 / Text reconstruction: 0.0009678067872300744\n",
            "loss in epoch 19/21 iteration 58/67: 1.3867881298065186 / BPR loss: 1.3855829238891602 / Matching loss: 2.652272451086901e-05 / Item reconstruction: 0.0020106525626033545 / Text reconstruction: 0.0008670826209709048\n",
            "loss in epoch 19/21 iteration 59/67: 1.3873438835144043 / BPR loss: 1.386124849319458 / Matching loss: 2.7786532882601023e-05 / Item reconstruction: 0.002047667745500803 / Text reconstruction: 0.0008368339040316641\n",
            "loss in epoch 19/21 iteration 60/67: 1.386837124824524 / BPR loss: 1.3856992721557617 / Matching loss: 2.594408579170704e-05 / Item reconstruction: 0.0018887766636908054 / Text reconstruction: 0.0008375241886824369\n",
            "loss in epoch 19/21 iteration 61/67: 1.3877291679382324 / BPR loss: 1.3865940570831299 / Matching loss: 2.6459740183781832e-05 / Item reconstruction: 0.001878792536444962 / Text reconstruction: 0.0008462124387733638\n",
            "loss in epoch 19/21 iteration 62/67: 1.3856358528137207 / BPR loss: 1.384528398513794 / Matching loss: 1.978796353796497e-05 / Item reconstruction: 0.0017646474298089743 / Text reconstruction: 0.001026736106723547\n",
            "loss in epoch 19/21 iteration 63/67: 1.3876701593399048 / BPR loss: 1.3863554000854492 / Matching loss: 3.1070383556652814e-05 / Item reconstruction: 0.0021789036691188812 / Text reconstruction: 0.0009709892328828573\n",
            "loss in epoch 19/21 iteration 64/67: 1.3878318071365356 / BPR loss: 1.3866853713989258 / Matching loss: 2.9811088097631e-05 / Item reconstruction: 0.0019166506826877594 / Text reconstruction: 0.0007913484587334096\n",
            "loss in epoch 19/21 iteration 65/67: 1.3874863386154175 / BPR loss: 1.3863613605499268 / Matching loss: 2.7312114980304614e-05 / Item reconstruction: 0.001860710559412837 / Text reconstruction: 0.000836673250887543\n",
            "loss in epoch 19/21 iteration 66/67: 1.3869000673294067 / BPR loss: 1.3859483003616333 / Matching loss: 2.2568061467609368e-05 / Item reconstruction: 0.0015300184022635221 / Text reconstruction: 0.0008210783707909286\n",
            "loss in epoch 19/21 iteration 67/67: 1.386878252029419 / BPR loss: 1.38603937625885 / Matching loss: 1.589142448210623e-05 / Item reconstruction: 0.0013276117388159037 / Text reconstruction: 0.0007963513489812613\n",
            " 95% 19/20 [37:45<02:00, 120.10s/it]loss in epoch 20/21 iteration 0/67: 1.3865597248077393 / BPR loss: 1.3850839138031006 / Matching loss: 3.117665619356558e-05 / Item reconstruction: 0.0024157827720046043 / Text reconstruction: 0.0011833321768790483\n",
            "loss in epoch 20/21 iteration 1/67: 1.3800604343414307 / BPR loss: 1.3777662515640259 / Matching loss: 4.4461427023634315e-05 / Item reconstruction: 0.0028123599477112293 / Text reconstruction: 0.004217898473143578\n",
            "loss in epoch 20/21 iteration 2/67: 1.3748140335083008 / BPR loss: 1.3720394372940063 / Matching loss: 3.9413102058460936e-05 / Item reconstruction: 0.003220531390979886 / Text reconstruction: 0.005624408833682537\n",
            "loss in epoch 20/21 iteration 3/67: 1.371917486190796 / BPR loss: 1.3691766262054443 / Matching loss: 3.389894118299708e-05 / Item reconstruction: 0.003348823171108961 / Text reconstruction: 0.0051629142835736275\n",
            "loss in epoch 20/21 iteration 4/67: 1.3713030815124512 / BPR loss: 1.3686927556991577 / Matching loss: 3.553683927748352e-05 / Item reconstruction: 0.003256624797359109 / Text reconstruction: 0.004732721019536257\n",
            "loss in epoch 20/21 iteration 5/67: 1.3713840246200562 / BPR loss: 1.368942379951477 / Matching loss: 3.964579082094133e-05 / Item reconstruction: 0.0030378703959286213 / Text reconstruction: 0.00441485783085227\n",
            "loss in epoch 20/21 iteration 6/67: 1.3723628520965576 / BPR loss: 1.3701510429382324 / Matching loss: 3.0790630262345076e-05 / Item reconstruction: 0.0026947760488837957 / Text reconstruction: 0.004167873878031969\n",
            "loss in epoch 20/21 iteration 7/67: 1.3703548908233643 / BPR loss: 1.3681919574737549 / Matching loss: 3.345361619722098e-05 / Item reconstruction: 0.0026452832389622927 / Text reconstruction: 0.004033846780657768\n",
            "loss in epoch 20/21 iteration 8/67: 1.3696569204330444 / BPR loss: 1.3675038814544678 / Matching loss: 3.0789429729338735e-05 / Item reconstruction: 0.0025798813439905643 / Text reconstruction: 0.004161694087088108\n",
            "loss in epoch 20/21 iteration 9/67: 1.3714611530303955 / BPR loss: 1.3693649768829346 / Matching loss: 3.14001263177488e-05 / Item reconstruction: 0.002503066323697567 / Text reconstruction: 0.004066049586981535\n",
            "loss in epoch 20/21 iteration 10/67: 1.3696693181991577 / BPR loss: 1.3676549196243286 / Matching loss: 3.121172630926594e-05 / Item reconstruction: 0.002402751473709941 / Text reconstruction: 0.00390907097607851\n",
            "loss in epoch 20/21 iteration 11/67: 1.369519829750061 / BPR loss: 1.3675625324249268 / Matching loss: 2.8317714168224484e-05 / Item reconstruction: 0.0024071503430604935 / Text reconstruction: 0.0036271726712584496\n",
            "loss in epoch 20/21 iteration 12/67: 1.370621919631958 / BPR loss: 1.3686048984527588 / Matching loss: 2.7980982849840075e-05 / Item reconstruction: 0.0026737276930361986 / Text reconstruction: 0.003260823432356119\n",
            "loss in epoch 20/21 iteration 13/67: 1.3690226078033447 / BPR loss: 1.367016315460205 / Matching loss: 2.9879114663344808e-05 / Item reconstruction: 0.0026400501374155283 / Text reconstruction: 0.003281960031017661\n",
            "loss in epoch 20/21 iteration 14/67: 1.369798183441162 / BPR loss: 1.3678091764450073 / Matching loss: 3.051799285458401e-05 / Item reconstruction: 0.0026149877812713385 / Text reconstruction: 0.0032548774033784866\n",
            "loss in epoch 20/21 iteration 15/67: 1.3696801662445068 / BPR loss: 1.3677266836166382 / Matching loss: 2.7617610612651333e-05 / Item reconstruction: 0.0024801541585475206 / Text reconstruction: 0.0034284288994967937\n",
            "loss in epoch 20/21 iteration 16/67: 1.3689930438995361 / BPR loss: 1.366992712020874 / Matching loss: 2.7601161491475068e-05 / Item reconstruction: 0.0025452030822634697 / Text reconstruction: 0.003500589868053794\n",
            "loss in epoch 20/21 iteration 17/67: 1.3706753253936768 / BPR loss: 1.3686754703521729 / Matching loss: 2.8402937459759414e-05 / Item reconstruction: 0.002492197323590517 / Text reconstruction: 0.0036271652206778526\n",
            "loss in epoch 20/21 iteration 18/67: 1.3853399753570557 / BPR loss: 1.3824424743652344 / Matching loss: 4.1289993532700464e-05 / Item reconstruction: 0.0037687676958739758 / Text reconstruction: 0.004859767388552427\n",
            "loss in epoch 20/21 iteration 19/67: 1.3890936374664307 / BPR loss: 1.3860535621643066 / Matching loss: 4.0090504626277834e-05 / Item reconstruction: 0.004094628617167473 / Text reconstruction: 0.004763630218803883\n",
            "loss in epoch 20/21 iteration 20/67: 1.3879958391189575 / BPR loss: 1.385390043258667 / Matching loss: 3.546861626091413e-05 / Item reconstruction: 0.0036811823956668377 / Text reconstruction: 0.0036481344141066074\n",
            "loss in epoch 20/21 iteration 21/67: 1.387043833732605 / BPR loss: 1.384504795074463 / Matching loss: 3.506647772155702e-05 / Item reconstruction: 0.003538798075169325 / Text reconstruction: 0.003672703169286251\n",
            "loss in epoch 20/21 iteration 22/67: 1.373164415359497 / BPR loss: 1.3708775043487549 / Matching loss: 3.2485564588569105e-05 / Item reconstruction: 0.0032230862416327 / Text reconstruction: 0.0032140014227479696\n",
            "loss in epoch 20/21 iteration 23/67: 1.3735159635543823 / BPR loss: 1.3714154958724976 / Matching loss: 2.762434451142326e-05 / Item reconstruction: 0.002919557737186551 / Text reconstruction: 0.0030646291561424732\n",
            "loss in epoch 20/21 iteration 24/67: 1.37424898147583 / BPR loss: 1.3721979856491089 / Matching loss: 2.6783392968354747e-05 / Item reconstruction: 0.002848527394235134 / Text reconstruction: 0.0029991513583809137\n",
            "loss in epoch 20/21 iteration 25/67: 1.3725354671478271 / BPR loss: 1.370474934577942 / Matching loss: 2.9330660254345275e-05 / Item reconstruction: 0.0027504106983542442 / Text reconstruction: 0.0032798945903778076\n",
            "loss in epoch 20/21 iteration 26/67: 1.373772144317627 / BPR loss: 1.371796727180481 / Matching loss: 2.523057264625095e-05 / Item reconstruction: 0.0026854511816054583 / Text reconstruction: 0.003036627545952797\n",
            "loss in epoch 20/21 iteration 27/67: 1.3723292350769043 / BPR loss: 1.3703420162200928 / Matching loss: 2.706140367081389e-05 / Item reconstruction: 0.0027283448725938797 / Text reconstruction: 0.0029796031303703785\n",
            "loss in epoch 20/21 iteration 28/67: 1.371399998664856 / BPR loss: 1.369421124458313 / Matching loss: 2.7050993594457395e-05 / Item reconstruction: 0.0026787584647536278 / Text reconstruction: 0.0030620761681348085\n",
            "loss in epoch 20/21 iteration 29/67: 1.3725996017456055 / BPR loss: 1.3707051277160645 / Matching loss: 2.618535654619336e-05 / Item reconstruction: 0.0025088530965149403 / Text reconstruction: 0.003069279482588172\n",
            "loss in epoch 20/21 iteration 30/67: 1.3721303939819336 / BPR loss: 1.3702633380889893 / Matching loss: 2.620436134748161e-05 / Item reconstruction: 0.0023961407132446766 / Text reconstruction: 0.003214082447811961\n",
            "loss in epoch 20/21 iteration 31/67: 1.3734034299850464 / BPR loss: 1.371675968170166 / Matching loss: 2.4457982362946495e-05 / Item reconstruction: 0.0023033434990793467 / Text reconstruction: 0.002756713191047311\n",
            "loss in epoch 20/21 iteration 32/67: 1.3720753192901611 / BPR loss: 1.3703782558441162 / Matching loss: 2.7524067263584584e-05 / Item reconstruction: 0.002258305437862873 / Text reconstruction: 0.002701706485822797\n",
            "loss in epoch 20/21 iteration 33/67: 1.3747546672821045 / BPR loss: 1.3726701736450195 / Matching loss: 2.77435847237939e-05 / Item reconstruction: 0.002974071307107806 / Text reconstruction: 0.002848669420927763\n",
            "loss in epoch 20/21 iteration 34/67: 1.3784769773483276 / BPR loss: 1.3767271041870117 / Matching loss: 2.6070842068293132e-05 / Item reconstruction: 0.002695441711694002 / Text reconstruction: 0.0018798424862325191\n",
            "loss in epoch 20/21 iteration 35/67: 1.3767237663269043 / BPR loss: 1.37482488155365 / Matching loss: 2.955532181658782e-05 / Item reconstruction: 0.002789038699120283 / Text reconstruction: 0.0023741554468870163\n",
            "loss in epoch 20/21 iteration 36/67: 1.3852274417877197 / BPR loss: 1.3832576274871826 / Matching loss: 3.314429704914801e-05 / Item reconstruction: 0.0029177512042224407 / Text reconstruction: 0.0023888389114290476\n",
            "loss in epoch 20/21 iteration 37/67: 1.3865081071853638 / BPR loss: 1.3845187425613403 / Matching loss: 3.3649164834059775e-05 / Item reconstruction: 0.0028636311180889606 / Text reconstruction: 0.002619599923491478\n",
            "loss in epoch 20/21 iteration 38/67: 1.3845362663269043 / BPR loss: 1.3826117515563965 / Matching loss: 3.325668512843549e-05 / Item reconstruction: 0.002849985845386982 / Text reconstruction: 0.0023312182165682316\n",
            "loss in epoch 20/21 iteration 39/67: 1.3857717514038086 / BPR loss: 1.384127140045166 / Matching loss: 2.9315071515156887e-05 / Item reconstruction: 0.002597711980342865 / Text reconstruction: 0.0015818023821339011\n",
            "loss in epoch 20/21 iteration 40/67: 1.3876112699508667 / BPR loss: 1.3860501050949097 / Matching loss: 2.8820799343520775e-05 / Item reconstruction: 0.002507200464606285 / Text reconstruction: 0.0013932869769632816\n",
            "loss in epoch 20/21 iteration 41/67: 1.3802107572555542 / BPR loss: 1.3781538009643555 / Matching loss: 2.944278094219044e-05 / Item reconstruction: 0.0029547486919909716 / Text reconstruction: 0.0027505054604262114\n",
            "loss in epoch 20/21 iteration 42/67: 1.3733701705932617 / BPR loss: 1.3709665536880493 / Matching loss: 2.658405173860956e-05 / Item reconstruction: 0.003257148200646043 / Text reconstruction: 0.003742450848221779\n",
            "loss in epoch 20/21 iteration 43/67: 1.3700226545333862 / BPR loss: 1.3674051761627197 / Matching loss: 2.873205448850058e-05 / Item reconstruction: 0.0034409360960125923 / Text reconstruction: 0.004341749008744955\n",
            "loss in epoch 20/21 iteration 44/67: 1.3848416805267334 / BPR loss: 1.3832414150238037 / Matching loss: 2.7225605663261376e-05 / Item reconstruction: 0.0024051780346781015 / Text reconstruction: 0.0018525898922234774\n",
            "loss in epoch 20/21 iteration 45/67: 1.3866701126098633 / BPR loss: 1.3853521347045898 / Matching loss: 2.52962618105812e-05 / Item reconstruction: 0.0021127567160874605 / Text reconstruction: 0.0011811577714979649\n",
            "loss in epoch 20/21 iteration 46/67: 1.384407877922058 / BPR loss: 1.3829442262649536 / Matching loss: 2.443077573843766e-05 / Item reconstruction: 0.0023153284564614296 / Text reconstruction: 0.0014075738145038486\n",
            "loss in epoch 20/21 iteration 47/67: 1.385331153869629 / BPR loss: 1.3839383125305176 / Matching loss: 2.4244702217401937e-05 / Item reconstruction: 0.0022158436477184296 / Text reconstruction: 0.0013035880401730537\n",
            "loss in epoch 20/21 iteration 48/67: 1.3853169679641724 / BPR loss: 1.383905053138733 / Matching loss: 2.3457359930034727e-05 / Item reconstruction: 0.002247182186692953 / Text reconstruction: 0.0013244744623079896\n",
            "loss in epoch 20/21 iteration 49/67: 1.3858710527420044 / BPR loss: 1.384469985961914 / Matching loss: 2.2490039555123076e-05 / Item reconstruction: 0.002224802505224943 / Text reconstruction: 0.0013312572846189141\n",
            "loss in epoch 20/21 iteration 50/67: 1.3862358331680298 / BPR loss: 1.384817361831665 / Matching loss: 2.5794879547902383e-05 / Item reconstruction: 0.0022662412375211716 / Text reconstruction: 0.0012984509812667966\n",
            "loss in epoch 20/21 iteration 51/67: 1.387241244316101 / BPR loss: 1.385911226272583 / Matching loss: 2.6269341105944477e-05 / Item reconstruction: 0.0021756512578576803 / Text reconstruction: 0.0010801177704706788\n",
            "loss in epoch 20/21 iteration 52/67: 1.3865673542022705 / BPR loss: 1.3851828575134277 / Matching loss: 2.525201125536114e-05 / Item reconstruction: 0.002251115394756198 / Text reconstruction: 0.0011684764176607132\n",
            "loss in epoch 20/21 iteration 53/67: 1.3862154483795166 / BPR loss: 1.3848512172698975 / Matching loss: 2.4809442038531415e-05 / Item reconstruction: 0.0021758130751550198 / Text reconstruction: 0.0012578398454934359\n",
            "loss in epoch 20/21 iteration 54/67: 1.3879812955856323 / BPR loss: 1.3867084980010986 / Matching loss: 2.822412170644384e-05 / Item reconstruction: 0.002058065962046385 / Text reconstruction: 0.0010774543043226004\n",
            "loss in epoch 20/21 iteration 55/67: 1.387438416481018 / BPR loss: 1.386242151260376 / Matching loss: 2.6090918254340068e-05 / Item reconstruction: 0.0019876076839864254 / Text reconstruction: 0.0008817952475510538\n",
            "loss in epoch 20/21 iteration 56/67: 1.3872153759002686 / BPR loss: 1.385941505432129 / Matching loss: 2.671918446139898e-05 / Item reconstruction: 0.002114970004186034 / Text reconstruction: 0.0009482858004048467\n",
            "loss in epoch 20/21 iteration 57/67: 1.3872668743133545 / BPR loss: 1.3860571384429932 / Matching loss: 2.658037374203559e-05 / Item reconstruction: 0.001999773783609271 / Text reconstruction: 0.0009162483038380742\n",
            "loss in epoch 20/21 iteration 58/67: 1.3868333101272583 / BPR loss: 1.3856539726257324 / Matching loss: 2.674543793546036e-05 / Item reconstruction: 0.001965773059055209 / Text reconstruction: 0.0008490369655191898\n",
            "loss in epoch 20/21 iteration 59/67: 1.388317584991455 / BPR loss: 1.3871164321899414 / Matching loss: 2.6488742150831968e-05 / Item reconstruction: 0.0020140018314123154 / Text reconstruction: 0.0008389296708628535\n",
            "loss in epoch 20/21 iteration 60/67: 1.3872554302215576 / BPR loss: 1.386121392250061 / Matching loss: 2.249522731290199e-05 / Item reconstruction: 0.0018565040081739426 / Text reconstruction: 0.0009160119807347655\n",
            "loss in epoch 20/21 iteration 61/67: 1.3879342079162598 / BPR loss: 1.386825442314148 / Matching loss: 2.4527367713744752e-05 / Item reconstruction: 0.001852651359513402 / Text reconstruction: 0.0007891074055805802\n",
            "loss in epoch 20/21 iteration 62/67: 1.3858414888381958 / BPR loss: 1.3846793174743652 / Matching loss: 1.9373019313206896e-05 / Item reconstruction: 0.0018311227904632688 / Text reconstruction: 0.0011358025949448347\n",
            "loss in epoch 20/21 iteration 63/67: 1.3874338865280151 / BPR loss: 1.3861267566680908 / Matching loss: 3.039065995835699e-05 / Item reconstruction: 0.002170128747820854 / Text reconstruction: 0.0009583699284121394\n",
            "loss in epoch 20/21 iteration 64/67: 1.3877389430999756 / BPR loss: 1.3865216970443726 / Matching loss: 2.7227142709307373e-05 / Item reconstruction: 0.002032520715147257 / Text reconstruction: 0.0008692411938682199\n",
            "loss in epoch 20/21 iteration 65/67: 1.387189269065857 / BPR loss: 1.386038899421692 / Matching loss: 2.756636058620643e-05 / Item reconstruction: 0.0019117920892313123 / Text reconstruction: 0.0008342944784089923\n",
            "loss in epoch 20/21 iteration 66/67: 1.3872045278549194 / BPR loss: 1.386272668838501 / Matching loss: 2.0630059225368313e-05 / Item reconstruction: 0.0015268215211108327 / Text reconstruction: 0.0007388857193291187\n",
            "loss in epoch 20/21 iteration 67/67: 1.3869315385818481 / BPR loss: 1.3860807418823242 / Matching loss: 1.589766179677099e-05 / Item reconstruction: 0.0013461015187203884 / Text reconstruction: 0.0008092192001640797\n",
            "100% 20/20 [39:46<00:00, 119.33s/it]\n",
            "train time : 2386.566441297531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check current accelerate installation\n",
        "!pip show accelerate\n",
        "\n",
        "# If needed, reinstall accelerate\n",
        "!pip install accelerate --upgrade\n",
        "\n",
        "# Import accelerate to ensure it's properly loaded\n",
        "import accelerate\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k-Syy_udZhf3",
        "outputId": "95627db5-1262-4a02-b7b6-48448640a9e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: accelerate\n",
            "Version: 0.25.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: sylvain@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/site-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (0.25.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/site-packages (from accelerate) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (2.8.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (65.6.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
            "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.25.0\n",
            "    Uninstalling accelerate-0.25.0:\n",
            "      Successfully uninstalled accelerate-0.25.0\n",
            "Successfully installed accelerate-1.10.0\n",
            "Accelerate version: 1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train stage 2\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --pretrain_stage2 --rec_pre_trained_data All_Beauty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RzL1XeJfNBVf",
        "outputId": "9b8b6caf-fa9b-4ec2-e433-21ba38d43a9a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec strat train phase-2\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2169\n",
            "  0% 0/1 [00:00<?, ?it/s]A-LLMRec model loss in epoch 1/2 iteration 0/1084: 3.749458074569702\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1/1084: 1.1695094108581543\n",
            "A-LLMRec model loss in epoch 1/2 iteration 2/1084: 1.1876015663146973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 3/1084: 1.1115187406539917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 4/1084: 0.4738333821296692\n",
            "A-LLMRec model loss in epoch 1/2 iteration 5/1084: 0.6107915639877319\n",
            "A-LLMRec model loss in epoch 1/2 iteration 6/1084: 0.5962163209915161\n",
            "A-LLMRec model loss in epoch 1/2 iteration 7/1084: 0.7804021835327148\n",
            "A-LLMRec model loss in epoch 1/2 iteration 8/1084: 0.6375555992126465\n",
            "A-LLMRec model loss in epoch 1/2 iteration 9/1084: 0.5988432168960571\n",
            "A-LLMRec model loss in epoch 1/2 iteration 10/1084: 0.7886521816253662\n",
            "A-LLMRec model loss in epoch 1/2 iteration 11/1084: 1.149165153503418\n",
            "A-LLMRec model loss in epoch 1/2 iteration 12/1084: 0.8805671334266663\n",
            "A-LLMRec model loss in epoch 1/2 iteration 13/1084: 1.411594271659851\n",
            "A-LLMRec model loss in epoch 1/2 iteration 14/1084: 0.6790457367897034\n",
            "A-LLMRec model loss in epoch 1/2 iteration 15/1084: 1.1810444593429565\n",
            "A-LLMRec model loss in epoch 1/2 iteration 16/1084: 0.7943547964096069\n",
            "A-LLMRec model loss in epoch 1/2 iteration 17/1084: 0.46148574352264404\n",
            "A-LLMRec model loss in epoch 1/2 iteration 18/1084: 0.5371509790420532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 19/1084: 0.9139592051506042\n",
            "A-LLMRec model loss in epoch 1/2 iteration 20/1084: 0.5019413828849792\n",
            "A-LLMRec model loss in epoch 1/2 iteration 21/1084: 0.7473748922348022\n",
            "A-LLMRec model loss in epoch 1/2 iteration 22/1084: 0.8510785698890686\n",
            "A-LLMRec model loss in epoch 1/2 iteration 23/1084: 0.8874857425689697\n",
            "A-LLMRec model loss in epoch 1/2 iteration 24/1084: 0.9465659856796265\n",
            "A-LLMRec model loss in epoch 1/2 iteration 25/1084: 0.4165889024734497\n",
            "A-LLMRec model loss in epoch 1/2 iteration 26/1084: 0.5430973172187805\n",
            "A-LLMRec model loss in epoch 1/2 iteration 27/1084: 0.38874906301498413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 28/1084: 0.317933052778244\n",
            "A-LLMRec model loss in epoch 1/2 iteration 29/1084: 0.33045122027397156\n",
            "A-LLMRec model loss in epoch 1/2 iteration 30/1084: 0.44921523332595825\n",
            "A-LLMRec model loss in epoch 1/2 iteration 31/1084: 0.19920796155929565\n",
            "A-LLMRec model loss in epoch 1/2 iteration 32/1084: 0.624294638633728\n",
            "A-LLMRec model loss in epoch 1/2 iteration 33/1084: 0.11518973112106323\n",
            "A-LLMRec model loss in epoch 1/2 iteration 34/1084: 0.759300708770752\n",
            "A-LLMRec model loss in epoch 1/2 iteration 35/1084: 0.1643761843442917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 36/1084: 0.3738659620285034\n",
            "A-LLMRec model loss in epoch 1/2 iteration 37/1084: 0.4427277147769928\n",
            "A-LLMRec model loss in epoch 1/2 iteration 38/1084: 0.2745484709739685\n",
            "A-LLMRec model loss in epoch 1/2 iteration 39/1084: 0.1141388937830925\n",
            "A-LLMRec model loss in epoch 1/2 iteration 40/1084: 0.07538731396198273\n",
            "A-LLMRec model loss in epoch 1/2 iteration 41/1084: 0.16575497388839722\n",
            "A-LLMRec model loss in epoch 1/2 iteration 42/1084: 0.28526410460472107\n",
            "A-LLMRec model loss in epoch 1/2 iteration 43/1084: 0.24232247471809387\n",
            "A-LLMRec model loss in epoch 1/2 iteration 44/1084: 0.18038444221019745\n",
            "A-LLMRec model loss in epoch 1/2 iteration 45/1084: 0.257997065782547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 46/1084: 0.14320997893810272\n",
            "A-LLMRec model loss in epoch 1/2 iteration 47/1084: 0.14106276631355286\n",
            "A-LLMRec model loss in epoch 1/2 iteration 48/1084: 0.12240727245807648\n",
            "A-LLMRec model loss in epoch 1/2 iteration 49/1084: 0.43325063586235046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 50/1084: 0.3303346633911133\n",
            "A-LLMRec model loss in epoch 1/2 iteration 51/1084: 0.16065646708011627\n",
            "A-LLMRec model loss in epoch 1/2 iteration 52/1084: 0.07876289635896683\n",
            "A-LLMRec model loss in epoch 1/2 iteration 53/1084: 0.08423072844743729\n",
            "A-LLMRec model loss in epoch 1/2 iteration 54/1084: 0.18430738151073456\n",
            "A-LLMRec model loss in epoch 1/2 iteration 55/1084: 0.215040385723114\n",
            "A-LLMRec model loss in epoch 1/2 iteration 56/1084: 0.05834067612886429\n",
            "A-LLMRec model loss in epoch 1/2 iteration 57/1084: 0.2290651798248291\n",
            "A-LLMRec model loss in epoch 1/2 iteration 58/1084: 0.21694320440292358\n",
            "A-LLMRec model loss in epoch 1/2 iteration 59/1084: 0.19450850784778595\n",
            "A-LLMRec model loss in epoch 1/2 iteration 60/1084: 0.09094741940498352\n",
            "A-LLMRec model loss in epoch 1/2 iteration 61/1084: 0.2085694819688797\n",
            "A-LLMRec model loss in epoch 1/2 iteration 62/1084: 0.2278575301170349\n",
            "A-LLMRec model loss in epoch 1/2 iteration 63/1084: 0.09914896637201309\n",
            "A-LLMRec model loss in epoch 1/2 iteration 64/1084: 0.20137016475200653\n",
            "A-LLMRec model loss in epoch 1/2 iteration 65/1084: 0.47913601994514465\n",
            "A-LLMRec model loss in epoch 1/2 iteration 66/1084: 0.2229975014925003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 67/1084: 0.0395359992980957\n",
            "A-LLMRec model loss in epoch 1/2 iteration 68/1084: 0.12436278909444809\n",
            "A-LLMRec model loss in epoch 1/2 iteration 69/1084: 0.2020462453365326\n",
            "A-LLMRec model loss in epoch 1/2 iteration 70/1084: 0.47445178031921387\n",
            "A-LLMRec model loss in epoch 1/2 iteration 71/1084: 0.20631426572799683\n",
            "A-LLMRec model loss in epoch 1/2 iteration 72/1084: 0.1803494691848755\n",
            "A-LLMRec model loss in epoch 1/2 iteration 73/1084: 0.08029621094465256\n",
            "A-LLMRec model loss in epoch 1/2 iteration 74/1084: 0.10273431241512299\n",
            "A-LLMRec model loss in epoch 1/2 iteration 75/1084: 0.1547292023897171\n",
            "A-LLMRec model loss in epoch 1/2 iteration 76/1084: 0.2146843522787094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 77/1084: 0.3590331971645355\n",
            "A-LLMRec model loss in epoch 1/2 iteration 78/1084: 0.21227987110614777\n",
            "A-LLMRec model loss in epoch 1/2 iteration 79/1084: 0.0754624530673027\n",
            "A-LLMRec model loss in epoch 1/2 iteration 80/1084: 0.33057835698127747\n",
            "A-LLMRec model loss in epoch 1/2 iteration 81/1084: 0.26556524634361267\n",
            "A-LLMRec model loss in epoch 1/2 iteration 82/1084: 0.09146551787853241\n",
            "A-LLMRec model loss in epoch 1/2 iteration 83/1084: 0.18868809938430786\n",
            "A-LLMRec model loss in epoch 1/2 iteration 84/1084: 0.07623668760061264\n",
            "A-LLMRec model loss in epoch 1/2 iteration 85/1084: 0.3213806450366974\n",
            "A-LLMRec model loss in epoch 1/2 iteration 86/1084: 0.10924461483955383\n",
            "A-LLMRec model loss in epoch 1/2 iteration 87/1084: 0.35737237334251404\n",
            "A-LLMRec model loss in epoch 1/2 iteration 88/1084: 0.09471980482339859\n",
            "A-LLMRec model loss in epoch 1/2 iteration 89/1084: 0.0393611416220665\n",
            "A-LLMRec model loss in epoch 1/2 iteration 90/1084: 0.18295195698738098\n",
            "A-LLMRec model loss in epoch 1/2 iteration 91/1084: 0.08287219703197479\n",
            "A-LLMRec model loss in epoch 1/2 iteration 92/1084: 0.12607990205287933\n",
            "A-LLMRec model loss in epoch 1/2 iteration 93/1084: 0.663994550704956\n",
            "A-LLMRec model loss in epoch 1/2 iteration 94/1084: 0.0581117607653141\n",
            "A-LLMRec model loss in epoch 1/2 iteration 95/1084: 0.28392311930656433\n",
            "A-LLMRec model loss in epoch 1/2 iteration 96/1084: 0.07493245601654053\n",
            "A-LLMRec model loss in epoch 1/2 iteration 97/1084: 0.1043083444237709\n",
            "A-LLMRec model loss in epoch 1/2 iteration 98/1084: 0.04536747187376022\n",
            "A-LLMRec model loss in epoch 1/2 iteration 99/1084: 0.14508751034736633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 100/1084: 0.09813416749238968\n",
            "A-LLMRec model loss in epoch 1/2 iteration 101/1084: 0.06767033785581589\n",
            "A-LLMRec model loss in epoch 1/2 iteration 102/1084: 0.14530695974826813\n",
            "A-LLMRec model loss in epoch 1/2 iteration 103/1084: 0.3126475512981415\n",
            "A-LLMRec model loss in epoch 1/2 iteration 104/1084: 0.16246366500854492\n",
            "A-LLMRec model loss in epoch 1/2 iteration 105/1084: 0.14821042120456696\n",
            "A-LLMRec model loss in epoch 1/2 iteration 106/1084: 0.11318481713533401\n",
            "A-LLMRec model loss in epoch 1/2 iteration 107/1084: 0.11951769888401031\n",
            "A-LLMRec model loss in epoch 1/2 iteration 108/1084: 0.0922873243689537\n",
            "A-LLMRec model loss in epoch 1/2 iteration 109/1084: 0.046489741653203964\n",
            "A-LLMRec model loss in epoch 1/2 iteration 110/1084: 0.14283142983913422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 111/1084: 0.25993862748146057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 112/1084: 0.5833490490913391\n",
            "A-LLMRec model loss in epoch 1/2 iteration 113/1084: 0.12592259049415588\n",
            "A-LLMRec model loss in epoch 1/2 iteration 114/1084: 0.09592178463935852\n",
            "A-LLMRec model loss in epoch 1/2 iteration 115/1084: 0.07403529435396194\n",
            "A-LLMRec model loss in epoch 1/2 iteration 116/1084: 0.07255178689956665\n",
            "A-LLMRec model loss in epoch 1/2 iteration 117/1084: 0.17410160601139069\n",
            "A-LLMRec model loss in epoch 1/2 iteration 118/1084: 0.1086966022849083\n",
            "A-LLMRec model loss in epoch 1/2 iteration 119/1084: 0.2680111229419708\n",
            "A-LLMRec model loss in epoch 1/2 iteration 120/1084: 0.19979293644428253\n",
            "A-LLMRec model loss in epoch 1/2 iteration 121/1084: 0.3224242329597473\n",
            "A-LLMRec model loss in epoch 1/2 iteration 122/1084: 0.07557255774736404\n",
            "A-LLMRec model loss in epoch 1/2 iteration 123/1084: 0.07058251649141312\n",
            "A-LLMRec model loss in epoch 1/2 iteration 124/1084: 0.03970227390527725\n",
            "A-LLMRec model loss in epoch 1/2 iteration 125/1084: 0.05510963127017021\n",
            "A-LLMRec model loss in epoch 1/2 iteration 126/1084: 0.04591941833496094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 127/1084: 0.02526874653995037\n",
            "A-LLMRec model loss in epoch 1/2 iteration 128/1084: 0.3125768303871155\n",
            "A-LLMRec model loss in epoch 1/2 iteration 129/1084: 0.14689110219478607\n",
            "A-LLMRec model loss in epoch 1/2 iteration 130/1084: 0.05034103989601135\n",
            "A-LLMRec model loss in epoch 1/2 iteration 131/1084: 0.03817938268184662\n",
            "A-LLMRec model loss in epoch 1/2 iteration 132/1084: 0.40875813364982605\n",
            "A-LLMRec model loss in epoch 1/2 iteration 133/1084: 0.048820946365594864\n",
            "A-LLMRec model loss in epoch 1/2 iteration 134/1084: 0.07463327795267105\n",
            "A-LLMRec model loss in epoch 1/2 iteration 135/1084: 0.05980173498392105\n",
            "A-LLMRec model loss in epoch 1/2 iteration 136/1084: 0.5070236921310425\n",
            "A-LLMRec model loss in epoch 1/2 iteration 137/1084: 0.23497475683689117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 138/1084: 0.2901427149772644\n",
            "A-LLMRec model loss in epoch 1/2 iteration 139/1084: 0.11676850914955139\n",
            "A-LLMRec model loss in epoch 1/2 iteration 140/1084: 0.029609182849526405\n",
            "A-LLMRec model loss in epoch 1/2 iteration 141/1084: 0.13272233307361603\n",
            "A-LLMRec model loss in epoch 1/2 iteration 142/1084: 0.12670780718326569\n",
            "A-LLMRec model loss in epoch 1/2 iteration 143/1084: 0.033142540603876114\n",
            "A-LLMRec model loss in epoch 1/2 iteration 144/1084: 0.17767241597175598\n",
            "A-LLMRec model loss in epoch 1/2 iteration 145/1084: 0.19931983947753906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 146/1084: 0.14692023396492004\n",
            "A-LLMRec model loss in epoch 1/2 iteration 147/1084: 0.1243104636669159\n",
            "A-LLMRec model loss in epoch 1/2 iteration 148/1084: 0.1009138971567154\n",
            "A-LLMRec model loss in epoch 1/2 iteration 149/1084: 0.02405654825270176\n",
            "A-LLMRec model loss in epoch 1/2 iteration 150/1084: 0.03641688451170921\n",
            "A-LLMRec model loss in epoch 1/2 iteration 151/1084: 0.2721853256225586\n",
            "A-LLMRec model loss in epoch 1/2 iteration 152/1084: 0.12276303023099899\n",
            "A-LLMRec model loss in epoch 1/2 iteration 153/1084: 0.02691488526761532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 154/1084: 0.08143625408411026\n",
            "A-LLMRec model loss in epoch 1/2 iteration 155/1084: 0.29178231954574585\n",
            "A-LLMRec model loss in epoch 1/2 iteration 156/1084: 0.21450787782669067\n",
            "A-LLMRec model loss in epoch 1/2 iteration 157/1084: 0.07590773701667786\n",
            "A-LLMRec model loss in epoch 1/2 iteration 158/1084: 0.06445063650608063\n",
            "A-LLMRec model loss in epoch 1/2 iteration 159/1084: 0.03747379779815674\n",
            "A-LLMRec model loss in epoch 1/2 iteration 160/1084: 0.13938041031360626\n",
            "A-LLMRec model loss in epoch 1/2 iteration 161/1084: 0.15141834318637848\n",
            "A-LLMRec model loss in epoch 1/2 iteration 162/1084: 0.06732962280511856\n",
            "A-LLMRec model loss in epoch 1/2 iteration 163/1084: 0.04738469794392586\n",
            "A-LLMRec model loss in epoch 1/2 iteration 164/1084: 0.09167042374610901\n",
            "A-LLMRec model loss in epoch 1/2 iteration 165/1084: 0.3694501221179962\n",
            "A-LLMRec model loss in epoch 1/2 iteration 166/1084: 0.021109461784362793\n",
            "A-LLMRec model loss in epoch 1/2 iteration 167/1084: 0.034463878720998764\n",
            "A-LLMRec model loss in epoch 1/2 iteration 168/1084: 0.6035643219947815\n",
            "A-LLMRec model loss in epoch 1/2 iteration 169/1084: 0.055873312056064606\n",
            "A-LLMRec model loss in epoch 1/2 iteration 170/1084: 0.028745397925376892\n",
            "A-LLMRec model loss in epoch 1/2 iteration 171/1084: 0.07178990542888641\n",
            "A-LLMRec model loss in epoch 1/2 iteration 172/1084: 0.1472034454345703\n",
            "A-LLMRec model loss in epoch 1/2 iteration 173/1084: 0.008242294192314148\n",
            "A-LLMRec model loss in epoch 1/2 iteration 174/1084: 0.037595801055431366\n",
            "A-LLMRec model loss in epoch 1/2 iteration 175/1084: 0.1741776168346405\n",
            "A-LLMRec model loss in epoch 1/2 iteration 176/1084: 0.2444395124912262\n",
            "A-LLMRec model loss in epoch 1/2 iteration 177/1084: 0.3149120509624481\n",
            "A-LLMRec model loss in epoch 1/2 iteration 178/1084: 0.2779664695262909\n",
            "A-LLMRec model loss in epoch 1/2 iteration 179/1084: 0.040528226643800735\n",
            "A-LLMRec model loss in epoch 1/2 iteration 180/1084: 0.06101067364215851\n",
            "A-LLMRec model loss in epoch 1/2 iteration 181/1084: 0.08670902252197266\n",
            "A-LLMRec model loss in epoch 1/2 iteration 182/1084: 0.6937190294265747\n",
            "A-LLMRec model loss in epoch 1/2 iteration 183/1084: 0.03373733535408974\n",
            "A-LLMRec model loss in epoch 1/2 iteration 184/1084: 0.04556848108768463\n",
            "A-LLMRec model loss in epoch 1/2 iteration 185/1084: 0.23071345686912537\n",
            "A-LLMRec model loss in epoch 1/2 iteration 186/1084: 0.10491618514060974\n",
            "A-LLMRec model loss in epoch 1/2 iteration 187/1084: 0.07880457490682602\n",
            "A-LLMRec model loss in epoch 1/2 iteration 188/1084: 0.06503435969352722\n",
            "A-LLMRec model loss in epoch 1/2 iteration 189/1084: 0.3518298268318176\n",
            "A-LLMRec model loss in epoch 1/2 iteration 190/1084: 0.10201532393693924\n",
            "A-LLMRec model loss in epoch 1/2 iteration 191/1084: 0.1503317654132843\n",
            "A-LLMRec model loss in epoch 1/2 iteration 192/1084: 0.147210955619812\n",
            "A-LLMRec model loss in epoch 1/2 iteration 193/1084: 0.16489335894584656\n",
            "A-LLMRec model loss in epoch 1/2 iteration 194/1084: 0.011897294782102108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 195/1084: 0.17795871198177338\n",
            "A-LLMRec model loss in epoch 1/2 iteration 196/1084: 0.32553306221961975\n",
            "A-LLMRec model loss in epoch 1/2 iteration 197/1084: 0.19554220139980316\n",
            "A-LLMRec model loss in epoch 1/2 iteration 198/1084: 0.1972849816083908\n",
            "A-LLMRec model loss in epoch 1/2 iteration 199/1084: 0.26029786467552185\n",
            "A-LLMRec model loss in epoch 1/2 iteration 200/1084: 0.1808357834815979\n",
            "A-LLMRec model loss in epoch 1/2 iteration 201/1084: 0.11139509826898575\n",
            "A-LLMRec model loss in epoch 1/2 iteration 202/1084: 0.188576802611351\n",
            "A-LLMRec model loss in epoch 1/2 iteration 203/1084: 0.21286793053150177\n",
            "A-LLMRec model loss in epoch 1/2 iteration 204/1084: 0.013606095686554909\n",
            "A-LLMRec model loss in epoch 1/2 iteration 205/1084: 0.12893079221248627\n",
            "A-LLMRec model loss in epoch 1/2 iteration 206/1084: 0.07657503336668015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 207/1084: 0.050790805369615555\n",
            "A-LLMRec model loss in epoch 1/2 iteration 208/1084: 0.02247835136950016\n",
            "A-LLMRec model loss in epoch 1/2 iteration 209/1084: 0.12225159257650375\n",
            "A-LLMRec model loss in epoch 1/2 iteration 210/1084: 0.06945505738258362\n",
            "A-LLMRec model loss in epoch 1/2 iteration 211/1084: 0.09634652733802795\n",
            "A-LLMRec model loss in epoch 1/2 iteration 212/1084: 0.11651529371738434\n",
            "A-LLMRec model loss in epoch 1/2 iteration 213/1084: 0.010271641425788403\n",
            "A-LLMRec model loss in epoch 1/2 iteration 214/1084: 0.08974818885326385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 215/1084: 0.021743658930063248\n",
            "A-LLMRec model loss in epoch 1/2 iteration 216/1084: 0.16669704020023346\n",
            "A-LLMRec model loss in epoch 1/2 iteration 217/1084: 0.11456514894962311\n",
            "A-LLMRec model loss in epoch 1/2 iteration 218/1084: 0.1294519454240799\n",
            "A-LLMRec model loss in epoch 1/2 iteration 219/1084: 0.05574629828333855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 220/1084: 0.1611868441104889\n",
            "A-LLMRec model loss in epoch 1/2 iteration 221/1084: 0.006724660284817219\n",
            "A-LLMRec model loss in epoch 1/2 iteration 222/1084: 0.19061124324798584\n",
            "A-LLMRec model loss in epoch 1/2 iteration 223/1084: 0.008466045372188091\n",
            "A-LLMRec model loss in epoch 1/2 iteration 224/1084: 0.01702575758099556\n",
            "A-LLMRec model loss in epoch 1/2 iteration 225/1084: 0.07074315845966339\n",
            "A-LLMRec model loss in epoch 1/2 iteration 226/1084: 0.03335847705602646\n",
            "A-LLMRec model loss in epoch 1/2 iteration 227/1084: 0.3063355088233948\n",
            "A-LLMRec model loss in epoch 1/2 iteration 228/1084: 0.01947716996073723\n",
            "A-LLMRec model loss in epoch 1/2 iteration 229/1084: 0.04998178035020828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 230/1084: 0.20729777216911316\n",
            "A-LLMRec model loss in epoch 1/2 iteration 231/1084: 0.1726633757352829\n",
            "A-LLMRec model loss in epoch 1/2 iteration 232/1084: 0.12932850420475006\n",
            "A-LLMRec model loss in epoch 1/2 iteration 233/1084: 0.031082989647984505\n",
            "A-LLMRec model loss in epoch 1/2 iteration 234/1084: 0.4909971356391907\n",
            "A-LLMRec model loss in epoch 1/2 iteration 235/1084: 0.043070677667856216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 236/1084: 0.02092285454273224\n",
            "A-LLMRec model loss in epoch 1/2 iteration 237/1084: 0.02197198197245598\n",
            "A-LLMRec model loss in epoch 1/2 iteration 238/1084: 0.06130359321832657\n",
            "A-LLMRec model loss in epoch 1/2 iteration 239/1084: 0.031129131093621254\n",
            "A-LLMRec model loss in epoch 1/2 iteration 240/1084: 0.01684585213661194\n",
            "A-LLMRec model loss in epoch 1/2 iteration 241/1084: 0.027213390916585922\n",
            "A-LLMRec model loss in epoch 1/2 iteration 242/1084: 0.013036362826824188\n",
            "A-LLMRec model loss in epoch 1/2 iteration 243/1084: 0.08531997352838516\n",
            "A-LLMRec model loss in epoch 1/2 iteration 244/1084: 0.026082785800099373\n",
            "A-LLMRec model loss in epoch 1/2 iteration 245/1084: 0.026796676218509674\n",
            "A-LLMRec model loss in epoch 1/2 iteration 246/1084: 0.06356140226125717\n",
            "A-LLMRec model loss in epoch 1/2 iteration 247/1084: 0.0296180360019207\n",
            "A-LLMRec model loss in epoch 1/2 iteration 248/1084: 0.10050027072429657\n",
            "A-LLMRec model loss in epoch 1/2 iteration 249/1084: 0.46426886320114136\n",
            "A-LLMRec model loss in epoch 1/2 iteration 250/1084: 0.17053653299808502\n",
            "A-LLMRec model loss in epoch 1/2 iteration 251/1084: 0.0024127578362822533\n",
            "A-LLMRec model loss in epoch 1/2 iteration 252/1084: 0.1671113818883896\n",
            "A-LLMRec model loss in epoch 1/2 iteration 253/1084: 0.012514142319560051\n",
            "A-LLMRec model loss in epoch 1/2 iteration 254/1084: 0.1720208376646042\n",
            "A-LLMRec model loss in epoch 1/2 iteration 255/1084: 0.11006490141153336\n",
            "A-LLMRec model loss in epoch 1/2 iteration 256/1084: 0.15584610402584076\n",
            "A-LLMRec model loss in epoch 1/2 iteration 257/1084: 0.060761354863643646\n",
            "A-LLMRec model loss in epoch 1/2 iteration 258/1084: 0.07526733726263046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 259/1084: 0.2792268395423889\n",
            "A-LLMRec model loss in epoch 1/2 iteration 260/1084: 0.1258191615343094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 261/1084: 0.07632825523614883\n",
            "A-LLMRec model loss in epoch 1/2 iteration 262/1084: 0.023027103394269943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 263/1084: 0.33902397751808167\n",
            "A-LLMRec model loss in epoch 1/2 iteration 264/1084: 0.07442627102136612\n",
            "A-LLMRec model loss in epoch 1/2 iteration 265/1084: 0.1294778287410736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 266/1084: 0.07139065116643906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 267/1084: 0.039616070687770844\n",
            "A-LLMRec model loss in epoch 1/2 iteration 268/1084: 0.18962115049362183\n",
            "A-LLMRec model loss in epoch 1/2 iteration 269/1084: 0.07761865854263306\n",
            "A-LLMRec model loss in epoch 1/2 iteration 270/1084: 0.021282648667693138\n",
            "A-LLMRec model loss in epoch 1/2 iteration 271/1084: 0.10147053748369217\n",
            "A-LLMRec model loss in epoch 1/2 iteration 272/1084: 0.05516568943858147\n",
            "A-LLMRec model loss in epoch 1/2 iteration 273/1084: 0.07261038571596146\n",
            "A-LLMRec model loss in epoch 1/2 iteration 274/1084: 0.017364928498864174\n",
            "A-LLMRec model loss in epoch 1/2 iteration 275/1084: 0.10069590061903\n",
            "A-LLMRec model loss in epoch 1/2 iteration 276/1084: 0.01980779506266117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 277/1084: 0.06572982668876648\n",
            "A-LLMRec model loss in epoch 1/2 iteration 278/1084: 0.028932679444551468\n",
            "A-LLMRec model loss in epoch 1/2 iteration 279/1084: 0.04370056092739105\n",
            "A-LLMRec model loss in epoch 1/2 iteration 280/1084: 0.5052855014801025\n",
            "A-LLMRec model loss in epoch 1/2 iteration 281/1084: 0.07787065953016281\n",
            "A-LLMRec model loss in epoch 1/2 iteration 282/1084: 0.027430538088083267\n",
            "A-LLMRec model loss in epoch 1/2 iteration 283/1084: 0.037468865513801575\n",
            "A-LLMRec model loss in epoch 1/2 iteration 284/1084: 0.08859608322381973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 285/1084: 0.0488177090883255\n",
            "A-LLMRec model loss in epoch 1/2 iteration 286/1084: 0.02301963046193123\n",
            "A-LLMRec model loss in epoch 1/2 iteration 287/1084: 0.019119789823889732\n",
            "A-LLMRec model loss in epoch 1/2 iteration 288/1084: 0.03404473140835762\n",
            "A-LLMRec model loss in epoch 1/2 iteration 289/1084: 0.14718236029148102\n",
            "A-LLMRec model loss in epoch 1/2 iteration 290/1084: 0.20533689856529236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 291/1084: 0.026986422017216682\n",
            "A-LLMRec model loss in epoch 1/2 iteration 292/1084: 0.13962788879871368\n",
            "A-LLMRec model loss in epoch 1/2 iteration 293/1084: 0.2788521945476532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 294/1084: 0.27444130182266235\n",
            "A-LLMRec model loss in epoch 1/2 iteration 295/1084: 0.22490738332271576\n",
            "A-LLMRec model loss in epoch 1/2 iteration 296/1084: 0.012126751244068146\n",
            "A-LLMRec model loss in epoch 1/2 iteration 297/1084: 0.007408024277538061\n",
            "A-LLMRec model loss in epoch 1/2 iteration 298/1084: 0.2071373462677002\n",
            "A-LLMRec model loss in epoch 1/2 iteration 299/1084: 0.08965073525905609\n",
            "A-LLMRec model loss in epoch 1/2 iteration 300/1084: 0.005427661817520857\n",
            "A-LLMRec model loss in epoch 1/2 iteration 301/1084: 0.20308521389961243\n",
            "A-LLMRec model loss in epoch 1/2 iteration 302/1084: 0.16443270444869995\n",
            "A-LLMRec model loss in epoch 1/2 iteration 303/1084: 0.45765694975852966\n",
            "A-LLMRec model loss in epoch 1/2 iteration 304/1084: 0.6235061883926392\n",
            "A-LLMRec model loss in epoch 1/2 iteration 305/1084: 0.04324033483862877\n",
            "A-LLMRec model loss in epoch 1/2 iteration 306/1084: 0.07042098045349121\n",
            "A-LLMRec model loss in epoch 1/2 iteration 307/1084: 0.0812077447772026\n",
            "A-LLMRec model loss in epoch 1/2 iteration 308/1084: 0.19227702915668488\n",
            "A-LLMRec model loss in epoch 1/2 iteration 309/1084: 0.21909643709659576\n",
            "A-LLMRec model loss in epoch 1/2 iteration 310/1084: 0.08583354204893112\n",
            "A-LLMRec model loss in epoch 1/2 iteration 311/1084: 0.02107437327504158\n",
            "A-LLMRec model loss in epoch 1/2 iteration 312/1084: 0.0073250941932201385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 313/1084: 0.11853643506765366\n",
            "A-LLMRec model loss in epoch 1/2 iteration 314/1084: 0.319556325674057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 315/1084: 0.20346641540527344\n",
            "A-LLMRec model loss in epoch 1/2 iteration 316/1084: 0.1506078690290451\n",
            "A-LLMRec model loss in epoch 1/2 iteration 317/1084: 0.012566895224153996\n",
            "A-LLMRec model loss in epoch 1/2 iteration 318/1084: 0.031737323850393295\n",
            "A-LLMRec model loss in epoch 1/2 iteration 319/1084: 0.029672536998987198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 320/1084: 0.15212677419185638\n",
            "A-LLMRec model loss in epoch 1/2 iteration 321/1084: 0.06191856041550636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 322/1084: 0.28904154896736145\n",
            "A-LLMRec model loss in epoch 1/2 iteration 323/1084: 0.0658801943063736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 324/1084: 0.35105639696121216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 325/1084: 0.019864298403263092\n",
            "A-LLMRec model loss in epoch 1/2 iteration 326/1084: 0.04253285005688667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 327/1084: 0.048363059759140015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 328/1084: 0.15349848568439484\n",
            "A-LLMRec model loss in epoch 1/2 iteration 329/1084: 0.14419586956501007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 330/1084: 0.10012184828519821\n",
            "A-LLMRec model loss in epoch 1/2 iteration 331/1084: 0.10734494775533676\n",
            "A-LLMRec model loss in epoch 1/2 iteration 332/1084: 0.12700411677360535\n",
            "A-LLMRec model loss in epoch 1/2 iteration 333/1084: 0.03331146016716957\n",
            "A-LLMRec model loss in epoch 1/2 iteration 334/1084: 0.033691491931676865\n",
            "A-LLMRec model loss in epoch 1/2 iteration 335/1084: 0.19532348215579987\n",
            "A-LLMRec model loss in epoch 1/2 iteration 336/1084: 0.030309995636343956\n",
            "A-LLMRec model loss in epoch 1/2 iteration 337/1084: 0.040241241455078125\n",
            "A-LLMRec model loss in epoch 1/2 iteration 338/1084: 0.15784874558448792\n",
            "A-LLMRec model loss in epoch 1/2 iteration 339/1084: 0.09918224066495895\n",
            "A-LLMRec model loss in epoch 1/2 iteration 340/1084: 0.3355838656425476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 341/1084: 0.15639930963516235\n",
            "A-LLMRec model loss in epoch 1/2 iteration 342/1084: 0.04638950154185295\n",
            "A-LLMRec model loss in epoch 1/2 iteration 343/1084: 0.08882391452789307\n",
            "A-LLMRec model loss in epoch 1/2 iteration 344/1084: 0.03489324077963829\n",
            "A-LLMRec model loss in epoch 1/2 iteration 345/1084: 0.12447083741426468\n",
            "A-LLMRec model loss in epoch 1/2 iteration 346/1084: 0.015567734837532043\n",
            "A-LLMRec model loss in epoch 1/2 iteration 347/1084: 0.0988662838935852\n",
            "A-LLMRec model loss in epoch 1/2 iteration 348/1084: 0.2266264408826828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 349/1084: 0.2000361979007721\n",
            "A-LLMRec model loss in epoch 1/2 iteration 350/1084: 0.016597336158156395\n",
            "A-LLMRec model loss in epoch 1/2 iteration 351/1084: 0.18938708305358887\n",
            "A-LLMRec model loss in epoch 1/2 iteration 352/1084: 0.1500018686056137\n",
            "A-LLMRec model loss in epoch 1/2 iteration 353/1084: 0.11951694637537003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 354/1084: 0.07315458357334137\n",
            "A-LLMRec model loss in epoch 1/2 iteration 355/1084: 0.005337251350283623\n",
            "A-LLMRec model loss in epoch 1/2 iteration 356/1084: 0.46700549125671387\n",
            "A-LLMRec model loss in epoch 1/2 iteration 357/1084: 0.10015543550252914\n",
            "A-LLMRec model loss in epoch 1/2 iteration 358/1084: 0.1245720311999321\n",
            "A-LLMRec model loss in epoch 1/2 iteration 359/1084: 0.6169806122779846\n",
            "A-LLMRec model loss in epoch 1/2 iteration 360/1084: 0.016049984842538834\n",
            "A-LLMRec model loss in epoch 1/2 iteration 361/1084: 0.13389243185520172\n",
            "A-LLMRec model loss in epoch 1/2 iteration 362/1084: 0.02928456850349903\n",
            "A-LLMRec model loss in epoch 1/2 iteration 363/1084: 0.18450261652469635\n",
            "A-LLMRec model loss in epoch 1/2 iteration 364/1084: 0.10282469540834427\n",
            "A-LLMRec model loss in epoch 1/2 iteration 365/1084: 0.05808287858963013\n",
            "A-LLMRec model loss in epoch 1/2 iteration 366/1084: 0.16249454021453857\n",
            "A-LLMRec model loss in epoch 1/2 iteration 367/1084: 0.09681027382612228\n",
            "A-LLMRec model loss in epoch 1/2 iteration 368/1084: 0.08835621178150177\n",
            "A-LLMRec model loss in epoch 1/2 iteration 369/1084: 0.036459293216466904\n",
            "A-LLMRec model loss in epoch 1/2 iteration 370/1084: 0.07110326737165451\n",
            "A-LLMRec model loss in epoch 1/2 iteration 371/1084: 0.04972938448190689\n",
            "A-LLMRec model loss in epoch 1/2 iteration 372/1084: 0.12483617663383484\n",
            "A-LLMRec model loss in epoch 1/2 iteration 373/1084: 0.04711702838540077\n",
            "A-LLMRec model loss in epoch 1/2 iteration 374/1084: 0.19985410571098328\n",
            "A-LLMRec model loss in epoch 1/2 iteration 375/1084: 0.043204739689826965\n",
            "A-LLMRec model loss in epoch 1/2 iteration 376/1084: 0.09250737726688385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 377/1084: 0.1121036559343338\n",
            "A-LLMRec model loss in epoch 1/2 iteration 378/1084: 0.10342006385326385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 379/1084: 0.01760769635438919\n",
            "A-LLMRec model loss in epoch 1/2 iteration 380/1084: 0.05466032400727272\n",
            "A-LLMRec model loss in epoch 1/2 iteration 381/1084: 0.005507344380021095\n",
            "A-LLMRec model loss in epoch 1/2 iteration 382/1084: 0.009648733772337437\n",
            "A-LLMRec model loss in epoch 1/2 iteration 383/1084: 0.007548287510871887\n",
            "A-LLMRec model loss in epoch 1/2 iteration 384/1084: 0.127354234457016\n",
            "A-LLMRec model loss in epoch 1/2 iteration 385/1084: 0.19272035360336304\n",
            "A-LLMRec model loss in epoch 1/2 iteration 386/1084: 0.1106603592634201\n",
            "A-LLMRec model loss in epoch 1/2 iteration 387/1084: 0.12614688277244568\n",
            "A-LLMRec model loss in epoch 1/2 iteration 388/1084: 0.17366808652877808\n",
            "A-LLMRec model loss in epoch 1/2 iteration 389/1084: 0.07039955258369446\n",
            "A-LLMRec model loss in epoch 1/2 iteration 390/1084: 0.4845629036426544\n",
            "A-LLMRec model loss in epoch 1/2 iteration 391/1084: 0.20332731306552887\n",
            "A-LLMRec model loss in epoch 1/2 iteration 392/1084: 0.0620514340698719\n",
            "A-LLMRec model loss in epoch 1/2 iteration 393/1084: 0.010903946124017239\n",
            "A-LLMRec model loss in epoch 1/2 iteration 394/1084: 0.06995636969804764\n",
            "A-LLMRec model loss in epoch 1/2 iteration 395/1084: 0.19476190209388733\n",
            "A-LLMRec model loss in epoch 1/2 iteration 396/1084: 0.0819915384054184\n",
            "A-LLMRec model loss in epoch 1/2 iteration 397/1084: 0.3558933138847351\n",
            "A-LLMRec model loss in epoch 1/2 iteration 398/1084: 0.16505374014377594\n",
            "A-LLMRec model loss in epoch 1/2 iteration 399/1084: 0.008353115990757942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 400/1084: 0.023522527888417244\n",
            "A-LLMRec model loss in epoch 1/2 iteration 401/1084: 0.02548871375620365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 402/1084: 0.032652221620082855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 403/1084: 0.1492326259613037\n",
            "A-LLMRec model loss in epoch 1/2 iteration 404/1084: 0.008678244426846504\n",
            "A-LLMRec model loss in epoch 1/2 iteration 405/1084: 0.018397778272628784\n",
            "A-LLMRec model loss in epoch 1/2 iteration 406/1084: 0.4121968746185303\n",
            "A-LLMRec model loss in epoch 1/2 iteration 407/1084: 0.02442416176199913\n",
            "A-LLMRec model loss in epoch 1/2 iteration 408/1084: 0.07603061199188232\n",
            "A-LLMRec model loss in epoch 1/2 iteration 409/1084: 0.1673726737499237\n",
            "A-LLMRec model loss in epoch 1/2 iteration 410/1084: 0.12652118504047394\n",
            "A-LLMRec model loss in epoch 1/2 iteration 411/1084: 0.4467140734195709\n",
            "A-LLMRec model loss in epoch 1/2 iteration 412/1084: 0.12736158072948456\n",
            "A-LLMRec model loss in epoch 1/2 iteration 413/1084: 0.20024478435516357\n",
            "A-LLMRec model loss in epoch 1/2 iteration 414/1084: 0.015838690102100372\n",
            "A-LLMRec model loss in epoch 1/2 iteration 415/1084: 0.025391506031155586\n",
            "A-LLMRec model loss in epoch 1/2 iteration 416/1084: 0.13947512209415436\n",
            "A-LLMRec model loss in epoch 1/2 iteration 417/1084: 0.04394344612956047\n",
            "A-LLMRec model loss in epoch 1/2 iteration 418/1084: 0.038397517055273056\n",
            "A-LLMRec model loss in epoch 1/2 iteration 419/1084: 0.23744316399097443\n",
            "A-LLMRec model loss in epoch 1/2 iteration 420/1084: 0.04840492084622383\n",
            "A-LLMRec model loss in epoch 1/2 iteration 421/1084: 0.26141560077667236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 422/1084: 0.04017691686749458\n",
            "A-LLMRec model loss in epoch 1/2 iteration 423/1084: 0.178646519780159\n",
            "A-LLMRec model loss in epoch 1/2 iteration 424/1084: 0.051366694271564484\n",
            "A-LLMRec model loss in epoch 1/2 iteration 425/1084: 0.008723449893295765\n",
            "A-LLMRec model loss in epoch 1/2 iteration 426/1084: 0.03394421190023422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 427/1084: 0.012619875371456146\n",
            "A-LLMRec model loss in epoch 1/2 iteration 428/1084: 0.17129568755626678\n",
            "A-LLMRec model loss in epoch 1/2 iteration 429/1084: 0.02605067938566208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 430/1084: 0.12648575007915497\n",
            "A-LLMRec model loss in epoch 1/2 iteration 431/1084: 0.4516298472881317\n",
            "A-LLMRec model loss in epoch 1/2 iteration 432/1084: 0.15442386269569397\n",
            "A-LLMRec model loss in epoch 1/2 iteration 433/1084: 0.010205094702541828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 434/1084: 0.009555964730679989\n",
            "A-LLMRec model loss in epoch 1/2 iteration 435/1084: 0.016490599140524864\n",
            "A-LLMRec model loss in epoch 1/2 iteration 436/1084: 0.007444244809448719\n",
            "A-LLMRec model loss in epoch 1/2 iteration 437/1084: 0.016562307253479958\n",
            "A-LLMRec model loss in epoch 1/2 iteration 438/1084: 0.07279793173074722\n",
            "A-LLMRec model loss in epoch 1/2 iteration 439/1084: 0.2102532982826233\n",
            "A-LLMRec model loss in epoch 1/2 iteration 440/1084: 0.00401168130338192\n",
            "A-LLMRec model loss in epoch 1/2 iteration 441/1084: 0.1833619624376297\n",
            "A-LLMRec model loss in epoch 1/2 iteration 442/1084: 0.1362791657447815\n",
            "A-LLMRec model loss in epoch 1/2 iteration 443/1084: 0.007754666730761528\n",
            "A-LLMRec model loss in epoch 1/2 iteration 444/1084: 0.010622825473546982\n",
            "A-LLMRec model loss in epoch 1/2 iteration 445/1084: 0.018901372328400612\n",
            "A-LLMRec model loss in epoch 1/2 iteration 446/1084: 0.08305034786462784\n",
            "A-LLMRec model loss in epoch 1/2 iteration 447/1084: 0.12823258340358734\n",
            "A-LLMRec model loss in epoch 1/2 iteration 448/1084: 0.07765552401542664\n",
            "A-LLMRec model loss in epoch 1/2 iteration 449/1084: 0.017870141193270683\n",
            "A-LLMRec model loss in epoch 1/2 iteration 450/1084: 0.10674814134836197\n",
            "A-LLMRec model loss in epoch 1/2 iteration 451/1084: 0.007860822603106499\n",
            "A-LLMRec model loss in epoch 1/2 iteration 452/1084: 0.010293341241776943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 453/1084: 0.20811933279037476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 454/1084: 0.027263447642326355\n",
            "A-LLMRec model loss in epoch 1/2 iteration 455/1084: 0.012541648931801319\n",
            "A-LLMRec model loss in epoch 1/2 iteration 456/1084: 0.021595416590571404\n",
            "A-LLMRec model loss in epoch 1/2 iteration 457/1084: 0.5838671326637268\n",
            "A-LLMRec model loss in epoch 1/2 iteration 458/1084: 0.15024375915527344\n",
            "A-LLMRec model loss in epoch 1/2 iteration 459/1084: 0.01566782221198082\n",
            "A-LLMRec model loss in epoch 1/2 iteration 460/1084: 0.2224072515964508\n",
            "A-LLMRec model loss in epoch 1/2 iteration 461/1084: 0.21214091777801514\n",
            "A-LLMRec model loss in epoch 1/2 iteration 462/1084: 0.20936451852321625\n",
            "A-LLMRec model loss in epoch 1/2 iteration 463/1084: 0.18315517902374268\n",
            "A-LLMRec model loss in epoch 1/2 iteration 464/1084: 0.21250687539577484\n",
            "A-LLMRec model loss in epoch 1/2 iteration 465/1084: 0.055891506373882294\n",
            "A-LLMRec model loss in epoch 1/2 iteration 466/1084: 0.1512109935283661\n",
            "A-LLMRec model loss in epoch 1/2 iteration 467/1084: 0.10727598518133163\n",
            "A-LLMRec model loss in epoch 1/2 iteration 468/1084: 0.108609139919281\n",
            "A-LLMRec model loss in epoch 1/2 iteration 469/1084: 0.027695728465914726\n",
            "A-LLMRec model loss in epoch 1/2 iteration 470/1084: 0.08362752944231033\n",
            "A-LLMRec model loss in epoch 1/2 iteration 471/1084: 0.01155488658696413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 472/1084: 0.018146712332963943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 473/1084: 0.049725241959095\n",
            "A-LLMRec model loss in epoch 1/2 iteration 474/1084: 0.011395196430385113\n",
            "A-LLMRec model loss in epoch 1/2 iteration 475/1084: 0.013754704967141151\n",
            "A-LLMRec model loss in epoch 1/2 iteration 476/1084: 0.0663720965385437\n",
            "A-LLMRec model loss in epoch 1/2 iteration 477/1084: 0.011552740819752216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 478/1084: 0.12961934506893158\n",
            "A-LLMRec model loss in epoch 1/2 iteration 479/1084: 0.1639794409275055\n",
            "A-LLMRec model loss in epoch 1/2 iteration 480/1084: 0.07319636642932892\n",
            "A-LLMRec model loss in epoch 1/2 iteration 481/1084: 0.1821291744709015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 482/1084: 0.09436041116714478\n",
            "A-LLMRec model loss in epoch 1/2 iteration 483/1084: 0.0045183501206338406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 484/1084: 0.021476978436112404\n",
            "A-LLMRec model loss in epoch 1/2 iteration 485/1084: 0.0024615731090307236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 486/1084: 0.04212331399321556\n",
            "A-LLMRec model loss in epoch 1/2 iteration 487/1084: 0.2913215160369873\n",
            "A-LLMRec model loss in epoch 1/2 iteration 488/1084: 0.0207948237657547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 489/1084: 0.008125633001327515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 490/1084: 0.07990638166666031\n",
            "A-LLMRec model loss in epoch 1/2 iteration 491/1084: 0.014554494991898537\n",
            "A-LLMRec model loss in epoch 1/2 iteration 492/1084: 0.019435884431004524\n",
            "A-LLMRec model loss in epoch 1/2 iteration 493/1084: 0.03561646118760109\n",
            "A-LLMRec model loss in epoch 1/2 iteration 494/1084: 0.003945020027458668\n",
            "A-LLMRec model loss in epoch 1/2 iteration 495/1084: 0.16814175248146057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 496/1084: 0.060478758066892624\n",
            "A-LLMRec model loss in epoch 1/2 iteration 497/1084: 0.03004429116845131\n",
            "A-LLMRec model loss in epoch 1/2 iteration 498/1084: 0.045979488641023636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 499/1084: 0.007286204025149345\n",
            "A-LLMRec model loss in epoch 1/2 iteration 500/1084: 0.0054306890815496445\n",
            "A-LLMRec model loss in epoch 1/2 iteration 501/1084: 0.2410096377134323\n",
            "A-LLMRec model loss in epoch 1/2 iteration 502/1084: 0.013595166616141796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 503/1084: 0.07896741479635239\n",
            "A-LLMRec model loss in epoch 1/2 iteration 504/1084: 0.20882607996463776\n",
            "A-LLMRec model loss in epoch 1/2 iteration 505/1084: 0.002462979406118393\n",
            "A-LLMRec model loss in epoch 1/2 iteration 506/1084: 0.10341167449951172\n",
            "A-LLMRec model loss in epoch 1/2 iteration 507/1084: 0.19943837821483612\n",
            "A-LLMRec model loss in epoch 1/2 iteration 508/1084: 0.18572869896888733\n",
            "A-LLMRec model loss in epoch 1/2 iteration 509/1084: 0.13753175735473633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 510/1084: 0.036265648901462555\n",
            "A-LLMRec model loss in epoch 1/2 iteration 511/1084: 0.030497979372739792\n",
            "A-LLMRec model loss in epoch 1/2 iteration 512/1084: 0.0489703044295311\n",
            "A-LLMRec model loss in epoch 1/2 iteration 513/1084: 0.10984694957733154\n",
            "A-LLMRec model loss in epoch 1/2 iteration 514/1084: 0.08118735998868942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 515/1084: 0.0068435207940638065\n",
            "A-LLMRec model loss in epoch 1/2 iteration 516/1084: 0.06854495406150818\n",
            "A-LLMRec model loss in epoch 1/2 iteration 517/1084: 0.014664876274764538\n",
            "A-LLMRec model loss in epoch 1/2 iteration 518/1084: 0.00370263890363276\n",
            "A-LLMRec model loss in epoch 1/2 iteration 519/1084: 0.008884783834218979\n",
            "A-LLMRec model loss in epoch 1/2 iteration 520/1084: 0.03518441319465637\n",
            "A-LLMRec model loss in epoch 1/2 iteration 521/1084: 0.4620918929576874\n",
            "A-LLMRec model loss in epoch 1/2 iteration 522/1084: 0.13867636024951935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 523/1084: 0.16489452123641968\n",
            "A-LLMRec model loss in epoch 1/2 iteration 524/1084: 0.06235164403915405\n",
            "A-LLMRec model loss in epoch 1/2 iteration 525/1084: 0.06449181586503983\n",
            "A-LLMRec model loss in epoch 1/2 iteration 526/1084: 0.049573373049497604\n",
            "A-LLMRec model loss in epoch 1/2 iteration 527/1084: 0.020277395844459534\n",
            "A-LLMRec model loss in epoch 1/2 iteration 528/1084: 0.009516761638224125\n",
            "A-LLMRec model loss in epoch 1/2 iteration 529/1084: 0.030187858268618584\n",
            "A-LLMRec model loss in epoch 1/2 iteration 530/1084: 0.2878517508506775\n",
            "A-LLMRec model loss in epoch 1/2 iteration 531/1084: 0.06075366213917732\n",
            "A-LLMRec model loss in epoch 1/2 iteration 532/1084: 0.12246295064687729\n",
            "A-LLMRec model loss in epoch 1/2 iteration 533/1084: 0.013324614614248276\n",
            "A-LLMRec model loss in epoch 1/2 iteration 534/1084: 0.15321028232574463\n",
            "A-LLMRec model loss in epoch 1/2 iteration 535/1084: 0.2223535180091858\n",
            "A-LLMRec model loss in epoch 1/2 iteration 536/1084: 0.19090522825717926\n",
            "A-LLMRec model loss in epoch 1/2 iteration 537/1084: 0.330699622631073\n",
            "A-LLMRec model loss in epoch 1/2 iteration 538/1084: 0.24396321177482605\n",
            "A-LLMRec model loss in epoch 1/2 iteration 539/1084: 0.22828513383865356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 540/1084: 0.016056612133979797\n",
            "A-LLMRec model loss in epoch 1/2 iteration 541/1084: 0.18499308824539185\n",
            "A-LLMRec model loss in epoch 1/2 iteration 542/1084: 0.05155368521809578\n",
            "A-LLMRec model loss in epoch 1/2 iteration 543/1084: 0.1364358365535736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 544/1084: 0.058960914611816406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 545/1084: 0.08997415006160736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 546/1084: 0.07758178561925888\n",
            "A-LLMRec model loss in epoch 1/2 iteration 547/1084: 0.05640813708305359\n",
            "A-LLMRec model loss in epoch 1/2 iteration 548/1084: 0.15007084608078003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 549/1084: 0.1724923998117447\n",
            "A-LLMRec model loss in epoch 1/2 iteration 550/1084: 0.13527244329452515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 551/1084: 0.08629410713911057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 552/1084: 0.12206738442182541\n",
            "A-LLMRec model loss in epoch 1/2 iteration 553/1084: 0.25117605924606323\n",
            "A-LLMRec model loss in epoch 1/2 iteration 554/1084: 0.1419181376695633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 555/1084: 0.01332961767911911\n",
            "A-LLMRec model loss in epoch 1/2 iteration 556/1084: 0.006519087590277195\n",
            "A-LLMRec model loss in epoch 1/2 iteration 557/1084: 0.012597640976309776\n",
            "A-LLMRec model loss in epoch 1/2 iteration 558/1084: 0.007899516262114048\n",
            "A-LLMRec model loss in epoch 1/2 iteration 559/1084: 0.01225955132395029\n",
            "A-LLMRec model loss in epoch 1/2 iteration 560/1084: 0.018245892599225044\n",
            "A-LLMRec model loss in epoch 1/2 iteration 561/1084: 0.17418009042739868\n",
            "A-LLMRec model loss in epoch 1/2 iteration 562/1084: 0.04710401967167854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 563/1084: 0.007046227343380451\n",
            "A-LLMRec model loss in epoch 1/2 iteration 564/1084: 0.1269223392009735\n",
            "A-LLMRec model loss in epoch 1/2 iteration 565/1084: 0.07993733882904053\n",
            "A-LLMRec model loss in epoch 1/2 iteration 566/1084: 0.3576166331768036\n",
            "A-LLMRec model loss in epoch 1/2 iteration 567/1084: 0.16740266978740692\n",
            "A-LLMRec model loss in epoch 1/2 iteration 568/1084: 0.011512493714690208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 569/1084: 0.13765279948711395\n",
            "A-LLMRec model loss in epoch 1/2 iteration 570/1084: 0.019045909866690636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 571/1084: 0.12424097955226898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 572/1084: 0.013463198207318783\n",
            "A-LLMRec model loss in epoch 1/2 iteration 573/1084: 0.0920945256948471\n",
            "A-LLMRec model loss in epoch 1/2 iteration 574/1084: 0.15840940177440643\n",
            "A-LLMRec model loss in epoch 1/2 iteration 575/1084: 0.07027442008256912\n",
            "A-LLMRec model loss in epoch 1/2 iteration 576/1084: 0.2875942885875702\n",
            "A-LLMRec model loss in epoch 1/2 iteration 577/1084: 0.026360666379332542\n",
            "A-LLMRec model loss in epoch 1/2 iteration 578/1084: 0.004244664683938026\n",
            "A-LLMRec model loss in epoch 1/2 iteration 579/1084: 0.011248771101236343\n",
            "A-LLMRec model loss in epoch 1/2 iteration 580/1084: 0.10612709820270538\n",
            "A-LLMRec model loss in epoch 1/2 iteration 581/1084: 0.013199320994317532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 582/1084: 0.0218010563403368\n",
            "A-LLMRec model loss in epoch 1/2 iteration 583/1084: 0.010772066190838814\n",
            "A-LLMRec model loss in epoch 1/2 iteration 584/1084: 0.08551597595214844\n",
            "A-LLMRec model loss in epoch 1/2 iteration 585/1084: 0.24180202186107635\n",
            "A-LLMRec model loss in epoch 1/2 iteration 586/1084: 0.03668643906712532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 587/1084: 0.02157927118241787\n",
            "A-LLMRec model loss in epoch 1/2 iteration 588/1084: 0.03403915464878082\n",
            "A-LLMRec model loss in epoch 1/2 iteration 589/1084: 0.22169511020183563\n",
            "A-LLMRec model loss in epoch 1/2 iteration 590/1084: 0.0652940571308136\n",
            "A-LLMRec model loss in epoch 1/2 iteration 591/1084: 0.13105250895023346\n",
            "A-LLMRec model loss in epoch 1/2 iteration 592/1084: 0.030882053077220917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 593/1084: 0.07815387845039368\n",
            "A-LLMRec model loss in epoch 1/2 iteration 594/1084: 0.01566009782254696\n",
            "A-LLMRec model loss in epoch 1/2 iteration 595/1084: 0.007814121432602406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 596/1084: 0.041893064975738525\n",
            "A-LLMRec model loss in epoch 1/2 iteration 597/1084: 0.18243810534477234\n",
            "A-LLMRec model loss in epoch 1/2 iteration 598/1084: 0.014188366942107677\n",
            "A-LLMRec model loss in epoch 1/2 iteration 599/1084: 0.008679480291903019\n",
            "A-LLMRec model loss in epoch 1/2 iteration 600/1084: 0.0049475026316940784\n",
            "A-LLMRec model loss in epoch 1/2 iteration 601/1084: 0.09307027608156204\n",
            "A-LLMRec model loss in epoch 1/2 iteration 602/1084: 0.1259201169013977\n",
            "A-LLMRec model loss in epoch 1/2 iteration 603/1084: 0.004218380898237228\n",
            "A-LLMRec model loss in epoch 1/2 iteration 604/1084: 0.23162315785884857\n",
            "A-LLMRec model loss in epoch 1/2 iteration 605/1084: 0.10395972430706024\n",
            "A-LLMRec model loss in epoch 1/2 iteration 606/1084: 0.02094513177871704\n",
            "A-LLMRec model loss in epoch 1/2 iteration 607/1084: 0.12844064831733704\n",
            "A-LLMRec model loss in epoch 1/2 iteration 608/1084: 0.3124949634075165\n",
            "A-LLMRec model loss in epoch 1/2 iteration 609/1084: 0.10583516955375671\n",
            "A-LLMRec model loss in epoch 1/2 iteration 610/1084: 0.009863617829978466\n",
            "A-LLMRec model loss in epoch 1/2 iteration 611/1084: 0.13140955567359924\n",
            "A-LLMRec model loss in epoch 1/2 iteration 612/1084: 0.06681227684020996\n",
            "A-LLMRec model loss in epoch 1/2 iteration 613/1084: 0.025047319009900093\n",
            "A-LLMRec model loss in epoch 1/2 iteration 614/1084: 0.021646371111273766\n",
            "A-LLMRec model loss in epoch 1/2 iteration 615/1084: 0.0031405985355377197\n",
            "A-LLMRec model loss in epoch 1/2 iteration 616/1084: 0.025812117382884026\n",
            "A-LLMRec model loss in epoch 1/2 iteration 617/1084: 0.15305814146995544\n",
            "A-LLMRec model loss in epoch 1/2 iteration 618/1084: 0.012890461832284927\n",
            "A-LLMRec model loss in epoch 1/2 iteration 619/1084: 0.09270565956830978\n",
            "A-LLMRec model loss in epoch 1/2 iteration 620/1084: 0.06167564541101456\n",
            "A-LLMRec model loss in epoch 1/2 iteration 621/1084: 0.09347960352897644\n",
            "A-LLMRec model loss in epoch 1/2 iteration 622/1084: 0.09029129892587662\n",
            "A-LLMRec model loss in epoch 1/2 iteration 623/1084: 0.14077524840831757\n",
            "A-LLMRec model loss in epoch 1/2 iteration 624/1084: 0.15152105689048767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 625/1084: 0.002101530320942402\n",
            "A-LLMRec model loss in epoch 1/2 iteration 626/1084: 0.19103223085403442\n",
            "A-LLMRec model loss in epoch 1/2 iteration 627/1084: 0.0034689931198954582\n",
            "A-LLMRec model loss in epoch 1/2 iteration 628/1084: 0.0873003602027893\n",
            "A-LLMRec model loss in epoch 1/2 iteration 629/1084: 0.06336664408445358\n",
            "A-LLMRec model loss in epoch 1/2 iteration 630/1084: 0.04391653463244438\n",
            "A-LLMRec model loss in epoch 1/2 iteration 631/1084: 0.16173624992370605\n",
            "A-LLMRec model loss in epoch 1/2 iteration 632/1084: 0.06442507356405258\n",
            "A-LLMRec model loss in epoch 1/2 iteration 633/1084: 0.025590555742383003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 634/1084: 0.03313680738210678\n",
            "A-LLMRec model loss in epoch 1/2 iteration 635/1084: 0.20066501200199127\n",
            "A-LLMRec model loss in epoch 1/2 iteration 636/1084: 0.28104835748672485\n",
            "A-LLMRec model loss in epoch 1/2 iteration 637/1084: 0.015690352767705917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 638/1084: 0.03940664604306221\n",
            "A-LLMRec model loss in epoch 1/2 iteration 639/1084: 0.05561313033103943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 640/1084: 0.032083384692668915\n",
            "A-LLMRec model loss in epoch 1/2 iteration 641/1084: 0.005856244824826717\n",
            "A-LLMRec model loss in epoch 1/2 iteration 642/1084: 0.026863273233175278\n",
            "A-LLMRec model loss in epoch 1/2 iteration 643/1084: 0.018421366810798645\n",
            "A-LLMRec model loss in epoch 1/2 iteration 644/1084: 0.005264581181108952\n",
            "A-LLMRec model loss in epoch 1/2 iteration 645/1084: 0.30383944511413574\n",
            "A-LLMRec model loss in epoch 1/2 iteration 646/1084: 0.48589104413986206\n",
            "A-LLMRec model loss in epoch 1/2 iteration 647/1084: 0.11104026436805725\n",
            "A-LLMRec model loss in epoch 1/2 iteration 648/1084: 0.04620024561882019\n",
            "A-LLMRec model loss in epoch 1/2 iteration 649/1084: 0.005053992848843336\n",
            "A-LLMRec model loss in epoch 1/2 iteration 650/1084: 0.10885121673345566\n",
            "A-LLMRec model loss in epoch 1/2 iteration 651/1084: 0.08402781188488007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 652/1084: 0.0038635139353573322\n",
            "A-LLMRec model loss in epoch 1/2 iteration 653/1084: 0.1593494713306427\n",
            "A-LLMRec model loss in epoch 1/2 iteration 654/1084: 0.012512936256825924\n",
            "A-LLMRec model loss in epoch 1/2 iteration 655/1084: 0.1055031418800354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 656/1084: 0.10309390723705292\n",
            "A-LLMRec model loss in epoch 1/2 iteration 657/1084: 0.06489045917987823\n",
            "A-LLMRec model loss in epoch 1/2 iteration 658/1084: 0.0031393233221024275\n",
            "A-LLMRec model loss in epoch 1/2 iteration 659/1084: 0.2195708155632019\n",
            "A-LLMRec model loss in epoch 1/2 iteration 660/1084: 0.06765405833721161\n",
            "A-LLMRec model loss in epoch 1/2 iteration 661/1084: 0.18007241189479828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 662/1084: 0.10674499720335007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 663/1084: 0.09614487737417221\n",
            "A-LLMRec model loss in epoch 1/2 iteration 664/1084: 0.03975032642483711\n",
            "A-LLMRec model loss in epoch 1/2 iteration 665/1084: 0.012789778411388397\n",
            "A-LLMRec model loss in epoch 1/2 iteration 666/1084: 0.07488347589969635\n",
            "A-LLMRec model loss in epoch 1/2 iteration 667/1084: 0.14547514915466309\n",
            "A-LLMRec model loss in epoch 1/2 iteration 668/1084: 0.043269846588373184\n",
            "A-LLMRec model loss in epoch 1/2 iteration 669/1084: 0.0064931102097034454\n",
            "A-LLMRec model loss in epoch 1/2 iteration 670/1084: 0.024424133822321892\n",
            "A-LLMRec model loss in epoch 1/2 iteration 671/1084: 0.05222811922430992\n",
            "A-LLMRec model loss in epoch 1/2 iteration 672/1084: 0.17060431838035583\n",
            "A-LLMRec model loss in epoch 1/2 iteration 673/1084: 0.010300161316990852\n",
            "A-LLMRec model loss in epoch 1/2 iteration 674/1084: 0.08347106724977493\n",
            "A-LLMRec model loss in epoch 1/2 iteration 675/1084: 0.011169557459652424\n",
            "A-LLMRec model loss in epoch 1/2 iteration 676/1084: 0.056855328381061554\n",
            "A-LLMRec model loss in epoch 1/2 iteration 677/1084: 0.01132495328783989\n",
            "A-LLMRec model loss in epoch 1/2 iteration 678/1084: 0.04518003389239311\n",
            "A-LLMRec model loss in epoch 1/2 iteration 679/1084: 0.11755841225385666\n",
            "A-LLMRec model loss in epoch 1/2 iteration 680/1084: 0.020314905792474747\n",
            "A-LLMRec model loss in epoch 1/2 iteration 681/1084: 0.423073410987854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 682/1084: 0.0690847635269165\n",
            "A-LLMRec model loss in epoch 1/2 iteration 683/1084: 0.004304605536162853\n",
            "A-LLMRec model loss in epoch 1/2 iteration 684/1084: 0.07874796539545059\n",
            "A-LLMRec model loss in epoch 1/2 iteration 685/1084: 0.1475117951631546\n",
            "A-LLMRec model loss in epoch 1/2 iteration 686/1084: 0.005909913685172796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 687/1084: 0.0048986938782036304\n",
            "A-LLMRec model loss in epoch 1/2 iteration 688/1084: 0.010517912916839123\n",
            "A-LLMRec model loss in epoch 1/2 iteration 689/1084: 0.022582003846764565\n",
            "A-LLMRec model loss in epoch 1/2 iteration 690/1084: 0.006095598451793194\n",
            "A-LLMRec model loss in epoch 1/2 iteration 691/1084: 0.21277107298374176\n",
            "A-LLMRec model loss in epoch 1/2 iteration 692/1084: 0.08193853497505188\n",
            "A-LLMRec model loss in epoch 1/2 iteration 693/1084: 0.005254325456917286\n",
            "A-LLMRec model loss in epoch 1/2 iteration 694/1084: 0.12200947105884552\n",
            "A-LLMRec model loss in epoch 1/2 iteration 695/1084: 0.00467143626883626\n",
            "A-LLMRec model loss in epoch 1/2 iteration 696/1084: 0.08536440879106522\n",
            "A-LLMRec model loss in epoch 1/2 iteration 697/1084: 0.0031378199346363544\n",
            "A-LLMRec model loss in epoch 1/2 iteration 698/1084: 0.032311003655195236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 699/1084: 0.006207259837538004\n",
            "A-LLMRec model loss in epoch 1/2 iteration 700/1084: 0.012976780533790588\n",
            "A-LLMRec model loss in epoch 1/2 iteration 701/1084: 0.19845034182071686\n",
            "A-LLMRec model loss in epoch 1/2 iteration 702/1084: 0.13588376343250275\n",
            "A-LLMRec model loss in epoch 1/2 iteration 703/1084: 0.18159867823123932\n",
            "A-LLMRec model loss in epoch 1/2 iteration 704/1084: 0.10242721438407898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 705/1084: 0.003684194991365075\n",
            "A-LLMRec model loss in epoch 1/2 iteration 706/1084: 0.04956383258104324\n",
            "A-LLMRec model loss in epoch 1/2 iteration 707/1084: 0.1448313593864441\n",
            "A-LLMRec model loss in epoch 1/2 iteration 708/1084: 0.10233961045742035\n",
            "A-LLMRec model loss in epoch 1/2 iteration 709/1084: 0.0035415678285062313\n",
            "A-LLMRec model loss in epoch 1/2 iteration 710/1084: 0.02294790744781494\n",
            "A-LLMRec model loss in epoch 1/2 iteration 711/1084: 0.0023398278281092644\n",
            "A-LLMRec model loss in epoch 1/2 iteration 712/1084: 0.1438390463590622\n",
            "A-LLMRec model loss in epoch 1/2 iteration 713/1084: 0.09800364822149277\n",
            "A-LLMRec model loss in epoch 1/2 iteration 714/1084: 0.15171918272972107\n",
            "A-LLMRec model loss in epoch 1/2 iteration 715/1084: 0.013636630959808826\n",
            "A-LLMRec model loss in epoch 1/2 iteration 716/1084: 0.013225981965661049\n",
            "A-LLMRec model loss in epoch 1/2 iteration 717/1084: 0.004382972605526447\n",
            "A-LLMRec model loss in epoch 1/2 iteration 718/1084: 0.09656224399805069\n",
            "A-LLMRec model loss in epoch 1/2 iteration 719/1084: 0.10560869425535202\n",
            "A-LLMRec model loss in epoch 1/2 iteration 720/1084: 0.0093785859644413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 721/1084: 0.014999305829405785\n",
            "A-LLMRec model loss in epoch 1/2 iteration 722/1084: 0.01274225115776062\n",
            "A-LLMRec model loss in epoch 1/2 iteration 723/1084: 0.02042323164641857\n",
            "A-LLMRec model loss in epoch 1/2 iteration 724/1084: 0.01818123832345009\n",
            "A-LLMRec model loss in epoch 1/2 iteration 725/1084: 0.15175293385982513\n",
            "A-LLMRec model loss in epoch 1/2 iteration 726/1084: 0.010307524353265762\n",
            "A-LLMRec model loss in epoch 1/2 iteration 727/1084: 0.18589192628860474\n",
            "A-LLMRec model loss in epoch 1/2 iteration 728/1084: 0.10872615873813629\n",
            "A-LLMRec model loss in epoch 1/2 iteration 729/1084: 0.23365430533885956\n",
            "A-LLMRec model loss in epoch 1/2 iteration 730/1084: 0.10966946929693222\n",
            "A-LLMRec model loss in epoch 1/2 iteration 731/1084: 0.16332903504371643\n",
            "A-LLMRec model loss in epoch 1/2 iteration 732/1084: 0.09522257000207901\n",
            "A-LLMRec model loss in epoch 1/2 iteration 733/1084: 0.008030170574784279\n",
            "A-LLMRec model loss in epoch 1/2 iteration 734/1084: 0.11971022933721542\n",
            "A-LLMRec model loss in epoch 1/2 iteration 735/1084: 0.2726612687110901\n",
            "A-LLMRec model loss in epoch 1/2 iteration 736/1084: 0.10533830523490906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 737/1084: 0.004588792100548744\n",
            "A-LLMRec model loss in epoch 1/2 iteration 738/1084: 0.007033747620880604\n",
            "A-LLMRec model loss in epoch 1/2 iteration 739/1084: 0.04265441745519638\n",
            "A-LLMRec model loss in epoch 1/2 iteration 740/1084: 0.14134038984775543\n",
            "A-LLMRec model loss in epoch 1/2 iteration 741/1084: 0.12121538817882538\n",
            "A-LLMRec model loss in epoch 1/2 iteration 742/1084: 0.17861904203891754\n",
            "A-LLMRec model loss in epoch 1/2 iteration 743/1084: 0.015596750192344189\n",
            "A-LLMRec model loss in epoch 1/2 iteration 744/1084: 0.24114523828029633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 745/1084: 0.009256581775844097\n",
            "A-LLMRec model loss in epoch 1/2 iteration 746/1084: 0.09193982928991318\n",
            "A-LLMRec model loss in epoch 1/2 iteration 747/1084: 0.022450748831033707\n",
            "A-LLMRec model loss in epoch 1/2 iteration 748/1084: 0.07617626339197159\n",
            "A-LLMRec model loss in epoch 1/2 iteration 749/1084: 0.20638114213943481\n",
            "A-LLMRec model loss in epoch 1/2 iteration 750/1084: 0.02798435278236866\n",
            "A-LLMRec model loss in epoch 1/2 iteration 751/1084: 0.006259771529585123\n",
            "A-LLMRec model loss in epoch 1/2 iteration 752/1084: 0.41217780113220215\n",
            "A-LLMRec model loss in epoch 1/2 iteration 753/1084: 0.012923529371619225\n",
            "A-LLMRec model loss in epoch 1/2 iteration 754/1084: 0.017830422148108482\n",
            "A-LLMRec model loss in epoch 1/2 iteration 755/1084: 0.01852324791252613\n",
            "A-LLMRec model loss in epoch 1/2 iteration 756/1084: 0.20130589604377747\n",
            "A-LLMRec model loss in epoch 1/2 iteration 757/1084: 0.006679082754999399\n",
            "A-LLMRec model loss in epoch 1/2 iteration 758/1084: 0.12388203293085098\n",
            "A-LLMRec model loss in epoch 1/2 iteration 759/1084: 0.03557894378900528\n",
            "A-LLMRec model loss in epoch 1/2 iteration 760/1084: 0.06217899173498154\n",
            "A-LLMRec model loss in epoch 1/2 iteration 761/1084: 0.009163150563836098\n",
            "A-LLMRec model loss in epoch 1/2 iteration 762/1084: 0.019176023080945015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 763/1084: 0.020716676488518715\n",
            "A-LLMRec model loss in epoch 1/2 iteration 764/1084: 0.2278316169977188\n",
            "A-LLMRec model loss in epoch 1/2 iteration 765/1084: 0.0024356446228921413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 766/1084: 0.1533822864294052\n",
            "A-LLMRec model loss in epoch 1/2 iteration 767/1084: 0.005990315228700638\n",
            "A-LLMRec model loss in epoch 1/2 iteration 768/1084: 0.00767435971647501\n",
            "A-LLMRec model loss in epoch 1/2 iteration 769/1084: 0.05893919989466667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 770/1084: 0.025145502761006355\n",
            "A-LLMRec model loss in epoch 1/2 iteration 771/1084: 0.002998870564624667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 772/1084: 0.017793739214539528\n",
            "A-LLMRec model loss in epoch 1/2 iteration 773/1084: 0.1417286992073059\n",
            "A-LLMRec model loss in epoch 1/2 iteration 774/1084: 0.1364525705575943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 775/1084: 0.25157588720321655\n",
            "A-LLMRec model loss in epoch 1/2 iteration 776/1084: 0.023662777617573738\n",
            "A-LLMRec model loss in epoch 1/2 iteration 777/1084: 0.04943927377462387\n",
            "A-LLMRec model loss in epoch 1/2 iteration 778/1084: 0.07447590678930283\n",
            "A-LLMRec model loss in epoch 1/2 iteration 779/1084: 0.09734386950731277\n",
            "A-LLMRec model loss in epoch 1/2 iteration 780/1084: 0.05294818431138992\n",
            "A-LLMRec model loss in epoch 1/2 iteration 781/1084: 0.15607191622257233\n",
            "A-LLMRec model loss in epoch 1/2 iteration 782/1084: 0.01047926302999258\n",
            "A-LLMRec model loss in epoch 1/2 iteration 783/1084: 0.07230666279792786\n",
            "A-LLMRec model loss in epoch 1/2 iteration 784/1084: 0.006104396656155586\n",
            "A-LLMRec model loss in epoch 1/2 iteration 785/1084: 0.019198084250092506\n",
            "A-LLMRec model loss in epoch 1/2 iteration 786/1084: 0.12975187599658966\n",
            "A-LLMRec model loss in epoch 1/2 iteration 787/1084: 0.12995706498622894\n",
            "A-LLMRec model loss in epoch 1/2 iteration 788/1084: 0.2306855171918869\n",
            "A-LLMRec model loss in epoch 1/2 iteration 789/1084: 0.3212241530418396\n",
            "A-LLMRec model loss in epoch 1/2 iteration 790/1084: 0.4610406160354614\n",
            "A-LLMRec model loss in epoch 1/2 iteration 791/1084: 0.17650815844535828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 792/1084: 0.11672934144735336\n",
            "A-LLMRec model loss in epoch 1/2 iteration 793/1084: 0.12648893892765045\n",
            "A-LLMRec model loss in epoch 1/2 iteration 794/1084: 0.025843197479844093\n",
            "A-LLMRec model loss in epoch 1/2 iteration 795/1084: 0.061619702726602554\n",
            "A-LLMRec model loss in epoch 1/2 iteration 796/1084: 0.020403943955898285\n",
            "A-LLMRec model loss in epoch 1/2 iteration 797/1084: 0.07033773511648178\n",
            "A-LLMRec model loss in epoch 1/2 iteration 798/1084: 0.02951139211654663\n",
            "A-LLMRec model loss in epoch 1/2 iteration 799/1084: 0.01486101746559143\n",
            "A-LLMRec model loss in epoch 1/2 iteration 800/1084: 0.05737937241792679\n",
            "A-LLMRec model loss in epoch 1/2 iteration 801/1084: 0.32973355054855347\n",
            "A-LLMRec model loss in epoch 1/2 iteration 802/1084: 0.12606769800186157\n",
            "A-LLMRec model loss in epoch 1/2 iteration 803/1084: 0.06552593410015106\n",
            "A-LLMRec model loss in epoch 1/2 iteration 804/1084: 0.18413494527339935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 805/1084: 0.06745392084121704\n",
            "A-LLMRec model loss in epoch 1/2 iteration 806/1084: 0.0917150005698204\n",
            "A-LLMRec model loss in epoch 1/2 iteration 807/1084: 0.15429097414016724\n",
            "A-LLMRec model loss in epoch 1/2 iteration 808/1084: 0.038691435009241104\n",
            "A-LLMRec model loss in epoch 1/2 iteration 809/1084: 0.006129873916506767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 810/1084: 0.11139651387929916\n",
            "A-LLMRec model loss in epoch 1/2 iteration 811/1084: 0.00630315113812685\n",
            "A-LLMRec model loss in epoch 1/2 iteration 812/1084: 0.008282964117825031\n",
            "A-LLMRec model loss in epoch 1/2 iteration 813/1084: 0.028235048055648804\n",
            "A-LLMRec model loss in epoch 1/2 iteration 814/1084: 0.0761823058128357\n",
            "A-LLMRec model loss in epoch 1/2 iteration 815/1084: 0.011842609383165836\n",
            "A-LLMRec model loss in epoch 1/2 iteration 816/1084: 0.07257785648107529\n",
            "A-LLMRec model loss in epoch 1/2 iteration 817/1084: 0.1767837554216385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 818/1084: 0.09475243836641312\n",
            "A-LLMRec model loss in epoch 1/2 iteration 819/1084: 0.0762343630194664\n",
            "A-LLMRec model loss in epoch 1/2 iteration 820/1084: 0.09454352408647537\n",
            "A-LLMRec model loss in epoch 1/2 iteration 821/1084: 0.002554723061621189\n",
            "A-LLMRec model loss in epoch 1/2 iteration 822/1084: 0.049333471804857254\n",
            "A-LLMRec model loss in epoch 1/2 iteration 823/1084: 0.0036953368689864874\n",
            "A-LLMRec model loss in epoch 1/2 iteration 824/1084: 0.09791040420532227\n",
            "A-LLMRec model loss in epoch 1/2 iteration 825/1084: 0.006327297538518906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 826/1084: 0.020640814676880836\n",
            "A-LLMRec model loss in epoch 1/2 iteration 827/1084: 0.14935751259326935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 828/1084: 0.1738704890012741\n",
            "A-LLMRec model loss in epoch 1/2 iteration 829/1084: 0.009460026398301125\n",
            "A-LLMRec model loss in epoch 1/2 iteration 830/1084: 0.16189302504062653\n",
            "A-LLMRec model loss in epoch 1/2 iteration 831/1084: 0.16113659739494324\n",
            "A-LLMRec model loss in epoch 1/2 iteration 832/1084: 0.0037180983927100897\n",
            "A-LLMRec model loss in epoch 1/2 iteration 833/1084: 0.10265123844146729\n",
            "A-LLMRec model loss in epoch 1/2 iteration 834/1084: 0.39106032252311707\n",
            "A-LLMRec model loss in epoch 1/2 iteration 835/1084: 0.0028737944085150957\n",
            "A-LLMRec model loss in epoch 1/2 iteration 836/1084: 0.2533605396747589\n",
            "A-LLMRec model loss in epoch 1/2 iteration 837/1084: 0.06994929909706116\n",
            "A-LLMRec model loss in epoch 1/2 iteration 838/1084: 0.07229983061552048\n",
            "A-LLMRec model loss in epoch 1/2 iteration 839/1084: 0.0052680158987641335\n",
            "A-LLMRec model loss in epoch 1/2 iteration 840/1084: 0.08382570743560791\n",
            "A-LLMRec model loss in epoch 1/2 iteration 841/1084: 0.23214934766292572\n",
            "A-LLMRec model loss in epoch 1/2 iteration 842/1084: 0.06816823035478592\n",
            "A-LLMRec model loss in epoch 1/2 iteration 843/1084: 0.190860778093338\n",
            "A-LLMRec model loss in epoch 1/2 iteration 844/1084: 0.13980631530284882\n",
            "A-LLMRec model loss in epoch 1/2 iteration 845/1084: 0.02740117348730564\n",
            "A-LLMRec model loss in epoch 1/2 iteration 846/1084: 0.0936436578631401\n",
            "A-LLMRec model loss in epoch 1/2 iteration 847/1084: 0.08319492638111115\n",
            "A-LLMRec model loss in epoch 1/2 iteration 848/1084: 0.10090924799442291\n",
            "A-LLMRec model loss in epoch 1/2 iteration 849/1084: 0.022805040702223778\n",
            "A-LLMRec model loss in epoch 1/2 iteration 850/1084: 0.21566618978977203\n",
            "A-LLMRec model loss in epoch 1/2 iteration 851/1084: 0.09927985817193985\n",
            "A-LLMRec model loss in epoch 1/2 iteration 852/1084: 0.008542840369045734\n",
            "A-LLMRec model loss in epoch 1/2 iteration 853/1084: 0.20371754467487335\n",
            "A-LLMRec model loss in epoch 1/2 iteration 854/1084: 0.23344001173973083\n",
            "A-LLMRec model loss in epoch 1/2 iteration 855/1084: 0.02465674839913845\n",
            "A-LLMRec model loss in epoch 1/2 iteration 856/1084: 0.09684041887521744\n",
            "A-LLMRec model loss in epoch 1/2 iteration 857/1084: 0.0756976380944252\n",
            "A-LLMRec model loss in epoch 1/2 iteration 858/1084: 0.00903844553977251\n",
            "A-LLMRec model loss in epoch 1/2 iteration 859/1084: 0.07812312245368958\n",
            "A-LLMRec model loss in epoch 1/2 iteration 860/1084: 0.01737075299024582\n",
            "A-LLMRec model loss in epoch 1/2 iteration 861/1084: 0.008776266127824783\n",
            "A-LLMRec model loss in epoch 1/2 iteration 862/1084: 0.03067460097372532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 863/1084: 0.0071950554847717285\n",
            "A-LLMRec model loss in epoch 1/2 iteration 864/1084: 0.03905588760972023\n",
            "A-LLMRec model loss in epoch 1/2 iteration 865/1084: 0.025838064029812813\n",
            "A-LLMRec model loss in epoch 1/2 iteration 866/1084: 0.049997907131910324\n",
            "A-LLMRec model loss in epoch 1/2 iteration 867/1084: 0.03633445128798485\n",
            "A-LLMRec model loss in epoch 1/2 iteration 868/1084: 0.1258200705051422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 869/1084: 0.005232632625848055\n",
            "A-LLMRec model loss in epoch 1/2 iteration 870/1084: 0.1373363733291626\n",
            "A-LLMRec model loss in epoch 1/2 iteration 871/1084: 0.0042515830136835575\n",
            "A-LLMRec model loss in epoch 1/2 iteration 872/1084: 0.03177706152200699\n",
            "A-LLMRec model loss in epoch 1/2 iteration 873/1084: 0.027404801920056343\n",
            "A-LLMRec model loss in epoch 1/2 iteration 874/1084: 0.052493151277303696\n",
            "A-LLMRec model loss in epoch 1/2 iteration 875/1084: 0.15698640048503876\n",
            "A-LLMRec model loss in epoch 1/2 iteration 876/1084: 0.0037190699949860573\n",
            "A-LLMRec model loss in epoch 1/2 iteration 877/1084: 0.21535685658454895\n",
            "A-LLMRec model loss in epoch 1/2 iteration 878/1084: 0.15271100401878357\n",
            "A-LLMRec model loss in epoch 1/2 iteration 879/1084: 0.176443949341774\n",
            "A-LLMRec model loss in epoch 1/2 iteration 880/1084: 0.2267468273639679\n",
            "A-LLMRec model loss in epoch 1/2 iteration 881/1084: 0.003952510189265013\n",
            "A-LLMRec model loss in epoch 1/2 iteration 882/1084: 0.1343207210302353\n",
            "A-LLMRec model loss in epoch 1/2 iteration 883/1084: 0.026290830224752426\n",
            "A-LLMRec model loss in epoch 1/2 iteration 884/1084: 0.02729615941643715\n",
            "A-LLMRec model loss in epoch 1/2 iteration 885/1084: 0.008230183273553848\n",
            "A-LLMRec model loss in epoch 1/2 iteration 886/1084: 0.005525868386030197\n",
            "A-LLMRec model loss in epoch 1/2 iteration 887/1084: 0.043199487030506134\n",
            "A-LLMRec model loss in epoch 1/2 iteration 888/1084: 0.027113361284136772\n",
            "A-LLMRec model loss in epoch 1/2 iteration 889/1084: 0.23536765575408936\n",
            "A-LLMRec model loss in epoch 1/2 iteration 890/1084: 0.10695312917232513\n",
            "A-LLMRec model loss in epoch 1/2 iteration 891/1084: 0.012066294439136982\n",
            "A-LLMRec model loss in epoch 1/2 iteration 892/1084: 0.14451931416988373\n",
            "A-LLMRec model loss in epoch 1/2 iteration 893/1084: 0.007387632038444281\n",
            "A-LLMRec model loss in epoch 1/2 iteration 894/1084: 0.04187997058033943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 895/1084: 0.0068945009261369705\n",
            "A-LLMRec model loss in epoch 1/2 iteration 896/1084: 0.07620889693498611\n",
            "A-LLMRec model loss in epoch 1/2 iteration 897/1084: 0.007222718093544245\n",
            "A-LLMRec model loss in epoch 1/2 iteration 898/1084: 0.05136915668845177\n",
            "A-LLMRec model loss in epoch 1/2 iteration 899/1084: 0.22410230338573456\n",
            "A-LLMRec model loss in epoch 1/2 iteration 900/1084: 0.03396231681108475\n",
            "A-LLMRec model loss in epoch 1/2 iteration 901/1084: 0.01483073364943266\n",
            "A-LLMRec model loss in epoch 1/2 iteration 902/1084: 0.055695947259664536\n",
            "A-LLMRec model loss in epoch 1/2 iteration 903/1084: 0.004826958756893873\n",
            "A-LLMRec model loss in epoch 1/2 iteration 904/1084: 0.00649974774569273\n",
            "A-LLMRec model loss in epoch 1/2 iteration 905/1084: 0.10142681747674942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 906/1084: 0.11386524140834808\n",
            "A-LLMRec model loss in epoch 1/2 iteration 907/1084: 0.10380051285028458\n",
            "A-LLMRec model loss in epoch 1/2 iteration 908/1084: 0.012395736761391163\n",
            "A-LLMRec model loss in epoch 1/2 iteration 909/1084: 0.06836642324924469\n",
            "A-LLMRec model loss in epoch 1/2 iteration 910/1084: 0.01336871087551117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 911/1084: 0.17232836782932281\n",
            "A-LLMRec model loss in epoch 1/2 iteration 912/1084: 0.02131826989352703\n",
            "A-LLMRec model loss in epoch 1/2 iteration 913/1084: 0.10107047855854034\n",
            "A-LLMRec model loss in epoch 1/2 iteration 914/1084: 0.010228237137198448\n",
            "A-LLMRec model loss in epoch 1/2 iteration 915/1084: 0.2720128297805786\n",
            "A-LLMRec model loss in epoch 1/2 iteration 916/1084: 0.09731198847293854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 917/1084: 0.004909124691039324\n",
            "A-LLMRec model loss in epoch 1/2 iteration 918/1084: 0.013406643643975258\n",
            "A-LLMRec model loss in epoch 1/2 iteration 919/1084: 0.0062128836289048195\n",
            "A-LLMRec model loss in epoch 1/2 iteration 920/1084: 0.12080729752779007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 921/1084: 0.16535112261772156\n",
            "A-LLMRec model loss in epoch 1/2 iteration 922/1084: 0.011379371397197247\n",
            "A-LLMRec model loss in epoch 1/2 iteration 923/1084: 0.2176668345928192\n",
            "A-LLMRec model loss in epoch 1/2 iteration 924/1084: 0.20985376834869385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 925/1084: 0.041052550077438354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 926/1084: 0.07539365440607071\n",
            "A-LLMRec model loss in epoch 1/2 iteration 927/1084: 0.1323322355747223\n",
            "A-LLMRec model loss in epoch 1/2 iteration 928/1084: 0.004003298468887806\n",
            "A-LLMRec model loss in epoch 1/2 iteration 929/1084: 0.0024336311034858227\n",
            "A-LLMRec model loss in epoch 1/2 iteration 930/1084: 0.007580718956887722\n",
            "A-LLMRec model loss in epoch 1/2 iteration 931/1084: 0.14507171511650085\n",
            "A-LLMRec model loss in epoch 1/2 iteration 932/1084: 0.004996315110474825\n",
            "A-LLMRec model loss in epoch 1/2 iteration 933/1084: 0.003167901188135147\n",
            "A-LLMRec model loss in epoch 1/2 iteration 934/1084: 0.4097226560115814\n",
            "A-LLMRec model loss in epoch 1/2 iteration 935/1084: 0.19186259806156158\n",
            "A-LLMRec model loss in epoch 1/2 iteration 936/1084: 0.13519512116909027\n",
            "A-LLMRec model loss in epoch 1/2 iteration 937/1084: 0.01826622150838375\n",
            "A-LLMRec model loss in epoch 1/2 iteration 938/1084: 0.11595352739095688\n",
            "A-LLMRec model loss in epoch 1/2 iteration 939/1084: 0.07419896870851517\n",
            "A-LLMRec model loss in epoch 1/2 iteration 940/1084: 0.14456208050251007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 941/1084: 0.09637220948934555\n",
            "A-LLMRec model loss in epoch 1/2 iteration 942/1084: 0.004106911830604076\n",
            "A-LLMRec model loss in epoch 1/2 iteration 943/1084: 0.07923372834920883\n",
            "A-LLMRec model loss in epoch 1/2 iteration 944/1084: 0.004866801202297211\n",
            "A-LLMRec model loss in epoch 1/2 iteration 945/1084: 0.006722670514136553\n",
            "A-LLMRec model loss in epoch 1/2 iteration 946/1084: 0.0034455941058695316\n",
            "A-LLMRec model loss in epoch 1/2 iteration 947/1084: 0.1433744579553604\n",
            "A-LLMRec model loss in epoch 1/2 iteration 948/1084: 0.0632944107055664\n",
            "A-LLMRec model loss in epoch 1/2 iteration 949/1084: 0.014027372933924198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 950/1084: 0.16053460538387299\n",
            "A-LLMRec model loss in epoch 1/2 iteration 951/1084: 0.01184272114187479\n",
            "A-LLMRec model loss in epoch 1/2 iteration 952/1084: 0.09556647390127182\n",
            "A-LLMRec model loss in epoch 1/2 iteration 953/1084: 0.47389644384384155\n",
            "A-LLMRec model loss in epoch 1/2 iteration 954/1084: 0.6040019989013672\n",
            "A-LLMRec model loss in epoch 1/2 iteration 955/1084: 0.005379031412303448\n",
            "A-LLMRec model loss in epoch 1/2 iteration 956/1084: 0.1291760951280594\n",
            "A-LLMRec model loss in epoch 1/2 iteration 957/1084: 0.16310599446296692\n",
            "A-LLMRec model loss in epoch 1/2 iteration 958/1084: 0.005439144559204578\n",
            "A-LLMRec model loss in epoch 1/2 iteration 959/1084: 0.09960147738456726\n",
            "A-LLMRec model loss in epoch 1/2 iteration 960/1084: 0.612922728061676\n",
            "A-LLMRec model loss in epoch 1/2 iteration 961/1084: 0.09103713184595108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 962/1084: 0.02958563342690468\n",
            "A-LLMRec model loss in epoch 1/2 iteration 963/1084: 0.22661928832530975\n",
            "A-LLMRec model loss in epoch 1/2 iteration 964/1084: 0.004516985267400742\n",
            "A-LLMRec model loss in epoch 1/2 iteration 965/1084: 0.10712185502052307\n",
            "A-LLMRec model loss in epoch 1/2 iteration 966/1084: 0.0024810105096548796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 967/1084: 0.05787758156657219\n",
            "A-LLMRec model loss in epoch 1/2 iteration 968/1084: 0.00495666591450572\n",
            "A-LLMRec model loss in epoch 1/2 iteration 969/1084: 0.007320552133023739\n",
            "A-LLMRec model loss in epoch 1/2 iteration 970/1084: 0.0055085099302232265\n",
            "A-LLMRec model loss in epoch 1/2 iteration 971/1084: 0.0075241634622216225\n",
            "A-LLMRec model loss in epoch 1/2 iteration 972/1084: 0.006468600127846003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 973/1084: 0.12002185732126236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 974/1084: 0.22896459698677063\n",
            "A-LLMRec model loss in epoch 1/2 iteration 975/1084: 0.0032128519378602505\n",
            "A-LLMRec model loss in epoch 1/2 iteration 976/1084: 0.15542584657669067\n",
            "A-LLMRec model loss in epoch 1/2 iteration 977/1084: 0.003934834618121386\n",
            "A-LLMRec model loss in epoch 1/2 iteration 978/1084: 0.00473801838234067\n",
            "A-LLMRec model loss in epoch 1/2 iteration 979/1084: 0.032874032855033875\n",
            "A-LLMRec model loss in epoch 1/2 iteration 980/1084: 0.04374832287430763\n",
            "A-LLMRec model loss in epoch 1/2 iteration 981/1084: 0.009807772003114223\n",
            "A-LLMRec model loss in epoch 1/2 iteration 982/1084: 0.08271921426057816\n",
            "A-LLMRec model loss in epoch 1/2 iteration 983/1084: 0.020729754120111465\n",
            "A-LLMRec model loss in epoch 1/2 iteration 984/1084: 0.24886265397071838\n",
            "A-LLMRec model loss in epoch 1/2 iteration 985/1084: 0.07752988487482071\n",
            "A-LLMRec model loss in epoch 1/2 iteration 986/1084: 0.19259639084339142\n",
            "A-LLMRec model loss in epoch 1/2 iteration 987/1084: 0.062342721968889236\n",
            "A-LLMRec model loss in epoch 1/2 iteration 988/1084: 0.12570041418075562\n",
            "A-LLMRec model loss in epoch 1/2 iteration 989/1084: 0.07884494960308075\n",
            "A-LLMRec model loss in epoch 1/2 iteration 990/1084: 0.12183146923780441\n",
            "A-LLMRec model loss in epoch 1/2 iteration 991/1084: 0.00511639378964901\n",
            "A-LLMRec model loss in epoch 1/2 iteration 992/1084: 0.12271330505609512\n",
            "A-LLMRec model loss in epoch 1/2 iteration 993/1084: 0.2696044147014618\n",
            "A-LLMRec model loss in epoch 1/2 iteration 994/1084: 0.07150411605834961\n",
            "A-LLMRec model loss in epoch 1/2 iteration 995/1084: 0.26084163784980774\n",
            "A-LLMRec model loss in epoch 1/2 iteration 996/1084: 0.00399532075971365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 997/1084: 0.02134661190211773\n",
            "A-LLMRec model loss in epoch 1/2 iteration 998/1084: 0.16990120708942413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 999/1084: 0.22337961196899414\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1000/1084: 0.010985476896166801\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1001/1084: 0.005573248490691185\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1002/1084: 0.08271029591560364\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1003/1084: 0.004488288424909115\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1004/1084: 0.1685962826013565\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1005/1084: 0.0682666227221489\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1006/1084: 0.025307457894086838\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1007/1084: 0.18497957289218903\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1008/1084: 0.03171452134847641\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1009/1084: 0.029041331261396408\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1010/1084: 0.03571999818086624\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1011/1084: 0.18969127535820007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1012/1084: 0.04722132906317711\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1013/1084: 0.018910350278019905\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1014/1084: 0.12925724685192108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1015/1084: 0.09179162979125977\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1016/1084: 0.1339474618434906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1017/1084: 0.0033198907040059566\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1018/1084: 0.13168850541114807\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1019/1084: 0.15856696665287018\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1020/1084: 0.08314677327871323\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1021/1084: 0.004374908749014139\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1022/1084: 0.008048320189118385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1023/1084: 0.0038862423971295357\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1024/1084: 0.0115065798163414\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1025/1084: 0.3852199912071228\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1026/1084: 0.01286390796303749\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1027/1084: 0.0031071791891008615\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1028/1084: 0.1308412104845047\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1029/1084: 0.003270888701081276\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1030/1084: 0.13785631954669952\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1031/1084: 0.007302325684577227\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1032/1084: 0.03982536867260933\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1033/1084: 0.005080612376332283\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1034/1084: 0.05901578441262245\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1035/1084: 0.08226732909679413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1036/1084: 0.002024503191933036\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1037/1084: 0.06631357222795486\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1038/1084: 0.15447787940502167\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1039/1084: 0.0033973664976656437\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1040/1084: 0.08930397778749466\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1041/1084: 0.062450747936964035\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1042/1084: 0.07299480587244034\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1043/1084: 0.03377804905176163\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1044/1084: 0.007142405025660992\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1045/1084: 0.04882470518350601\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1046/1084: 0.2413146197795868\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1047/1084: 0.22739063203334808\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1048/1084: 0.005157785024493933\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1049/1084: 0.0025237102527171373\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1050/1084: 0.2376224249601364\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1051/1084: 0.009321868419647217\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1052/1084: 0.005344277247786522\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1053/1084: 0.011316493153572083\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1054/1084: 0.028170760720968246\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1055/1084: 0.01978605054318905\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1056/1084: 0.0030589960515499115\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1057/1084: 0.08312677592039108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1058/1084: 0.06003875285387039\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1059/1084: 0.03483051061630249\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1060/1084: 0.10214666277170181\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1061/1084: 0.11737283319234848\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1062/1084: 0.01696140505373478\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1063/1084: 0.0026567645836621523\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1064/1084: 0.04038141667842865\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1065/1084: 0.17188246548175812\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1066/1084: 0.3331875801086426\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1067/1084: 0.026439309120178223\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1068/1084: 0.0033321217633783817\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1069/1084: 0.006454534363001585\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1070/1084: 0.0031698551028966904\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1071/1084: 0.08609699457883835\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1072/1084: 0.0030371707398444414\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1073/1084: 0.04695327952504158\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1074/1084: 0.20009885728359222\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1075/1084: 0.0031499338801950216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1076/1084: 0.003230844158679247\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1077/1084: 0.2820981740951538\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1078/1084: 0.04911421239376068\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1079/1084: 0.10483074933290482\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1080/1084: 0.22729834914207458\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1081/1084: 0.30793046951293945\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1082/1084: 0.003980344161391258\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1083/1084: 0.08416635543107986\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1084/1084: 0.004339538514614105\n",
            "100% 1/1 [08:41<00:00, 521.75s/it]\n",
            "phase2 train time : 521.7553853988647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --inference --rec_pre_trained_data All_Beauty\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQmwg8EQNSJj",
        "outputId": "deea41af-9bb2-4524-86a4-12ddbd3b4ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec start inference\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2099\n"
          ]
        }
      ]
    }
  ]
}