{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpQy1R3MIQKv",
        "outputId": "3ddf6242-a4ea-418c-9727-9b8eb6382417",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/MyDrive/Rec_Proj_DL'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 86 (delta 37), reused 59 (delta 19), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (86/86), 140.41 KiB | 15.60 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SoheilHoseini/A-LLMRec.git /content/drive/MyDrive/Rec_Proj_DL/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda create -n [env name] python=3.10 pip\n",
        "!conda install pytorch==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
        "!conda install numpy=1.26.3\n",
        "!conda install tqdm\n",
        "!conda install pytz\n",
        "!conda install transformers=4.32.1\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!conda install conda-forge::accelerate=0.25.0\n",
        "!conda install conda-forge::bitsandbytes=0.42.0\n",
        "\n",
        "!pip install -U sentence-transformers\n",
        "\n",
        "import torch.serialization\n",
        "import argparse\n",
        "torch.serialization.add_safe_globals([argparse.Namespace])\n",
        "\n",
        "import torch.serialization\n",
        "import argparse\n",
        "torch.serialization.add_safe_globals([argparse.Namespace])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t8Joi6DOJpP_",
        "outputId": "338a4e4a-27de-4433-a74b-3931e9653cc3",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:09\n",
            "ðŸ” Restarting kernel...\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\bfailed\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - name]\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/conda-forge\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch-cuda=11.8\n",
            "    - pytorch==2.1.2\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       3_kmp_llvm           7 KB  conda-forge\n",
            "    blas-2.116                 |              mkl          13 KB  conda-forge\n",
            "    blas-devel-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    ca-certificates-2025.8.3   |       hbd8a1cb_0         151 KB  conda-forge\n",
            "    certifi-2025.8.3           |     pyhd8ed1ab_0         155 KB  conda-forge\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    cpython-3.11.13            |  py311hd8ed1ab_0          46 KB  conda-forge\n",
            "    cuda-cudart-11.8.89        |                0         197 KB  nvidia\n",
            "    cuda-cupti-11.8.87         |                0        25.3 MB  nvidia\n",
            "    cuda-libraries-11.8.0      |                0           1 KB  nvidia\n",
            "    cuda-nvrtc-11.8.89         |                0        19.1 MB  nvidia\n",
            "    cuda-nvtx-11.8.86          |                0          57 KB  nvidia\n",
            "    cuda-runtime-11.8.0        |                0           1 KB  nvidia\n",
            "    cuda-version-12.9          |                3          17 KB  nvidia\n",
            "    filelock-3.19.1            |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    gmpy2-2.2.1                |  py311h0f6cedb_0         198 KB  conda-forge\n",
            "    jinja2-3.1.6               |     pyhd8ed1ab_0         110 KB  conda-forge\n",
            "    libblas-3.9.0              |   16_linux64_mkl          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libcublas-11.11.3.6        |                0       364.0 MB  nvidia\n",
            "    libcufft-10.9.0.58         |                0       142.8 MB  nvidia\n",
            "    libcufile-1.14.1.1         |                4         946 KB  nvidia\n",
            "    libcurand-10.3.10.19       |                0        44.0 MB  nvidia\n",
            "    libcusolver-11.4.1.48      |                0        96.5 MB  nvidia\n",
            "    libcusparse-11.7.5.86      |                0       176.3 MB  nvidia\n",
            "    libgfortran-14.2.0         |       h69a702a_2          52 KB  conda-forge\n",
            "    libgfortran-ng-14.2.0      |       h69a702a_2          53 KB  conda-forge\n",
            "    libgfortran5-14.2.0        |       hf1ad2bd_2         1.4 MB  conda-forge\n",
            "    libhwloc-2.11.2            |default_h0d58e46_1001         2.3 MB  conda-forge\n",
            "    liblapack-3.9.0            |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblapacke-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libnpp-11.8.0.86           |                0       147.8 MB  nvidia\n",
            "    libnvjpeg-11.9.0.86        |                0         2.4 MB  nvidia\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    markupsafe-3.0.2           |  py311h2dc5d0c_1          25 KB  conda-forge\n",
            "    mkl-2022.1.0               |     h84fe81f_915       199.6 MB  conda-forge\n",
            "    mkl-devel-2022.1.0         |     ha770c72_916          25 KB  conda-forge\n",
            "    mkl-include-2022.1.0       |     h84fe81f_915         745 KB  conda-forge\n",
            "    mpc-1.3.1                  |       h24ddda3_1         114 KB  conda-forge\n",
            "    mpfr-4.2.1                 |       h90cbb55_3         620 KB  conda-forge\n",
            "    mpmath-1.3.0               |     pyhd8ed1ab_1         429 KB  conda-forge\n",
            "    networkx-3.5               |     pyhe01879c_0         1.5 MB  conda-forge\n",
            "    openssl-3.5.2              |       h26f9b46_0         3.0 MB  conda-forge\n",
            "    pytorch-2.1.2              |py3.11_cuda11.8_cudnn8.7.0_0        1.46 GB  pytorch\n",
            "    pytorch-cuda-11.8          |       h7e8668a_6           7 KB  pytorch\n",
            "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
            "    pyyaml-6.0.2               |  py311h2dc5d0c_2         208 KB  conda-forge\n",
            "    sympy-1.14.0               |   pyh2585a3b_105         4.4 MB  conda-forge\n",
            "    tbb-2021.13.0              |       hceb3a55_1         172 KB  conda-forge\n",
            "    torchtriton-2.1.0          |            py311        91.0 MB  pytorch\n",
            "    typing_extensions-4.14.1   |     pyhe01879c_0          50 KB  conda-forge\n",
            "    yaml-0.2.5                 |       h280c20c_3          83 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.76 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               conda-forge/linux-64::blas-2.116-mkl \n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-16_linux64_mkl \n",
            "  cpython            conda-forge/noarch::cpython-3.11.13-py311hd8ed1ab_0 \n",
            "  cuda-cudart        nvidia/linux-64::cuda-cudart-11.8.89-0 \n",
            "  cuda-cupti         nvidia/linux-64::cuda-cupti-11.8.87-0 \n",
            "  cuda-libraries     nvidia/linux-64::cuda-libraries-11.8.0-0 \n",
            "  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.8.89-0 \n",
            "  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.8.86-0 \n",
            "  cuda-runtime       nvidia/linux-64::cuda-runtime-11.8.0-0 \n",
            "  cuda-version       nvidia/noarch::cuda-version-12.9-3 \n",
            "  filelock           conda-forge/noarch::filelock-3.19.1-pyhd8ed1ab_0 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  gmpy2              conda-forge/linux-64::gmpy2-2.2.1-py311h0f6cedb_0 \n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhd8ed1ab_0 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_mkl \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_mkl \n",
            "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 \n",
            "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 \n",
            "  libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 \n",
            "  libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 \n",
            "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 \n",
            "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_2 \n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-14.2.0-h69a702a_2 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hf1ad2bd_2 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.11.2-default_h0d58e46_1001 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_mkl \n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-16_linux64_mkl \n",
            "  libnpp             nvidia/linux-64::libnpp-11.8.0.86-0 \n",
            "  libnvjpeg          nvidia/linux-64::libnvjpeg-11.9.0.86-0 \n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 \n",
            "  markupsafe         conda-forge/linux-64::markupsafe-3.0.2-py311h2dc5d0c_1 \n",
            "  mkl                conda-forge/linux-64::mkl-2022.1.0-h84fe81f_915 \n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2022.1.0-ha770c72_916 \n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2022.1.0-h84fe81f_915 \n",
            "  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n",
            "  mpfr               conda-forge/linux-64::mpfr-4.2.1-h90cbb55_3 \n",
            "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
            "  networkx           conda-forge/noarch::networkx-3.5-pyhe01879c_0 \n",
            "  pytorch            pytorch/linux-64::pytorch-2.1.2-py3.11_cuda11.8_cudnn8.7.0_0 \n",
            "  pytorch-cuda       pytorch/linux-64::pytorch-cuda-11.8-h7e8668a_6 \n",
            "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0.2-py311h2dc5d0c_2 \n",
            "  sympy              conda-forge/noarch::sympy-1.14.0-pyh2585a3b_105 \n",
            "  tbb                conda-forge/linux-64::tbb-2021.13.0-hceb3a55_1 \n",
            "  torchtriton        pytorch/linux-64::torchtriton-2.1.0-py311 \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.14.1-pyhe01879c_0 \n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0 \n",
            "  certifi                           2024.12.14-pyhd8ed1ab_0 --> 2025.8.3-pyhd8ed1ab_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "  openssl                                  3.4.0-h7b32b05_1 --> 3.5.2-h26f9b46_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-3_kmp_llvm \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0.0008140073583551226/1 [00:00<02:02, 122.97s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   0% 0.002833429361097844/1 [00:00<00:35, 35.42s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   1% 0.007435645192631188/1 [00:00<00:13, 13.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   0% 0.004607925328902348/1 [00:00<00:21, 21.73s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   0% 0.00216025029717321/1 [00:00<01:28, 89.16s/it]   \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   1% 0.014982831015502237/1 [00:00<00:11, 12.09s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   3% 0.03287337874636946/1 [00:00<00:05,  5.56s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   3% 0.026672798538453973/1 [00:00<00:06,  6.74s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.006000695269925583/1 [00:00<00:42, 42.39s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   5% 0.053849725184529025/1 [00:00<00:04,  5.19s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   2% 0.02326846535931866/1 [00:00<00:11, 12.19s/it] \u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   5% 0.049180741491169286/1 [00:00<00:05,  5.46s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.008369665402574465/1 [00:00<00:42, 42.71s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   7% 0.07318240268537012/1 [00:00<00:04,  5.21s/it] \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   4% 0.03722095842533077/1 [00:00<00:09,  9.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   7% 0.07496740054329588/1 [00:00<00:04,  4.71s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  10% 0.10179500417237274/1 [00:00<00:03,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   5% 0.053405850381904825/1 [00:00<00:07,  8.02s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  10% 0.10096823472099192/1 [00:00<00:04,  4.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  10% 0.09977930616046236/1 [00:00<00:03,  4.44s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.010717763551675781/1 [00:00<00:43, 43.96s/it]\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   1% 0.013003245750134394/1 [00:00<00:43, 44.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  17% 0.16511297665342287/1 [00:00<00:02,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  13% 0.1287560673633675/1 [00:00<00:03,  4.16s/it] \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.01526785596504544/1 [00:00<00:43, 44.44s/it] \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  20% 0.19671910982843788/1 [00:00<00:02,  3.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  15% 0.15321351718600304/1 [00:00<00:03,  4.42s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  16% 0.1551310397031054/1 [00:00<00:03,  4.67s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.017584646138825405/1 [00:00<00:43, 44.06s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  23% 0.22747959395529194/1 [00:00<00:02,  3.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  18% 0.17713928331684217/1 [00:00<00:03,  4.35s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  18% 0.17728143538220675/1 [00:00<00:03,  4.63s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.019859692345510233/1 [00:00<00:43, 44.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  26% 0.25771154742704544/1 [00:00<00:02,  3.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  20% 0.20026752390998664/1 [00:00<00:03,  4.51s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  20% 0.19943183106130807/1 [00:00<00:03,  4.64s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.022103430576873712/1 [00:01<00:44, 45.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  29% 0.2872035579816581/1 [00:01<00:02,  3.42s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  23% 0.2256997271675823/1 [00:01<00:03,  4.33s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  22% 0.22134741689222104/1 [00:01<00:03,  5.04s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   2% 0.024722864512093403/1 [00:01<00:41, 42.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  32% 0.3189153972876932/1 [00:01<00:02,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  25% 0.24900519565799223/1 [00:01<00:03,  4.37s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  24% 0.24169760373521168/1 [00:01<00:03,  5.10s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.02819804977276335/1 [00:01<00:36, 37.54s/it] \n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  28% 0.2755893802478135/1 [00:01<00:03,  4.17s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  35% 0.34893593849740645/1 [00:01<00:02,  3.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  26% 0.2616564408312217/1 [00:01<00:03,  5.09s/it] \u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.03194457081955167/1 [00:01<00:32, 33.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  38% 0.3766309448246771/1 [00:01<00:02,  3.83s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  30% 0.29969237427591805/1 [00:01<00:03,  4.70s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  15% 0.14862624921395057/1 [00:01<00:07,  8.73s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   3% 0.034950136450401355/1 [00:01<00:33, 34.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  41% 0.4085541963927525/1 [00:01<00:02,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  32% 0.3215800195882042/1 [00:01<00:03,  4.70s/it] \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.03786177815528698/1 [00:01<00:33, 34.70s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  30% 0.30032179583290386/1 [00:01<00:04,  5.75s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  44% 0.43751767629226457/1 [00:01<00:02,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  36% 0.35888649196258665/1 [00:01<00:02,  3.89s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  18% 0.1763595123543931/1 [00:01<00:06,  8.27s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.04075254787662505/1 [00:01<00:35, 37.40s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  39% 0.3852934486551424/1 [00:01<00:02,  3.91s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  47% 0.4657412132746358/1 [00:01<00:02,  3.86s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  19% 0.1908701051430457/1 [00:01<00:06,  7.83s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   4% 0.04349721371313014/1 [00:01<00:35, 37.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  49% 0.4943875747810875/1 [00:01<00:01,  3.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  41% 0.4113459495531672/1 [00:01<00:02,  4.15s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  36% 0.35745885889206985/1 [00:01<00:03,  5.44s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.04621057157431388/1 [00:01<00:35, 37.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  53% 0.5304333654589475/1 [00:01<00:01,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  44% 0.43598062727306824/1 [00:01<00:02,  4.14s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  38% 0.3805484939639246/1 [00:01<00:03,  5.07s/it] \u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.04891349344372384/1 [00:01<00:36, 38.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  56% 0.5618280863719223/1 [00:02<00:01,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  46% 0.461058374736133/1 [00:02<00:02,  4.09s/it]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  40% 0.40050733105993463/1 [00:02<00:03,  5.19s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.05154336337071731/1 [00:02<00:36, 38.90s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  49% 0.48666780589099407/1 [00:02<00:02,  4.04s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  59% 0.5918486275816355/1 [00:02<00:01,  3.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  42% 0.4214836774980942/1 [00:02<00:02,  5.06s/it] \u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   5% 0.054308901190769976/1 [00:02<00:36, 38.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  62% 0.6201778706950268/1 [00:02<00:01,  3.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  44% 0.4413642446447081/1 [00:02<00:02,  5.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  51% 0.511656939405426/1 [00:02<00:02,  4.42s/it]  \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.05820152612239127/1 [00:02<00:31, 33.45s/it] \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  65% 0.6522068283941224/1 [00:02<00:01,  3.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  46% 0.4611665418419259/1 [00:02<00:02,  5.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  53% 0.5347851799985706/1 [00:02<00:02,  4.46s/it]\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.06121752774501473/1 [00:02<00:32, 34.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  68% 0.6809588960315942/1 [00:02<00:01,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  48% 0.4823776981282738/1 [00:02<00:02,  5.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  56% 0.557558964797184/1 [00:02<00:01,  4.48s/it] \u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :   6% 0.06443181321134009/1 [00:02<00:31, 34.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  72% 0.7157362131372127/1 [00:02<00:00,  3.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  50% 0.5028844248700567/1 [00:02<00:02,  4.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.06742694285041599/1 [00:02<00:31, 33.94s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  29% 0.2880223876303854/1 [00:02<00:06,  8.97s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  75% 0.7547417754836359/1 [00:02<00:00,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.07051599641545594/1 [00:02<00:31, 33.54s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  30% 0.3011591964863845/1 [00:02<00:06,  8.68s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  61% 0.6062080225965569/1 [00:02<00:02,  5.44s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  55% 0.5456980871897331/1 [00:03<00:07, 16.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  63% 0.6262347749875555/1 [00:04<00:10, 29.27s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   7% 0.07351112605453185/1 [00:04<03:49, 247.89s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  31% 0.3127504984181484/1 [00:05<00:43, 62.92s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  56% 0.5608824573725799/1 [00:05<00:16, 38.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  64% 0.640590234666059/1 [00:05<00:13, 38.72s/it] \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  32% 0.32103613276196485/1 [00:05<00:46, 69.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  81% 0.8110831433173583/1 [00:05<00:04, 26.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.07565050436815748/1 [00:05<04:15, 276.70s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  67% 0.6699214516634951/1 [00:05<00:08, 25.24s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  33% 0.331940542727402/1 [00:05<00:34, 51.17s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  84% 0.8360297902381059/1 [00:05<00:03, 20.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.0777377027229142/1 [00:05<03:23, 221.01s/it] \n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  70% 0.6994298965581967/1 [00:05<00:05, 17.50s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  34% 0.3425444374575712/1 [00:05<00:25, 38.98s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  87% 0.8696443399025031/1 [00:05<00:01, 14.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.07985620905299229/1 [00:05<02:41, 175.89s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  73% 0.730356164631022/1 [00:06<00:03, 12.56s/it] \u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  35% 0.353921085649858/1 [00:06<00:19, 29.65s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  90% 0.8990306443260957/1 [00:06<00:01, 11.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.08205820331726063/1 [00:06<02:08, 139.47s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  76% 0.7634977814196658/1 [00:06<00:02,  9.25s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  37% 0.3662851410437395/1 [00:06<00:14, 22.65s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  93% 0.9257742954741853/1 [00:06<00:00,  9.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   8% 0.08485504911263464/1 [00:06<01:35, 104.61s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  38% 0.3767602435302224/1 [00:06<00:11, 19.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  79% 0.7898161241635889/1 [00:06<00:01,  7.86s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  95% 0.9515665914430939/1 [00:06<00:00,  7.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.08789192271880568/1 [00:06<01:14, 81.48s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  39% 0.3870206922772283/1 [00:06<00:10, 16.40s/it]\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  82% 0.8151597134725518/1 [00:06<00:01,  6.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  70% 0.7032554953241181/1 [00:06<00:02,  8.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.09066789653063212/1 [00:06<01:01, 67.43s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  40% 0.3979680329905608/1 [00:06<00:08, 14.24s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :   9% 0.09332907443294694/1 [00:06<00:53, 58.55s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  84% 0.8398830051410856/1 [00:06<00:01,  6.44s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  41% 0.41028915763654694/1 [00:06<00:07, 12.25s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.09741998320827013/1 [00:06<00:40, 45.31s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  86% 0.8642518410150883/1 [00:06<00:00,  5.78s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  42% 0.4227390745262193/1 [00:06<00:06, 10.90s/it] \u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.10080124454297601/1 [00:06<00:36, 40.52s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  89% 0.8939375138070554/1 [00:06<00:00,  4.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  43% 0.4349743376764145/1 [00:06<00:05, 10.09s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  10% 0.10387986211624219/1 [00:06<00:34, 38.41s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  92% 0.9223825913181641/1 [00:06<00:00,  4.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  45% 0.45154560636404734/1 [00:06<00:04,  8.61s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  83% 0.831383402485563/1 [00:06<00:00,  4.52s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.10693760770596078/1 [00:06<00:35, 39.71s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  46% 0.4645965537242556/1 [00:06<00:04,  8.41s/it] \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  86% 0.8560384365453401/1 [00:07<00:00,  4.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.10977619746842993/1 [00:07<00:34, 38.53s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  48% 0.4775187088407776/1 [00:07<00:04,  8.53s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  11% 0.11411757004632392/1 [00:07<00:28, 32.70s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  49% 0.49104189442783547/1 [00:07<00:04,  8.23s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.11765537125763656/1 [00:07<00:27, 31.57s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  51% 0.5088152240565401/1 [00:07<00:03,  7.37s/it] \u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  12% 0.12170453606586461/1 [00:07<00:26, 29.90s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  52% 0.5232399553494019/1 [00:07<00:03,  7.25s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.12519015731830835/1 [00:07<00:25, 29.60s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  54% 0.5373641714069957/1 [00:07<00:03,  7.21s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.12919757815944125/1 [00:07<00:24, 28.34s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  13% 0.13278755932962283/1 [00:07<00:25, 29.04s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.13628361657384033/1 [00:07<00:25, 29.18s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.1397483658427365/1 [00:07<00:25, 29.61s/it] \n",
            "pytorch-2.1.2        | 1.46 GB   | :  14% 0.14315049916098996/1 [00:07<00:25, 30.18s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.14647958053682694/1 [00:08<00:26, 30.48s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.15030958951780551/1 [00:08<00:24, 29.34s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  15% 0.15432744635071222/1 [00:08<00:23, 27.89s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.15792786351266758/1 [00:08<00:23, 27.99s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | :  16% 0.16155958864994427/1 [00:08<00:23, 27.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:08<00:00,  6.59s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0.00010941492379625203/1 [00:08<21:40:02, 78010.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.16516000581189963/1 [00:08<00:25, 30.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   3% 0.028885539882210536/1 [00:08<03:24, 210.95s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  71% 0.7073699330728663/1 [00:08<00:02,  8.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.1684995231795104/1 [00:08<00:28, 33.90s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  72% 0.72046381118097/1 [00:08<00:02,  7.95s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.1715468327774552/1 [00:09<01:11, 86.17s/it]\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [00:09<00:00,  4.27s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.0001619872369599508/1 [00:09<16:34:59, 59709.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.002591795791359213/1 [00:09<44:54, 2701.97s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.004535642634878622/1 [00:09<21:53, 1319.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.006479489478398032/1 [00:09<12:53, 778.88s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [00:10<00:00,  3.98s/it]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.008423336321917442/1 [00:10<08:20, 504.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0.00017172886155179142/1 [00:10<16:19:13, 58763.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.010367183165436852/1 [00:10<05:42, 346.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.006182239015864491/1 [00:10<19:22, 1169.86s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.012311030008956262/1 [00:10<04:05, 248.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   1% 0.014254876852475671/1 [00:10<03:03, 186.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   1% 0.011849291447073609/1 [00:10<08:47, 533.88s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.01619872369599508/1 [00:10<02:22, 145.05s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.01814257053951449/1 [00:10<02:08, 130.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  10% 0.10481949699680944/1 [00:10<00:57, 64.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.015283868678109437/1 [00:10<06:16, 382.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.0200864173830339/1 [00:10<01:57, 120.35s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.017859801601386307/1 [00:10<04:59, 305.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.022030264226553308/1 [00:11<01:37, 100.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.020092276801559596/1 [00:11<03:57, 242.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   2% 0.02413609830703267/1 [00:11<01:22, 84.29s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.022153023140181093/1 [00:11<03:10, 195.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.026079945150552078/1 [00:11<01:13, 75.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   2% 0.024385498340354382/1 [00:11<02:31, 155.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.027861804757111537/1 [00:11<01:07, 69.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  73% 0.7334718277932829/1 [00:11<00:15, 59.98s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   3% 0.02661797354052767/1 [00:11<02:01, 124.81s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.029805651600630947/1 [00:11<01:02, 64.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  17% 0.17381144299236626/1 [00:11<03:42, 269.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.031749498444150356/1 [00:11<00:59, 61.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   3% 0.03108292394087425/1 [00:11<01:24, 87.10s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   3% 0.03369334528766977/1 [00:11<00:56, 58.95s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   4% 0.035637192131189176/1 [00:11<00:55, 57.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   3% 0.03331539914104754/1 [00:11<01:13, 75.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   4% 0.03537614547966903/1 [00:11<01:06, 68.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   4% 0.037743026211668536/1 [00:11<00:53, 55.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.1754290217173027/1 [00:11<03:38, 265.35s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  74% 0.742744869338694/1 [00:11<00:15, 59.50s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   6% 0.06096374585088596/1 [00:11<00:13, 14.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   6% 0.0605832266230216/1 [00:11<00:12, 12.94s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.17796496771833212/1 [00:12<02:44, 199.70s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  76% 0.7563109856736473/1 [00:12<00:10, 43.13s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  10% 0.10097657059245335/1 [00:12<00:06,  6.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  10% 0.10124202309996926/1 [00:12<00:05,  5.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.18089748140676531/1 [00:12<01:59, 145.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  14% 0.1361809872105706/1 [00:12<00:04,  5.03s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  14% 0.14319671747259652/1 [00:12<00:03,  4.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  77% 0.7652835119837905/1 [00:12<00:08, 36.30s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  18% 0.1832142715805453/1 [00:12<01:36, 118.24s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  17% 0.16760736887454844/1 [00:12<00:03,  4.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  18% 0.17769999894506602/1 [00:12<00:03,  3.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  77% 0.774599484277097/1 [00:12<00:06, 30.01s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.18577108956512228/1 [00:12<01:17, 94.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  21% 0.21105477084715166/1 [00:12<00:02,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  21% 0.21139334423273579/1 [00:12<00:02,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  78% 0.7841730410577761/1 [00:12<00:05, 24.80s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.18800439180471196/1 [00:12<01:06, 82.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  25% 0.24711783177302785/1 [00:12<00:02,  3.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  24% 0.24087502135944683/1 [00:12<00:02,  3.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  79% 0.7929738443763376/1 [00:12<00:04, 22.12s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.19018551408543274/1 [00:12<00:58, 72.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  29% 0.28953486057632033/1 [00:12<00:02,  2.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  28% 0.2776461241493557/1 [00:12<00:02,  3.29s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  80% 0.8012165479722586/1 [00:12<00:04, 20.13s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.19242925231679622/1 [00:12<00:52, 65.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  35% 0.3489530466732402/1 [00:12<00:01,  2.50s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  31% 0.312797354569665/1 [00:12<00:02,  3.17s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  81% 0.813666464861931/1 [00:12<00:02, 15.92s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  19% 0.19468342653993348/1 [00:12<00:47, 59.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  39% 0.38982451572256654/1 [00:12<00:01,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  34% 0.3447088402507753/1 [00:12<00:02,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  82% 0.822724852667865/1 [00:12<00:02, 14.91s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.197167192582094/1 [00:12<00:42, 53.19s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  44% 0.44117144532655217/1 [00:12<00:01,  2.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  39% 0.39022725383652146/1 [00:12<00:01,  3.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.19948398275587395/1 [00:12<00:40, 50.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  48% 0.48496230502225895/1 [00:12<00:01,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  37% 0.36850946334577683/1 [00:12<00:03,  5.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  42% 0.4237586118872313/1 [00:13<00:01,  3.21s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.20185295288852284/1 [00:13<00:38, 47.82s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  39% 0.39061127795261974/1 [00:13<00:03,  5.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  53% 0.5284097069948622/1 [00:13<00:01,  2.50s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  46% 0.45777593164882097/1 [00:13<00:01,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  20% 0.2041697430623028/1 [00:13<00:40, 50.70s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  42% 0.4186214984444602/1 [00:13<00:02,  5.06s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  57% 0.5704832780750511/1 [00:13<00:01,  2.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  49% 0.4929271620691303/1 [00:13<00:01,  3.08s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.20630912137592844/1 [00:13<00:39, 49.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  45% 0.445865814469727/1 [00:13<00:02,  4.64s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  61% 0.6108395605397221/1 [00:13<00:01,  2.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  54% 0.5390935246027163/1 [00:13<00:01,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.2084484996895541/1 [00:13<00:38, 49.16s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  47% 0.4707030021714762/1 [00:13<00:02,  4.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  65% 0.6506806564197377/1 [00:13<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  58% 0.5755406529187052/1 [00:13<00:01,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.21057744201140594/1 [00:13<00:38, 48.74s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  50% 0.499260297282298/1 [00:13<00:02,  4.19s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  69% 0.6886327348226836/1 [00:13<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  21% 0.2132803638808159/1 [00:13<00:35, 44.71s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  52% 0.5248633894506209/1 [00:13<00:01,  4.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  89% 0.89141404930054/1 [00:13<00:01, 11.74s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  73% 0.7264130843640777/1 [00:13<00:00,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.21557628207104831/1 [00:13<00:35, 45.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  55% 0.5517794607044989/1 [00:13<00:01,  4.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  90% 0.9014598443080687/1 [00:13<00:01, 11.24s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  77% 0.7655672647978862/1 [00:13<00:00,  2.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.2178200203024118/1 [00:13<00:36, 46.17s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  91% 0.9115485700634929/1 [00:13<00:00, 11.03s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  80% 0.804377987508591/1 [00:13<00:00,  2.67s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  58% 0.5774919677966182/1 [00:13<00:01,  4.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.22039771027053634/1 [00:13<00:34, 44.04s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  92% 0.9224100492810345/1 [00:13<00:00, 10.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  61% 0.6053927733646625/1 [00:13<00:01,  4.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  84% 0.8421583370499851/1 [00:13<00:00,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  80% 0.7981111165016775/1 [00:13<00:00,  2.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.22269362846076873/1 [00:14<00:36, 47.50s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  63% 0.6337312386278917/1 [00:14<00:01,  4.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  88% 0.8792517711451721/1 [00:14<00:00,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  84% 0.8389319002155852/1 [00:14<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  22% 0.22484344276616816/1 [00:14<00:38, 49.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  66% 0.663382682976676/1 [00:14<00:01,  3.85s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  92% 0.9228709019793271/1 [00:14<00:00,  2.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  88% 0.8813725562990923/1 [00:14<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  69% 0.694237691487219/1 [00:14<00:01,  3.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.22728546484123352/1 [00:14<00:38, 49.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  96% 0.9621968112746874/1 [00:14<00:00,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  92% 0.9207354548803603/1 [00:14<00:00,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  97% 0.9652549356806656/1 [00:14<00:00, 10.78s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.2295813830314659/1 [00:14<00:37, 48.41s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  96% 0.9575065576702692/1 [00:14<00:00,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.2318773012216983/1 [00:14<00:37, 48.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  75% 0.7488357384615488/1 [00:14<00:00,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  23% 0.23447586317337044/1 [00:14<00:35, 45.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  77% 0.7743294157060756/1 [00:14<00:00,  4.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.23718922103455417/1 [00:14<00:32, 42.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.23954775517542928/1 [00:14<00:32, 43.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  24% 0.24224024105306546/1 [00:14<00:32, 42.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  25% 0.24525624267568893/1 [00:15<00:29, 39.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  91% 0.9062838138043555/1 [00:15<00:00,  3.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  25% 0.24779218867671834/1 [00:15<00:32, 43.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.28684366989421667/1 [00:16<00:25, 35.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [00:16<00:00, 18.97s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [00:16<00:00, 18.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [00:16<00:00, 17.13s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.2911432985050155/1 [00:16<00:22, 31.22s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   0% 0.00035504780175590466/1 [00:16<12:56:23, 46599.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :   0% 0.0006180718489662367/1 [00:16<7:26:46, 26822.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  29% 0.29444107190553115/1 [00:16<00:23, 33.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  20% 0.2021094946119594/1 [00:16<00:46, 57.97s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  19% 0.18711019152536176/1 [00:16<00:41, 50.73s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.29748838150347595/1 [00:16<00:25, 36.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.3003374072577189/1 [00:16<00:27, 39.03s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  60% 0.6007658371951821/1 [00:16<00:05, 13.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  30% 0.30296727718471234/1 [00:17<00:27, 39.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  80% 0.7973126851664454/1 [00:17<00:01,  8.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  31% 0.3058267389307291/1 [00:17<00:26, 38.13s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  97% 0.9722270184238904/1 [00:17<00:00,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  31% 0.31126389064487037/1 [00:17<00:26, 38.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  31% 0.3141337883826608/1 [00:17<00:25, 37.53s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  77% 0.7651280127839746/1 [00:17<00:00,  4.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.3168158382685232/1 [00:17<00:26, 38.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.31945614418729046/1 [00:17<00:27, 39.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  32% 0.32279566155490125/1 [00:17<00:25, 36.93s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.32551945540785876/1 [00:17<00:25, 38.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.32902594864385004/1 [00:18<00:23, 35.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  33% 0.33208369423356865/1 [00:18<00:23, 34.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  34% 0.33618503900066565/1 [00:18<00:20, 31.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  34% 0.33960804430246666/1 [00:18<00:20, 30.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.3460887951939863/1 [00:18<00:25, 38.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:18<00:00, 13.10s/it]                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:18<00:00, 13.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :   1% 0.005012289041185573/1 [00:18<1:01:39, 3718.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.3488752049975865/1 [00:18<00:25, 39.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | :   1% 0.005236433740607962/1 [00:18<59:14, 3573.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:18<00:00,  8.36s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:18<00:00,  8.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:18<00:00, 13.22s/it]                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:18<00:00, 13.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  35% 0.35247562215954187/1 [00:18<00:23, 35.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | : 100% 1.0/1 [00:18<00:00, 13.22s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | : 100% 1.0/1 [00:18<00:00, 13.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   1% 0.006761307362165732/1 [00:18<46:05, 2784.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | :   1% 0.01047260975338487/1 [00:18<29:41, 1800.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:18<00:00, 2784.54s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | : 100% 1.0/1 [00:18<00:00, 13.30s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | : 100% 1.0/1 [00:18<00:00, 1800.09s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  36% 0.3553872638644275/1 [00:18<00:24, 37.61s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   1% 0.011206734985068174/1 [00:18<27:51, 1690.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   1% 0.01364371451460054/1 [00:18<22:50, 1389.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [00:18<00:00, 1389.14s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.2        | 1.46 GB   | :  48% 0.48064003713337855/1 [00:21<00:11, 21.94s/it]\n",
            "pytorch-2.1.2        | 1.46 GB   | : 100% 1.0/1 [00:42<00:00, 16.67s/it]               \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:51<00:00,  6.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [00:55<00:00,  4.27s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [01:14<00:00, 18.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [01:38<00:00,  3.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [01:38<00:00, 17.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [01:44<00:00,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [01:44<00:00, 13.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | : 100% 1.0/1 [01:45<00:00,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [01:49<00:00,  8.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [01:49<00:00, 13.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.2        | 3.0 MB    | : 100% 1.0/1 [01:49<00:00, 13.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [01:49<00:00, 104.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [01:49<00:00, 104.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | : 100% 1.0/1 [01:50<00:00, 13.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | : 100% 1.0/1 [01:50<00:00, 104.90s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.5         | 1.5 MB    | : 100% 1.0/1 [01:50<00:00, 104.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [01:50<00:00, 105.17s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [01:50<00:00, 105.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [01:50<00:00, 105.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [01:50<00:00, 105.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [02:06<00:00,  3.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.2        | 1.46 GB   | : 100% 1.0/1 [05:28<00:00, 16.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - numpy=1.26.3\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    numpy-1.26.3               |  py311h64a7726_0         7.8 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         7.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  numpy              conda-forge/linux-64::numpy-1.26.3-py311h64a7726_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytz\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pytz-2025.2                |     pyhd8ed1ab_0         185 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         185 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  pytz               conda-forge/noarch::pytz-2025.2-pyhd8ed1ab_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - transformers=4.32.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _python_abi3_support-1.0   |       hd8ed1ab_2           8 KB  conda-forge\n",
            "    aiohappyeyeballs-2.6.1     |     pyhd8ed1ab_0          19 KB  conda-forge\n",
            "    aiohttp-3.12.15            |  py311h3778330_0         988 KB  conda-forge\n",
            "    aiosignal-1.4.0            |     pyhd8ed1ab_0          13 KB  conda-forge\n",
            "    attrs-25.3.0               |     pyh71513ae_0          56 KB  conda-forge\n",
            "    aws-c-auth-0.8.1           |       h205f482_0         106 KB  conda-forge\n",
            "    aws-c-cal-0.8.1            |       h1a47875_3          46 KB  conda-forge\n",
            "    aws-c-common-0.10.6        |       hb9d3cd8_0         231 KB  conda-forge\n",
            "    aws-c-compression-0.3.0    |       h4e1184b_5          19 KB  conda-forge\n",
            "    aws-c-event-stream-0.5.0   |      h7959bf6_11          53 KB  conda-forge\n",
            "    aws-c-http-0.9.2           |       hefd7a92_4         193 KB  conda-forge\n",
            "    aws-c-io-0.15.3            |       h173a860_6         154 KB  conda-forge\n",
            "    aws-c-mqtt-0.11.0          |      h11f4f37_12         190 KB  conda-forge\n",
            "    aws-c-s3-0.7.9             |       he1b24dc_1         113 KB  conda-forge\n",
            "    aws-c-sdkutils-0.2.2       |       h4e1184b_0          55 KB  conda-forge\n",
            "    aws-checksums-0.2.2        |       h4e1184b_4          71 KB  conda-forge\n",
            "    aws-crt-cpp-0.29.9         |       he0e7f3f_2         345 KB  conda-forge\n",
            "    aws-sdk-cpp-1.11.489       |       h4d475cb_0         3.0 MB  conda-forge\n",
            "    azure-core-cpp-1.14.0      |       h5cfcd09_0         337 KB  conda-forge\n",
            "    azure-identity-cpp-1.10.0  |       h113e628_0         227 KB  conda-forge\n",
            "    azure-storage-blobs-cpp-12.13.0|       h3cf044e_1         536 KB  conda-forge\n",
            "    azure-storage-common-cpp-12.8.0|       h736e048_1         146 KB  conda-forge\n",
            "    azure-storage-files-datalake-cpp-12.12.0|       ha633028_1         281 KB  conda-forge\n",
            "    click-8.2.1                |     pyh707e725_0          86 KB  conda-forge\n",
            "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
            "    datasets-3.6.0             |     pyhd8ed1ab_0         331 KB  conda-forge\n",
            "    dill-0.3.8                 |     pyhd8ed1ab_0          86 KB  conda-forge\n",
            "    frozenlist-1.7.0           |  py311h52bc045_0          54 KB  conda-forge\n",
            "    fsspec-2025.3.0            |     pyhd8ed1ab_0         138 KB  conda-forge\n",
            "    gflags-2.2.2               |    h5888daf_1005         117 KB  conda-forge\n",
            "    glog-0.7.1                 |       hbabe93e_0         140 KB  conda-forge\n",
            "    hf-xet-1.1.7               |   py39h598437d_0         2.5 MB  conda-forge\n",
            "    huggingface_hub-0.34.4     |     pyhd8ed1ab_0         326 KB  conda-forge\n",
            "    importlib-metadata-8.7.0   |     pyhe01879c_1          34 KB  conda-forge\n",
            "    importlib_metadata-8.7.0   |       h40b2b14_1          22 KB  conda-forge\n",
            "    joblib-1.5.1               |     pyhd8ed1ab_0         219 KB  conda-forge\n",
            "    libabseil-20240722.0       | cxx17_hbbce691_4         1.3 MB  conda-forge\n",
            "    libarrow-19.0.1            |   hfa2a6e7_0_cpu         8.6 MB  conda-forge\n",
            "    libarrow-acero-19.0.1      |   hcb10f89_0_cpu         623 KB  conda-forge\n",
            "    libarrow-dataset-19.0.1    |   hcb10f89_0_cpu         590 KB  conda-forge\n",
            "    libarrow-substrait-19.0.1  |   h08228c5_0_cpu         511 KB  conda-forge\n",
            "    libbrotlicommon-1.1.0      |       hb9d3cd8_2          67 KB  conda-forge\n",
            "    libbrotlidec-1.1.0         |       hb9d3cd8_2          32 KB  conda-forge\n",
            "    libbrotlienc-1.1.0         |       hb9d3cd8_2         275 KB  conda-forge\n",
            "    libcrc32c-1.1.2            |       h9c3ff4c_0          20 KB  conda-forge\n",
            "    libevent-2.1.12            |       hf998b51_1         417 KB  conda-forge\n",
            "    libgoogle-cloud-2.35.0     |       h2b5623c_0         1.2 MB  conda-forge\n",
            "    libgoogle-cloud-storage-2.35.0|       h0121fbd_0         767 KB  conda-forge\n",
            "    libgrpc-1.67.1             |       h25350d4_2         7.8 MB  conda-forge\n",
            "    libopentelemetry-cpp-1.18.0|       hfcad708_1         783 KB  conda-forge\n",
            "    libopentelemetry-cpp-headers-1.18.0|       ha770c72_1         313 KB  conda-forge\n",
            "    libparquet-19.0.1          |   h081d1f1_0_cpu         1.2 MB  conda-forge\n",
            "    libprotobuf-5.28.3         |       h6128344_1         2.8 MB  conda-forge\n",
            "    libre2-11-2024.07.02       |       hbbce691_2         205 KB  conda-forge\n",
            "    libthrift-0.21.0           |       h0e7cc3e_0         416 KB  conda-forge\n",
            "    libutf8proc-2.10.0         |       h202a827_0          81 KB  conda-forge\n",
            "    multidict-6.6.3            |  py311h2dc5d0c_0          95 KB  conda-forge\n",
            "    multiprocess-0.70.16       |  py311h9ecbd09_1         340 KB  conda-forge\n",
            "    nlohmann_json-3.12.0       |       h3f2d84a_0         133 KB  conda-forge\n",
            "    orc-2.0.3                  |       h12ee42a_2         1.1 MB  conda-forge\n",
            "    pandas-2.3.1               |  py311hed34c8f_0        14.7 MB  conda-forge\n",
            "    prometheus-cpp-1.3.0       |       ha5d0236_0         195 KB  conda-forge\n",
            "    propcache-0.3.1            |  py311h2dc5d0c_0          53 KB  conda-forge\n",
            "    pyarrow-19.0.1             |  py311h38be061_0          25 KB  conda-forge\n",
            "    pyarrow-core-19.0.1        |py311h4854187_0_cpu         4.5 MB  conda-forge\n",
            "    python-dateutil-2.9.0.post0|     pyhe01879c_2         228 KB  conda-forge\n",
            "    python-gil-3.11.13         |       hd8ed1ab_0          46 KB  conda-forge\n",
            "    python-tzdata-2025.2       |     pyhd8ed1ab_0         141 KB  conda-forge\n",
            "    python-xxhash-3.5.0        |  py311h9ecbd09_2          23 KB  conda-forge\n",
            "    re2-2024.07.02             |       h9925aae_2          26 KB  conda-forge\n",
            "    regex-2025.7.34            |  py311h49ec1c0_0         406 KB  conda-forge\n",
            "    s2n-1.5.11                 |       h072c03f_0         348 KB  conda-forge\n",
            "    sacremoses-0.0.53          |     pyhd8ed1ab_0         427 KB  conda-forge\n",
            "    safetensors-0.6.2          |  py311hc8fb587_0         433 KB  conda-forge\n",
            "    six-1.17.0                 |     pyhe01879c_1          18 KB  conda-forge\n",
            "    snappy-1.2.2               |       h03e3b7b_0          45 KB  conda-forge\n",
            "    tokenizers-0.13.3          |  py311h1b04a43_0         3.9 MB  conda-forge\n",
            "    transformers-4.32.1        |     pyhd8ed1ab_0         2.5 MB  conda-forge\n",
            "    typing-extensions-4.14.1   |       h4440ef1_0          88 KB  conda-forge\n",
            "    xxhash-0.8.3               |       hb47aa4a_0         106 KB  conda-forge\n",
            "    yarl-1.20.1                |  py311h2dc5d0c_0         148 KB  conda-forge\n",
            "    zipp-3.23.0                |     pyhd8ed1ab_0          22 KB  conda-forge\n",
            "    zlib-1.3.1                 |       hb9d3cd8_2          90 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        68.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _python_abi3_supp~ conda-forge/noarch::_python_abi3_support-1.0-hd8ed1ab_2 \n",
            "  aiohappyeyeballs   conda-forge/noarch::aiohappyeyeballs-2.6.1-pyhd8ed1ab_0 \n",
            "  aiohttp            conda-forge/linux-64::aiohttp-3.12.15-py311h3778330_0 \n",
            "  aiosignal          conda-forge/noarch::aiosignal-1.4.0-pyhd8ed1ab_0 \n",
            "  attrs              conda-forge/noarch::attrs-25.3.0-pyh71513ae_0 \n",
            "  aws-c-auth         conda-forge/linux-64::aws-c-auth-0.8.1-h205f482_0 \n",
            "  aws-c-cal          conda-forge/linux-64::aws-c-cal-0.8.1-h1a47875_3 \n",
            "  aws-c-common       conda-forge/linux-64::aws-c-common-0.10.6-hb9d3cd8_0 \n",
            "  aws-c-compression  conda-forge/linux-64::aws-c-compression-0.3.0-h4e1184b_5 \n",
            "  aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.5.0-h7959bf6_11 \n",
            "  aws-c-http         conda-forge/linux-64::aws-c-http-0.9.2-hefd7a92_4 \n",
            "  aws-c-io           conda-forge/linux-64::aws-c-io-0.15.3-h173a860_6 \n",
            "  aws-c-mqtt         conda-forge/linux-64::aws-c-mqtt-0.11.0-h11f4f37_12 \n",
            "  aws-c-s3           conda-forge/linux-64::aws-c-s3-0.7.9-he1b24dc_1 \n",
            "  aws-c-sdkutils     conda-forge/linux-64::aws-c-sdkutils-0.2.2-h4e1184b_0 \n",
            "  aws-checksums      conda-forge/linux-64::aws-checksums-0.2.2-h4e1184b_4 \n",
            "  aws-crt-cpp        conda-forge/linux-64::aws-crt-cpp-0.29.9-he0e7f3f_2 \n",
            "  aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.11.489-h4d475cb_0 \n",
            "  azure-core-cpp     conda-forge/linux-64::azure-core-cpp-1.14.0-h5cfcd09_0 \n",
            "  azure-identity-cpp conda-forge/linux-64::azure-identity-cpp-1.10.0-h113e628_0 \n",
            "  azure-storage-blo~ conda-forge/linux-64::azure-storage-blobs-cpp-12.13.0-h3cf044e_1 \n",
            "  azure-storage-com~ conda-forge/linux-64::azure-storage-common-cpp-12.8.0-h736e048_1 \n",
            "  azure-storage-fil~ conda-forge/linux-64::azure-storage-files-datalake-cpp-12.12.0-ha633028_1 \n",
            "  click              conda-forge/noarch::click-8.2.1-pyh707e725_0 \n",
            "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3 \n",
            "  datasets           conda-forge/noarch::datasets-3.6.0-pyhd8ed1ab_0 \n",
            "  dill               conda-forge/noarch::dill-0.3.8-pyhd8ed1ab_0 \n",
            "  frozenlist         conda-forge/linux-64::frozenlist-1.7.0-py311h52bc045_0 \n",
            "  fsspec             conda-forge/noarch::fsspec-2025.3.0-pyhd8ed1ab_0 \n",
            "  gflags             conda-forge/linux-64::gflags-2.2.2-h5888daf_1005 \n",
            "  glog               conda-forge/linux-64::glog-0.7.1-hbabe93e_0 \n",
            "  hf-xet             conda-forge/linux-64::hf-xet-1.1.7-py39h598437d_0 \n",
            "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.34.4-pyhd8ed1ab_0 \n",
            "  importlib-metadata conda-forge/noarch::importlib-metadata-8.7.0-pyhe01879c_1 \n",
            "  importlib_metadata conda-forge/noarch::importlib_metadata-8.7.0-h40b2b14_1 \n",
            "  joblib             conda-forge/noarch::joblib-1.5.1-pyhd8ed1ab_0 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20240722.0-cxx17_hbbce691_4 \n",
            "  libarrow           conda-forge/linux-64::libarrow-19.0.1-hfa2a6e7_0_cpu \n",
            "  libarrow-acero     conda-forge/linux-64::libarrow-acero-19.0.1-hcb10f89_0_cpu \n",
            "  libarrow-dataset   conda-forge/linux-64::libarrow-dataset-19.0.1-hcb10f89_0_cpu \n",
            "  libarrow-substrait conda-forge/linux-64::libarrow-substrait-19.0.1-h08228c5_0_cpu \n",
            "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.1.0-hb9d3cd8_2 \n",
            "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.1.0-hb9d3cd8_2 \n",
            "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.1.0-hb9d3cd8_2 \n",
            "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 \n",
            "  libevent           conda-forge/linux-64::libevent-2.1.12-hf998b51_1 \n",
            "  libgoogle-cloud    conda-forge/linux-64::libgoogle-cloud-2.35.0-h2b5623c_0 \n",
            "  libgoogle-cloud-s~ conda-forge/linux-64::libgoogle-cloud-storage-2.35.0-h0121fbd_0 \n",
            "  libgrpc            conda-forge/linux-64::libgrpc-1.67.1-h25350d4_2 \n",
            "  libopentelemetry-~ conda-forge/linux-64::libopentelemetry-cpp-1.18.0-hfcad708_1 \n",
            "  libopentelemetry-~ conda-forge/linux-64::libopentelemetry-cpp-headers-1.18.0-ha770c72_1 \n",
            "  libparquet         conda-forge/linux-64::libparquet-19.0.1-h081d1f1_0_cpu \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-5.28.3-h6128344_1 \n",
            "  libre2-11          conda-forge/linux-64::libre2-11-2024.07.02-hbbce691_2 \n",
            "  libthrift          conda-forge/linux-64::libthrift-0.21.0-h0e7cc3e_0 \n",
            "  libutf8proc        conda-forge/linux-64::libutf8proc-2.10.0-h202a827_0 \n",
            "  multidict          conda-forge/linux-64::multidict-6.6.3-py311h2dc5d0c_0 \n",
            "  multiprocess       conda-forge/linux-64::multiprocess-0.70.16-py311h9ecbd09_1 \n",
            "  nlohmann_json      conda-forge/linux-64::nlohmann_json-3.12.0-h3f2d84a_0 \n",
            "  orc                conda-forge/linux-64::orc-2.0.3-h12ee42a_2 \n",
            "  pandas             conda-forge/linux-64::pandas-2.3.1-py311hed34c8f_0 \n",
            "  prometheus-cpp     conda-forge/linux-64::prometheus-cpp-1.3.0-ha5d0236_0 \n",
            "  propcache          conda-forge/linux-64::propcache-0.3.1-py311h2dc5d0c_0 \n",
            "  pyarrow            conda-forge/linux-64::pyarrow-19.0.1-py311h38be061_0 \n",
            "  pyarrow-core       conda-forge/linux-64::pyarrow-core-19.0.1-py311h4854187_0_cpu \n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhe01879c_2 \n",
            "  python-gil         conda-forge/noarch::python-gil-3.11.13-hd8ed1ab_0 \n",
            "  python-tzdata      conda-forge/noarch::python-tzdata-2025.2-pyhd8ed1ab_0 \n",
            "  python-xxhash      conda-forge/linux-64::python-xxhash-3.5.0-py311h9ecbd09_2 \n",
            "  re2                conda-forge/linux-64::re2-2024.07.02-h9925aae_2 \n",
            "  regex              conda-forge/linux-64::regex-2025.7.34-py311h49ec1c0_0 \n",
            "  s2n                conda-forge/linux-64::s2n-1.5.11-h072c03f_0 \n",
            "  sacremoses         conda-forge/noarch::sacremoses-0.0.53-pyhd8ed1ab_0 \n",
            "  safetensors        conda-forge/linux-64::safetensors-0.6.2-py311hc8fb587_0 \n",
            "  six                conda-forge/noarch::six-1.17.0-pyhe01879c_1 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_0 \n",
            "  tokenizers         conda-forge/linux-64::tokenizers-0.13.3-py311h1b04a43_0 \n",
            "  transformers       conda-forge/noarch::transformers-4.32.1-pyhd8ed1ab_0 \n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.14.1-h4440ef1_0 \n",
            "  xxhash             conda-forge/linux-64::xxhash-0.8.3-hb47aa4a_0 \n",
            "  yarl               conda-forge/linux-64::yarl-1.20.1-py311h2dc5d0c_0 \n",
            "  zipp               conda-forge/noarch::zipp-3.23.0-pyhd8ed1ab_0 \n",
            "  zlib               conda-forge/linux-64::zlib-1.3.1-hb9d3cd8_2 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pandas-2.3.1         | 14.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libarrow-19.0.1      | 8.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :   6% 0.056497864003737755/1 [00:00<00:01,  1.78s/it]\n",
            "libarrow-19.0.1      | 8.6 MB    | :  10% 0.10231082059053437/1 [00:00<00:00,  1.02it/s]\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :   6% 0.05599887892869332/1 [00:00<00:01,  1.79s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | :  12% 0.11764603927361612/1 [00:00<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.94it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  35% 0.34858116092872166/1 [00:00<00:00,  1.95it/s] \n",
            "libarrow-19.0.1      | 8.6 MB    | :  66% 0.6595393970211233/1 [00:00<00:00,  3.68it/s] \u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | :  66% 0.6619867473356247/1 [00:00<00:00,  3.77it/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | :   1% 0.005210592666752323/1 [00:00<00:39, 39.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  4.41it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  63% 0.6300044835133777/1 [00:00<00:00,  2.34it/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | :   1% 0.0055336115225030945/1 [00:00<00:52, 52.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | :  94% 0.9431172726821704/1 [00:00<00:00,  3.84it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | :  86% 0.864523919000591/1 [00:00<00:00,  2.34it/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | :   1% 0.00614833611404443/1 [00:00<01:06, 66.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.77it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.85it/s]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | : 100% 1.0/1 [00:00<00:00,  3.68it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | :   1% 0.006298219784190638/1 [00:00<01:14, 74.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | :   1% 0.012491622820694435/1 [00:00<00:38, 38.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:00<00:00, 66.72s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | :   1% 0.013023485038174614/1 [00:00<00:38, 38.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:00<00:00, 38.68s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | :   1% 0.013162493000596907/1 [00:00<00:40, 40.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:00<00:00, 38.64s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:00<00:00, 74.77s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:00<00:00, 40.69s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | :   1% 0.013781026023630624/1 [00:00<00:41, 42.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | :   2% 0.016199984377456473/1 [00:00<00:35, 36.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | :   2% 0.02085069937145017/1 [00:00<00:28, 29.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | :   2% 0.020430787340992386/1 [00:00<00:29, 30.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:00<00:00, 36.39s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 42.35s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:00<00:00, 29.13s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:00<00:00, 30.14s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | :   3% 0.025678077404106863/1 [00:00<00:25, 25.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | :   3% 0.029824772181992275/1 [00:00<00:21, 22.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:00<00:00, 22.33s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | :   3% 0.02710339123242349/1 [00:00<00:24, 25.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:00<00:00, 25.90s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | : 100% 1.0/1 [00:00<00:00,  2.34it/s]              \n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.13.3    | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  4.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pyarrow-core-19.0.1  | 4.5 MB    | : 100% 1.0/1 [00:01<00:00,  5.94it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aws-sdk-cpp-1.11.489 | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  3.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libgrpc-1.67.1       | 7.8 MB    | : 100% 1.0/1 [00:02<00:00,  3.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-5.28.3   | 2.8 MB    | : 100% 1.0/1 [00:02<00:00,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libarrow-19.0.1      | 8.6 MB    | : 100% 1.0/1 [00:02<00:00,  3.68it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:02<00:00,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libabseil-20240722.0 | 1.3 MB    | : 100% 1.0/1 [00:02<00:00,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-2.35 | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.32.1  | 2.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hf-xet-1.1.7         | 2.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libparquet-19.0.1    | 1.2 MB    | : 100% 1.0/1 [00:03<00:00,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orc-2.0.3            | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:03<00:00,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aiohttp-3.12.15      | 988 KB    | : 100% 1.0/1 [00:03<00:00,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:03<00:00,  3.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgoogle-cloud-stor | 767 KB    | : 100% 1.0/1 [00:03<00:00,  3.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:03<00:00,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "azure-storage-blobs- | 536 KB    | : 100% 1.0/1 [00:03<00:00,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:03<00:00,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopentelemetry-cpp | 783 KB    | : 100% 1.0/1 [00:03<00:00,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:03<00:00,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-acero-19.0. | 623 KB    | : 100% 1.0/1 [00:03<00:00,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarrow-dataset-19. | 590 KB    | : 100% 1.0/1 [00:03<00:00,  3.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.3.1         | 14.7 MB   | : 100% 1.0/1 [00:08<00:00,  2.34it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.32.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (2.1.2)\n",
            "Collecting torchvision (from sentence-transformers==2.2.2)\n",
            "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.26.3)\n",
            "Collecting scikit-learn (from sentence-transformers==2.2.2)\n",
            "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence-transformers==2.2.2)\n",
            "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "Collecting nltk (from sentence-transformers==2.2.2)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
            "  Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.1.7)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (1.5.1)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==2.2.2)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch>=1.6.0 (from sentence-transformers==2.2.2)\n",
            "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers==2.2.2)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.6.0->sentence-transformers==2.2.2) (65.6.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.8.3)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m189.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m165.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=0659e5d571a9acfac160658f215085d21a3bb74072b2249a268caa375be193f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: nvidia-cusparselt-cu12, triton, threadpoolctl, sentencepiece, scipy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, sentence-transformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "Successfully installed nltk-3.9.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pillow-11.3.0 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-2.2.2 sentencepiece-0.2.1 threadpoolctl-3.6.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "63467288874b46449320f3dcd7de9733"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda-forge::accelerate=0.25.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    accelerate-0.25.0          |     pyhd8ed1ab_0         175 KB  conda-forge\n",
            "    psutil-7.0.0               |  py311h9ecbd09_0         473 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         648 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  accelerate         conda-forge/noarch::accelerate-0.25.0-pyhd8ed1ab_0 \n",
            "  psutil             conda-forge/linux-64::psutil-7.0.0-py311h9ecbd09_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "psutil-7.0.0         | 473 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "psutil-7.0.0         | 473 KB    | : 100% 1.0/1 [00:00<00:00, 14.02it/s]\n",
            "accelerate-0.25.0    | 175 KB    | : 100% 1.0/1 [00:00<00:00, 13.34it/s]\u001b[A\n",
            "accelerate-0.25.0    | 175 KB    | : 100% 1.0/1 [00:00<00:00,  7.43it/s]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - nvidia\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda-forge::bitsandbytes=0.42.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bitsandbytes-0.42.0        |  py311hccbc8e4_0         272 KB  conda-forge\n",
            "    scipy-1.16.0               |  py311h2d3ef60_0        16.1 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        16.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  bitsandbytes       conda-forge/linux-64::bitsandbytes-0.42.0-py311hccbc8e4_0 \n",
            "  scipy              conda-forge/linux-64::scipy-1.16.0-py311h2d3ef60_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "scipy-1.16.0         | 16.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "bitsandbytes-0.42.0  | 272 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "scipy-1.16.0         | 16.1 MB   | :  17% 0.16941042784050508/1 [00:00<00:00,  1.69it/s]\n",
            "bitsandbytes-0.42.0  | 272 KB    | : 100% 1.0/1 [00:00<00:00,  5.62it/s]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\bdone\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/site-packages (2.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (65.6.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
            "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, sentence-transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.32.1\n",
            "    Uninstalling transformers-4.32.1:\n",
            "      Successfully uninstalled transformers-4.32.1\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.2.2\n",
            "    Uninstalling sentence-transformers-2.2.2:\n",
            "      Successfully uninstalled sentence-transformers-2.2.2\n",
            "Successfully installed sentence-transformers-5.1.0 tokenizers-0.21.4 transformers-4.55.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movies_and_TV Dataset\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/Movies_and_TV.json.gz\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_Movies_and_TV.json.gz\n",
        "\n",
        "with gzip.open('/content/Movies_and_TV.json.gz', 'rb') as f_in:\n",
        "    with open('/content/Movies_and_TV.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "with gzip.open('/content/meta_Movies_and_TV.json.gz', 'rb') as f_in:\n",
        "    with open('/content/meta_Movies_and_TV.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "metadata": {
        "id": "vNtW7yMW9QV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All_Beauty Dataset\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/All_Beauty.json.gz\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_All_Beauty.json.gz\n",
        "\n",
        "with gzip.open('/content/All_Beauty.json.gz', 'rb') as f_in:\n",
        "    with open('/content/All_Beauty.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "with gzip.open('/content/meta_All_Beauty.json.gz', 'rb') as f_in:\n",
        "    with open('/content/meta_All_Beauty.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OjMIf1en9Nx7",
        "outputId": "c5a198ec-ba7f-4dd3-b8f9-5f8c65fd7bc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-18 18:04:21--  https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFiles/All_Beauty.json.gz\n",
            "Resolving mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)... 169.228.63.88\n",
            "Connecting to mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)|169.228.63.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46650072 (44M) [application/gzip]\n",
            "Saving to: â€˜All_Beauty.json.gzâ€™\n",
            "\n",
            "All_Beauty.json.gz  100%[===================>]  44.49M  12.7MB/s    in 3.7s    \n",
            "\n",
            "2025-08-18 18:04:26 (12.1 MB/s) - â€˜All_Beauty.json.gzâ€™ saved [46650072/46650072]\n",
            "\n",
            "--2025-08-18 18:04:26--  https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_All_Beauty.json.gz\n",
            "Resolving mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)... 169.228.63.88\n",
            "Connecting to mcauleylab.ucsd.edu (mcauleylab.ucsd.edu)|169.228.63.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10349695 (9.9M) [application/gzip]\n",
            "Saving to: â€˜meta_All_Beauty.json.gzâ€™\n",
            "\n",
            "meta_All_Beauty.jso 100%[===================>]   9.87M  5.14MB/s    in 1.9s    \n",
            "\n",
            "2025-08-18 18:04:29 (5.14 MB/s) - â€˜meta_All_Beauty.json.gzâ€™ saved [10349695/10349695]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA device count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMYAmHUv_uZ3",
        "outputId": "b6b74f80-05b5-4dd2-87bd-800f21066aba",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA device count: 1\n",
            "Current CUDA device: 0\n",
            "CUDA device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Rec_Proj_DL/pre_train/sasrec/main.py --device=cuda --dataset All_Beauty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du-3ugMSSQUb",
        "outputId": "73878ec2-94a9-4593-eeac-a9a698814dc3",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371345it [00:03, 109888.12it/s]\n",
            "371345it [00:03, 105726.64it/s]\n",
            "2169 1854\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "  0% 0/1 [00:00<?, ?it/s]loss in epoch 1 iteration 0: 1.3672395944595337\n",
            "Evaluating........................................\n",
            "\n",
            "epoch:1, time: 1.578335(s), valid (NDCG@10: 0.5819, HR@10: 0.6608), test (NDCG@10: 0.4388, HR@10: 0.4388)\n",
            "(0.5819053582221886, 0.6607908527870414) (0.43878037160552646, 0.43878037160552646)\n",
            "\n",
            "Saving model to: /content/All_Beauty/SASRec.epoch=1.lr=0.001.layer=2.head=1.hidden=50.maxlen=50.pth\n",
            "100% 1/1 [00:16<00:00, 16.76s/it]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train stage1\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --pretrain_stage1 --rec_pre_trained_data All_Beauty"
      ],
      "metadata": {
        "id": "adWqS5QoSzWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef838c4-8376-4c4f-dbbf-f28e91d743fb",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec start train phase-1\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2169\n",
            "  0% 0/20 [00:00<?, ?it/s]loss in epoch 1/21 iteration 0/67: 1.5755795240402222 / BPR loss: 1.3865745067596436 / Matching loss: 0.010317654348909855 / Item reconstruction: 0.1283802092075348 / Text reconstruction: 0.572486162185669\n",
            "loss in epoch 1/21 iteration 1/67: 1.557134747505188 / BPR loss: 1.3865888118743896 / Matching loss: 0.007584666833281517 / Item reconstruction: 0.12635378539562225 / Text reconstruction: 0.4989219307899475\n",
            "loss in epoch 1/21 iteration 2/67: 1.5348403453826904 / BPR loss: 1.386764645576477 / Matching loss: 0.005994034465402365 / Item reconstruction: 0.12254840135574341 / Text reconstruction: 0.40403735637664795\n",
            "loss in epoch 1/21 iteration 3/67: 1.5184757709503174 / BPR loss: 1.3864963054656982 / Matching loss: 0.004016737453639507 / Item reconstruction: 0.11916961520910263 / Text reconstruction: 0.3418893814086914\n",
            "loss in epoch 1/21 iteration 4/67: 1.5076485872268677 / BPR loss: 1.386338472366333 / Matching loss: 0.0031239648815244436 / Item reconstruction: 0.11384877562522888 / Text reconstruction: 0.3063091039657593\n",
            "loss in epoch 1/21 iteration 5/67: 1.5016372203826904 / BPR loss: 1.3865926265716553 / Matching loss: 0.002677721669897437 / Item reconstruction: 0.10858563333749771 / Text reconstruction: 0.29037052392959595\n",
            "loss in epoch 1/21 iteration 6/67: 1.4963494539260864 / BPR loss: 1.3864169120788574 / Matching loss: 0.002383539453148842 / Item reconstruction: 0.10466772317886353 / Text reconstruction: 0.27607548236846924\n",
            "loss in epoch 1/21 iteration 7/67: 1.493294596672058 / BPR loss: 1.386523962020874 / Matching loss: 0.0022904775105416775 / Item reconstruction: 0.10068583488464355 / Text reconstruction: 0.2706861197948456\n",
            "loss in epoch 1/21 iteration 8/67: 1.4886178970336914 / BPR loss: 1.3863353729248047 / Matching loss: 0.0021311806049197912 / Item reconstruction: 0.09676167368888855 / Text reconstruction: 0.25885209441185\n",
            "loss in epoch 1/21 iteration 9/67: 1.4851657152175903 / BPR loss: 1.3862547874450684 / Matching loss: 0.001980834174901247 / Item reconstruction: 0.09300301223993301 / Text reconstruction: 0.25214332342147827\n",
            "loss in epoch 1/21 iteration 10/67: 1.481095314025879 / BPR loss: 1.386275053024292 / Matching loss: 0.0018135060090571642 / Item reconstruction: 0.08875191956758499 / Text reconstruction: 0.24315351247787476\n",
            "loss in epoch 1/21 iteration 11/67: 1.4781239032745361 / BPR loss: 1.3862553834915161 / Matching loss: 0.0016537157353013754 / Item reconstruction: 0.0858749970793724 / Text reconstruction: 0.23638677597045898\n",
            "loss in epoch 1/21 iteration 12/67: 1.474532961845398 / BPR loss: 1.3863790035247803 / Matching loss: 0.0015518059954047203 / Item reconstruction: 0.08185315132141113 / Text reconstruction: 0.22837789356708527\n",
            "loss in epoch 1/21 iteration 13/67: 1.4708435535430908 / BPR loss: 1.3862433433532715 / Matching loss: 0.0014180380385369062 / Item reconstruction: 0.0782165601849556 / Text reconstruction: 0.22036942839622498\n",
            "loss in epoch 1/21 iteration 14/67: 1.4681390523910522 / BPR loss: 1.3862853050231934 / Matching loss: 0.001368012628518045 / Item reconstruction: 0.0754464790225029 / Text reconstruction: 0.21381276845932007\n",
            "loss in epoch 1/21 iteration 15/67: 1.4657204151153564 / BPR loss: 1.3862731456756592 / Matching loss: 0.0013482205104082823 / Item reconstruction: 0.07240156829357147 / Text reconstruction: 0.20949125289916992\n",
            "loss in epoch 1/21 iteration 16/67: 1.462958812713623 / BPR loss: 1.386138677597046 / Matching loss: 0.001290542888455093 / Item reconstruction: 0.06917116045951843 / Text reconstruction: 0.204720139503479\n",
            "loss in epoch 1/21 iteration 17/67: 1.4607865810394287 / BPR loss: 1.386181354522705 / Matching loss: 0.0012142498744651675 / Item reconstruction: 0.06674481928348541 / Text reconstruction: 0.2000926285982132\n",
            "loss in epoch 1/21 iteration 18/67: 1.4577112197875977 / BPR loss: 1.3863356113433838 / Matching loss: 0.0012229265412315726 / Item reconstruction: 0.061207689344882965 / Text reconstruction: 0.19774384796619415\n",
            "loss in epoch 1/21 iteration 19/67: 1.4548285007476807 / BPR loss: 1.3864498138427734 / Matching loss: 0.0011373767629265785 / Item reconstruction: 0.057052548974752426 / Text reconstruction: 0.1935749351978302\n",
            "loss in epoch 1/21 iteration 20/67: 1.4525763988494873 / BPR loss: 1.38649582862854 / Matching loss: 0.0010449782712385058 / Item reconstruction: 0.0547395721077919 / Text reconstruction: 0.1883293092250824\n",
            "loss in epoch 1/21 iteration 21/67: 1.4502373933792114 / BPR loss: 1.3862838745117188 / Matching loss: 0.000972938199993223 / Item reconstruction: 0.05248524993658066 / Text reconstruction: 0.1836898773908615\n",
            "loss in epoch 1/21 iteration 22/67: 1.4494128227233887 / BPR loss: 1.3864226341247559 / Matching loss: 0.0009053404210135341 / Item reconstruction: 0.05212745815515518 / Text reconstruction: 0.1801057755947113\n",
            "loss in epoch 1/21 iteration 23/67: 1.4473872184753418 / BPR loss: 1.3863897323608398 / Matching loss: 0.0008539626724086702 / Item reconstruction: 0.050215933471918106 / Text reconstruction: 0.17517733573913574\n",
            "loss in epoch 1/21 iteration 24/67: 1.4453072547912598 / BPR loss: 1.386296272277832 / Matching loss: 0.0008272178238257766 / Item reconstruction: 0.04792733117938042 / Text reconstruction: 0.17110034823417664\n",
            "loss in epoch 1/21 iteration 25/67: 1.4435895681381226 / BPR loss: 1.3863780498504639 / Matching loss: 0.0008064158027991652 / Item reconstruction: 0.04591112583875656 / Text reconstruction: 0.16724738478660583\n",
            "loss in epoch 1/21 iteration 26/67: 1.4417448043823242 / BPR loss: 1.3863732814788818 / Matching loss: 0.0007754573598504066 / Item reconstruction: 0.04395036771893501 / Text reconstruction: 0.16310466825962067\n",
            "loss in epoch 1/21 iteration 27/67: 1.439600944519043 / BPR loss: 1.3863141536712646 / Matching loss: 0.0007404395146295428 / Item reconstruction: 0.04156169295310974 / Text reconstruction: 0.15882760286331177\n",
            "loss in epoch 1/21 iteration 28/67: 1.4378069639205933 / BPR loss: 1.3863524198532104 / Matching loss: 0.0007006758823990822 / Item reconstruction: 0.03983527421951294 / Text reconstruction: 0.15418140590190887\n",
            "loss in epoch 1/21 iteration 29/67: 1.436353325843811 / BPR loss: 1.3863422870635986 / Matching loss: 0.0006571518024429679 / Item reconstruction: 0.038518525660037994 / Text reconstruction: 0.15047331154346466\n",
            "loss in epoch 1/21 iteration 30/67: 1.4342455863952637 / BPR loss: 1.3863375186920166 / Matching loss: 0.0006049986695870757 / Item reconstruction: 0.036158014088869095 / Text reconstruction: 0.14612042903900146\n",
            "loss in epoch 1/21 iteration 31/67: 1.4328933954238892 / BPR loss: 1.386344075202942 / Matching loss: 0.0005741349887102842 / Item reconstruction: 0.03484191372990608 / Text reconstruction: 0.1427709460258484\n",
            "loss in epoch 1/21 iteration 32/67: 1.431288242340088 / BPR loss: 1.3862988948822021 / Matching loss: 0.000539233151357621 / Item reconstruction: 0.03323765844106674 / Text reconstruction: 0.13915660977363586\n",
            "loss in epoch 1/21 iteration 33/67: 1.4298532009124756 / BPR loss: 1.3861682415008545 / Matching loss: 0.0005349181010387838 / Item reconstruction: 0.03205857798457146 / Text reconstruction: 0.13560394942760468\n",
            "loss in epoch 1/21 iteration 34/67: 1.4287022352218628 / BPR loss: 1.386362075805664 / Matching loss: 0.000530697638168931 / Item reconstruction: 0.030521109700202942 / Text reconstruction: 0.13274458050727844\n",
            "loss in epoch 1/21 iteration 35/67: 1.4271376132965088 / BPR loss: 1.3862640857696533 / Matching loss: 0.000495283049531281 / Item reconstruction: 0.029112856835126877 / Text reconstruction: 0.1291092187166214\n",
            "loss in epoch 1/21 iteration 36/67: 1.4255201816558838 / BPR loss: 1.386401653289795 / Matching loss: 0.00048779018106870353 / Item reconstruction: 0.027114156633615494 / Text reconstruction: 0.12536802887916565\n",
            "loss in epoch 1/21 iteration 37/67: 1.4238767623901367 / BPR loss: 1.3863340616226196 / Matching loss: 0.0004727013292722404 / Item reconstruction: 0.025338858366012573 / Text reconstruction: 0.12200324237346649\n",
            "loss in epoch 1/21 iteration 38/67: 1.422589898109436 / BPR loss: 1.386298418045044 / Matching loss: 0.00045087101170793176 / Item reconstruction: 0.024081554263830185 / Text reconstruction: 0.11899959295988083\n",
            "loss in epoch 1/21 iteration 39/67: 1.4212734699249268 / BPR loss: 1.3863075971603394 / Matching loss: 0.0004535189364105463 / Item reconstruction: 0.02269357442855835 / Text reconstruction: 0.11582793295383453\n",
            "loss in epoch 1/21 iteration 40/67: 1.4203721284866333 / BPR loss: 1.386312484741211 / Matching loss: 0.00043989039841108024 / Item reconstruction: 0.02190230041742325 / Text reconstruction: 0.11334311217069626\n",
            "loss in epoch 1/21 iteration 41/67: 1.4195553064346313 / BPR loss: 1.386225700378418 / Matching loss: 0.00042425302672199905 / Item reconstruction: 0.021772192791104317 / Text reconstruction: 0.110096275806427\n",
            "loss in epoch 1/21 iteration 42/67: 1.4186445474624634 / BPR loss: 1.3859148025512695 / Matching loss: 0.00039624166674911976 / Item reconstruction: 0.021634399890899658 / Text reconstruction: 0.10758164525032043\n",
            "loss in epoch 1/21 iteration 43/67: 1.4177424907684326 / BPR loss: 1.3859479427337646 / Matching loss: 0.0003711629833560437 / Item reconstruction: 0.021010801196098328 / Text reconstruction: 0.10458923131227493\n",
            "loss in epoch 1/21 iteration 44/67: 1.4162424802780151 / BPR loss: 1.3863798379898071 / Matching loss: 0.0003676255000755191 / Item reconstruction: 0.018264692276716232 / Text reconstruction: 0.10181289911270142\n",
            "loss in epoch 1/21 iteration 45/67: 1.4152640104293823 / BPR loss: 1.3863451480865479 / Matching loss: 0.00035672562080435455 / Item reconstruction: 0.017287183552980423 / Text reconstruction: 0.09959295392036438\n",
            "loss in epoch 1/21 iteration 46/67: 1.4145450592041016 / BPR loss: 1.3862802982330322 / Matching loss: 0.0003597773320507258 / Item reconstruction: 0.016992561519145966 / Text reconstruction: 0.0970432385802269\n",
            "loss in epoch 1/21 iteration 47/67: 1.4135708808898926 / BPR loss: 1.3863286972045898 / Matching loss: 0.0003417097614146769 / Item reconstruction: 0.015981508418917656 / Text reconstruction: 0.09454895555973053\n",
            "loss in epoch 1/21 iteration 48/67: 1.4127129316329956 / BPR loss: 1.3862791061401367 / Matching loss: 0.00032200198620557785 / Item reconstruction: 0.015192393213510513 / Text reconstruction: 0.0925777480006218\n",
            "loss in epoch 1/21 iteration 49/67: 1.4116650819778442 / BPR loss: 1.3861825466156006 / Matching loss: 0.0003133371355943382 / Item reconstruction: 0.014446699991822243 / Text reconstruction: 0.08972936868667603\n",
            "loss in epoch 1/21 iteration 50/67: 1.4110041856765747 / BPR loss: 1.3862512111663818 / Matching loss: 0.0003029979416169226 / Item reconstruction: 0.013877727091312408 / Text reconstruction: 0.08755557239055634\n",
            "loss in epoch 1/21 iteration 51/67: 1.4105428457260132 / BPR loss: 1.3863574266433716 / Matching loss: 0.0002944067819043994 / Item reconstruction: 0.013405585661530495 / Text reconstruction: 0.08594073355197906\n",
            "loss in epoch 1/21 iteration 52/67: 1.4096693992614746 / BPR loss: 1.3863120079040527 / Matching loss: 0.00028112693689763546 / Item reconstruction: 0.012683323584496975 / Text reconstruction: 0.08367307484149933\n",
            "loss in epoch 1/21 iteration 53/67: 1.4089257717132568 / BPR loss: 1.386345624923706 / Matching loss: 0.00027214124565944076 / Item reconstruction: 0.011908180080354214 / Text reconstruction: 0.08176927268505096\n",
            "loss in epoch 1/21 iteration 54/67: 1.4083161354064941 / BPR loss: 1.3863046169281006 / Matching loss: 0.00027536743436940014 / Item reconstruction: 0.011549945920705795 / Text reconstruction: 0.07980562746524811\n",
            "loss in epoch 1/21 iteration 55/67: 1.4076502323150635 / BPR loss: 1.3862955570220947 / Matching loss: 0.0002663086634129286 / Item reconstruction: 0.010920155793428421 / Text reconstruction: 0.07814185321331024\n",
            "loss in epoch 1/21 iteration 56/67: 1.4071236848831177 / BPR loss: 1.3863184452056885 / Matching loss: 0.0002672410919331014 / Item reconstruction: 0.010633068159222603 / Text reconstruction: 0.07610748708248138\n",
            "loss in epoch 1/21 iteration 57/67: 1.4065138101577759 / BPR loss: 1.3863641023635864 / Matching loss: 0.00026184640591964126 / Item reconstruction: 0.009988829493522644 / Text reconstruction: 0.07446709275245667\n",
            "loss in epoch 1/21 iteration 58/67: 1.4059616327285767 / BPR loss: 1.3863768577575684 / Matching loss: 0.000255561521044001 / Item reconstruction: 0.009550762362778187 / Text reconstruction: 0.07276906818151474\n",
            "loss in epoch 1/21 iteration 59/67: 1.4053224325180054 / BPR loss: 1.3863208293914795 / Matching loss: 0.0002448473242111504 / Item reconstruction: 0.009090909734368324 / Text reconstruction: 0.07105644047260284\n",
            "loss in epoch 1/21 iteration 60/67: 1.4048926830291748 / BPR loss: 1.3863970041275024 / Matching loss: 0.000232021848205477 / Item reconstruction: 0.008706842549145222 / Text reconstruction: 0.0695517361164093\n",
            "loss in epoch 1/21 iteration 61/67: 1.4042482376098633 / BPR loss: 1.3862206935882568 / Matching loss: 0.00022279657423496246 / Item reconstruction: 0.008370783179998398 / Text reconstruction: 0.06809630990028381\n",
            "loss in epoch 1/21 iteration 62/67: 1.4039456844329834 / BPR loss: 1.3862837553024292 / Matching loss: 0.00022406625794246793 / Item reconstruction: 0.008132077753543854 / Text reconstruction: 0.06685896962881088\n",
            "loss in epoch 1/21 iteration 63/67: 1.4035310745239258 / BPR loss: 1.3863028287887573 / Matching loss: 0.00022421873291023076 / Item reconstruction: 0.007976596243679523 / Text reconstruction: 0.065078504383564\n",
            "loss in epoch 1/21 iteration 64/67: 1.4030911922454834 / BPR loss: 1.3862993717193604 / Matching loss: 0.00021297711646184325 / Item reconstruction: 0.0076255109161138535 / Text reconstruction: 0.06382988393306732\n",
            "loss in epoch 1/21 iteration 65/67: 1.402546763420105 / BPR loss: 1.386246919631958 / Matching loss: 0.0002061588311335072 / Item reconstruction: 0.007122690789401531 / Text reconstruction: 0.06266187131404877\n",
            "loss in epoch 1/21 iteration 66/67: 1.402171015739441 / BPR loss: 1.3863341808319092 / Matching loss: 0.00018877090769819915 / Item reconstruction: 0.0065934364683926105 / Text reconstruction: 0.061756327748298645\n",
            "loss in epoch 1/21 iteration 67/67: 1.4017857313156128 / BPR loss: 1.3862786293029785 / Matching loss: 0.0001855543232522905 / Item reconstruction: 0.006330878008157015 / Text reconstruction: 0.06078030914068222\n",
            "  5% 1/20 [01:57<37:12, 117.49s/it]loss in epoch 2/21 iteration 0/67: 1.4014763832092285 / BPR loss: 1.3862848281860352 / Matching loss: 0.0002132899680873379 / Item reconstruction: 0.006562704220414162 / Text reconstruction: 0.05848485976457596\n",
            "loss in epoch 2/21 iteration 1/67: 1.4013030529022217 / BPR loss: 1.386121392250061 / Matching loss: 0.00020831654546782374 / Item reconstruction: 0.0069867996498942375 / Text reconstruction: 0.057399824261665344\n",
            "loss in epoch 2/21 iteration 2/67: 1.40096116065979 / BPR loss: 1.3859184980392456 / Matching loss: 0.00020367848628666252 / Item reconstruction: 0.007149314042180777 / Text reconstruction: 0.05632176995277405\n",
            "loss in epoch 2/21 iteration 3/67: 1.4006679058074951 / BPR loss: 1.3859076499938965 / Matching loss: 0.00019485906523186713 / Item reconstruction: 0.00702583696693182 / Text reconstruction: 0.05526250973343849\n",
            "loss in epoch 2/21 iteration 4/67: 1.400306224822998 / BPR loss: 1.3858494758605957 / Matching loss: 0.00018183240899816155 / Item reconstruction: 0.006855615880340338 / Text reconstruction: 0.05423565208911896\n",
            "loss in epoch 2/21 iteration 5/67: 1.4000442028045654 / BPR loss: 1.3858795166015625 / Matching loss: 0.00018551378161646426 / Item reconstruction: 0.006598861888051033 / Text reconstruction: 0.05339876934885979\n",
            "loss in epoch 2/21 iteration 6/67: 1.3997178077697754 / BPR loss: 1.385831356048584 / Matching loss: 0.00018065520271193236 / Item reconstruction: 0.00641624303534627 / Text reconstruction: 0.05248825252056122\n",
            "loss in epoch 2/21 iteration 7/67: 1.3992897272109985 / BPR loss: 1.38584566116333 / Matching loss: 0.00017715264402795583 / Item reconstruction: 0.005941004492342472 / Text reconstruction: 0.051482610404491425\n",
            "loss in epoch 2/21 iteration 8/67: 1.398992896080017 / BPR loss: 1.385842204093933 / Matching loss: 0.0001718195853754878 / Item reconstruction: 0.005727084819227457 / Text reconstruction: 0.050577059388160706\n",
            "loss in epoch 2/21 iteration 9/67: 1.3986157178878784 / BPR loss: 1.3857026100158691 / Matching loss: 0.00016667894669808447 / Item reconstruction: 0.005617109127342701 / Text reconstruction: 0.049689263105392456\n",
            "loss in epoch 2/21 iteration 10/67: 1.3984565734863281 / BPR loss: 1.3858120441436768 / Matching loss: 0.00016395360580645502 / Item reconstruction: 0.0054503148421645164 / Text reconstruction: 0.048777662217617035\n",
            "loss in epoch 2/21 iteration 11/67: 1.3982142210006714 / BPR loss: 1.3858561515808105 / Matching loss: 0.00016488305118400604 / Item reconstruction: 0.005245979875326157 / Text reconstruction: 0.047851018607616425\n",
            "loss in epoch 2/21 iteration 12/67: 1.3978767395019531 / BPR loss: 1.3857958316802979 / Matching loss: 0.00016528295236639678 / Item reconstruction: 0.005010237451642752 / Text reconstruction: 0.04705308377742767\n",
            "loss in epoch 2/21 iteration 13/67: 1.3975094556808472 / BPR loss: 1.3856563568115234 / Matching loss: 0.0001642395363887772 / Item reconstruction: 0.004871320445090532 / Text reconstruction: 0.046265795826911926\n",
            "loss in epoch 2/21 iteration 14/67: 1.3974326848983765 / BPR loss: 1.3858070373535156 / Matching loss: 0.00016181112732738256 / Item reconstruction: 0.004681849852204323 / Text reconstruction: 0.045614950358867645\n",
            "loss in epoch 2/21 iteration 15/67: 1.3972351551055908 / BPR loss: 1.3858028650283813 / Matching loss: 0.0001554122136440128 / Item reconstruction: 0.004549821838736534 / Text reconstruction: 0.045009955763816833\n",
            "loss in epoch 2/21 iteration 16/67: 1.3968690633773804 / BPR loss: 1.3856617212295532 / Matching loss: 0.0001522117672720924 / Item reconstruction: 0.004401334561407566 / Text reconstruction: 0.0442718081176281\n",
            "loss in epoch 2/21 iteration 17/67: 1.3967925310134888 / BPR loss: 1.385758876800537 / Matching loss: 0.0001504949468653649 / Item reconstruction: 0.004357989877462387 / Text reconstruction: 0.0435207337141037\n",
            "loss in epoch 2/21 iteration 18/67: 1.3970168828964233 / BPR loss: 1.386183500289917 / Matching loss: 0.0001608394959475845 / Item reconstruction: 0.004073976539075375 / Text reconstruction: 0.04317820444703102\n",
            "loss in epoch 2/21 iteration 19/67: 1.3968966007232666 / BPR loss: 1.3862652778625488 / Matching loss: 0.00015858646656852216 / Item reconstruction: 0.003809181973338127 / Text reconstruction: 0.04284100979566574\n",
            "loss in epoch 2/21 iteration 20/67: 1.3966354131698608 / BPR loss: 1.3862783908843994 / Matching loss: 0.0001462147629354149 / Item reconstruction: 0.003519698977470398 / Text reconstruction: 0.04225422441959381\n",
            "loss in epoch 2/21 iteration 21/67: 1.3964484930038452 / BPR loss: 1.386218547821045 / Matching loss: 0.0001539318764116615 / Item reconstruction: 0.003517530160024762 / Text reconstruction: 0.041586004197597504\n",
            "loss in epoch 2/21 iteration 22/67: 1.396198034286499 / BPR loss: 1.3859916925430298 / Matching loss: 0.00015569280367344618 / Item reconstruction: 0.003855121321976185 / Text reconstruction: 0.04061523452401161\n",
            "loss in epoch 2/21 iteration 23/67: 1.3960182666778564 / BPR loss: 1.3860063552856445 / Matching loss: 0.000147236991324462 / Item reconstruction: 0.0037079944740980864 / Text reconstruction: 0.04005379229784012\n",
            "loss in epoch 2/21 iteration 24/67: 1.3957456350326538 / BPR loss: 1.3859608173370361 / Matching loss: 0.00014483470295090228 / Item reconstruction: 0.0034937718883156776 / Text reconstruction: 0.03946530073881149\n",
            "loss in epoch 2/21 iteration 25/67: 1.3957059383392334 / BPR loss: 1.3860461711883545 / Matching loss: 0.0001435832673450932 / Item reconstruction: 0.0034739659167826176 / Text reconstruction: 0.03889608383178711\n",
            "loss in epoch 2/21 iteration 26/67: 1.3955029249191284 / BPR loss: 1.3860156536102295 / Matching loss: 0.00014267013466451317 / Item reconstruction: 0.003313840366899967 / Text reconstruction: 0.03843856602907181\n",
            "loss in epoch 2/21 iteration 27/67: 1.3953676223754883 / BPR loss: 1.38600492477417 / Matching loss: 0.00014675692364107817 / Item reconstruction: 0.0032442472875118256 / Text reconstruction: 0.037969402968883514\n",
            "loss in epoch 2/21 iteration 28/67: 1.3952295780181885 / BPR loss: 1.3860549926757812 / Matching loss: 0.0001392795384163037 / Item reconstruction: 0.0030755591578781605 / Text reconstruction: 0.037487804889678955\n",
            "loss in epoch 2/21 iteration 29/67: 1.3950183391571045 / BPR loss: 1.3859679698944092 / Matching loss: 0.00013463773939292878 / Item reconstruction: 0.003022096585482359 / Text reconstruction: 0.03702341765165329\n",
            "loss in epoch 2/21 iteration 30/67: 1.394883155822754 / BPR loss: 1.3859801292419434 / Matching loss: 0.00013294146629050374 / Item reconstruction: 0.0029016011394560337 / Text reconstruction: 0.0365963950753212\n",
            "loss in epoch 2/21 iteration 31/67: 1.3946956396102905 / BPR loss: 1.386007308959961 / Matching loss: 0.0001276296388823539 / Item reconstruction: 0.0026903627440333366 / Text reconstruction: 0.036077674478292465\n",
            "loss in epoch 2/21 iteration 32/67: 1.3946329355239868 / BPR loss: 1.386068344116211 / Matching loss: 0.00012582741328515112 / Item reconstruction: 0.0026326654478907585 / Text reconstruction: 0.03561174124479294\n",
            "loss in epoch 2/21 iteration 33/67: 1.3947054147720337 / BPR loss: 1.3859730958938599 / Matching loss: 0.00013626545842271298 / Item reconstruction: 0.0030964300967752934 / Text reconstruction: 0.035239387303590775\n",
            "loss in epoch 2/21 iteration 34/67: 1.3948085308074951 / BPR loss: 1.3862223625183105 / Matching loss: 0.0001394551363773644 / Item reconstruction: 0.0029722810722887516 / Text reconstruction: 0.03480277210474014\n",
            "loss in epoch 2/21 iteration 35/67: 1.3947908878326416 / BPR loss: 1.3862351179122925 / Matching loss: 0.00013341332669369876 / Item reconstruction: 0.0030556325800716877 / Text reconstruction: 0.034473076462745667\n",
            "loss in epoch 2/21 iteration 36/67: 1.3947418928146362 / BPR loss: 1.3862340450286865 / Matching loss: 0.00014194461982697248 / Item reconstruction: 0.0029555053915828466 / Text reconstruction: 0.03444095700979233\n",
            "loss in epoch 2/21 iteration 37/67: 1.3946244716644287 / BPR loss: 1.3861968517303467 / Matching loss: 0.00014426669804379344 / Item reconstruction: 0.0029204392340034246 / Text reconstruction: 0.034116003662347794\n",
            "loss in epoch 2/21 iteration 38/67: 1.394376516342163 / BPR loss: 1.3861262798309326 / Matching loss: 0.00014043404371477664 / Item reconstruction: 0.0027375961653888226 / Text reconstruction: 0.033705003559589386\n",
            "loss in epoch 2/21 iteration 39/67: 1.3942465782165527 / BPR loss: 1.3861507177352905 / Matching loss: 0.00013121520169079304 / Item reconstruction: 0.00255713053047657 / Text reconstruction: 0.03343048691749573\n",
            "loss in epoch 2/21 iteration 40/67: 1.3942691087722778 / BPR loss: 1.3862791061401367 / Matching loss: 0.0001415743463439867 / Item reconstruction: 0.002576810773462057 / Text reconstruction: 0.03279954940080643\n",
            "loss in epoch 2/21 iteration 41/67: 1.3939461708068848 / BPR loss: 1.3859862089157104 / Matching loss: 0.00013688263425137848 / Item reconstruction: 0.0026572784408926964 / Text reconstruction: 0.03247246891260147\n",
            "loss in epoch 2/21 iteration 42/67: 1.3939204216003418 / BPR loss: 1.385850191116333 / Matching loss: 0.00012026806507492438 / Item reconstruction: 0.0027766521088778973 / Text reconstruction: 0.03280846029520035\n",
            "loss in epoch 2/21 iteration 43/67: 1.3936713933944702 / BPR loss: 1.3857024908065796 / Matching loss: 0.00012060264270985499 / Item reconstruction: 0.002822065958753228 / Text reconstruction: 0.03218575567007065\n",
            "loss in epoch 2/21 iteration 44/67: 1.393824815750122 / BPR loss: 1.3861839771270752 / Matching loss: 0.00013313550152815878 / Item reconstruction: 0.0023381663486361504 / Text reconstruction: 0.031692929565906525\n",
            "loss in epoch 2/21 iteration 45/67: 1.3939356803894043 / BPR loss: 1.386283040046692 / Matching loss: 0.00013350554218050092 / Item reconstruction: 0.0024006369058042765 / Text reconstruction: 0.03159399703145027\n",
            "loss in epoch 2/21 iteration 46/67: 1.3938000202178955 / BPR loss: 1.386165976524353 / Matching loss: 0.00014119615661911666 / Item reconstruction: 0.0026025031693279743 / Text reconstruction: 0.030958063900470734\n",
            "loss in epoch 2/21 iteration 47/67: 1.3938980102539062 / BPR loss: 1.3862724304199219 / Matching loss: 0.00013663309800904244 / Item reconstruction: 0.0026854462921619415 / Text reconstruction: 0.030730880796909332\n",
            "loss in epoch 2/21 iteration 48/67: 1.393716812133789 / BPR loss: 1.3862632513046265 / Matching loss: 0.00012743810657411814 / Item reconstruction: 0.002384594641625881 / Text reconstruction: 0.030668791383504868\n",
            "loss in epoch 2/21 iteration 49/67: 1.3934693336486816 / BPR loss: 1.3861075639724731 / Matching loss: 0.00013518950436264277 / Item reconstruction: 0.002311874646693468 / Text reconstruction: 0.030353356152772903\n",
            "loss in epoch 2/21 iteration 50/67: 1.3933825492858887 / BPR loss: 1.3861223459243774 / Matching loss: 0.0001336686545982957 / Item reconstruction: 0.0023045651614665985 / Text reconstruction: 0.02987135387957096\n",
            "loss in epoch 2/21 iteration 51/67: 1.3934881687164307 / BPR loss: 1.3862113952636719 / Matching loss: 0.00012326808064244688 / Item reconstruction: 0.002358071506023407 / Text reconstruction: 0.029872749000787735\n",
            "loss in epoch 2/21 iteration 52/67: 1.3935517072677612 / BPR loss: 1.386338472366333 / Matching loss: 0.00012853888620156795 / Item reconstruction: 0.002400972181931138 / Text reconstruction: 0.02942172810435295\n",
            "loss in epoch 2/21 iteration 53/67: 1.3934569358825684 / BPR loss: 1.3862749338150024 / Matching loss: 0.00012947552022524178 / Item reconstruction: 0.0022500334307551384 / Text reconstruction: 0.029637707397341728\n",
            "loss in epoch 2/21 iteration 54/67: 1.393445372581482 / BPR loss: 1.38634192943573 / Matching loss: 0.0001288828789256513 / Item reconstruction: 0.0022351909428834915 / Text reconstruction: 0.029284745454788208\n",
            "loss in epoch 2/21 iteration 55/67: 1.3934383392333984 / BPR loss: 1.3863561153411865 / Matching loss: 0.0001255827082786709 / Item reconstruction: 0.0022566234692931175 / Text reconstruction: 0.029142050072550774\n",
            "loss in epoch 2/21 iteration 56/67: 1.393229603767395 / BPR loss: 1.3862860202789307 / Matching loss: 0.00012378214159980416 / Item reconstruction: 0.002165415557101369 / Text reconstruction: 0.028685877099633217\n",
            "loss in epoch 2/21 iteration 57/67: 1.3932989835739136 / BPR loss: 1.3863558769226074 / Matching loss: 0.00012039241846650839 / Item reconstruction: 0.002132364548742771 / Text reconstruction: 0.02878272905945778\n",
            "loss in epoch 2/21 iteration 58/67: 1.3931692838668823 / BPR loss: 1.386305570602417 / Matching loss: 0.00011590436042752117 / Item reconstruction: 0.0020654802210628986 / Text reconstruction: 0.028575856238603592\n",
            "loss in epoch 2/21 iteration 59/67: 1.3932299613952637 / BPR loss: 1.386379599571228 / Matching loss: 0.00011867814464494586 / Item reconstruction: 0.0022094445303082466 / Text reconstruction: 0.02813456580042839\n",
            "loss in epoch 2/21 iteration 60/67: 1.3930920362472534 / BPR loss: 1.3862950801849365 / Matching loss: 0.00011234702833462507 / Item reconstruction: 0.0021152617409825325 / Text reconstruction: 0.02813507243990898\n",
            "loss in epoch 2/21 iteration 61/67: 1.3929150104522705 / BPR loss: 1.3861865997314453 / Matching loss: 0.00011034237832063809 / Item reconstruction: 0.0020582680590450764 / Text reconstruction: 0.027944564819335938\n",
            "loss in epoch 2/21 iteration 62/67: 1.3928672075271606 / BPR loss: 1.3861351013183594 / Matching loss: 0.00011355969763826579 / Item reconstruction: 0.002157308394089341 / Text reconstruction: 0.02769925817847252\n",
            "loss in epoch 2/21 iteration 63/67: 1.3928405046463013 / BPR loss: 1.386225938796997 / Matching loss: 0.0001205402659252286 / Item reconstruction: 0.0021642812062054873 / Text reconstruction: 0.02705960161983967\n",
            "loss in epoch 2/21 iteration 64/67: 1.3927676677703857 / BPR loss: 1.3861973285675049 / Matching loss: 0.00011478632222861052 / Item reconstruction: 0.0021200021728873253 / Text reconstruction: 0.026977533474564552\n",
            "loss in epoch 2/21 iteration 65/67: 1.3928014039993286 / BPR loss: 1.3862370252609253 / Matching loss: 0.00011076610826421529 / Item reconstruction: 0.0021024495363235474 / Text reconstruction: 0.027012497186660767\n",
            "loss in epoch 2/21 iteration 66/67: 1.3928073644638062 / BPR loss: 1.3863186836242676 / Matching loss: 0.00010319077409803867 / Item reconstruction: 0.001841279910877347 / Text reconstruction: 0.02732418291270733\n",
            "loss in epoch 2/21 iteration 67/67: 1.3926947116851807 / BPR loss: 1.3862593173980713 / Matching loss: 0.00010198898962698877 / Item reconstruction: 0.001729909097775817 / Text reconstruction: 0.027341902256011963\n",
            " 10% 2/20 [03:55<35:17, 117.65s/it]loss in epoch 3/21 iteration 0/67: 1.3926728963851929 / BPR loss: 1.3862076997756958 / Matching loss: 0.00012406206224113703 / Item reconstruction: 0.0022703325375914574 / Text reconstruction: 0.026030156761407852\n",
            "loss in epoch 3/21 iteration 1/67: 1.3925451040267944 / BPR loss: 1.3859467506408691 / Matching loss: 0.00011861936945933849 / Item reconstruction: 0.002511576283723116 / Text reconstruction: 0.02611968293786049\n",
            "loss in epoch 3/21 iteration 2/67: 1.3923728466033936 / BPR loss: 1.3857367038726807 / Matching loss: 0.000111745874164626 / Item reconstruction: 0.002643840853124857 / Text reconstruction: 0.026012519374489784\n",
            "loss in epoch 3/21 iteration 3/67: 1.3922390937805176 / BPR loss: 1.3855514526367188 / Matching loss: 0.00010693640797398984 / Item reconstruction: 0.0027064925525337458 / Text reconstruction: 0.02613743208348751\n",
            "loss in epoch 3/21 iteration 4/67: 1.3922110795974731 / BPR loss: 1.385584831237793 / Matching loss: 9.949413652066141e-05 / Item reconstruction: 0.002664425177499652 / Text reconstruction: 0.025972437113523483\n",
            "loss in epoch 3/21 iteration 5/67: 1.392126202583313 / BPR loss: 1.385583519935608 / Matching loss: 9.997087909141555e-05 / Item reconstruction: 0.0025492284912616014 / Text reconstruction: 0.025840189307928085\n",
            "loss in epoch 3/21 iteration 6/67: 1.3921282291412354 / BPR loss: 1.3856761455535889 / Matching loss: 9.686979319667444e-05 / Item reconstruction: 0.0024393803905695677 / Text reconstruction: 0.02567705139517784\n",
            "loss in epoch 3/21 iteration 7/67: 1.3918583393096924 / BPR loss: 1.385498285293579 / Matching loss: 9.812651842366904e-05 / Item reconstruction: 0.0023632741067558527 / Text reconstruction: 0.02540162205696106\n",
            "loss in epoch 3/21 iteration 8/67: 1.3917957544326782 / BPR loss: 1.385434865951538 / Matching loss: 0.00010190862667514011 / Item reconstruction: 0.002404511673375964 / Text reconstruction: 0.02528369054198265\n",
            "loss in epoch 3/21 iteration 9/67: 1.391797423362732 / BPR loss: 1.385613203048706 / Matching loss: 9.648315608501434e-05 / Item reconstruction: 0.00211489200592041 / Text reconstruction: 0.02515130676329136\n",
            "loss in epoch 3/21 iteration 10/67: 1.3916656970977783 / BPR loss: 1.3854682445526123 / Matching loss: 9.945742203854024e-05 / Item reconstruction: 0.0022132564336061478 / Text reconstruction: 0.024956949055194855\n",
            "loss in epoch 3/21 iteration 11/67: 1.3915987014770508 / BPR loss: 1.3854475021362305 / Matching loss: 9.80320037342608e-05 / Item reconstruction: 0.002162758493795991 / Text reconstruction: 0.024859145283699036\n",
            "loss in epoch 3/21 iteration 12/67: 1.391606092453003 / BPR loss: 1.385495901107788 / Matching loss: 9.843353473115712e-05 / Item reconstruction: 0.0021523621398955584 / Text reconstruction: 0.02467777207493782\n",
            "loss in epoch 3/21 iteration 13/67: 1.391631841659546 / BPR loss: 1.3854939937591553 / Matching loss: 9.791323827812448e-05 / Item reconstruction: 0.002225418109446764 / Text reconstruction: 0.024636557325720787\n",
            "loss in epoch 3/21 iteration 14/67: 1.3914798498153687 / BPR loss: 1.3853864669799805 / Matching loss: 9.455590770812705e-05 / Item reconstruction: 0.0022119167260825634 / Text reconstruction: 0.024464581161737442\n",
            "loss in epoch 3/21 iteration 15/67: 1.3914932012557983 / BPR loss: 1.3854529857635498 / Matching loss: 8.949633775046095e-05 / Item reconstruction: 0.0020907826256006956 / Text reconstruction: 0.02452697791159153\n",
            "loss in epoch 3/21 iteration 16/67: 1.3914923667907715 / BPR loss: 1.3854469060897827 / Matching loss: 9.048078209161758e-05 / Item reconstruction: 0.002162777353078127 / Text reconstruction: 0.02436790056526661\n",
            "loss in epoch 3/21 iteration 17/67: 1.391543984413147 / BPR loss: 1.3855770826339722 / Matching loss: 8.918644743971527e-05 / Item reconstruction: 0.0020164549350738525 / Text reconstruction: 0.024347428232431412\n",
            "loss in epoch 3/21 iteration 18/67: 1.3922828435897827 / BPR loss: 1.3860595226287842 / Matching loss: 0.0001036266767187044 / Item reconstruction: 0.0024375328794121742 / Text reconstruction: 0.024504613131284714\n",
            "loss in epoch 3/21 iteration 19/67: 1.3926563262939453 / BPR loss: 1.3862788677215576 / Matching loss: 0.00010640828986652195 / Item reconstruction: 0.0027257935144007206 / Text reconstruction: 0.024540239945054054\n",
            "loss in epoch 3/21 iteration 20/67: 1.3925912380218506 / BPR loss: 1.3862628936767578 / Matching loss: 0.0001017806789604947 / Item reconstruction: 0.00268561951816082 / Text reconstruction: 0.02441854402422905\n",
            "loss in epoch 3/21 iteration 21/67: 1.3924896717071533 / BPR loss: 1.3862416744232178 / Matching loss: 0.00010998873767675832 / Item reconstruction: 0.0025886299554258585 / Text reconstruction: 0.02421814762055874\n",
            "loss in epoch 3/21 iteration 22/67: 1.3918390274047852 / BPR loss: 1.3858146667480469 / Matching loss: 0.00010837163426913321 / Item reconstruction: 0.002401532605290413 / Text reconstruction: 0.02357618138194084\n",
            "loss in epoch 3/21 iteration 23/67: 1.3915905952453613 / BPR loss: 1.3857276439666748 / Matching loss: 0.00010182231926592067 / Item reconstruction: 0.002204346004873514 / Text reconstruction: 0.023294799029827118\n",
            "loss in epoch 3/21 iteration 24/67: 1.3917924165725708 / BPR loss: 1.3859190940856934 / Matching loss: 0.00010432496492285281 / Item reconstruction: 0.0022850725799798965 / Text reconstruction: 0.023132838308811188\n",
            "loss in epoch 3/21 iteration 25/67: 1.391503095626831 / BPR loss: 1.3857100009918213 / Matching loss: 9.826051245909184e-05 / Item reconstruction: 0.002217264147475362 / Text reconstruction: 0.02293081395328045\n",
            "loss in epoch 3/21 iteration 26/67: 1.3915914297103882 / BPR loss: 1.3858782052993774 / Matching loss: 9.062558820005506e-05 / Item reconstruction: 0.002090130001306534 / Text reconstruction: 0.022887447848916054\n",
            "loss in epoch 3/21 iteration 27/67: 1.3916006088256836 / BPR loss: 1.3858983516693115 / Matching loss: 9.096701251110062e-05 / Item reconstruction: 0.0021117350552231073 / Text reconstruction: 0.022777274250984192\n",
            "loss in epoch 3/21 iteration 28/67: 1.391501545906067 / BPR loss: 1.3858652114868164 / Matching loss: 9.22081817407161e-05 / Item reconstruction: 0.002050475450232625 / Text reconstruction: 0.022595038637518883\n",
            "loss in epoch 3/21 iteration 29/67: 1.3914837837219238 / BPR loss: 1.385890007019043 / Matching loss: 9.441228758078068e-05 / Item reconstruction: 0.002024834742769599 / Text reconstruction: 0.022434860467910767\n",
            "loss in epoch 3/21 iteration 30/67: 1.3912874460220337 / BPR loss: 1.3857591152191162 / Matching loss: 9.187145042233169e-05 / Item reconstruction: 0.0019419135060161352 / Text reconstruction: 0.022327186539769173\n",
            "loss in epoch 3/21 iteration 31/67: 1.3912867307662964 / BPR loss: 1.3857874870300293 / Matching loss: 9.372390195494518e-05 / Item reconstruction: 0.001944411196745932 / Text reconstruction: 0.02216693013906479\n",
            "loss in epoch 3/21 iteration 32/67: 1.3912924528121948 / BPR loss: 1.3858507871627808 / Matching loss: 9.618820331525058e-05 / Item reconstruction: 0.0018726622220128775 / Text reconstruction: 0.022045258432626724\n",
            "loss in epoch 3/21 iteration 33/67: 1.3916085958480835 / BPR loss: 1.3857569694519043 / Matching loss: 9.980969480238855e-05 / Item reconstruction: 0.0026059558149427176 / Text reconstruction: 0.022244542837142944\n",
            "loss in epoch 3/21 iteration 34/67: 1.3920248746871948 / BPR loss: 1.3862402439117432 / Matching loss: 9.651864820625633e-05 / Item reconstruction: 0.0026691285893321037 / Text reconstruction: 0.02176738902926445\n",
            "loss in epoch 3/21 iteration 35/67: 1.391823172569275 / BPR loss: 1.3860548734664917 / Matching loss: 9.265987318940461e-05 / Item reconstruction: 0.0026160492561757565 / Text reconstruction: 0.02183808758854866\n",
            "loss in epoch 3/21 iteration 36/67: 1.392094373703003 / BPR loss: 1.3862550258636475 / Matching loss: 0.00011749143595807254 / Item reconstruction: 0.0027270375285297632 / Text reconstruction: 0.02179141342639923\n",
            "loss in epoch 3/21 iteration 37/67: 1.3919774293899536 / BPR loss: 1.3862085342407227 / Matching loss: 0.00011347200779709965 / Item reconstruction: 0.00267261965200305 / Text reconstruction: 0.02159561589360237\n",
            "loss in epoch 3/21 iteration 38/67: 1.391730546951294 / BPR loss: 1.386095404624939 / Matching loss: 0.00010604451381368563 / Item reconstruction: 0.0025227991864085197 / Text reconstruction: 0.021338511258363724\n",
            "loss in epoch 3/21 iteration 39/67: 1.3918486833572388 / BPR loss: 1.3861994743347168 / Matching loss: 0.0001072227896656841 / Item reconstruction: 0.002507018856704235 / Text reconstruction: 0.021442990750074387\n",
            "loss in epoch 3/21 iteration 40/67: 1.3918876647949219 / BPR loss: 1.38630211353302 / Matching loss: 0.0001116874409490265 / Item reconstruction: 0.002479270100593567 / Text reconstruction: 0.021171271800994873\n",
            "loss in epoch 3/21 iteration 41/67: 1.3916088342666626 / BPR loss: 1.3859434127807617 / Matching loss: 0.00010005517106037587 / Item reconstruction: 0.002542024478316307 / Text reconstruction: 0.021472107619047165\n",
            "loss in epoch 3/21 iteration 42/67: 1.3912278413772583 / BPR loss: 1.3855072259902954 / Matching loss: 8.570983482059091e-05 / Item reconstruction: 0.002353846561163664 / Text reconstruction: 0.022289620712399483\n",
            "loss in epoch 3/21 iteration 43/67: 1.3911008834838867 / BPR loss: 1.3854262828826904 / Matching loss: 8.98855651030317e-05 / Item reconstruction: 0.0023350920528173447 / Text reconstruction: 0.022086191922426224\n",
            "loss in epoch 3/21 iteration 44/67: 1.391650915145874 / BPR loss: 1.3862348794937134 / Matching loss: 0.00010639762331265956 / Item reconstruction: 0.0022440243046730757 / Text reconstruction: 0.020937927067279816\n",
            "loss in epoch 3/21 iteration 45/67: 1.3917537927627563 / BPR loss: 1.3863000869750977 / Matching loss: 0.00010858054156415164 / Item reconstruction: 0.0023341826163232327 / Text reconstruction: 0.020890286192297935\n",
            "loss in epoch 3/21 iteration 46/67: 1.391579508781433 / BPR loss: 1.386087417602539 / Matching loss: 0.00011857080971822143 / Item reconstruction: 0.0025625075213611126 / Text reconstruction: 0.020461052656173706\n",
            "loss in epoch 3/21 iteration 47/67: 1.391616940498352 / BPR loss: 1.3861576318740845 / Matching loss: 0.00010936948820017278 / Item reconstruction: 0.0025295084342360497 / Text reconstruction: 0.020425736904144287\n",
            "loss in epoch 3/21 iteration 48/67: 1.3915022611618042 / BPR loss: 1.3861099481582642 / Matching loss: 0.0001012074135360308 / Item reconstruction: 0.0023447617422789335 / Text reconstruction: 0.02059362083673477\n",
            "loss in epoch 3/21 iteration 49/67: 1.391404628753662 / BPR loss: 1.3860524892807007 / Matching loss: 0.00010290019417880103 / Item reconstruction: 0.0022715998347848654 / Text reconstruction: 0.020567074418067932\n",
            "loss in epoch 3/21 iteration 50/67: 1.391367793083191 / BPR loss: 1.3860461711883545 / Matching loss: 0.00010215900692855939 / Item reconstruction: 0.0023361127823591232 / Text reconstruction: 0.020257476717233658\n",
            "loss in epoch 3/21 iteration 51/67: 1.3915534019470215 / BPR loss: 1.3862663507461548 / Matching loss: 0.00010549323633313179 / Item reconstruction: 0.0022195824421942234 / Text reconstruction: 0.020358409732580185\n",
            "loss in epoch 3/21 iteration 52/67: 1.3915705680847168 / BPR loss: 1.3862721920013428 / Matching loss: 0.00011608547356445342 / Item reconstruction: 0.0023423717357218266 / Text reconstruction: 0.02005508355796337\n",
            "loss in epoch 3/21 iteration 53/67: 1.3914813995361328 / BPR loss: 1.3862128257751465 / Matching loss: 0.00011036533396691084 / Item reconstruction: 0.002199386479333043 / Text reconstruction: 0.02029215730726719\n",
            "loss in epoch 3/21 iteration 54/67: 1.3915027379989624 / BPR loss: 1.3862416744232178 / Matching loss: 0.00010725202446337789 / Item reconstruction: 0.0021941112354397774 / Text reconstruction: 0.02028343454003334\n",
            "loss in epoch 3/21 iteration 55/67: 1.3915700912475586 / BPR loss: 1.386333703994751 / Matching loss: 0.0001001689670374617 / Item reconstruction: 0.0021613342687487602 / Text reconstruction: 0.020278126001358032\n",
            "loss in epoch 3/21 iteration 56/67: 1.391456127166748 / BPR loss: 1.3862855434417725 / Matching loss: 0.00010075159661937505 / Item reconstruction: 0.0021345859859138727 / Text reconstruction: 0.02001260593533516\n",
            "loss in epoch 3/21 iteration 57/67: 1.3914637565612793 / BPR loss: 1.3863376379013062 / Matching loss: 9.471256635151803e-05 / Item reconstruction: 0.0020188891794532537 / Text reconstruction: 0.020109200850129128\n",
            "loss in epoch 3/21 iteration 58/67: 1.3914326429367065 / BPR loss: 1.386309266090393 / Matching loss: 9.597774624126032e-05 / Item reconstruction: 0.00202025193721056 / Text reconstruction: 0.020086202770471573\n",
            "loss in epoch 3/21 iteration 59/67: 1.391350269317627 / BPR loss: 1.3862228393554688 / Matching loss: 9.893843525787815e-05 / Item reconstruction: 0.0021663429215550423 / Text reconstruction: 0.019726809114217758\n",
            "loss in epoch 3/21 iteration 60/67: 1.391456961631775 / BPR loss: 1.3863580226898193 / Matching loss: 9.362841956317425e-05 / Item reconstruction: 0.0020910026505589485 / Text reconstruction: 0.019799279049038887\n",
            "loss in epoch 3/21 iteration 61/67: 1.3913310766220093 / BPR loss: 1.3862636089324951 / Matching loss: 9.552663686918095e-05 / Item reconstruction: 0.0020537711679935455 / Text reconstruction: 0.01972554624080658\n",
            "loss in epoch 3/21 iteration 62/67: 1.3913241624832153 / BPR loss: 1.3862569332122803 / Matching loss: 9.696125925984234e-05 / Item reconstruction: 0.0020826528780162334 / Text reconstruction: 0.01964534819126129\n",
            "loss in epoch 3/21 iteration 63/67: 1.391395092010498 / BPR loss: 1.3863343000411987 / Matching loss: 0.00010545295663177967 / Item reconstruction: 0.002262543188408017 / Text reconstruction: 0.019120067358016968\n",
            "loss in epoch 3/21 iteration 64/67: 1.3912882804870605 / BPR loss: 1.3862943649291992 / Matching loss: 0.00010022746573667973 / Item reconstruction: 0.0021301377564668655 / Text reconstruction: 0.019142931327223778\n",
            "loss in epoch 3/21 iteration 65/67: 1.391306757926941 / BPR loss: 1.386338233947754 / Matching loss: 9.766635048436001e-05 / Item reconstruction: 0.0020625698380172253 / Text reconstruction: 0.019197924062609673\n",
            "loss in epoch 3/21 iteration 66/67: 1.3912413120269775 / BPR loss: 1.3863357305526733 / Matching loss: 8.717066521057859e-05 / Item reconstruction: 0.0018047306220978498 / Text reconstruction: 0.019580163061618805\n",
            "loss in epoch 3/21 iteration 67/67: 1.3911902904510498 / BPR loss: 1.3863193988800049 / Matching loss: 8.402022649534047e-05 / Item reconstruction: 0.001693336060270667 / Text reconstruction: 0.019701369106769562\n",
            " 15% 3/20 [05:49<32:56, 116.26s/it]loss in epoch 4/21 iteration 0/67: 1.3911383152008057 / BPR loss: 1.3861088752746582 / Matching loss: 0.00010646280134096742 / Item reconstruction: 0.0023460101801902056 / Text reconstruction: 0.018750067800283432\n",
            "loss in epoch 4/21 iteration 1/67: 1.391025185585022 / BPR loss: 1.3858506679534912 / Matching loss: 9.396787208970636e-05 / Item reconstruction: 0.0024590352550148964 / Text reconstruction: 0.01925499737262726\n",
            "loss in epoch 4/21 iteration 2/67: 1.3907885551452637 / BPR loss: 1.385498285293579 / Matching loss: 8.721167250769213e-05 / Item reconstruction: 0.00262793293222785 / Text reconstruction: 0.01944529078900814\n",
            "loss in epoch 4/21 iteration 3/67: 1.3904755115509033 / BPR loss: 1.3851988315582275 / Matching loss: 8.22776128188707e-05 / Item reconstruction: 0.0025235998909920454 / Text reconstruction: 0.019662922248244286\n",
            "loss in epoch 4/21 iteration 4/67: 1.3905445337295532 / BPR loss: 1.38531494140625 / Matching loss: 8.296852320199832e-05 / Item reconstruction: 0.002461931901052594 / Text reconstruction: 0.01957833766937256\n",
            "loss in epoch 4/21 iteration 5/67: 1.3906768560409546 / BPR loss: 1.3854548931121826 / Matching loss: 8.730431727599353e-05 / Item reconstruction: 0.002475390676409006 / Text reconstruction: 0.019484788179397583\n",
            "loss in epoch 4/21 iteration 6/67: 1.390396237373352 / BPR loss: 1.3853225708007812 / Matching loss: 8.379123028134927e-05 / Item reconstruction: 0.0022711954079568386 / Text reconstruction: 0.01927134022116661\n",
            "loss in epoch 4/21 iteration 7/67: 1.390280842781067 / BPR loss: 1.3852500915527344 / Matching loss: 8.410886221099645e-05 / Item reconstruction: 0.002261021640151739 / Text reconstruction: 0.01908082701265812\n",
            "loss in epoch 4/21 iteration 8/67: 1.3900398015975952 / BPR loss: 1.3850964307785034 / Matching loss: 8.052942575886846e-05 / Item reconstruction: 0.002103334292769432 / Text reconstruction: 0.019055724143981934\n",
            "loss in epoch 4/21 iteration 9/67: 1.3900985717773438 / BPR loss: 1.3852148056030273 / Matching loss: 7.98475302872248e-05 / Item reconstruction: 0.0020292168483138084 / Text reconstruction: 0.018946275115013123\n",
            "loss in epoch 4/21 iteration 10/67: 1.3899734020233154 / BPR loss: 1.385103702545166 / Matching loss: 7.79566471464932e-05 / Item reconstruction: 0.002035774989053607 / Text reconstruction: 0.01886921375989914\n",
            "loss in epoch 4/21 iteration 11/67: 1.3900576829910278 / BPR loss: 1.3852251768112183 / Matching loss: 8.129693742375821e-05 / Item reconstruction: 0.001958518521860242 / Text reconstruction: 0.01885942742228508\n",
            "loss in epoch 4/21 iteration 12/67: 1.3900878429412842 / BPR loss: 1.3852312564849854 / Matching loss: 8.215771958930418e-05 / Item reconstruction: 0.002087193075567484 / Text reconstruction: 0.018654633313417435\n",
            "loss in epoch 4/21 iteration 13/67: 1.3900315761566162 / BPR loss: 1.3852274417877197 / Matching loss: 8.245450590038672e-05 / Item reconstruction: 0.0019860556349158287 / Text reconstruction: 0.01864289864897728\n",
            "loss in epoch 4/21 iteration 14/67: 1.390076756477356 / BPR loss: 1.3852565288543701 / Matching loss: 7.898268813733011e-05 / Item reconstruction: 0.002032861113548279 / Text reconstruction: 0.018624208867549896\n",
            "loss in epoch 4/21 iteration 15/67: 1.3899050951004028 / BPR loss: 1.3851473331451416 / Matching loss: 7.49178507248871e-05 / Item reconstruction: 0.0019469794351607561 / Text reconstruction: 0.01854732446372509\n",
            "loss in epoch 4/21 iteration 16/67: 1.3899725675582886 / BPR loss: 1.3852756023406982 / Matching loss: 7.513647869927809e-05 / Item reconstruction: 0.0019038954051211476 / Text reconstruction: 0.0183491762727499\n",
            "loss in epoch 4/21 iteration 17/67: 1.389786958694458 / BPR loss: 1.3851391077041626 / Matching loss: 7.518459460698068e-05 / Item reconstruction: 0.0018746227724477649 / Text reconstruction: 0.01817665621638298\n",
            "loss in epoch 4/21 iteration 18/67: 1.3911060094833374 / BPR loss: 1.3860337734222412 / Matching loss: 9.61053156061098e-05 / Item reconstruction: 0.0025802506133913994 / Text reconstruction: 0.018430320546030998\n",
            "loss in epoch 4/21 iteration 19/67: 1.3915539979934692 / BPR loss: 1.3863203525543213 / Matching loss: 9.720215166453272e-05 / Item reconstruction: 0.002872510813176632 / Text reconstruction: 0.01850147731602192\n",
            "loss in epoch 4/21 iteration 20/67: 1.3913644552230835 / BPR loss: 1.3862066268920898 / Matching loss: 9.143368515651673e-05 / Item reconstruction: 0.002808116376399994 / Text reconstruction: 0.0183117538690567\n",
            "loss in epoch 4/21 iteration 21/67: 1.391178011894226 / BPR loss: 1.3861173391342163 / Matching loss: 9.350907930638641e-05 / Item reconstruction: 0.002716760616749525 / Text reconstruction: 0.018044382333755493\n",
            "loss in epoch 4/21 iteration 22/67: 1.3903892040252686 / BPR loss: 1.3856521844863892 / Matching loss: 8.41801956994459e-05 / Item reconstruction: 0.0023148292675614357 / Text reconstruction: 0.01747734658420086\n",
            "loss in epoch 4/21 iteration 23/67: 1.390295147895813 / BPR loss: 1.3855524063110352 / Matching loss: 8.213462569983676e-05 / Item reconstruction: 0.002347883302718401 / Text reconstruction: 0.01743341237306595\n",
            "loss in epoch 4/21 iteration 24/67: 1.3902915716171265 / BPR loss: 1.3855714797973633 / Matching loss: 8.374501339858398e-05 / Item reconstruction: 0.0023378650657832623 / Text reconstruction: 0.017336629331111908\n",
            "loss in epoch 4/21 iteration 25/67: 1.390279769897461 / BPR loss: 1.385614275932312 / Matching loss: 8.355255704373121e-05 / Item reconstruction: 0.002265951130539179 / Text reconstruction: 0.01724475994706154\n",
            "loss in epoch 4/21 iteration 26/67: 1.3900874853134155 / BPR loss: 1.3855485916137695 / Matching loss: 7.300930883502588e-05 / Item reconstruction: 0.0020676632411777973 / Text reconstruction: 0.017160730436444283\n",
            "loss in epoch 4/21 iteration 27/67: 1.390161156654358 / BPR loss: 1.3855985403060913 / Matching loss: 7.874579750932753e-05 / Item reconstruction: 0.0021267326083034277 / Text reconstruction: 0.01710229367017746\n",
            "loss in epoch 4/21 iteration 28/67: 1.3900295495986938 / BPR loss: 1.3855470418930054 / Matching loss: 7.794771227054298e-05 / Item reconstruction: 0.0020180935971438885 / Text reconstruction: 0.01697753369808197\n",
            "loss in epoch 4/21 iteration 29/67: 1.3900517225265503 / BPR loss: 1.3855628967285156 / Matching loss: 7.72168641560711e-05 / Item reconstruction: 0.002031841780990362 / Text reconstruction: 0.016978543251752853\n",
            "loss in epoch 4/21 iteration 30/67: 1.3899345397949219 / BPR loss: 1.3854718208312988 / Matching loss: 7.684034062549472e-05 / Item reconstruction: 0.0019520079949870706 / Text reconstruction: 0.01704913191497326\n",
            "loss in epoch 4/21 iteration 31/67: 1.3898320198059082 / BPR loss: 1.3854122161865234 / Matching loss: 7.832809933461249e-05 / Item reconstruction: 0.001889899605885148 / Text reconstruction: 0.016982577741146088\n",
            "loss in epoch 4/21 iteration 32/67: 1.3901053667068481 / BPR loss: 1.3857146501541138 / Matching loss: 7.573898619739339e-05 / Item reconstruction: 0.0019009767565876245 / Text reconstruction: 0.016822725534439087\n",
            "loss in epoch 4/21 iteration 33/67: 1.390470266342163 / BPR loss: 1.3857436180114746 / Matching loss: 8.639501174911857e-05 / Item reconstruction: 0.0025956216268241405 / Text reconstruction: 0.016712237149477005\n",
            "loss in epoch 4/21 iteration 34/67: 1.390863060951233 / BPR loss: 1.3861594200134277 / Matching loss: 8.667651854921132e-05 / Item reconstruction: 0.0027124816551804543 / Text reconstruction: 0.016303878277540207\n",
            "loss in epoch 4/21 iteration 35/67: 1.3906736373901367 / BPR loss: 1.385958194732666 / Matching loss: 8.032140613067895e-05 / Item reconstruction: 0.0027075577527284622 / Text reconstruction: 0.01640685833990574\n",
            "loss in epoch 4/21 iteration 36/67: 1.3910433053970337 / BPR loss: 1.3862521648406982 / Matching loss: 0.0001052383886417374 / Item reconstruction: 0.002791215665638447 / Text reconstruction: 0.01645166613161564\n",
            "loss in epoch 4/21 iteration 37/67: 1.3909391164779663 / BPR loss: 1.3862221240997314 / Matching loss: 0.00010294125968357548 / Item reconstruction: 0.0027157417498528957 / Text reconstruction: 0.016280315816402435\n",
            "loss in epoch 4/21 iteration 38/67: 1.3905518054962158 / BPR loss: 1.3859763145446777 / Matching loss: 9.622142533771694e-05 / Item reconstruction: 0.002558102598413825 / Text reconstruction: 0.016001589596271515\n",
            "loss in epoch 4/21 iteration 39/67: 1.3907736539840698 / BPR loss: 1.3861937522888184 / Matching loss: 9.453759412281215e-05 / Item reconstruction: 0.0025084437802433968 / Text reconstruction: 0.016156133264303207\n",
            "loss in epoch 4/21 iteration 40/67: 1.3907309770584106 / BPR loss: 1.3862438201904297 / Matching loss: 0.00010061086504720151 / Item reconstruction: 0.0024462402798235416 / Text reconstruction: 0.015817098319530487\n",
            "loss in epoch 4/21 iteration 41/67: 1.3904186487197876 / BPR loss: 1.3858684301376343 / Matching loss: 8.957982936408371e-05 / Item reconstruction: 0.00241185468621552 / Text reconstruction: 0.01627371832728386\n",
            "loss in epoch 4/21 iteration 42/67: 1.3899211883544922 / BPR loss: 1.385200023651123 / Matching loss: 7.747826020931825e-05 / Item reconstruction: 0.002384109888225794 / Text reconstruction: 0.017258165404200554\n",
            "loss in epoch 4/21 iteration 43/67: 1.3897130489349365 / BPR loss: 1.3850646018981934 / Matching loss: 7.924765668576583e-05 / Item reconstruction: 0.002325206995010376 / Text reconstruction: 0.017032384872436523\n",
            "loss in epoch 4/21 iteration 44/67: 1.3904199600219727 / BPR loss: 1.3860840797424316 / Matching loss: 0.00010270523489452899 / Item reconstruction: 0.002218392211943865 / Text reconstruction: 0.0156191885471344\n",
            "loss in epoch 4/21 iteration 45/67: 1.3905611038208008 / BPR loss: 1.3862230777740479 / Matching loss: 9.20799866435118e-05 / Item reconstruction: 0.0022444925270974636 / Text reconstruction: 0.0156190674751997\n",
            "loss in epoch 4/21 iteration 46/67: 1.3903714418411255 / BPR loss: 1.3859851360321045 / Matching loss: 0.00010196984658250585 / Item reconstruction: 0.002479738788679242 / Text reconstruction: 0.015222424641251564\n",
            "loss in epoch 4/21 iteration 47/67: 1.3905854225158691 / BPR loss: 1.3861968517303467 / Matching loss: 9.789581235963851e-05 / Item reconstruction: 0.0024909446947276592 / Text reconstruction: 0.015226155519485474\n",
            "loss in epoch 4/21 iteration 48/67: 1.390465497970581 / BPR loss: 1.3861796855926514 / Matching loss: 9.333078196505085e-05 / Item reconstruction: 0.0022495926823467016 / Text reconstruction: 0.015338936820626259\n",
            "loss in epoch 4/21 iteration 49/67: 1.3901641368865967 / BPR loss: 1.3858861923217773 / Matching loss: 8.786114631220698e-05 / Item reconstruction: 0.0022232967894524336 / Text reconstruction: 0.015392336994409561\n",
            "loss in epoch 4/21 iteration 50/67: 1.3902387619018555 / BPR loss: 1.3859591484069824 / Matching loss: 9.115025750361383e-05 / Item reconstruction: 0.002299367683008313 / Text reconstruction: 0.015194110572338104\n",
            "loss in epoch 4/21 iteration 51/67: 1.3905583620071411 / BPR loss: 1.386315107345581 / Matching loss: 9.209432755596936e-05 / Item reconstruction: 0.0022389492951333523 / Text reconstruction: 0.015157805755734444\n",
            "loss in epoch 4/21 iteration 52/67: 1.3903592824935913 / BPR loss: 1.3861415386199951 / Matching loss: 0.00010287533223163337 / Item reconstruction: 0.0022615082561969757 / Text reconstruction: 0.014921081252396107\n",
            "loss in epoch 4/21 iteration 53/67: 1.390377402305603 / BPR loss: 1.386176586151123 / Matching loss: 9.964725177269429e-05 / Item reconstruction: 0.002156236208975315 / Text reconstruction: 0.015115085057914257\n",
            "loss in epoch 4/21 iteration 54/67: 1.3904790878295898 / BPR loss: 1.3862581253051758 / Matching loss: 0.00010253980872221291 / Item reconstruction: 0.00225190632045269 / Text reconstruction: 0.014962753280997276\n",
            "loss in epoch 4/21 iteration 55/67: 1.3906300067901611 / BPR loss: 1.3864312171936035 / Matching loss: 9.673836757428944e-05 / Item reconstruction: 0.002190767554566264 / Text reconstruction: 0.015032852999866009\n",
            "loss in epoch 4/21 iteration 56/67: 1.3904882669448853 / BPR loss: 1.3863152265548706 / Matching loss: 9.176285675494e-05 / Item reconstruction: 0.002214574720710516 / Text reconstruction: 0.014869814738631248\n",
            "loss in epoch 4/21 iteration 57/67: 1.3904080390930176 / BPR loss: 1.3863129615783691 / Matching loss: 8.01065907580778e-05 / Item reconstruction: 0.0020345051307231188 / Text reconstruction: 0.014988882467150688\n",
            "loss in epoch 4/21 iteration 58/67: 1.3902958631515503 / BPR loss: 1.3862102031707764 / Matching loss: 7.735782855888829e-05 / Item reconstruction: 0.002011265140026808 / Text reconstruction: 0.015013223513960838\n",
            "loss in epoch 4/21 iteration 59/67: 1.3903392553329468 / BPR loss: 1.386263370513916 / Matching loss: 8.216987043851987e-05 / Item reconstruction: 0.0020881074015051126 / Text reconstruction: 0.014748616144061089\n",
            "loss in epoch 4/21 iteration 60/67: 1.3902909755706787 / BPR loss: 1.3862212896347046 / Matching loss: 8.487807644996792e-05 / Item reconstruction: 0.002063322812318802 / Text reconstruction: 0.014765653759241104\n",
            "loss in epoch 4/21 iteration 61/67: 1.3903881311416626 / BPR loss: 1.386381983757019 / Matching loss: 8.789553248789161e-05 / Item reconstruction: 0.001997709972783923 / Text reconstruction: 0.014597428031265736\n",
            "loss in epoch 4/21 iteration 62/67: 1.3903733491897583 / BPR loss: 1.3862884044647217 / Matching loss: 9.435747051611543e-05 / Item reconstruction: 0.002135811373591423 / Text reconstruction: 0.01461332943290472\n",
            "loss in epoch 4/21 iteration 63/67: 1.3902815580368042 / BPR loss: 1.3862292766571045 / Matching loss: 9.99177573248744e-05 / Item reconstruction: 0.0022479663603007793 / Text reconstruction: 0.014142057858407497\n",
            "loss in epoch 4/21 iteration 64/67: 1.390264630317688 / BPR loss: 1.3862577676773071 / Matching loss: 9.379005496157333e-05 / Item reconstruction: 0.0021411452908068895 / Text reconstruction: 0.014212353155016899\n",
            "loss in epoch 4/21 iteration 65/67: 1.3901854753494263 / BPR loss: 1.3862131834030151 / Matching loss: 8.641852764412761e-05 / Item reconstruction: 0.0020633796229958534 / Text reconstruction: 0.01427107211202383\n",
            "loss in epoch 4/21 iteration 66/67: 1.3901335000991821 / BPR loss: 1.3862709999084473 / Matching loss: 7.195129001047462e-05 / Item reconstruction: 0.0017590993084013462 / Text reconstruction: 0.014554991386830807\n",
            "loss in epoch 4/21 iteration 67/67: 1.3900879621505737 / BPR loss: 1.3862683773040771 / Matching loss: 6.710857996949926e-05 / Item reconstruction: 0.0016314644599333405 / Text reconstruction: 0.014683428220450878\n",
            " 20% 4/20 [07:49<31:18, 117.42s/it]loss in epoch 5/21 iteration 0/67: 1.3902841806411743 / BPR loss: 1.386265516281128 / Matching loss: 8.866994176059961e-05 / Item reconstruction: 0.0023104252759367228 / Text reconstruction: 0.013873681426048279\n",
            "loss in epoch 5/21 iteration 1/67: 1.3899681568145752 / BPR loss: 1.3857107162475586 / Matching loss: 8.24173039291054e-05 / Item reconstruction: 0.002520389389246702 / Text reconstruction: 0.014574609696865082\n",
            "loss in epoch 5/21 iteration 2/67: 1.3894942998886108 / BPR loss: 1.3850953578948975 / Matching loss: 7.654016371816397e-05 / Item reconstruction: 0.002587703987956047 / Text reconstruction: 0.015142735093832016\n",
            "loss in epoch 5/21 iteration 3/67: 1.389365315437317 / BPR loss: 1.3849825859069824 / Matching loss: 7.589001324959099e-05 / Item reconstruction: 0.002546187024563551 / Text reconstruction: 0.015168801881372929\n",
            "loss in epoch 5/21 iteration 4/67: 1.3893314599990845 / BPR loss: 1.3850421905517578 / Matching loss: 7.993853068910539e-05 / Item reconstruction: 0.0024493022356182337 / Text reconstruction: 0.01492305938154459\n",
            "loss in epoch 5/21 iteration 5/67: 1.3892381191253662 / BPR loss: 1.3850451707839966 / Matching loss: 7.979492511367425e-05 / Item reconstruction: 0.0023310377728194 / Text reconstruction: 0.014738640747964382\n",
            "loss in epoch 5/21 iteration 6/67: 1.3891079425811768 / BPR loss: 1.3850188255310059 / Matching loss: 7.518194615840912e-05 / Item reconstruction: 0.0021908136550337076 / Text reconstruction: 0.014592431485652924\n",
            "loss in epoch 5/21 iteration 7/67: 1.3890371322631836 / BPR loss: 1.3849947452545166 / Matching loss: 7.119045039871708e-05 / Item reconstruction: 0.0021727774292230606 / Text reconstruction: 0.014424454420804977\n",
            "loss in epoch 5/21 iteration 8/67: 1.388870358467102 / BPR loss: 1.3849377632141113 / Matching loss: 6.410744390450418e-05 / Item reconstruction: 0.0019515427993610501 / Text reconstruction: 0.014463504776358604\n",
            "loss in epoch 5/21 iteration 9/67: 1.3889954090118408 / BPR loss: 1.3851146697998047 / Matching loss: 6.64747494738549e-05 / Item reconstruction: 0.0018858787370845675 / Text reconstruction: 0.014356186613440514\n",
            "loss in epoch 5/21 iteration 10/67: 1.3887094259262085 / BPR loss: 1.384778618812561 / Matching loss: 6.979315367061645e-05 / Item reconstruction: 0.0020184891764074564 / Text reconstruction: 0.014259195886552334\n",
            "loss in epoch 5/21 iteration 11/67: 1.3885935544967651 / BPR loss: 1.384718418121338 / Matching loss: 7.000481127761304e-05 / Item reconstruction: 0.0019343248568475246 / Text reconstruction: 0.01419023796916008\n",
            "loss in epoch 5/21 iteration 12/67: 1.3887830972671509 / BPR loss: 1.3849177360534668 / Matching loss: 7.178837404353544e-05 / Item reconstruction: 0.0019667416345328093 / Text reconstruction: 0.014051231555640697\n",
            "loss in epoch 5/21 iteration 13/67: 1.3886638879776 / BPR loss: 1.3848426342010498 / Matching loss: 7.044168887659907e-05 / Item reconstruction: 0.001909807207994163 / Text reconstruction: 0.013979769311845303\n",
            "loss in epoch 5/21 iteration 14/67: 1.3887897729873657 / BPR loss: 1.3849796056747437 / Matching loss: 6.966981163714081e-05 / Item reconstruction: 0.0019068230176344514 / Text reconstruction: 0.013935333117842674\n",
            "loss in epoch 5/21 iteration 15/67: 1.3886494636535645 / BPR loss: 1.3848586082458496 / Matching loss: 6.426207983167842e-05 / Item reconstruction: 0.001920668175444007 / Text reconstruction: 0.013830965384840965\n",
            "loss in epoch 5/21 iteration 16/67: 1.388486623764038 / BPR loss: 1.3847646713256836 / Matching loss: 6.747280713170767e-05 / Item reconstruction: 0.00180536019615829 / Text reconstruction: 0.013759121298789978\n",
            "loss in epoch 5/21 iteration 17/67: 1.3886909484863281 / BPR loss: 1.3849252462387085 / Matching loss: 7.023377838777378e-05 / Item reconstruction: 0.0019009634852409363 / Text reconstruction: 0.01372496411204338\n",
            "loss in epoch 5/21 iteration 18/67: 1.390034556388855 / BPR loss: 1.3857967853546143 / Matching loss: 8.249260281445459e-05 / Item reconstruction: 0.0026841864455491304 / Text reconstruction: 0.01406598649919033\n",
            "loss in epoch 5/21 iteration 19/67: 1.3905941247940063 / BPR loss: 1.3862167596817017 / Matching loss: 8.103107393253595e-05 / Item reconstruction: 0.0029397751204669476 / Text reconstruction: 0.01413202565163374\n",
            "loss in epoch 5/21 iteration 20/67: 1.3904685974121094 / BPR loss: 1.3861980438232422 / Matching loss: 7.807253859937191e-05 / Item reconstruction: 0.0027741496451199055 / Text reconstruction: 0.01402650773525238\n",
            "loss in epoch 5/21 iteration 21/67: 1.3902250528335571 / BPR loss: 1.3860349655151367 / Matching loss: 8.211358363041654e-05 / Item reconstruction: 0.0027754418551921844 / Text reconstruction: 0.013601299375295639\n",
            "loss in epoch 5/21 iteration 22/67: 1.3893963098526 / BPR loss: 1.3854572772979736 / Matching loss: 6.710938760079443e-05 / Item reconstruction: 0.0024733785539865494 / Text reconstruction: 0.01317647099494934\n",
            "loss in epoch 5/21 iteration 23/67: 1.3890562057495117 / BPR loss: 1.385195255279541 / Matching loss: 7.008256216067821e-05 / Item reconstruction: 0.002378438599407673 / Text reconstruction: 0.013007976114749908\n",
            "loss in epoch 5/21 iteration 24/67: 1.3892046213150024 / BPR loss: 1.3853883743286133 / Matching loss: 7.452292629750445e-05 / Item reconstruction: 0.0023119538091123104 / Text reconstruction: 0.012929027900099754\n",
            "loss in epoch 5/21 iteration 25/67: 1.3891595602035522 / BPR loss: 1.3854143619537354 / Matching loss: 7.009627734078094e-05 / Item reconstruction: 0.0021778210066258907 / Text reconstruction: 0.0129313375800848\n",
            "loss in epoch 5/21 iteration 26/67: 1.3890079259872437 / BPR loss: 1.3853466510772705 / Matching loss: 6.473061512224376e-05 / Item reconstruction: 0.0020240319427102804 / Text reconstruction: 0.012923131696879864\n",
            "loss in epoch 5/21 iteration 27/67: 1.3889613151550293 / BPR loss: 1.385271430015564 / Matching loss: 6.726857827743515e-05 / Item reconstruction: 0.002075109165161848 / Text reconstruction: 0.012925044633448124\n",
            "loss in epoch 5/21 iteration 28/67: 1.3888822793960571 / BPR loss: 1.3852627277374268 / Matching loss: 6.688393477816135e-05 / Item reconstruction: 0.0019729502964764833 / Text reconstruction: 0.012831376865506172\n",
            "loss in epoch 5/21 iteration 29/67: 1.388864278793335 / BPR loss: 1.3852949142456055 / Matching loss: 6.17749392404221e-05 / Item reconstruction: 0.001895660301670432 / Text reconstruction: 0.01279880478978157\n",
            "loss in epoch 5/21 iteration 30/67: 1.3888089656829834 / BPR loss: 1.3852410316467285 / Matching loss: 6.123582716099918e-05 / Item reconstruction: 0.001914479653351009 / Text reconstruction: 0.012746917083859444\n",
            "loss in epoch 5/21 iteration 31/67: 1.3889418840408325 / BPR loss: 1.38543701171875 / Matching loss: 6.311072502285242e-05 / Item reconstruction: 0.0018668483244255185 / Text reconstruction: 0.012542210519313812\n",
            "loss in epoch 5/21 iteration 32/67: 1.3888381719589233 / BPR loss: 1.3853883743286133 / Matching loss: 6.696700438624248e-05 / Item reconstruction: 0.0018029704224318266 / Text reconstruction: 0.01240697130560875\n",
            "loss in epoch 5/21 iteration 33/67: 1.389414668083191 / BPR loss: 1.3855206966400146 / Matching loss: 7.95098312664777e-05 / Item reconstruction: 0.002684330102056265 / Text reconstruction: 0.012361183762550354\n",
            "loss in epoch 5/21 iteration 34/67: 1.3899922370910645 / BPR loss: 1.3861091136932373 / Matching loss: 8.023333793971688e-05 / Item reconstruction: 0.002830659970641136 / Text reconstruction: 0.011937538161873817\n",
            "loss in epoch 5/21 iteration 35/67: 1.3898178339004517 / BPR loss: 1.3859694004058838 / Matching loss: 7.426513184327632e-05 / Item reconstruction: 0.0026894412003457546 / Text reconstruction: 0.012147588655352592\n",
            "loss in epoch 5/21 iteration 36/67: 1.3900574445724487 / BPR loss: 1.3861584663391113 / Matching loss: 9.41137841437012e-05 / Item reconstruction: 0.002764699514955282 / Text reconstruction: 0.012112731114029884\n",
            "loss in epoch 5/21 iteration 37/67: 1.3898870944976807 / BPR loss: 1.3860857486724854 / Matching loss: 8.630454976810142e-05 / Item reconstruction: 0.0026426645927131176 / Text reconstruction: 0.011968838050961494\n",
            "loss in epoch 5/21 iteration 38/67: 1.3897684812545776 / BPR loss: 1.3860465288162231 / Matching loss: 8.302113565150648e-05 / Item reconstruction: 0.002580435713753104 / Text reconstruction: 0.011743729934096336\n",
            "loss in epoch 5/21 iteration 39/67: 1.3897299766540527 / BPR loss: 1.3860968351364136 / Matching loss: 8.255953434854746e-05 / Item reconstruction: 0.002416161820292473 / Text reconstruction: 0.011712028644979\n",
            "loss in epoch 5/21 iteration 40/67: 1.3898890018463135 / BPR loss: 1.3862709999084473 / Matching loss: 9.32295442908071e-05 / Item reconstruction: 0.002493911422789097 / Text reconstruction: 0.011389320716261864\n",
            "loss in epoch 5/21 iteration 41/67: 1.3893425464630127 / BPR loss: 1.385646104812622 / Matching loss: 8.404848631471395e-05 / Item reconstruction: 0.0024439184926450253 / Text reconstruction: 0.01195191778242588\n",
            "loss in epoch 5/21 iteration 42/67: 1.3888535499572754 / BPR loss: 1.3850305080413818 / Matching loss: 6.457579002017155e-05 / Item reconstruction: 0.0023346026428043842 / Text reconstruction: 0.012955822050571442\n",
            "loss in epoch 5/21 iteration 43/67: 1.3885927200317383 / BPR loss: 1.3848282098770142 / Matching loss: 6.879081774968654e-05 / Item reconstruction: 0.0023414245806634426 / Text reconstruction: 0.012624680995941162\n",
            "loss in epoch 5/21 iteration 44/67: 1.3895713090896606 / BPR loss: 1.3860909938812256 / Matching loss: 8.589791104895994e-05 / Item reconstruction: 0.0022869138047099113 / Text reconstruction: 0.011254423297941685\n",
            "loss in epoch 5/21 iteration 45/67: 1.3898144960403442 / BPR loss: 1.386354923248291 / Matching loss: 8.185166370822117e-05 / Item reconstruction: 0.0022342123556882143 / Text reconstruction: 0.01130297314375639\n",
            "loss in epoch 5/21 iteration 46/67: 1.3895344734191895 / BPR loss: 1.386037826538086 / Matching loss: 8.914471254684031e-05 / Item reconstruction: 0.002419504802674055 / Text reconstruction: 0.010988954454660416\n",
            "loss in epoch 5/21 iteration 47/67: 1.3896596431732178 / BPR loss: 1.3861154317855835 / Matching loss: 8.564502059016377e-05 / Item reconstruction: 0.002530356403440237 / Text reconstruction: 0.010967250913381577\n",
            "loss in epoch 5/21 iteration 48/67: 1.3896428346633911 / BPR loss: 1.3862497806549072 / Matching loss: 7.720051507931203e-05 / Item reconstruction: 0.0022213938646018505 / Text reconstruction: 0.011025832034647465\n",
            "loss in epoch 5/21 iteration 49/67: 1.389209508895874 / BPR loss: 1.3857744932174683 / Matching loss: 7.751914381515235e-05 / Item reconstruction: 0.002216978231444955 / Text reconstruction: 0.011245102621614933\n",
            "loss in epoch 5/21 iteration 50/67: 1.3893928527832031 / BPR loss: 1.3859105110168457 / Matching loss: 8.066545706242323e-05 / Item reconstruction: 0.002370225265622139 / Text reconstruction: 0.01108274795114994\n",
            "loss in epoch 5/21 iteration 51/67: 1.3895857334136963 / BPR loss: 1.3862295150756836 / Matching loss: 8.137027907650918e-05 / Item reconstruction: 0.002200082875788212 / Text reconstruction: 0.010873401537537575\n",
            "loss in epoch 5/21 iteration 52/67: 1.38965904712677 / BPR loss: 1.3862848281860352 / Matching loss: 8.504200377501547e-05 / Item reconstruction: 0.0022857002913951874 / Text reconstruction: 0.01073168870061636\n",
            "loss in epoch 5/21 iteration 53/67: 1.3895937204360962 / BPR loss: 1.3862558603286743 / Matching loss: 8.292986603919417e-05 / Item reconstruction: 0.002157349605113268 / Text reconstruction: 0.010881032794713974\n",
            "loss in epoch 5/21 iteration 54/67: 1.3896712064743042 / BPR loss: 1.3863329887390137 / Matching loss: 8.723878272576258e-05 / Item reconstruction: 0.002211947925388813 / Text reconstruction: 0.010724814608693123\n",
            "loss in epoch 5/21 iteration 55/67: 1.389652132987976 / BPR loss: 1.3863489627838135 / Matching loss: 8.3545884990599e-05 / Item reconstruction: 0.0021095394622534513 / Text reconstruction: 0.010823963209986687\n",
            "loss in epoch 5/21 iteration 56/67: 1.3895862102508545 / BPR loss: 1.386313557624817 / Matching loss: 7.999902300070971e-05 / Item reconstruction: 0.0021319971419870853 / Text reconstruction: 0.010633622296154499\n",
            "loss in epoch 5/21 iteration 57/67: 1.3895456790924072 / BPR loss: 1.3862836360931396 / Matching loss: 7.064971578074619e-05 / Item reconstruction: 0.002086074324324727 / Text reconstruction: 0.010741079226136208\n",
            "loss in epoch 5/21 iteration 58/67: 1.389430284500122 / BPR loss: 1.386191964149475 / Matching loss: 6.692206079605967e-05 / Item reconstruction: 0.002057076897472143 / Text reconstruction: 0.010714435018599033\n",
            "loss in epoch 5/21 iteration 59/67: 1.3894474506378174 / BPR loss: 1.3862419128417969 / Matching loss: 7.249225018313155e-05 / Item reconstruction: 0.0021003023721277714 / Text reconstruction: 0.010414618998765945\n",
            "loss in epoch 5/21 iteration 60/67: 1.3895572423934937 / BPR loss: 1.3863441944122314 / Matching loss: 7.689535414101556e-05 / Item reconstruction: 0.002083218889310956 / Text reconstruction: 0.010472560301423073\n",
            "loss in epoch 5/21 iteration 61/67: 1.389495849609375 / BPR loss: 1.3863428831100464 / Matching loss: 7.874959555920213e-05 / Item reconstruction: 0.002000006614252925 / Text reconstruction: 0.010370896197855473\n",
            "loss in epoch 5/21 iteration 62/67: 1.3895881175994873 / BPR loss: 1.386331558227539 / Matching loss: 7.926057151053101e-05 / Item reconstruction: 0.002161969430744648 / Text reconstruction: 0.010481532663106918\n",
            "loss in epoch 5/21 iteration 63/67: 1.38956880569458 / BPR loss: 1.3863742351531982 / Matching loss: 8.592888480052352e-05 / Item reconstruction: 0.0022161700762808323 / Text reconstruction: 0.010002972558140755\n",
            "loss in epoch 5/21 iteration 64/67: 1.3893977403640747 / BPR loss: 1.3862630128860474 / Matching loss: 7.758743595331907e-05 / Item reconstruction: 0.002093580551445484 / Text reconstruction: 0.010051684454083443\n",
            "loss in epoch 5/21 iteration 65/67: 1.3895013332366943 / BPR loss: 1.3863526582717896 / Matching loss: 7.679751433897763e-05 / Item reconstruction: 0.0021239956840872765 / Text reconstruction: 0.010049227625131607\n",
            "loss in epoch 5/21 iteration 66/67: 1.3893680572509766 / BPR loss: 1.386379599571228 / Matching loss: 6.293182377703488e-05 / Item reconstruction: 0.001758901751600206 / Text reconstruction: 0.01023070327937603\n",
            "loss in epoch 5/21 iteration 67/67: 1.3892602920532227 / BPR loss: 1.3863279819488525 / Matching loss: 5.7406425185035914e-05 / Item reconstruction: 0.0015810562763363123 / Text reconstruction: 0.01042160764336586\n",
            " 25% 5/20 [09:45<29:14, 117.00s/it]loss in epoch 6/21 iteration 0/67: 1.389339804649353 / BPR loss: 1.386122465133667 / Matching loss: 7.922643271740526e-05 / Item reconstruction: 0.002357237972319126 / Text reconstruction: 0.009797433391213417\n",
            "loss in epoch 6/21 iteration 1/67: 1.38888418674469 / BPR loss: 1.385400652885437 / Matching loss: 7.276714313775301e-05 / Item reconstruction: 0.002528426004573703 / Text reconstruction: 0.01073327474296093\n",
            "loss in epoch 6/21 iteration 2/67: 1.3883566856384277 / BPR loss: 1.384837031364441 / Matching loss: 6.841633876319975e-05 / Item reconstruction: 0.0024993056431412697 / Text reconstruction: 0.011007841676473618\n",
            "loss in epoch 6/21 iteration 3/67: 1.3879594802856445 / BPR loss: 1.3844726085662842 / Matching loss: 6.193050649017096e-05 / Item reconstruction: 0.002352528739720583 / Text reconstruction: 0.011243243701756\n",
            "loss in epoch 6/21 iteration 4/67: 1.387859582901001 / BPR loss: 1.3843852281570435 / Matching loss: 6.800343544455245e-05 / Item reconstruction: 0.0023697889409959316 / Text reconstruction: 0.01110754907131195\n",
            "loss in epoch 6/21 iteration 5/67: 1.3878475427627563 / BPR loss: 1.384512186050415 / Matching loss: 6.928951188456267e-05 / Item reconstruction: 0.002172477077692747 / Text reconstruction: 0.010899440385401249\n",
            "loss in epoch 6/21 iteration 6/67: 1.387786626815796 / BPR loss: 1.3845391273498535 / Matching loss: 6.448056956287473e-05 / Item reconstruction: 0.0020985971204936504 / Text reconstruction: 0.010668769478797913\n",
            "loss in epoch 6/21 iteration 7/67: 1.3876641988754272 / BPR loss: 1.38451087474823 / Matching loss: 5.9072186559205875e-05 / Item reconstruction: 0.0019802390597760677 / Text reconstruction: 0.01052026730030775\n",
            "loss in epoch 6/21 iteration 8/67: 1.3873405456542969 / BPR loss: 1.3842570781707764 / Matching loss: 5.666759534506127e-05 / Item reconstruction: 0.0018845221493393183 / Text reconstruction: 0.01042330265045166\n",
            "loss in epoch 6/21 iteration 9/67: 1.3875677585601807 / BPR loss: 1.384526014328003 / Matching loss: 5.8426470786798745e-05 / Item reconstruction: 0.0018574998248368502 / Text reconstruction: 0.010272815823554993\n",
            "loss in epoch 6/21 iteration 10/67: 1.3871902227401733 / BPR loss: 1.3841710090637207 / Matching loss: 5.8985122450394556e-05 / Item reconstruction: 0.0018262004014104605 / Text reconstruction: 0.010235097259283066\n",
            "loss in epoch 6/21 iteration 11/67: 1.3872886896133423 / BPR loss: 1.384279489517212 / Matching loss: 6.200143980095163e-05 / Item reconstruction: 0.001852997113019228 / Text reconstruction: 0.010103864595293999\n",
            "loss in epoch 6/21 iteration 12/67: 1.3874964714050293 / BPR loss: 1.3844813108444214 / Matching loss: 6.0819882492069155e-05 / Item reconstruction: 0.0018790506292134523 / Text reconstruction: 0.010074326768517494\n",
            "loss in epoch 6/21 iteration 13/67: 1.3875248432159424 / BPR loss: 1.3845374584197998 / Matching loss: 5.7973280490841717e-05 / Item reconstruction: 0.001834253198467195 / Text reconstruction: 0.01006198488175869\n",
            "loss in epoch 6/21 iteration 14/67: 1.387500286102295 / BPR loss: 1.3844530582427979 / Matching loss: 5.887546285521239e-05 / Item reconstruction: 0.001956809777766466 / Text reconstruction: 0.010049826465547085\n",
            "loss in epoch 6/21 iteration 15/67: 1.38764226436615 / BPR loss: 1.3846534490585327 / Matching loss: 5.801144288852811e-05 / Item reconstruction: 0.0018430602503940463 / Text reconstruction: 0.010046133771538734\n",
            "loss in epoch 6/21 iteration 16/67: 1.3873345851898193 / BPR loss: 1.3843903541564941 / Matching loss: 5.9757931012427434e-05 / Item reconstruction: 0.0017975375521928072 / Text reconstruction: 0.009929118677973747\n",
            "loss in epoch 6/21 iteration 17/67: 1.387283444404602 / BPR loss: 1.3843275308609009 / Matching loss: 6.0660517192445695e-05 / Item reconstruction: 0.00184228818397969 / Text reconstruction: 0.009870726615190506\n",
            "loss in epoch 6/21 iteration 18/67: 1.3891831636428833 / BPR loss: 1.3857102394104004 / Matching loss: 7.182240369729698e-05 / Item reconstruction: 0.0026992512866854668 / Text reconstruction: 0.010257761925458908\n",
            "loss in epoch 6/21 iteration 19/67: 1.3898169994354248 / BPR loss: 1.3861974477767944 / Matching loss: 7.202804408734664e-05 / Item reconstruction: 0.0029421476647257805 / Text reconstruction: 0.010382764041423798\n",
            "loss in epoch 6/21 iteration 20/67: 1.3897310495376587 / BPR loss: 1.3862183094024658 / Matching loss: 6.797500100219622e-05 / Item reconstruction: 0.0028104856610298157 / Text reconstruction: 0.010197830386459827\n",
            "loss in epoch 6/21 iteration 21/67: 1.3893942832946777 / BPR loss: 1.3859834671020508 / Matching loss: 7.296711555682123e-05 / Item reconstruction: 0.0027184407226741314 / Text reconstruction: 0.009893377311527729\n",
            "loss in epoch 6/21 iteration 22/67: 1.3882858753204346 / BPR loss: 1.3851773738861084 / Matching loss: 5.658339796354994e-05 / Item reconstruction: 0.0022812325041741133 / Text reconstruction: 0.00955626554787159\n",
            "loss in epoch 6/21 iteration 23/67: 1.3880045413970947 / BPR loss: 1.3849992752075195 / Matching loss: 5.887031147722155e-05 / Item reconstruction: 0.002160589676350355 / Text reconstruction: 0.009330501779913902\n",
            "loss in epoch 6/21 iteration 24/67: 1.388105034828186 / BPR loss: 1.3850948810577393 / Matching loss: 6.41735241515562e-05 / Item reconstruction: 0.0022039497271180153 / Text reconstruction: 0.009219955652952194\n",
            "loss in epoch 6/21 iteration 25/67: 1.3880598545074463 / BPR loss: 1.3850646018981934 / Matching loss: 6.333502824418247e-05 / Item reconstruction: 0.0021994742564857006 / Text reconstruction: 0.00916101224720478\n",
            "loss in epoch 6/21 iteration 26/67: 1.3879456520080566 / BPR loss: 1.3850103616714478 / Matching loss: 6.031773591530509e-05 / Item reconstruction: 0.0021059266291558743 / Text reconstruction: 0.009109850972890854\n",
            "loss in epoch 6/21 iteration 27/67: 1.3877829313278198 / BPR loss: 1.3849234580993652 / Matching loss: 5.647837679134682e-05 / Item reconstruction: 0.0020058040972799063 / Text reconstruction: 0.009000077843666077\n",
            "loss in epoch 6/21 iteration 28/67: 1.387645959854126 / BPR loss: 1.384838581085205 / Matching loss: 5.368608981370926e-05 / Item reconstruction: 0.001912791864015162 / Text reconstruction: 0.008986438624560833\n",
            "loss in epoch 6/21 iteration 29/67: 1.3876736164093018 / BPR loss: 1.384883165359497 / Matching loss: 5.169679207028821e-05 / Item reconstruction: 0.0018658048938959837 / Text reconstruction: 0.009029027074575424\n",
            "loss in epoch 6/21 iteration 30/67: 1.3877100944519043 / BPR loss: 1.3849058151245117 / Matching loss: 5.2541632612701505e-05 / Item reconstruction: 0.0018904421012848616 / Text reconstruction: 0.009032227098941803\n",
            "loss in epoch 6/21 iteration 31/67: 1.3876768350601196 / BPR loss: 1.3849036693572998 / Matching loss: 5.507336027221754e-05 / Item reconstruction: 0.0018509970977902412 / Text reconstruction: 0.008962687104940414\n",
            "loss in epoch 6/21 iteration 32/67: 1.3876583576202393 / BPR loss: 1.3849800825119019 / Matching loss: 5.793040691060014e-05 / Item reconstruction: 0.0017625453183427453 / Text reconstruction: 0.008694851770997047\n",
            "loss in epoch 6/21 iteration 33/67: 1.3884423971176147 / BPR loss: 1.3852717876434326 / Matching loss: 7.018599717412144e-05 / Item reconstruction: 0.0026698806323111057 / Text reconstruction: 0.008827309124171734\n",
            "loss in epoch 6/21 iteration 34/67: 1.3891146183013916 / BPR loss: 1.3860137462615967 / Matching loss: 6.71076268190518e-05 / Item reconstruction: 0.0027618794701993465 / Text reconstruction: 0.008263997733592987\n",
            "loss in epoch 6/21 iteration 35/67: 1.388910174369812 / BPR loss: 1.3858182430267334 / Matching loss: 6.195374589879066e-05 / Item reconstruction: 0.0026643392629921436 / Text reconstruction: 0.00848899595439434\n",
            "loss in epoch 6/21 iteration 36/67: 1.3893486261367798 / BPR loss: 1.3861684799194336 / Matching loss: 8.384748070966452e-05 / Item reconstruction: 0.0027674809098243713 / Text reconstruction: 0.00856275949627161\n",
            "loss in epoch 6/21 iteration 37/67: 1.3892031908035278 / BPR loss: 1.3861075639724731 / Matching loss: 7.829538662917912e-05 / Item reconstruction: 0.002667459659278393 / Text reconstruction: 0.008418064564466476\n",
            "loss in epoch 6/21 iteration 38/67: 1.388915777206421 / BPR loss: 1.3859686851501465 / Matching loss: 6.948114605620503e-05 / Item reconstruction: 0.0025455565191805363 / Text reconstruction: 0.008023839443922043\n",
            "loss in epoch 6/21 iteration 39/67: 1.3890712261199951 / BPR loss: 1.3862037658691406 / Matching loss: 7.406047370750457e-05 / Item reconstruction: 0.0023670955561101437 / Text reconstruction: 0.008049551397562027\n",
            "loss in epoch 6/21 iteration 40/67: 1.3890434503555298 / BPR loss: 1.3862216472625732 / Matching loss: 8.287379750981927e-05 / Item reconstruction: 0.0023359633050858974 / Text reconstruction: 0.007854700088500977\n",
            "loss in epoch 6/21 iteration 41/67: 1.3884074687957764 / BPR loss: 1.3854950666427612 / Matching loss: 7.343864854192361e-05 / Item reconstruction: 0.0023539657704532146 / Text reconstruction: 0.008310156874358654\n",
            "loss in epoch 6/21 iteration 42/67: 1.3876466751098633 / BPR loss: 1.3845863342285156 / Matching loss: 5.8154550060862675e-05 / Item reconstruction: 0.002287506125867367 / Text reconstruction: 0.009292494505643845\n",
            "loss in epoch 6/21 iteration 43/67: 1.3876187801361084 / BPR loss: 1.3845717906951904 / Matching loss: 5.9642785345204175e-05 / Item reconstruction: 0.0023016969207674265 / Text reconstruction: 0.00918261893093586\n",
            "loss in epoch 6/21 iteration 44/67: 1.3886815309524536 / BPR loss: 1.3859347105026245 / Matching loss: 7.074177847243845e-05 / Item reconstruction: 0.002250085584819317 / Text reconstruction: 0.007755282800644636\n",
            "loss in epoch 6/21 iteration 45/67: 1.3889577388763428 / BPR loss: 1.386264443397522 / Matching loss: 6.914233381394297e-05 / Item reconstruction: 0.002189008751884103 / Text reconstruction: 0.007648633327335119\n",
            "loss in epoch 6/21 iteration 46/67: 1.3886164426803589 / BPR loss: 1.3858067989349365 / Matching loss: 7.674060179851949e-05 / Item reconstruction: 0.002467177342623472 / Text reconstruction: 0.007496551610529423\n",
            "loss in epoch 6/21 iteration 47/67: 1.3888691663742065 / BPR loss: 1.3860666751861572 / Matching loss: 7.418337918352336e-05 / Item reconstruction: 0.002429685555398464 / Text reconstruction: 0.007567345164716244\n",
            "loss in epoch 6/21 iteration 48/67: 1.388740062713623 / BPR loss: 1.38601815700531 / Matching loss: 6.731729081366211e-05 / Item reconstruction: 0.0022526253014802933 / Text reconstruction: 0.007641525939106941\n",
            "loss in epoch 6/21 iteration 49/67: 1.388396978378296 / BPR loss: 1.3856267929077148 / Matching loss: 6.821201532147825e-05 / Item reconstruction: 0.002215417567640543 / Text reconstruction: 0.007971402257680893\n",
            "loss in epoch 6/21 iteration 50/67: 1.3885995149612427 / BPR loss: 1.3858776092529297 / Matching loss: 7.607851875945926e-05 / Item reconstruction: 0.002286337548866868 / Text reconstruction: 0.007513185031712055\n",
            "loss in epoch 6/21 iteration 51/67: 1.388845682144165 / BPR loss: 1.3861708641052246 / Matching loss: 7.188928429968655e-05 / Item reconstruction: 0.0022769425995647907 / Text reconstruction: 0.007322513498365879\n",
            "loss in epoch 6/21 iteration 52/67: 1.3889325857162476 / BPR loss: 1.3862857818603516 / Matching loss: 6.938406295375898e-05 / Item reconstruction: 0.002215030835941434 / Text reconstruction: 0.00734941940754652\n",
            "loss in epoch 6/21 iteration 53/67: 1.3887553215026855 / BPR loss: 1.3861185312271118 / Matching loss: 6.510720413643867e-05 / Item reconstruction: 0.002162107266485691 / Text reconstruction: 0.007453123107552528\n",
            "loss in epoch 6/21 iteration 54/67: 1.3889776468276978 / BPR loss: 1.3863269090652466 / Matching loss: 7.662684947717935e-05 / Item reconstruction: 0.0022537154145538807 / Text reconstruction: 0.007236127741634846\n",
            "loss in epoch 6/21 iteration 55/67: 1.3889895677566528 / BPR loss: 1.3863595724105835 / Matching loss: 7.904564699856564e-05 / Item reconstruction: 0.0021903873421251774 / Text reconstruction: 0.007278798148036003\n",
            "loss in epoch 6/21 iteration 56/67: 1.3889073133468628 / BPR loss: 1.3863232135772705 / Matching loss: 7.599739183206111e-05 / Item reconstruction: 0.0021763581316918135 / Text reconstruction: 0.007099239621311426\n",
            "loss in epoch 6/21 iteration 57/67: 1.388826847076416 / BPR loss: 1.3863253593444824 / Matching loss: 5.9196951042395085e-05 / Item reconstruction: 0.0019905767403542995 / Text reconstruction: 0.007234599441289902\n",
            "loss in epoch 6/21 iteration 58/67: 1.3888152837753296 / BPR loss: 1.3863182067871094 / Matching loss: 5.415044870460406e-05 / Item reconstruction: 0.0019746278412640095 / Text reconstruction: 0.007278049364686012\n",
            "loss in epoch 6/21 iteration 59/67: 1.3887901306152344 / BPR loss: 1.3862613439559937 / Matching loss: 6.164322257973254e-05 / Item reconstruction: 0.002103720558807254 / Text reconstruction: 0.0070763397961854935\n",
            "loss in epoch 6/21 iteration 60/67: 1.388782024383545 / BPR loss: 1.386246919631958 / Matching loss: 6.795357330702245e-05 / Item reconstruction: 0.002106240950524807 / Text reconstruction: 0.007070181425660849\n",
            "loss in epoch 6/21 iteration 61/67: 1.3888336420059204 / BPR loss: 1.3863883018493652 / Matching loss: 7.020942575763911e-05 / Item reconstruction: 0.0019854260608553886 / Text reconstruction: 0.006912347860634327\n",
            "loss in epoch 6/21 iteration 62/67: 1.3888661861419678 / BPR loss: 1.3862650394439697 / Matching loss: 6.261615635594353e-05 / Item reconstruction: 0.00211485568434 / Text reconstruction: 0.007406098768115044\n",
            "loss in epoch 6/21 iteration 63/67: 1.3887945413589478 / BPR loss: 1.386257290840149 / Matching loss: 7.469794945791364e-05 / Item reconstruction: 0.0022336095571517944 / Text reconstruction: 0.006728673353791237\n",
            "loss in epoch 6/21 iteration 64/67: 1.3887615203857422 / BPR loss: 1.3862969875335693 / Matching loss: 6.764059799024835e-05 / Item reconstruction: 0.0021286802366375923 / Text reconstruction: 0.006663335021585226\n",
            "loss in epoch 6/21 iteration 65/67: 1.388753890991211 / BPR loss: 1.3862799406051636 / Matching loss: 7.254505180753767e-05 / Item reconstruction: 0.0021427227184176445 / Text reconstruction: 0.006649927236139774\n",
            "loss in epoch 6/21 iteration 66/67: 1.3886626958847046 / BPR loss: 1.3863439559936523 / Matching loss: 6.032423334545456e-05 / Item reconstruction: 0.0017707590013742447 / Text reconstruction: 0.0068649956956505775\n",
            "loss in epoch 6/21 iteration 67/67: 1.3885189294815063 / BPR loss: 1.3862812519073486 / Matching loss: 5.1697588787646964e-05 / Item reconstruction: 0.0015604725340381265 / Text reconstruction: 0.007028654683381319\n",
            " 30% 6/20 [11:43<27:23, 117.40s/it]loss in epoch 7/21 iteration 0/67: 1.388659954071045 / BPR loss: 1.3860995769500732 / Matching loss: 6.761985423509032e-05 / Item reconstruction: 0.0023535650689154863 / Text reconstruction: 0.0065795620903372765\n",
            "loss in epoch 7/21 iteration 1/67: 1.3879895210266113 / BPR loss: 1.3852500915527344 / Matching loss: 5.588380736298859e-05 / Item reconstruction: 0.002358140889555216 / Text reconstruction: 0.0075218528509140015\n",
            "loss in epoch 7/21 iteration 2/67: 1.387147307395935 / BPR loss: 1.3842991590499878 / Matching loss: 5.8811197959585115e-05 / Item reconstruction: 0.002472073072567582 / Text reconstruction: 0.007766714319586754\n",
            "loss in epoch 7/21 iteration 3/67: 1.3869476318359375 / BPR loss: 1.384169578552246 / Matching loss: 5.95115743635688e-05 / Item reconstruction: 0.002288386458531022 / Text reconstruction: 0.007872170768678188\n",
            "loss in epoch 7/21 iteration 4/67: 1.3867944478988647 / BPR loss: 1.3840594291687012 / Matching loss: 5.746613896917552e-05 / Item reconstruction: 0.002166797872632742 / Text reconstruction: 0.007970914244651794\n",
            "loss in epoch 7/21 iteration 5/67: 1.3867095708847046 / BPR loss: 1.3840219974517822 / Matching loss: 5.8687848650151864e-05 / Item reconstruction: 0.0021519502624869347 / Text reconstruction: 0.0077645499259233475\n",
            "loss in epoch 7/21 iteration 6/67: 1.3866899013519287 / BPR loss: 1.3841842412948608 / Matching loss: 5.556464020628482e-05 / Item reconstruction: 0.0019912568386644125 / Text reconstruction: 0.007272612303495407\n",
            "loss in epoch 7/21 iteration 7/67: 1.3866212368011475 / BPR loss: 1.384183406829834 / Matching loss: 5.230040187598206e-05 / Item reconstruction: 0.0019236119696870446 / Text reconstruction: 0.00711870240047574\n",
            "loss in epoch 7/21 iteration 8/67: 1.3863836526870728 / BPR loss: 1.3839681148529053 / Matching loss: 5.293469439493492e-05 / Item reconstruction: 0.0018823472782969475 / Text reconstruction: 0.007107116281986237\n",
            "loss in epoch 7/21 iteration 9/67: 1.3866074085235596 / BPR loss: 1.3842401504516602 / Matching loss: 5.34797363798134e-05 / Item reconstruction: 0.0018101895693689585 / Text reconstruction: 0.0070434152148664\n",
            "loss in epoch 7/21 iteration 10/67: 1.3862724304199219 / BPR loss: 1.3839389085769653 / Matching loss: 5.017108560423367e-05 / Item reconstruction: 0.0017788475379347801 / Text reconstruction: 0.006969366688281298\n",
            "loss in epoch 7/21 iteration 11/67: 1.3862181901931763 / BPR loss: 1.383899450302124 / Matching loss: 5.185365444049239e-05 / Item reconstruction: 0.0017551559722051024 / Text reconstruction: 0.006946398410946131\n",
            "loss in epoch 7/21 iteration 12/67: 1.3866045475006104 / BPR loss: 1.3842406272888184 / Matching loss: 5.508670074050315e-05 / Item reconstruction: 0.0018551452085375786 / Text reconstruction: 0.006906590424478054\n",
            "loss in epoch 7/21 iteration 13/67: 1.3864502906799316 / BPR loss: 1.3840906620025635 / Matching loss: 5.1305803935974836e-05 / Item reconstruction: 0.001832065056078136 / Text reconstruction: 0.006961560342460871\n",
            "loss in epoch 7/21 iteration 14/67: 1.3862972259521484 / BPR loss: 1.3839553594589233 / Matching loss: 4.9864669563248754e-05 / Item reconstruction: 0.0018378081731498241 / Text reconstruction: 0.0068656872026622295\n",
            "loss in epoch 7/21 iteration 15/67: 1.3863978385925293 / BPR loss: 1.3840909004211426 / Matching loss: 4.733431342174299e-05 / Item reconstruction: 0.0017784549854695797 / Text reconstruction: 0.006852095015347004\n",
            "loss in epoch 7/21 iteration 16/67: 1.3862196207046509 / BPR loss: 1.3838894367218018 / Matching loss: 5.340313146007247e-05 / Item reconstruction: 0.0018608053214848042 / Text reconstruction: 0.006731890141963959\n",
            "loss in epoch 7/21 iteration 17/67: 1.386228322982788 / BPR loss: 1.3839157819747925 / Matching loss: 5.5035852710716426e-05 / Item reconstruction: 0.0018421784043312073 / Text reconstruction: 0.0066817402839660645\n",
            "loss in epoch 7/21 iteration 18/67: 1.3883880376815796 / BPR loss: 1.3856021165847778 / Matching loss: 6.588829273823649e-05 / Item reconstruction: 0.0026021315716207027 / Text reconstruction: 0.007094636559486389\n",
            "loss in epoch 7/21 iteration 19/67: 1.389168620109558 / BPR loss: 1.3862133026123047 / Matching loss: 6.40791913610883e-05 / Item reconstruction: 0.0029366612434387207 / Text reconstruction: 0.007114375941455364\n",
            "loss in epoch 7/21 iteration 20/67: 1.3890445232391357 / BPR loss: 1.386198878288269 / Matching loss: 6.178578769322485e-05 / Item reconstruction: 0.0028143913950771093 / Text reconstruction: 0.006884017959237099\n",
            "loss in epoch 7/21 iteration 21/67: 1.3886590003967285 / BPR loss: 1.385869026184082 / Matching loss: 6.291797035373747e-05 / Item reconstruction: 0.0027630003169178963 / Text reconstruction: 0.006727676838636398\n",
            "loss in epoch 7/21 iteration 22/67: 1.3871033191680908 / BPR loss: 1.38455331325531 / Matching loss: 4.994690971216187e-05 / Item reconstruction: 0.0023347940295934677 / Text reconstruction: 0.006663078907877207\n",
            "loss in epoch 7/21 iteration 23/67: 1.387036681175232 / BPR loss: 1.3846244812011719 / Matching loss: 4.8264751967508346e-05 / Item reconstruction: 0.002173027954995632 / Text reconstruction: 0.006387018132954836\n",
            "loss in epoch 7/21 iteration 24/67: 1.3870067596435547 / BPR loss: 1.3846540451049805 / Matching loss: 5.261740443529561e-05 / Item reconstruction: 0.0021022555883973837 / Text reconstruction: 0.006245552562177181\n",
            "loss in epoch 7/21 iteration 25/67: 1.3870824575424194 / BPR loss: 1.3847434520721436 / Matching loss: 5.340921779861674e-05 / Item reconstruction: 0.002063588472083211 / Text reconstruction: 0.006269196979701519\n",
            "loss in epoch 7/21 iteration 26/67: 1.3869011402130127 / BPR loss: 1.3846029043197632 / Matching loss: 4.959605576004833e-05 / Item reconstruction: 0.001983042573556304 / Text reconstruction: 0.006286189425736666\n",
            "loss in epoch 7/21 iteration 27/67: 1.3867493867874146 / BPR loss: 1.3844835758209229 / Matching loss: 4.910624920739792e-05 / Item reconstruction: 0.0019769971258938313 / Text reconstruction: 0.006141246296465397\n",
            "loss in epoch 7/21 iteration 28/67: 1.3868833780288696 / BPR loss: 1.3847088813781738 / Matching loss: 4.7546596761094406e-05 / Item reconstruction: 0.0018879143754020333 / Text reconstruction: 0.005915384739637375\n",
            "loss in epoch 7/21 iteration 29/67: 1.3868614435195923 / BPR loss: 1.3846509456634521 / Matching loss: 4.6106324589345604e-05 / Item reconstruction: 0.0019120441284030676 / Text reconstruction: 0.006041273009032011\n",
            "loss in epoch 7/21 iteration 30/67: 1.3866562843322754 / BPR loss: 1.3844547271728516 / Matching loss: 4.568124859360978e-05 / Item reconstruction: 0.0019076259341090918 / Text reconstruction: 0.006010265089571476\n",
            "loss in epoch 7/21 iteration 31/67: 1.3868404626846313 / BPR loss: 1.3847118616104126 / Matching loss: 4.740844087791629e-05 / Item reconstruction: 0.0018061462324112654 / Text reconstruction: 0.005889870226383209\n",
            "loss in epoch 7/21 iteration 32/67: 1.386549711227417 / BPR loss: 1.3844799995422363 / Matching loss: 4.853169957641512e-05 / Item reconstruction: 0.0017462830292060971 / Text reconstruction: 0.0057402425445616245\n",
            "loss in epoch 7/21 iteration 33/67: 1.3873255252838135 / BPR loss: 1.3848257064819336 / Matching loss: 5.6899771152529866e-05 / Item reconstruction: 0.0025644972920417786 / Text reconstruction: 0.005803704261779785\n",
            "loss in epoch 7/21 iteration 34/67: 1.3884447813034058 / BPR loss: 1.3859596252441406 / Matching loss: 5.82934808335267e-05 / Item reconstruction: 0.0026917762588709593 / Text reconstruction: 0.005404898896813393\n",
            "loss in epoch 7/21 iteration 35/67: 1.3882241249084473 / BPR loss: 1.3857076168060303 / Matching loss: 5.532648356165737e-05 / Item reconstruction: 0.0027119151782244444 / Text reconstruction: 0.005526012275367975\n",
            "loss in epoch 7/21 iteration 36/67: 1.3886648416519165 / BPR loss: 1.386154294013977 / Matching loss: 7.197690138127655e-05 / Item reconstruction: 0.0026446636766195297 / Text reconstruction: 0.0055807968601584435\n",
            "loss in epoch 7/21 iteration 37/67: 1.388465404510498 / BPR loss: 1.3859944343566895 / Matching loss: 7.00255623087287e-05 / Item reconstruction: 0.0026210350915789604 / Text reconstruction: 0.005452606361359358\n",
            "loss in epoch 7/21 iteration 38/67: 1.388238549232483 / BPR loss: 1.3859014511108398 / Matching loss: 6.206851685419679e-05 / Item reconstruction: 0.0024897586554288864 / Text reconstruction: 0.005150637589395046\n",
            "loss in epoch 7/21 iteration 39/67: 1.3883883953094482 / BPR loss: 1.3861067295074463 / Matching loss: 6.504402699647471e-05 / Item reconstruction: 0.0023845569230616093 / Text reconstruction: 0.005121118389070034\n",
            "loss in epoch 7/21 iteration 40/67: 1.388420820236206 / BPR loss: 1.3862011432647705 / Matching loss: 6.99568772688508e-05 / Item reconstruction: 0.0023187706246972084 / Text reconstruction: 0.004951161332428455\n",
            "loss in epoch 7/21 iteration 41/67: 1.3875412940979004 / BPR loss: 1.3852276802062988 / Matching loss: 6.243142706807703e-05 / Item reconstruction: 0.002321254927664995 / Text reconstruction: 0.005452579818665981\n",
            "loss in epoch 7/21 iteration 42/67: 1.3866424560546875 / BPR loss: 1.3841843605041504 / Matching loss: 5.102901559439488e-05 / Item reconstruction: 0.0022335893008857965 / Text reconstruction: 0.006451430264860392\n",
            "loss in epoch 7/21 iteration 43/67: 1.3865389823913574 / BPR loss: 1.3840599060058594 / Matching loss: 5.089648038847372e-05 / Item reconstruction: 0.0022678892128169537 / Text reconstruction: 0.006471189670264721\n",
            "loss in epoch 7/21 iteration 44/67: 1.3881123065948486 / BPR loss: 1.3859434127807617 / Matching loss: 6.222911179065704e-05 / Item reconstruction: 0.002247709548100829 / Text reconstruction: 0.004913919139653444\n",
            "loss in epoch 7/21 iteration 45/67: 1.3883857727050781 / BPR loss: 1.386277437210083 / Matching loss: 6.1295650084503e-05 / Item reconstruction: 0.0021784892305731773 / Text reconstruction: 0.0047893403097987175\n",
            "loss in epoch 7/21 iteration 46/67: 1.388060450553894 / BPR loss: 1.3857922554016113 / Matching loss: 6.370745541062206e-05 / Item reconstruction: 0.002488125581294298 / Text reconstruction: 0.004802128300070763\n",
            "loss in epoch 7/21 iteration 47/67: 1.38820219039917 / BPR loss: 1.3859037160873413 / Matching loss: 6.111360562499613e-05 / Item reconstruction: 0.0025225381832569838 / Text reconstruction: 0.0048804860562086105\n",
            "loss in epoch 7/21 iteration 48/67: 1.388253092765808 / BPR loss: 1.3860739469528198 / Matching loss: 5.952326682745479e-05 / Item reconstruction: 0.0022922945208847523 / Text reconstruction: 0.004867467097938061\n",
            "loss in epoch 7/21 iteration 49/67: 1.3877397775650024 / BPR loss: 1.38550865650177 / Matching loss: 5.5581596825504676e-05 / Item reconstruction: 0.0022812183015048504 / Text reconstruction: 0.005174723453819752\n",
            "loss in epoch 7/21 iteration 50/67: 1.3877156972885132 / BPR loss: 1.38556969165802 / Matching loss: 5.79325933358632e-05 / Item reconstruction: 0.0022693807259202003 / Text reconstruction: 0.0047672889195382595\n",
            "loss in epoch 7/21 iteration 51/67: 1.3882451057434082 / BPR loss: 1.3861074447631836 / Matching loss: 6.333275814540684e-05 / Item reconstruction: 0.0023040203377604485 / Text reconstruction: 0.0046118805184960365\n",
            "loss in epoch 7/21 iteration 52/67: 1.3883538246154785 / BPR loss: 1.3861957788467407 / Matching loss: 6.168171239551157e-05 / Item reconstruction: 0.00229438254609704 / Text reconstruction: 0.004746424034237862\n",
            "loss in epoch 7/21 iteration 53/67: 1.3882485628128052 / BPR loss: 1.386131763458252 / Matching loss: 5.897809751331806e-05 / Item reconstruction: 0.002197286346927285 / Text reconstruction: 0.004795784130692482\n",
            "loss in epoch 7/21 iteration 54/67: 1.388262152671814 / BPR loss: 1.3861989974975586 / Matching loss: 6.524890341097489e-05 / Item reconstruction: 0.002199324779212475 / Text reconstruction: 0.004491140134632587\n",
            "loss in epoch 7/21 iteration 55/67: 1.3884414434432983 / BPR loss: 1.3863860368728638 / Matching loss: 6.485538324341178e-05 / Item reconstruction: 0.002164437435567379 / Text reconstruction: 0.004541739821434021\n",
            "loss in epoch 7/21 iteration 56/67: 1.388325810432434 / BPR loss: 1.3863072395324707 / Matching loss: 6.602657958865166e-05 / Item reconstruction: 0.0021450098138302565 / Text reconstruction: 0.004399925470352173\n",
            "loss in epoch 7/21 iteration 57/67: 1.3881698846817017 / BPR loss: 1.3861868381500244 / Matching loss: 5.7062650739680976e-05 / Item reconstruction: 0.0020372665021568537 / Text reconstruction: 0.004536221735179424\n",
            "loss in epoch 7/21 iteration 58/67: 1.3881784677505493 / BPR loss: 1.3861727714538574 / Matching loss: 5.2963325288146734e-05 / Item reconstruction: 0.0020973486825823784 / Text reconstruction: 0.004520454443991184\n",
            "loss in epoch 7/21 iteration 59/67: 1.3881285190582275 / BPR loss: 1.3861411809921265 / Matching loss: 5.569094355450943e-05 / Item reconstruction: 0.002142026089131832 / Text reconstruction: 0.0043032108806073666\n",
            "loss in epoch 7/21 iteration 60/67: 1.388260841369629 / BPR loss: 1.3862922191619873 / Matching loss: 5.4402349633164704e-05 / Item reconstruction: 0.002076819073408842 / Text reconstruction: 0.0043792398646473885\n",
            "loss in epoch 7/21 iteration 61/67: 1.3882992267608643 / BPR loss: 1.3864035606384277 / Matching loss: 5.502519343281165e-05 / Item reconstruction: 0.0019788516219705343 / Text reconstruction: 0.00425550015643239\n",
            "loss in epoch 7/21 iteration 62/67: 1.3881890773773193 / BPR loss: 1.3861327171325684 / Matching loss: 5.335941386874765e-05 / Item reconstruction: 0.0021708901040256023 / Text reconstruction: 0.004587922245264053\n",
            "loss in epoch 7/21 iteration 63/67: 1.3882986307144165 / BPR loss: 1.3862895965576172 / Matching loss: 6.767361628590152e-05 / Item reconstruction: 0.002255056519061327 / Text reconstruction: 0.004068982321768999\n",
            "loss in epoch 7/21 iteration 64/67: 1.3882328271865845 / BPR loss: 1.3863049745559692 / Matching loss: 6.002460577292368e-05 / Item reconstruction: 0.002139731775969267 / Text reconstruction: 0.003989143297076225\n",
            "loss in epoch 7/21 iteration 65/67: 1.3882241249084473 / BPR loss: 1.3863022327423096 / Matching loss: 5.705182411475107e-05 / Item reconstruction: 0.002124086022377014 / Text reconstruction: 0.004013937897980213\n",
            "loss in epoch 7/21 iteration 66/67: 1.3880971670150757 / BPR loss: 1.386340856552124 / Matching loss: 4.407938104122877e-05 / Item reconstruction: 0.001763061387464404 / Text reconstruction: 0.004153355956077576\n",
            "loss in epoch 7/21 iteration 67/67: 1.388002634048462 / BPR loss: 1.3863117694854736 / Matching loss: 4.078316851519048e-05 / Item reconstruction: 0.001580644166097045 / Text reconstruction: 0.004298842512071133\n",
            " 35% 7/20 [13:40<25:26, 117.41s/it]loss in epoch 8/21 iteration 0/67: 1.3879507780075073 / BPR loss: 1.3859165906906128 / Matching loss: 6.433938688132912e-05 / Item reconstruction: 0.002383532002568245 / Text reconstruction: 0.003890206338837743\n",
            "loss in epoch 8/21 iteration 1/67: 1.3872097730636597 / BPR loss: 1.3848958015441895 / Matching loss: 5.536284879781306e-05 / Item reconstruction: 0.002359953476116061 / Text reconstruction: 0.0053933411836624146\n",
            "loss in epoch 8/21 iteration 2/67: 1.3866462707519531 / BPR loss: 1.3842331171035767 / Matching loss: 5.2343340939842165e-05 / Item reconstruction: 0.0023705027997493744 / Text reconstruction: 0.005877391900867224\n",
            "loss in epoch 8/21 iteration 3/67: 1.3859823942184448 / BPR loss: 1.383708119392395 / Matching loss: 4.6923862100811675e-05 / Item reconstruction: 0.0021962961181998253 / Text reconstruction: 0.005645680241286755\n",
            "loss in epoch 8/21 iteration 4/67: 1.3853557109832764 / BPR loss: 1.3831090927124023 / Matching loss: 5.2009076171088964e-05 / Item reconstruction: 0.002209052909165621 / Text reconstruction: 0.005450736731290817\n",
            "loss in epoch 8/21 iteration 5/67: 1.3857059478759766 / BPR loss: 1.3835856914520264 / Matching loss: 4.9427930207457393e-05 / Item reconstruction: 0.002027240116149187 / Text reconstruction: 0.005285956896841526\n",
            "loss in epoch 8/21 iteration 6/67: 1.3856679201126099 / BPR loss: 1.3836259841918945 / Matching loss: 5.0456743338145316e-05 / Item reconstruction: 0.0019924810621887445 / Text reconstruction: 0.004976415541023016\n",
            "loss in epoch 8/21 iteration 7/67: 1.38538658618927 / BPR loss: 1.3834600448608398 / Matching loss: 4.725328471977264e-05 / Item reconstruction: 0.0018850108608603477 / Text reconstruction: 0.004684383515268564\n",
            "loss in epoch 8/21 iteration 8/67: 1.3853583335876465 / BPR loss: 1.383454442024231 / Matching loss: 4.413189162733033e-05 / Item reconstruction: 0.001855766400694847 / Text reconstruction: 0.004659391939640045\n",
            "loss in epoch 8/21 iteration 9/67: 1.3853294849395752 / BPR loss: 1.383482813835144 / Matching loss: 4.4056348997401074e-05 / Item reconstruction: 0.0017550447955727577 / Text reconstruction: 0.004625302739441395\n",
            "loss in epoch 8/21 iteration 10/67: 1.3853509426116943 / BPR loss: 1.3835111856460571 / Matching loss: 4.366547364043072e-05 / Item reconstruction: 0.0017262592446058989 / Text reconstruction: 0.004665406420826912\n",
            "loss in epoch 8/21 iteration 11/67: 1.385102391242981 / BPR loss: 1.383293628692627 / Matching loss: 4.529905709205195e-05 / Item reconstruction: 0.001656278152950108 / Text reconstruction: 0.004676435608416796\n",
            "loss in epoch 8/21 iteration 12/67: 1.3855602741241455 / BPR loss: 1.383664608001709 / Matching loss: 4.800324677489698e-05 / Item reconstruction: 0.0018434901721775532 / Text reconstruction: 0.004629264120012522\n",
            "loss in epoch 8/21 iteration 13/67: 1.3851046562194824 / BPR loss: 1.3832533359527588 / Matching loss: 4.580742825055495e-05 / Item reconstruction: 0.001788218505680561 / Text reconstruction: 0.004557131789624691\n",
            "loss in epoch 8/21 iteration 14/67: 1.385216474533081 / BPR loss: 1.3833463191986084 / Matching loss: 4.4245622120797634e-05 / Item reconstruction: 0.0018455804092809558 / Text reconstruction: 0.004515830893069506\n",
            "loss in epoch 8/21 iteration 15/67: 1.3852629661560059 / BPR loss: 1.3834069967269897 / Matching loss: 4.1269853682024404e-05 / Item reconstruction: 0.0018064172472804785 / Text reconstruction: 0.004557556472718716\n",
            "loss in epoch 8/21 iteration 16/67: 1.3851372003555298 / BPR loss: 1.383331537246704 / Matching loss: 4.390515823615715e-05 / Item reconstruction: 0.0017630128422752023 / Text reconstruction: 0.004401246085762978\n",
            "loss in epoch 8/21 iteration 17/67: 1.3850724697113037 / BPR loss: 1.383263349533081 / Matching loss: 4.524873656919226e-05 / Item reconstruction: 0.0017493389314040542 / Text reconstruction: 0.004446018021553755\n",
            "loss in epoch 8/21 iteration 18/67: 1.3878295421600342 / BPR loss: 1.3855470418930054 / Matching loss: 5.5305186833720654e-05 / Item reconstruction: 0.0025145942345261574 / Text reconstruction: 0.004849343094974756\n",
            "loss in epoch 8/21 iteration 19/67: 1.3887443542480469 / BPR loss: 1.3862411975860596 / Matching loss: 5.640175731969066e-05 / Item reconstruction: 0.00287050474435091 / Text reconstruction: 0.005057413596659899\n",
            "loss in epoch 8/21 iteration 20/67: 1.3885630369186401 / BPR loss: 1.3861815929412842 / Matching loss: 5.475071520777419e-05 / Item reconstruction: 0.002725641243159771 / Text reconstruction: 0.004819503985345364\n",
            "loss in epoch 8/21 iteration 21/67: 1.3880926370620728 / BPR loss: 1.3857941627502441 / Matching loss: 5.4409752920037135e-05 / Item reconstruction: 0.0026316107250750065 / Text reconstruction: 0.004641417879611254\n",
            "loss in epoch 8/21 iteration 22/67: 1.3861712217330933 / BPR loss: 1.3841032981872559 / Matching loss: 4.4475935283116996e-05 / Item reconstruction: 0.0023814495652914047 / Text reconstruction: 0.004163282457739115\n",
            "loss in epoch 8/21 iteration 23/67: 1.3860118389129639 / BPR loss: 1.3841074705123901 / Matching loss: 4.1482882807031274e-05 / Item reconstruction: 0.002085336484014988 / Text reconstruction: 0.004101030062884092\n",
            "loss in epoch 8/21 iteration 24/67: 1.3861570358276367 / BPR loss: 1.3842014074325562 / Matching loss: 4.615013676811941e-05 / Item reconstruction: 0.002192939165979624 / Text reconstruction: 0.0040649427101016045\n",
            "loss in epoch 8/21 iteration 25/67: 1.386290192604065 / BPR loss: 1.3844667673110962 / Matching loss: 4.3179505155421793e-05 / Item reconstruction: 0.001971716759726405 / Text reconstruction: 0.003972212318331003\n",
            "loss in epoch 8/21 iteration 26/67: 1.386107087135315 / BPR loss: 1.3842735290527344 / Matching loss: 4.1529689042363316e-05 / Item reconstruction: 0.0019721006974577904 / Text reconstruction: 0.004029771313071251\n",
            "loss in epoch 8/21 iteration 27/67: 1.3858914375305176 / BPR loss: 1.3841049671173096 / Matching loss: 4.075636388733983e-05 / Item reconstruction: 0.0018872676882892847 / Text reconstruction: 0.004010351840406656\n",
            "loss in epoch 8/21 iteration 28/67: 1.3859273195266724 / BPR loss: 1.384211540222168 / Matching loss: 4.104818435735069e-05 / Item reconstruction: 0.0018188448157161474 / Text reconstruction: 0.0038265555631369352\n",
            "loss in epoch 8/21 iteration 29/67: 1.3859193325042725 / BPR loss: 1.3841909170150757 / Matching loss: 4.31858679803554e-05 / Item reconstruction: 0.0018283056560903788 / Text reconstruction: 0.003855632385239005\n",
            "loss in epoch 8/21 iteration 30/67: 1.385898470878601 / BPR loss: 1.384150505065918 / Matching loss: 3.93442387576215e-05 / Item reconstruction: 0.0018617502646520734 / Text reconstruction: 0.0038886098191142082\n",
            "loss in epoch 8/21 iteration 31/67: 1.3859014511108398 / BPR loss: 1.384202241897583 / Matching loss: 4.0277838706970215e-05 / Item reconstruction: 0.0017815822502598166 / Text reconstruction: 0.0038406739477068186\n",
            "loss in epoch 8/21 iteration 32/67: 1.3858628273010254 / BPR loss: 1.3842389583587646 / Matching loss: 4.246239404892549e-05 / Item reconstruction: 0.0017391557339578867 / Text reconstruction: 0.0035590033512562513\n",
            "loss in epoch 8/21 iteration 33/67: 1.3867937326431274 / BPR loss: 1.3847274780273438 / Matching loss: 4.656647070078179e-05 / Item reconstruction: 0.0025478857569396496 / Text reconstruction: 0.003728287061676383\n",
            "loss in epoch 8/21 iteration 34/67: 1.387799620628357 / BPR loss: 1.3857598304748535 / Matching loss: 4.705456376541406e-05 / Item reconstruction: 0.0026759677566587925 / Text reconstruction: 0.0032734652049839497\n",
            "loss in epoch 8/21 iteration 35/67: 1.3876378536224365 / BPR loss: 1.3855972290039062 / Matching loss: 4.777356662089005e-05 / Item reconstruction: 0.0026547610759735107 / Text reconstruction: 0.003327283076941967\n",
            "loss in epoch 8/21 iteration 36/67: 1.3879905939102173 / BPR loss: 1.385923147201538 / Matching loss: 6.259286601562053e-05 / Item reconstruction: 0.002664357889443636 / Text reconstruction: 0.003363193478435278\n",
            "loss in epoch 8/21 iteration 37/67: 1.3881027698516846 / BPR loss: 1.3860578536987305 / Matching loss: 6.095314893173054e-05 / Item reconstruction: 0.0026447661221027374 / Text reconstruction: 0.003308024723082781\n",
            "loss in epoch 8/21 iteration 38/67: 1.387694001197815 / BPR loss: 1.3858253955841064 / Matching loss: 5.18365231982898e-05 / Item reconstruction: 0.00241753738373518 / Text reconstruction: 0.0030397376976907253\n",
            "loss in epoch 8/21 iteration 39/67: 1.3878123760223389 / BPR loss: 1.3859665393829346 / Matching loss: 5.169900396140292e-05 / Item reconstruction: 0.002369555179029703 / Text reconstruction: 0.003046426922082901\n",
            "loss in epoch 8/21 iteration 40/67: 1.3879139423370361 / BPR loss: 1.386115312576294 / Matching loss: 6.111878610681742e-05 / Item reconstruction: 0.0023226900957524776 / Text reconstruction: 0.002880923915654421\n",
            "loss in epoch 8/21 iteration 41/67: 1.3868743181228638 / BPR loss: 1.3850270509719849 / Matching loss: 5.4440275562228635e-05 / Item reconstruction: 0.002256840467453003 / Text reconstruction: 0.0033215084113180637\n",
            "loss in epoch 8/21 iteration 42/67: 1.3856792449951172 / BPR loss: 1.383683681488037 / Matching loss: 4.058001650264487e-05 / Item reconstruction: 0.0021690938156098127 / Text reconstruction: 0.00435209646821022\n",
            "loss in epoch 8/21 iteration 43/67: 1.3851839303970337 / BPR loss: 1.3831440210342407 / Matching loss: 4.292406447348185e-05 / Item reconstruction: 0.002240207511931658 / Text reconstruction: 0.004384411498904228\n",
            "loss in epoch 8/21 iteration 44/67: 1.3873075246810913 / BPR loss: 1.3855555057525635 / Matching loss: 5.062159470980987e-05 / Item reconstruction: 0.0022130892612040043 / Text reconstruction: 0.0029740920290350914\n",
            "loss in epoch 8/21 iteration 45/67: 1.3879314661026 / BPR loss: 1.3862800598144531 / Matching loss: 5.238112498773262e-05 / Item reconstruction: 0.0021092824172228575 / Text reconstruction: 0.002721912693232298\n",
            "loss in epoch 8/21 iteration 46/67: 1.3876559734344482 / BPR loss: 1.3857721090316772 / Matching loss: 5.4247149819275364e-05 / Item reconstruction: 0.002491133287549019 / Text reconstruction: 0.002920124912634492\n",
            "loss in epoch 8/21 iteration 47/67: 1.3877136707305908 / BPR loss: 1.3857871294021606 / Matching loss: 4.898565384792164e-05 / Item reconstruction: 0.0025346241891384125 / Text reconstruction: 0.0030510996002703905\n",
            "loss in epoch 8/21 iteration 48/67: 1.3877170085906982 / BPR loss: 1.3859174251556396 / Matching loss: 4.998971780878492e-05 / Item reconstruction: 0.0023176968097686768 / Text reconstruction: 0.0029541272670030594\n",
            "loss in epoch 8/21 iteration 49/67: 1.387270212173462 / BPR loss: 1.38548743724823 / Matching loss: 4.5488202886190265e-05 / Item reconstruction: 0.002227488439530134 / Text reconstruction: 0.003117506392300129\n",
            "loss in epoch 8/21 iteration 50/67: 1.3873647451400757 / BPR loss: 1.3856114149093628 / Matching loss: 4.891229036729783e-05 / Item reconstruction: 0.002218693494796753 / Text reconstruction: 0.0029753621201962233\n",
            "loss in epoch 8/21 iteration 51/67: 1.3878148794174194 / BPR loss: 1.3861174583435059 / Matching loss: 5.679286550730467e-05 / Item reconstruction: 0.0022547284606844187 / Text reconstruction: 0.002566293813288212\n",
            "loss in epoch 8/21 iteration 52/67: 1.3880292177200317 / BPR loss: 1.3863105773925781 / Matching loss: 5.384823452914134e-05 / Item reconstruction: 0.002234736457467079 / Text reconstruction: 0.002737294649705291\n",
            "loss in epoch 8/21 iteration 53/67: 1.3876872062683105 / BPR loss: 1.3860118389129639 / Matching loss: 5.0916198233608156e-05 / Item reconstruction: 0.0021293412428349257 / Text reconstruction: 0.0027989051304757595\n",
            "loss in epoch 8/21 iteration 54/67: 1.387961983680725 / BPR loss: 1.386277437210083 / Matching loss: 5.7435208873357624e-05 / Item reconstruction: 0.002234244719147682 / Text reconstruction: 0.0025498312897980213\n",
            "loss in epoch 8/21 iteration 55/67: 1.3880023956298828 / BPR loss: 1.3863325119018555 / Matching loss: 5.399687142926268e-05 / Item reconstruction: 0.002198191825300455 / Text reconstruction: 0.0025839165318757296\n",
            "loss in epoch 8/21 iteration 56/67: 1.387930154800415 / BPR loss: 1.3862937688827515 / Matching loss: 5.668029552907683e-05 / Item reconstruction: 0.002169365528970957 / Text reconstruction: 0.0024753608740866184\n",
            "loss in epoch 8/21 iteration 57/67: 1.3878390789031982 / BPR loss: 1.3862500190734863 / Matching loss: 4.64820877823513e-05 / Item reconstruction: 0.002036299556493759 / Text reconstruction: 0.002622057683765888\n",
            "loss in epoch 8/21 iteration 58/67: 1.3878040313720703 / BPR loss: 1.3861814737319946 / Matching loss: 5.037636583438143e-05 / Item reconstruction: 0.002127233659848571 / Text reconstruction: 0.0025425185449421406\n",
            "loss in epoch 8/21 iteration 59/67: 1.3878074884414673 / BPR loss: 1.3861968517303467 / Matching loss: 5.342795338947326e-05 / Item reconstruction: 0.0021537928842008114 / Text reconstruction: 0.0024015246890485287\n",
            "loss in epoch 8/21 iteration 60/67: 1.3877955675125122 / BPR loss: 1.3862136602401733 / Matching loss: 4.7351819375762716e-05 / Item reconstruction: 0.0020666252821683884 / Text reconstruction: 0.0025062812492251396\n",
            "loss in epoch 8/21 iteration 61/67: 1.387749195098877 / BPR loss: 1.3862245082855225 / Matching loss: 4.845728835789487e-05 / Item reconstruction: 0.001988627016544342 / Text reconstruction: 0.002409684471786022\n",
            "loss in epoch 8/21 iteration 62/67: 1.3878514766693115 / BPR loss: 1.386115312576294 / Matching loss: 4.022141365567222e-05 / Item reconstruction: 0.0021262795198708773 / Text reconstruction: 0.0031644271221011877\n",
            "loss in epoch 8/21 iteration 63/67: 1.3878453969955444 / BPR loss: 1.3862391710281372 / Matching loss: 5.73780489503406e-05 / Item reconstruction: 0.0022262895945459604 / Text reconstruction: 0.0021783635020256042\n",
            "loss in epoch 8/21 iteration 64/67: 1.3877414464950562 / BPR loss: 1.3862074613571167 / Matching loss: 5.41566259926185e-05 / Item reconstruction: 0.0020863234531134367 / Text reconstruction: 0.0021832608617842197\n",
            "loss in epoch 8/21 iteration 65/67: 1.387664794921875 / BPR loss: 1.3861103057861328 / Matching loss: 5.440209497464821e-05 / Item reconstruction: 0.0021121827885508537 / Text reconstruction: 0.002220126334577799\n",
            "loss in epoch 8/21 iteration 66/67: 1.3877559900283813 / BPR loss: 1.3863525390625 / Matching loss: 4.0525617805542424e-05 / Item reconstruction: 0.0017616376280784607 / Text reconstruction: 0.0024105412885546684\n",
            "loss in epoch 8/21 iteration 67/67: 1.3875514268875122 / BPR loss: 1.3861896991729736 / Matching loss: 3.4356649848632514e-05 / Item reconstruction: 0.0016337853157892823 / Text reconstruction: 0.002552419900894165\n",
            " 40% 8/20 [15:37<23:24, 117.05s/it]loss in epoch 9/21 iteration 0/67: 1.3876763582229614 / BPR loss: 1.3859457969665527 / Matching loss: 5.425761628430337e-05 / Item reconstruction: 0.002437539165839553 / Text reconstruction: 0.002287560608237982\n",
            "loss in epoch 9/21 iteration 1/67: 1.3864117860794067 / BPR loss: 1.3844785690307617 / Matching loss: 4.71049606858287e-05 / Item reconstruction: 0.0023296873550862074 / Text reconstruction: 0.003606707789003849\n",
            "loss in epoch 9/21 iteration 2/67: 1.3853131532669067 / BPR loss: 1.3833346366882324 / Matching loss: 4.6814246161375195e-05 / Item reconstruction: 0.0023132653441280127 / Text reconstruction: 0.003874683752655983\n",
            "loss in epoch 9/21 iteration 3/67: 1.384852409362793 / BPR loss: 1.3829188346862793 / Matching loss: 4.286428156774491e-05 / Item reconstruction: 0.0022046579979360104 / Text reconstruction: 0.0039413971826434135\n",
            "loss in epoch 9/21 iteration 4/67: 1.3844877481460571 / BPR loss: 1.382654070854187 / Matching loss: 4.388329398352653e-05 / Item reconstruction: 0.0021117092110216618 / Text reconstruction: 0.003670062869787216\n",
            "loss in epoch 9/21 iteration 5/67: 1.3846731185913086 / BPR loss: 1.3829545974731445 / Matching loss: 4.007817187812179e-05 / Item reconstruction: 0.0019435103749856353 / Text reconstruction: 0.003533382201567292\n",
            "loss in epoch 9/21 iteration 6/67: 1.3845089673995972 / BPR loss: 1.3828394412994385 / Matching loss: 3.7272675399435684e-05 / Item reconstruction: 0.001865740166977048 / Text reconstruction: 0.0034970322158187628\n",
            "loss in epoch 9/21 iteration 7/67: 1.3845919370651245 / BPR loss: 1.3829870223999023 / Matching loss: 3.7436930142575875e-05 / Item reconstruction: 0.0018368703313171864 / Text reconstruction: 0.0032456915359944105\n",
            "loss in epoch 9/21 iteration 8/67: 1.3841780424118042 / BPR loss: 1.3826395273208618 / Matching loss: 3.8310310628730804e-05 / Item reconstruction: 0.001751609263010323 / Text reconstruction: 0.003121812827885151\n",
            "loss in epoch 9/21 iteration 9/67: 1.3846060037612915 / BPR loss: 1.383122444152832 / Matching loss: 3.77663855033461e-05 / Item reconstruction: 0.0016613602638244629 / Text reconstruction: 0.003075515851378441\n",
            "loss in epoch 9/21 iteration 10/67: 1.384210467338562 / BPR loss: 1.3827425241470337 / Matching loss: 3.8163329008966684e-05 / Item reconstruction: 0.0016144287073984742 / Text reconstruction: 0.0031130495481193066\n",
            "loss in epoch 9/21 iteration 11/67: 1.3842660188674927 / BPR loss: 1.3828128576278687 / Matching loss: 3.528578599798493e-05 / Item reconstruction: 0.0016375475097447634 / Text reconstruction: 0.002995572052896023\n",
            "loss in epoch 9/21 iteration 12/67: 1.3842920064926147 / BPR loss: 1.3828498125076294 / Matching loss: 3.3453728974564e-05 / Item reconstruction: 0.0016566043486818671 / Text reconstruction: 0.0029021829832345247\n",
            "loss in epoch 9/21 iteration 13/67: 1.3840562105178833 / BPR loss: 1.382611632347107 / Matching loss: 3.4840435546357185e-05 / Item reconstruction: 0.0016469571273773909 / Text reconstruction: 0.0029315082356333733\n",
            "loss in epoch 9/21 iteration 14/67: 1.384321928024292 / BPR loss: 1.3828449249267578 / Matching loss: 3.800424747169018e-05 / Item reconstruction: 0.0017180241411551833 / Text reconstruction: 0.002899607177823782\n",
            "loss in epoch 9/21 iteration 15/67: 1.3842387199401855 / BPR loss: 1.382728099822998 / Matching loss: 3.8311911339405924e-05 / Item reconstruction: 0.0018251878209412098 / Text reconstruction: 0.0027992776595056057\n",
            "loss in epoch 9/21 iteration 16/67: 1.3840256929397583 / BPR loss: 1.382551670074463 / Matching loss: 3.7758036341983825e-05 / Item reconstruction: 0.001716341357678175 / Text reconstruction: 0.002890437375754118\n",
            "loss in epoch 9/21 iteration 17/67: 1.3843629360198975 / BPR loss: 1.3828891515731812 / Matching loss: 3.864951941068284e-05 / Item reconstruction: 0.00168123422190547 / Text reconstruction: 0.0029725427739322186\n",
            "loss in epoch 9/21 iteration 18/67: 1.387040376663208 / BPR loss: 1.385087013244629 / Matching loss: 4.605893627740443e-05 / Item reconstruction: 0.0024720141664147377 / Text reconstruction: 0.003357194596901536\n",
            "loss in epoch 9/21 iteration 19/67: 1.3882325887680054 / BPR loss: 1.3861075639724731 / Matching loss: 4.801440081791952e-05 / Item reconstruction: 0.0027761796955019236 / Text reconstruction: 0.0034447568468749523\n",
            "loss in epoch 9/21 iteration 20/67: 1.3881454467773438 / BPR loss: 1.3861048221588135 / Matching loss: 4.537306813290343e-05 / Item reconstruction: 0.002655290998518467 / Text reconstruction: 0.0033378133084625006\n",
            "loss in epoch 9/21 iteration 21/67: 1.3877369165420532 / BPR loss: 1.3857519626617432 / Matching loss: 5.086794408271089e-05 / Item reconstruction: 0.0025855726562440395 / Text reconstruction: 0.0032061575911939144\n",
            "loss in epoch 9/21 iteration 22/67: 1.3856446743011475 / BPR loss: 1.3839058876037598 / Matching loss: 3.960093454224989e-05 / Item reconstruction: 0.00220392644405365 / Text reconstruction: 0.0029862523078918457\n",
            "loss in epoch 9/21 iteration 23/67: 1.38516366481781 / BPR loss: 1.383516788482666 / Matching loss: 3.6946265026926994e-05 / Item reconstruction: 0.002110568806529045 / Text reconstruction: 0.0027735403273254633\n",
            "loss in epoch 9/21 iteration 24/67: 1.3854318857192993 / BPR loss: 1.3838038444519043 / Matching loss: 4.209616599837318e-05 / Item reconstruction: 0.0021314616315066814 / Text reconstruction: 0.002600865438580513\n",
            "loss in epoch 9/21 iteration 25/67: 1.3855090141296387 / BPR loss: 1.3839824199676514 / Matching loss: 3.691817255457863e-05 / Item reconstruction: 0.0020319519098848104 / Text reconstruction: 0.002367796842008829\n",
            "loss in epoch 9/21 iteration 26/67: 1.3852574825286865 / BPR loss: 1.3837207555770874 / Matching loss: 4.355566488811746e-05 / Item reconstruction: 0.0020343265496194363 / Text reconstruction: 0.0023799468763172626\n",
            "loss in epoch 9/21 iteration 27/67: 1.384926199913025 / BPR loss: 1.3835010528564453 / Matching loss: 3.4932727430714294e-05 / Item reconstruction: 0.001858542556874454 / Text reconstruction: 0.002304669236764312\n",
            "loss in epoch 9/21 iteration 28/67: 1.3850226402282715 / BPR loss: 1.3836463689804077 / Matching loss: 3.606819154811092e-05 / Item reconstruction: 0.0017919023521244526 / Text reconstruction: 0.0022206674329936504\n",
            "loss in epoch 9/21 iteration 29/67: 1.3849992752075195 / BPR loss: 1.3835694789886475 / Matching loss: 3.611505962908268e-05 / Item reconstruction: 0.0018390354234725237 / Text reconstruction: 0.0023712364491075277\n",
            "loss in epoch 9/21 iteration 30/67: 1.3849376440048218 / BPR loss: 1.3835151195526123 / Matching loss: 3.311972614028491e-05 / Item reconstruction: 0.0017426934791728854 / Text reconstruction: 0.002590627409517765\n",
            "loss in epoch 9/21 iteration 31/67: 1.3850209712982178 / BPR loss: 1.3835630416870117 / Matching loss: 3.695134000736289e-05 / Item reconstruction: 0.0017802383517846465 / Text reconstruction: 0.0026541168335825205\n",
            "loss in epoch 9/21 iteration 32/67: 1.384955883026123 / BPR loss: 1.3835725784301758 / Matching loss: 3.576255767256953e-05 / Item reconstruction: 0.0017120572738349438 / Text reconstruction: 0.002457513939589262\n",
            "loss in epoch 9/21 iteration 33/67: 1.3861489295959473 / BPR loss: 1.38430917263031 / Matching loss: 4.4325191993266344e-05 / Item reconstruction: 0.002527435775846243 / Text reconstruction: 0.0026586304884403944\n",
            "loss in epoch 9/21 iteration 34/67: 1.38747239112854 / BPR loss: 1.3856329917907715 / Matching loss: 3.8606511225225404e-05 / Item reconstruction: 0.002759626368060708 / Text reconstruction: 0.0021045878529548645\n",
            "loss in epoch 9/21 iteration 35/67: 1.3871350288391113 / BPR loss: 1.385373592376709 / Matching loss: 4.094230098417029e-05 / Item reconstruction: 0.002606852911412716 / Text reconstruction: 0.0020853965543210506\n",
            "loss in epoch 9/21 iteration 36/67: 1.387877345085144 / BPR loss: 1.3860771656036377 / Matching loss: 5.54143734916579e-05 / Item reconstruction: 0.0026664105243980885 / Text reconstruction: 0.002057841047644615\n",
            "loss in epoch 9/21 iteration 37/67: 1.3877371549606323 / BPR loss: 1.3859905004501343 / Matching loss: 5.650547973345965e-05 / Item reconstruction: 0.0025730496272444725 / Text reconstruction: 0.002018434228375554\n",
            "loss in epoch 9/21 iteration 38/67: 1.3873871564865112 / BPR loss: 1.3857672214508057 / Matching loss: 4.7444525989703834e-05 / Item reconstruction: 0.002473703818395734 / Text reconstruction: 0.001678265631198883\n",
            "loss in epoch 9/21 iteration 39/67: 1.3875304460525513 / BPR loss: 1.3859831094741821 / Matching loss: 4.7954068577382714e-05 / Item reconstruction: 0.0023495459463447332 / Text reconstruction: 0.0016227451851591468\n",
            "loss in epoch 9/21 iteration 40/67: 1.3875709772109985 / BPR loss: 1.386090636253357 / Matching loss: 5.473352939588949e-05 / Item reconstruction: 0.0022565433755517006 / Text reconstruction: 0.001486665103584528\n",
            "loss in epoch 9/21 iteration 41/67: 1.3861629962921143 / BPR loss: 1.3845748901367188 / Matching loss: 4.8975038225762546e-05 / Item reconstruction: 0.002272442914545536 / Text reconstruction: 0.0020145042799413204\n",
            "loss in epoch 9/21 iteration 42/67: 1.3848763704299927 / BPR loss: 1.3831592798233032 / Matching loss: 3.985709554399364e-05 / Item reconstruction: 0.0021636951714754105 / Text reconstruction: 0.002977171912789345\n",
            "loss in epoch 9/21 iteration 43/67: 1.3844707012176514 / BPR loss: 1.3826870918273926 / Matching loss: 3.8510690501425415e-05 / Item reconstruction: 0.002198784612119198 / Text reconstruction: 0.003229029942303896\n",
            "loss in epoch 9/21 iteration 44/67: 1.387182593345642 / BPR loss: 1.385711908340454 / Matching loss: 4.666895983973518e-05 / Item reconstruction: 0.002182324882596731 / Text reconstruction: 0.0016648469027131796\n",
            "loss in epoch 9/21 iteration 45/67: 1.3876559734344482 / BPR loss: 1.38624107837677 / Matching loss: 4.772377360495739e-05 / Item reconstruction: 0.002188007580116391 / Text reconstruction: 0.0013662229757755995\n",
            "loss in epoch 9/21 iteration 46/67: 1.3871735334396362 / BPR loss: 1.385565996170044 / Matching loss: 4.808766971109435e-05 / Item reconstruction: 0.0024719592183828354 / Text reconstruction: 0.001617557369172573\n",
            "loss in epoch 9/21 iteration 47/67: 1.3873440027236938 / BPR loss: 1.385711431503296 / Matching loss: 4.490611900109798e-05 / Item reconstruction: 0.002478542272001505 / Text reconstruction: 0.0017417072085663676\n",
            "loss in epoch 9/21 iteration 48/67: 1.3873119354248047 / BPR loss: 1.3858283758163452 / Matching loss: 3.985498915426433e-05 / Item reconstruction: 0.002182628959417343 / Text reconstruction: 0.001761929364874959\n",
            "loss in epoch 9/21 iteration 49/67: 1.3868050575256348 / BPR loss: 1.3852304220199585 / Matching loss: 3.944158015656285e-05 / Item reconstruction: 0.002149835927411914 / Text reconstruction: 0.0023012112360447645\n",
            "loss in epoch 9/21 iteration 50/67: 1.3868768215179443 / BPR loss: 1.3853485584259033 / Matching loss: 4.474123124964535e-05 / Item reconstruction: 0.0022238038945943117 / Text reconstruction: 0.0018587682861834764\n",
            "loss in epoch 9/21 iteration 51/67: 1.3875559568405151 / BPR loss: 1.386113166809082 / Matching loss: 4.781972529599443e-05 / Item reconstruction: 0.0022355043329298496 / Text reconstruction: 0.001386604504659772\n",
            "loss in epoch 9/21 iteration 52/67: 1.3877497911453247 / BPR loss: 1.386255145072937 / Matching loss: 4.199835893814452e-05 / Item reconstruction: 0.0022564763203263283 / Text reconstruction: 0.0016222940757870674\n",
            "loss in epoch 9/21 iteration 53/67: 1.3874880075454712 / BPR loss: 1.3860646486282349 / Matching loss: 4.4989694288233295e-05 / Item reconstruction: 0.0021157599985599518 / Text reconstruction: 0.0016030308324843645\n",
            "loss in epoch 9/21 iteration 54/67: 1.3876774311065674 / BPR loss: 1.3862892389297485 / Matching loss: 5.0117123464588076e-05 / Item reconstruction: 0.0021060174331068993 / Text reconstruction: 0.0014255257556214929\n",
            "loss in epoch 9/21 iteration 55/67: 1.3878709077835083 / BPR loss: 1.3864588737487793 / Matching loss: 4.749075014842674e-05 / Item reconstruction: 0.0021449802443385124 / Text reconstruction: 0.0014602732844650745\n",
            "loss in epoch 9/21 iteration 56/67: 1.3876639604568481 / BPR loss: 1.3862731456756592 / Matching loss: 5.2321251132525504e-05 / Item reconstruction: 0.0021715806797146797 / Text reconstruction: 0.001263829180970788\n",
            "loss in epoch 9/21 iteration 57/67: 1.3875640630722046 / BPR loss: 1.3862231969833374 / Matching loss: 4.327089118305594e-05 / Item reconstruction: 0.0020592808723449707 / Text reconstruction: 0.0013396621216088533\n",
            "loss in epoch 9/21 iteration 58/67: 1.3874362707138062 / BPR loss: 1.386124610900879 / Matching loss: 4.0516984881833196e-05 / Item reconstruction: 0.002012070268392563 / Text reconstruction: 0.0013253873912617564\n",
            "loss in epoch 9/21 iteration 59/67: 1.3876662254333496 / BPR loss: 1.386303186416626 / Matching loss: 4.6610824938397855e-05 / Item reconstruction: 0.0021535165142267942 / Text reconstruction: 0.0011982563883066177\n",
            "loss in epoch 9/21 iteration 60/67: 1.3877122402191162 / BPR loss: 1.386358380317688 / Matching loss: 4.334653203841299e-05 / Item reconstruction: 0.0020916806533932686 / Text reconstruction: 0.0013231851626187563\n",
            "loss in epoch 9/21 iteration 61/67: 1.3877019882202148 / BPR loss: 1.3863956928253174 / Matching loss: 4.347169669927098e-05 / Item reconstruction: 0.002017672173678875 / Text reconstruction: 0.001269729109480977\n",
            "loss in epoch 9/21 iteration 62/67: 1.3876316547393799 / BPR loss: 1.3862158060073853 / Matching loss: 3.857336560031399e-05 / Item reconstruction: 0.002097880467772484 / Text reconstruction: 0.0016412701224908233\n",
            "loss in epoch 9/21 iteration 63/67: 1.3875292539596558 / BPR loss: 1.386186957359314 / Matching loss: 5.106756725581363e-05 / Item reconstruction: 0.002174674067646265 / Text reconstruction: 0.0010197259252890944\n",
            "loss in epoch 9/21 iteration 64/67: 1.387656807899475 / BPR loss: 1.3863428831100464 / Matching loss: 4.7782981710042804e-05 / Item reconstruction: 0.0020975819788873196 / Text reconstruction: 0.0010864973301067948\n",
            "loss in epoch 9/21 iteration 65/67: 1.3876533508300781 / BPR loss: 1.3863499164581299 / Matching loss: 4.547303251456469e-05 / Item reconstruction: 0.002063196152448654 / Text reconstruction: 0.001131701748818159\n",
            "loss in epoch 9/21 iteration 66/67: 1.387596607208252 / BPR loss: 1.3864216804504395 / Matching loss: 3.460079460637644e-05 / Item reconstruction: 0.0017616823315620422 / Text reconstruction: 0.0012978147715330124\n",
            "loss in epoch 9/21 iteration 67/67: 1.3873084783554077 / BPR loss: 1.3862195014953613 / Matching loss: 2.8257700250833295e-05 / Item reconstruction: 0.0015462484443560243 / Text reconstruction: 0.001438060076907277\n",
            " 45% 9/20 [17:36<21:34, 117.71s/it]loss in epoch 10/21 iteration 0/67: 1.3874177932739258 / BPR loss: 1.3859388828277588 / Matching loss: 5.055110523244366e-05 / Item reconstruction: 0.0023631034418940544 / Text reconstruction: 0.0012336511863395572\n",
            "loss in epoch 10/21 iteration 1/67: 1.3858474493026733 / BPR loss: 1.3840234279632568 / Matching loss: 4.7065026592463255e-05 / Item reconstruction: 0.0022820935118943453 / Text reconstruction: 0.0031795166432857513\n",
            "loss in epoch 10/21 iteration 2/67: 1.3843927383422852 / BPR loss: 1.382590651512146 / Matching loss: 4.013955913251266e-05 / Item reconstruction: 0.002155053662136197 / Text reconstruction: 0.003421892412006855\n",
            "loss in epoch 10/21 iteration 3/67: 1.3839691877365112 / BPR loss: 1.3822124004364014 / Matching loss: 4.07832303608302e-05 / Item reconstruction: 0.002110190223902464 / Text reconstruction: 0.0033043823204934597\n",
            "loss in epoch 10/21 iteration 4/67: 1.383863925933838 / BPR loss: 1.3821971416473389 / Matching loss: 4.476227331906557e-05 / Item reconstruction: 0.0021197895985096693 / Text reconstruction: 0.0028110898565500975\n",
            "loss in epoch 10/21 iteration 5/67: 1.3837862014770508 / BPR loss: 1.3822357654571533 / Matching loss: 4.059469938511029e-05 / Item reconstruction: 0.0019941916689276695 / Text reconstruction: 0.002563747577369213\n",
            "loss in epoch 10/21 iteration 6/67: 1.3835620880126953 / BPR loss: 1.3821455240249634 / Matching loss: 3.6759567592525855e-05 / Item reconstruction: 0.00183037668466568 / Text reconstruction: 0.0023233420215547085\n",
            "loss in epoch 10/21 iteration 7/67: 1.3837077617645264 / BPR loss: 1.3823498487472534 / Matching loss: 3.3468397305114195e-05 / Item reconstruction: 0.0017854964826256037 / Text reconstruction: 0.0021583293564617634\n",
            "loss in epoch 10/21 iteration 8/67: 1.3831157684326172 / BPR loss: 1.3817870616912842 / Matching loss: 3.494682823657058e-05 / Item reconstruction: 0.001696825958788395 / Text reconstruction: 0.0022268667817115784\n",
            "loss in epoch 10/21 iteration 9/67: 1.3837943077087402 / BPR loss: 1.38249933719635 / Matching loss: 3.12575648422353e-05 / Item reconstruction: 0.001604934222996235 / Text reconstruction: 0.002305885311216116\n",
            "loss in epoch 10/21 iteration 10/67: 1.3832460641860962 / BPR loss: 1.3819363117218018 / Matching loss: 3.463735993136652e-05 / Item reconstruction: 0.0015989351086318493 / Text reconstruction: 0.0023782127536833286\n",
            "loss in epoch 10/21 iteration 11/67: 1.3831707239151 / BPR loss: 1.3818724155426025 / Matching loss: 3.3752803574316204e-05 / Item reconstruction: 0.0015462815063074231 / Text reconstruction: 0.002456767950206995\n",
            "loss in epoch 10/21 iteration 12/67: 1.3835620880126953 / BPR loss: 1.3822128772735596 / Matching loss: 3.447314884397201e-05 / Item reconstruction: 0.001717111561447382 / Text reconstruction: 0.002281059045344591\n",
            "loss in epoch 10/21 iteration 13/67: 1.3834786415100098 / BPR loss: 1.382117509841919 / Matching loss: 3.441966691752896e-05 / Item reconstruction: 0.0017442373791709542 / Text reconstruction: 0.0022730203345417976\n",
            "loss in epoch 10/21 iteration 14/67: 1.3832849264144897 / BPR loss: 1.3820183277130127 / Matching loss: 3.17047415592242e-05 / Item reconstruction: 0.0016393354162573814 / Text reconstruction: 0.002076114062219858\n",
            "loss in epoch 10/21 iteration 15/67: 1.3834307193756104 / BPR loss: 1.3821613788604736 / Matching loss: 3.128112439299002e-05 / Item reconstruction: 0.0016321486327797174 / Text reconstruction: 0.002109779976308346\n",
            "loss in epoch 10/21 iteration 16/67: 1.3830803632736206 / BPR loss: 1.3817805051803589 / Matching loss: 3.574909715098329e-05 / Item reconstruction: 0.0017565294401720166 / Text reconstruction: 0.00192922237329185\n",
            "loss in epoch 10/21 iteration 17/67: 1.383270502090454 / BPR loss: 1.38201904296875 / Matching loss: 3.3691732824081555e-05 / Item reconstruction: 0.001643323339521885 / Text reconstruction: 0.001979994121938944\n",
            "loss in epoch 10/21 iteration 18/67: 1.3868054151535034 / BPR loss: 1.3849977254867554 / Matching loss: 4.230555350659415e-05 / Item reconstruction: 0.0024956688284873962 / Text reconstruction: 0.002587562659755349\n",
            "loss in epoch 10/21 iteration 19/67: 1.3881653547286987 / BPR loss: 1.3861002922058105 / Matching loss: 4.781591997016221e-05 / Item reconstruction: 0.0027781063690781593 / Text reconstruction: 0.003141441149637103\n",
            "loss in epoch 10/21 iteration 20/67: 1.3880139589309692 / BPR loss: 1.3861383199691772 / Matching loss: 4.526827615336515e-05 / Item reconstruction: 0.0026405886746942997 / Text reconstruction: 0.002550684381276369\n",
            "loss in epoch 10/21 iteration 21/67: 1.3872355222702026 / BPR loss: 1.3855242729187012 / Matching loss: 4.747270213556476e-05 / Item reconstruction: 0.0024972353130578995 / Text reconstruction: 0.0020761338528245687\n",
            "loss in epoch 10/21 iteration 22/67: 1.384562373161316 / BPR loss: 1.383013129234314 / Matching loss: 3.591565473470837e-05 / Item reconstruction: 0.002221041126176715 / Text reconstruction: 0.0020137864630669355\n",
            "loss in epoch 10/21 iteration 23/67: 1.3843915462493896 / BPR loss: 1.3829345703125 / Matching loss: 3.163677320117131e-05 / Item reconstruction: 0.002042788080871105 / Text reconstruction: 0.002019928302615881\n",
            "loss in epoch 10/21 iteration 24/67: 1.384514570236206 / BPR loss: 1.3830255270004272 / Matching loss: 3.5089200537186116e-05 / Item reconstruction: 0.0020678103901445866 / Text reconstruction: 0.0021001920104026794\n",
            "loss in epoch 10/21 iteration 25/67: 1.3844497203826904 / BPR loss: 1.3830851316452026 / Matching loss: 3.2077645300887525e-05 / Item reconstruction: 0.0019069160334765911 / Text reconstruction: 0.0018956770654767752\n",
            "loss in epoch 10/21 iteration 26/67: 1.3845629692077637 / BPR loss: 1.3831961154937744 / Matching loss: 3.236039628973231e-05 / Item reconstruction: 0.001944714691489935 / Text reconstruction: 0.0018110006349161267\n",
            "loss in epoch 10/21 iteration 27/67: 1.3841252326965332 / BPR loss: 1.3827776908874512 / Matching loss: 3.351692430442199e-05 / Item reconstruction: 0.0018796250224113464 / Text reconstruction: 0.0018708851421251893\n",
            "loss in epoch 10/21 iteration 28/67: 1.3841866254806519 / BPR loss: 1.3829002380371094 / Matching loss: 3.184637171216309e-05 / Item reconstruction: 0.001812837552279234 / Text reconstruction: 0.001740194740705192\n",
            "loss in epoch 10/21 iteration 29/67: 1.3844128847122192 / BPR loss: 1.38313889503479 / Matching loss: 3.1641768146073446e-05 / Item reconstruction: 0.0017683084588497877 / Text reconstruction: 0.0017912178300321102\n",
            "loss in epoch 10/21 iteration 30/67: 1.3842560052871704 / BPR loss: 1.3829957246780396 / Matching loss: 2.9860393624403514e-05 / Item reconstruction: 0.0017682418692857027 / Text reconstruction: 0.0017312555573880672\n",
            "loss in epoch 10/21 iteration 31/67: 1.3846759796142578 / BPR loss: 1.3834805488586426 / Matching loss: 3.060737799387425e-05 / Item reconstruction: 0.001675074570812285 / Text reconstruction: 0.0016359470319002867\n",
            "loss in epoch 10/21 iteration 32/67: 1.3842347860336304 / BPR loss: 1.3830814361572266 / Matching loss: 3.058390211663209e-05 / Item reconstruction: 0.0016183089464902878 / Text reconstruction: 0.0015676261391490698\n",
            "loss in epoch 10/21 iteration 33/67: 1.3854353427886963 / BPR loss: 1.3837319612503052 / Matching loss: 3.761857806239277e-05 / Item reconstruction: 0.0024839628022164106 / Text reconstruction: 0.002119240816682577\n",
            "loss in epoch 10/21 iteration 34/67: 1.3872674703598022 / BPR loss: 1.3855552673339844 / Matching loss: 3.6666700907517225e-05 / Item reconstruction: 0.0027088094502687454 / Text reconstruction: 0.0016052676364779472\n",
            "loss in epoch 10/21 iteration 35/67: 1.386459469795227 / BPR loss: 1.3848388195037842 / Matching loss: 3.818651748588309e-05 / Item reconstruction: 0.002586867194622755 / Text reconstruction: 0.001445618225261569\n",
            "loss in epoch 10/21 iteration 36/67: 1.3875367641448975 / BPR loss: 1.385925054550171 / Matching loss: 4.454534064279869e-05 / Item reconstruction: 0.0025576131884008646 / Text reconstruction: 0.0014417547499760985\n",
            "loss in epoch 10/21 iteration 37/67: 1.3876556158065796 / BPR loss: 1.3859977722167969 / Matching loss: 5.1733564760070294e-05 / Item reconstruction: 0.0025736307725310326 / Text reconstruction: 0.001596322632394731\n",
            "loss in epoch 10/21 iteration 38/67: 1.387022852897644 / BPR loss: 1.3855303525924683 / Matching loss: 4.161756805842742e-05 / Item reconstruction: 0.002447469625622034 / Text reconstruction: 0.00113590934779495\n",
            "loss in epoch 10/21 iteration 39/67: 1.3872631788253784 / BPR loss: 1.3858388662338257 / Matching loss: 4.343612818047404e-05 / Item reconstruction: 0.0023355018347501755 / Text reconstruction: 0.0010655558435246348\n",
            "loss in epoch 10/21 iteration 40/67: 1.3872491121292114 / BPR loss: 1.3858572244644165 / Matching loss: 4.96661668876186e-05 / Item reconstruction: 0.002309755887836218 / Text reconstruction: 0.0009365446167066693\n",
            "loss in epoch 10/21 iteration 41/67: 1.3860678672790527 / BPR loss: 1.3846237659454346 / Matching loss: 4.1754537960514426e-05 / Item reconstruction: 0.0022217980585992336 / Text reconstruction: 0.001457406673580408\n",
            "loss in epoch 10/21 iteration 42/67: 1.3838049173355103 / BPR loss: 1.3821930885314941 / Matching loss: 3.3731135772541165e-05 / Item reconstruction: 0.002146594226360321 / Text reconstruction: 0.0025242604315280914\n",
            "loss in epoch 10/21 iteration 43/67: 1.3834483623504639 / BPR loss: 1.3819117546081543 / Matching loss: 3.43415595125407e-05 / Item reconstruction: 0.0019688711035996675 / Text reconstruction: 0.002588937757536769\n",
            "loss in epoch 10/21 iteration 44/67: 1.3870019912719727 / BPR loss: 1.3856720924377441 / Matching loss: 4.1867759136948735e-05 / Item reconstruction: 0.0021929363720119 / Text reconstruction: 0.0009581252234056592\n",
            "loss in epoch 10/21 iteration 45/67: 1.3874270915985107 / BPR loss: 1.3861169815063477 / Matching loss: 4.768756843986921e-05 / Item reconstruction: 0.0022184806875884533 / Text reconstruction: 0.0007662073476240039\n",
            "loss in epoch 10/21 iteration 46/67: 1.3870304822921753 / BPR loss: 1.3855209350585938 / Matching loss: 3.6629437090596184e-05 / Item reconstruction: 0.0024644932709634304 / Text reconstruction: 0.0012037149863317609\n",
            "loss in epoch 10/21 iteration 47/67: 1.3871606588363647 / BPR loss: 1.3856149911880493 / Matching loss: 3.909672886948101e-05 / Item reconstruction: 0.0024818405508995056 / Text reconstruction: 0.0013281212886795402\n",
            "loss in epoch 10/21 iteration 48/67: 1.3871129751205444 / BPR loss: 1.385697364807129 / Matching loss: 4.031572461826727e-05 / Item reconstruction: 0.0022385013289749622 / Text reconstruction: 0.0012800786644220352\n",
            "loss in epoch 10/21 iteration 49/67: 1.3866500854492188 / BPR loss: 1.385246753692627 / Matching loss: 3.7105415685800835e-05 / Item reconstruction: 0.0021960039157420397 / Text reconstruction: 0.001341361436061561\n",
            "loss in epoch 10/21 iteration 50/67: 1.386687994003296 / BPR loss: 1.3852689266204834 / Matching loss: 4.475649620871991e-05 / Item reconstruction: 0.0022670081816613674 / Text reconstruction: 0.001203947700560093\n",
            "loss in epoch 10/21 iteration 51/67: 1.3876328468322754 / BPR loss: 1.3862760066986084 / Matching loss: 4.8352278099628165e-05 / Item reconstruction: 0.002298475243151188 / Text reconstruction: 0.0007957371417433023\n",
            "loss in epoch 10/21 iteration 52/67: 1.387486219406128 / BPR loss: 1.386103868484497 / Matching loss: 3.960934191127308e-05 / Item reconstruction: 0.002274302765727043 / Text reconstruction: 0.0010280804708600044\n",
            "loss in epoch 10/21 iteration 53/67: 1.3874168395996094 / BPR loss: 1.3861067295074463 / Matching loss: 3.967498196288943e-05 / Item reconstruction: 0.0021228177938610315 / Text reconstruction: 0.001044894102960825\n",
            "loss in epoch 10/21 iteration 54/67: 1.3875259160995483 / BPR loss: 1.3862643241882324 / Matching loss: 4.78867586934939e-05 / Item reconstruction: 0.0021065305918455124 / Text reconstruction: 0.0008023432455956936\n",
            "loss in epoch 10/21 iteration 55/67: 1.3876903057098389 / BPR loss: 1.3864048719406128 / Matching loss: 4.567623545881361e-05 / Item reconstruction: 0.002145176287740469 / Text reconstruction: 0.0008358891354873776\n",
            "loss in epoch 10/21 iteration 56/67: 1.3876208066940308 / BPR loss: 1.3863286972045898 / Matching loss: 4.7400830226251855e-05 / Item reconstruction: 0.002214194042608142 / Text reconstruction: 0.0006877786945551634\n",
            "loss in epoch 10/21 iteration 57/67: 1.3873940706253052 / BPR loss: 1.3862022161483765 / Matching loss: 3.841831858153455e-05 / Item reconstruction: 0.002005527028813958 / Text reconstruction: 0.0007534438045695424\n",
            "loss in epoch 10/21 iteration 58/67: 1.3874391317367554 / BPR loss: 1.386255145072937 / Matching loss: 3.977416781708598e-05 / Item reconstruction: 0.0019908177200704813 / Text reconstruction: 0.0007436294690705836\n",
            "loss in epoch 10/21 iteration 59/67: 1.3873639106750488 / BPR loss: 1.386144757270813 / Matching loss: 4.382517363410443e-05 / Item reconstruction: 0.002085471525788307 / Text reconstruction: 0.0006626540562137961\n",
            "loss in epoch 10/21 iteration 60/67: 1.3876100778579712 / BPR loss: 1.3864059448242188 / Matching loss: 3.978081076638773e-05 / Item reconstruction: 0.0020326045341789722 / Text reconstruction: 0.0007405356736853719\n",
            "loss in epoch 10/21 iteration 61/67: 1.387520432472229 / BPR loss: 1.3863208293914795 / Matching loss: 4.115005867788568e-05 / Item reconstruction: 0.002028712769970298 / Text reconstruction: 0.0007206967566162348\n",
            "loss in epoch 10/21 iteration 62/67: 1.3873118162155151 / BPR loss: 1.386033296585083 / Matching loss: 3.28538881149143e-05 / Item reconstruction: 0.00208930391818285 / Text reconstruction: 0.0010051506105810404\n",
            "loss in epoch 10/21 iteration 63/67: 1.387531042098999 / BPR loss: 1.3862546682357788 / Matching loss: 4.7126934077823535e-05 / Item reconstruction: 0.0022425446659326553 / Text reconstruction: 0.0005398218054324389\n",
            "loss in epoch 10/21 iteration 64/67: 1.3874850273132324 / BPR loss: 1.3862849473953247 / Matching loss: 4.348513903096318e-05 / Item reconstruction: 0.002064793137833476 / Text reconstruction: 0.0006212664302438498\n",
            "loss in epoch 10/21 iteration 65/67: 1.3874183893203735 / BPR loss: 1.3861849308013916 / Matching loss: 4.416738738655113e-05 / Item reconstruction: 0.0021121655590832233 / Text reconstruction: 0.0006658475613221526\n",
            "loss in epoch 10/21 iteration 66/67: 1.3873822689056396 / BPR loss: 1.386314868927002 / Matching loss: 3.3046519092749804e-05 / Item reconstruction: 0.0017654621042311192 / Text reconstruction: 0.0007579019293189049\n",
            "loss in epoch 10/21 iteration 67/67: 1.3872722387313843 / BPR loss: 1.3862872123718262 / Matching loss: 2.608379872981459e-05 / Item reconstruction: 0.001554802292957902 / Text reconstruction: 0.0009075289708562195\n",
            " 50% 10/20 [19:37<19:48, 118.86s/it]loss in epoch 11/21 iteration 0/67: 1.3872395753860474 / BPR loss: 1.3858389854431152 / Matching loss: 5.457269071484916e-05 / Item reconstruction: 0.00240523973479867 / Text reconstruction: 0.000717263319529593\n",
            "loss in epoch 11/21 iteration 1/67: 1.3856161832809448 / BPR loss: 1.383876085281372 / Matching loss: 4.53375032520853e-05 / Item reconstruction: 0.002304281573742628 / Text reconstruction: 0.002713350113481283\n",
            "loss in epoch 11/21 iteration 2/67: 1.3837575912475586 / BPR loss: 1.3819808959960938 / Matching loss: 3.790014670812525e-05 / Item reconstruction: 0.0021581046748906374 / Text reconstruction: 0.0032982362899929285\n",
            "loss in epoch 11/21 iteration 3/67: 1.3831084966659546 / BPR loss: 1.381467580795288 / Matching loss: 3.611858483054675e-05 / Item reconstruction: 0.0019906042143702507 / Text reconstruction: 0.00304745533503592\n",
            "loss in epoch 11/21 iteration 4/67: 1.3827600479125977 / BPR loss: 1.3812031745910645 / Matching loss: 4.242931754561141e-05 / Item reconstruction: 0.0019795456901192665 / Text reconstruction: 0.002623449545353651\n",
            "loss in epoch 11/21 iteration 5/67: 1.382935643196106 / BPR loss: 1.3814691305160522 / Matching loss: 3.7790472561027855e-05 / Item reconstruction: 0.0019028510432690382 / Text reconstruction: 0.0023863636888563633\n",
            "loss in epoch 11/21 iteration 6/67: 1.382870078086853 / BPR loss: 1.3815114498138428 / Matching loss: 3.597736213123426e-05 / Item reconstruction: 0.001764507032930851 / Text reconstruction: 0.0022017150186002254\n",
            "loss in epoch 11/21 iteration 7/67: 1.3824725151062012 / BPR loss: 1.3811753988265991 / Matching loss: 3.510537135298364e-05 / Item reconstruction: 0.001726104412227869 / Text reconstruction: 0.0019951758440583944\n",
            "loss in epoch 11/21 iteration 8/67: 1.3823350667953491 / BPR loss: 1.3810539245605469 / Matching loss: 3.4155516914324835e-05 / Item reconstruction: 0.0016570319421589375 / Text reconstruction: 0.0020923828706145287\n",
            "loss in epoch 11/21 iteration 9/67: 1.3829690217971802 / BPR loss: 1.3817228078842163 / Matching loss: 3.432573066675104e-05 / Item reconstruction: 0.001608672784641385 / Text reconstruction: 0.0020378627814352512\n",
            "loss in epoch 11/21 iteration 10/67: 1.3825539350509644 / BPR loss: 1.3813116550445557 / Matching loss: 3.2656200346536934e-05 / Item reconstruction: 0.0015481830341741443 / Text reconstruction: 0.00217730225995183\n",
            "loss in epoch 11/21 iteration 11/67: 1.3821942806243896 / BPR loss: 1.3809945583343506 / Matching loss: 3.013396963069681e-05 / Item reconstruction: 0.0015218995977193117 / Text reconstruction: 0.002043125219643116\n",
            "loss in epoch 11/21 iteration 12/67: 1.3827931880950928 / BPR loss: 1.3814971446990967 / Matching loss: 3.394181840121746e-05 / Item reconstruction: 0.001744257053360343 / Text reconstruction: 0.0019496099557727575\n",
            "loss in epoch 11/21 iteration 13/67: 1.382224678993225 / BPR loss: 1.3810150623321533 / Matching loss: 3.31581431964878e-05 / Item reconstruction: 0.00160115584731102 / Text reconstruction: 0.0018796063959598541\n",
            "loss in epoch 11/21 iteration 14/67: 1.3827728033065796 / BPR loss: 1.381490707397461 / Matching loss: 3.4228418371640146e-05 / Item reconstruction: 0.0016896020388230681 / Text reconstruction: 0.002015124773606658\n",
            "loss in epoch 11/21 iteration 15/67: 1.3827786445617676 / BPR loss: 1.3815404176712036 / Matching loss: 3.17445483233314e-05 / Item reconstruction: 0.0016537860501557589 / Text reconstruction: 0.0018986437935382128\n",
            "loss in epoch 11/21 iteration 16/67: 1.3819433450698853 / BPR loss: 1.3807604312896729 / Matching loss: 3.177184407832101e-05 / Item reconstruction: 0.0015524656046181917 / Text reconstruction: 0.0018738454673439264\n",
            "loss in epoch 11/21 iteration 17/67: 1.3820281028747559 / BPR loss: 1.380856990814209 / Matching loss: 3.214014941477217e-05 / Item reconstruction: 0.0015522685134783387 / Text reconstruction: 0.0018136989092454314\n",
            "loss in epoch 11/21 iteration 18/67: 1.3864856958389282 / BPR loss: 1.3847663402557373 / Matching loss: 4.484543023863807e-05 / Item reconstruction: 0.002432649489492178 / Text reconstruction: 0.002291128970682621\n",
            "loss in epoch 11/21 iteration 19/67: 1.3881326913833618 / BPR loss: 1.3861993551254272 / Matching loss: 4.2152940295636654e-05 / Item reconstruction: 0.002656863536685705 / Text reconstruction: 0.002813598606735468\n",
            "loss in epoch 11/21 iteration 20/67: 1.3877843618392944 / BPR loss: 1.3859387636184692 / Matching loss: 4.360172897577286e-05 / Item reconstruction: 0.002585416194051504 / Text reconstruction: 0.002546524628996849\n",
            "loss in epoch 11/21 iteration 21/67: 1.3871452808380127 / BPR loss: 1.3854262828826904 / Matching loss: 4.406252264743671e-05 / Item reconstruction: 0.002463942626491189 / Text reconstruction: 0.002214228268712759\n",
            "loss in epoch 11/21 iteration 22/67: 1.383886456489563 / BPR loss: 1.382462501525879 / Matching loss: 3.461737651377916e-05 / Item reconstruction: 0.002142460085451603 / Text reconstruction: 0.0015907862689346075\n",
            "loss in epoch 11/21 iteration 23/67: 1.3836922645568848 / BPR loss: 1.3823848962783813 / Matching loss: 3.164715599268675e-05 / Item reconstruction: 0.00194075470790267 / Text reconstruction: 0.0015270572621375322\n",
            "loss in epoch 11/21 iteration 24/67: 1.384142279624939 / BPR loss: 1.382800817489624 / Matching loss: 3.3051397622330114e-05 / Item reconstruction: 0.0019675930961966515 / Text reconstruction: 0.0016228228341788054\n",
            "loss in epoch 11/21 iteration 25/67: 1.3839303255081177 / BPR loss: 1.382619023323059 / Matching loss: 3.344361903145909e-05 / Item reconstruction: 0.0019172433530911803 / Text reconstruction: 0.0015954216942191124\n",
            "loss in epoch 11/21 iteration 26/67: 1.3835341930389404 / BPR loss: 1.3822426795959473 / Matching loss: 3.170803393004462e-05 / Item reconstruction: 0.0018911294173449278 / Text reconstruction: 0.0015712827444076538\n",
            "loss in epoch 11/21 iteration 27/67: 1.3836698532104492 / BPR loss: 1.3824052810668945 / Matching loss: 3.0028215405764058e-05 / Item reconstruction: 0.0017914075870066881 / Text reconstruction: 0.0016937708714976907\n",
            "loss in epoch 11/21 iteration 28/67: 1.3839188814163208 / BPR loss: 1.3826817274093628 / Matching loss: 2.9961462132632732e-05 / Item reconstruction: 0.001771159004420042 / Text reconstruction: 0.001608314923942089\n",
            "loss in epoch 11/21 iteration 29/67: 1.3834117650985718 / BPR loss: 1.3822228908538818 / Matching loss: 2.7589136152528226e-05 / Item reconstruction: 0.0016528187552466989 / Text reconstruction: 0.0016747387126088142\n",
            "loss in epoch 11/21 iteration 30/67: 1.3834753036499023 / BPR loss: 1.3822749853134155 / Matching loss: 2.8414602638804354e-05 / Item reconstruction: 0.001705678179860115 / Text reconstruction: 0.0015957857249304652\n",
            "loss in epoch 11/21 iteration 31/67: 1.3834693431854248 / BPR loss: 1.3822991847991943 / Matching loss: 2.751573993009515e-05 / Item reconstruction: 0.0016760185826569796 / Text reconstruction: 0.001523106242530048\n",
            "loss in epoch 11/21 iteration 32/67: 1.3838247060775757 / BPR loss: 1.3827632665634155 / Matching loss: 2.6970237740897574e-05 / Item reconstruction: 0.0015275421319529414 / Text reconstruction: 0.0013538203202188015\n",
            "loss in epoch 11/21 iteration 33/67: 1.385151982307434 / BPR loss: 1.383504867553711 / Matching loss: 3.419103813939728e-05 / Item reconstruction: 0.0025041531771421432 / Text reconstruction: 0.0018042208394035697\n",
            "loss in epoch 11/21 iteration 34/67: 1.3870055675506592 / BPR loss: 1.385382890701294 / Matching loss: 2.9923819965915754e-05 / Item reconstruction: 0.002625043038278818 / Text reconstruction: 0.0014010928571224213\n",
            "loss in epoch 11/21 iteration 35/67: 1.3866628408432007 / BPR loss: 1.3850170373916626 / Matching loss: 3.274865593994036e-05 / Item reconstruction: 0.0025747246108949184 / Text reconstruction: 0.0016282401047647\n",
            "loss in epoch 11/21 iteration 36/67: 1.3874258995056152 / BPR loss: 1.385807752609253 / Matching loss: 4.442642966751009e-05 / Item reconstruction: 0.0025945995002985 / Text reconstruction: 0.0013818766456097364\n",
            "loss in epoch 11/21 iteration 37/67: 1.3872430324554443 / BPR loss: 1.3857133388519287 / Matching loss: 4.789126251125708e-05 / Item reconstruction: 0.0025550825521349907 / Text reconstruction: 0.0010212500346824527\n",
            "loss in epoch 11/21 iteration 38/67: 1.3868234157562256 / BPR loss: 1.3854188919067383 / Matching loss: 4.039575287606567e-05 / Item reconstruction: 0.0023813920561224222 / Text reconstruction: 0.0008671719115227461\n",
            "loss in epoch 11/21 iteration 39/67: 1.3872907161712646 / BPR loss: 1.3858963251113892 / Matching loss: 4.0677652577869594e-05 / Item reconstruction: 0.0022982051596045494 / Text reconstruction: 0.001023591379635036\n",
            "loss in epoch 11/21 iteration 40/67: 1.387305498123169 / BPR loss: 1.385949730873108 / Matching loss: 4.633729986380786e-05 / Item reconstruction: 0.0022774855606257915 / Text reconstruction: 0.0008537009125575423\n",
            "loss in epoch 11/21 iteration 41/67: 1.3855037689208984 / BPR loss: 1.3841350078582764 / Matching loss: 4.003391950391233e-05 / Item reconstruction: 0.0021479157730937004 / Text reconstruction: 0.00127353984862566\n",
            "loss in epoch 11/21 iteration 42/67: 1.382893443107605 / BPR loss: 1.3813471794128418 / Matching loss: 3.060975359403528e-05 / Item reconstruction: 0.0020373095758259296 / Text reconstruction: 0.00248509319499135\n",
            "loss in epoch 11/21 iteration 43/67: 1.3824187517166138 / BPR loss: 1.380871057510376 / Matching loss: 3.404742892598733e-05 / Item reconstruction: 0.0019794234540313482 / Text reconstruction: 0.0026196695398539305\n",
            "loss in epoch 11/21 iteration 44/67: 1.3865301609039307 / BPR loss: 1.3852639198303223 / Matching loss: 3.726589784491807e-05 / Item reconstruction: 0.0021293656900525093 / Text reconstruction: 0.0008212677203118801\n",
            "loss in epoch 11/21 iteration 45/67: 1.3873155117034912 / BPR loss: 1.3860673904418945 / Matching loss: 4.090462971362285e-05 / Item reconstruction: 0.0021621352061629295 / Text reconstruction: 0.0006303913542069495\n",
            "loss in epoch 11/21 iteration 46/67: 1.3867255449295044 / BPR loss: 1.3852324485778809 / Matching loss: 3.5251068766228855e-05 / Item reconstruction: 0.002431020140647888 / Text reconstruction: 0.00121157499961555\n",
            "loss in epoch 11/21 iteration 47/67: 1.386824131011963 / BPR loss: 1.3853085041046143 / Matching loss: 3.2529307645745575e-05 / Item reconstruction: 0.002485236618667841 / Text reconstruction: 0.0012020082212984562\n",
            "loss in epoch 11/21 iteration 48/67: 1.3871177434921265 / BPR loss: 1.3857660293579102 / Matching loss: 3.504180858726613e-05 / Item reconstruction: 0.0022255205549299717 / Text reconstruction: 0.001019301824271679\n",
            "loss in epoch 11/21 iteration 49/67: 1.3860504627227783 / BPR loss: 1.384621024131775 / Matching loss: 3.8591562770307064e-05 / Item reconstruction: 0.0022748096380382776 / Text reconstruction: 0.0012670147698372602\n",
            "loss in epoch 11/21 iteration 50/67: 1.3864920139312744 / BPR loss: 1.3851275444030762 / Matching loss: 3.899914736393839e-05 / Item reconstruction: 0.0022286514285951853 / Text reconstruction: 0.0010557606583461165\n",
            "loss in epoch 11/21 iteration 51/67: 1.387373924255371 / BPR loss: 1.386049509048462 / Matching loss: 4.950541188009083e-05 / Item reconstruction: 0.002282142173498869 / Text reconstruction: 0.0006695553311146796\n",
            "loss in epoch 11/21 iteration 52/67: 1.3874460458755493 / BPR loss: 1.3860939741134644 / Matching loss: 4.0923841879703104e-05 / Item reconstruction: 0.0022317124530673027 / Text reconstruction: 0.0009771675104275346\n",
            "loss in epoch 11/21 iteration 53/67: 1.3871376514434814 / BPR loss: 1.3857841491699219 / Matching loss: 3.89840170100797e-05 / Item reconstruction: 0.00224279030226171 / Text reconstruction: 0.0009653093293309212\n",
            "loss in epoch 11/21 iteration 54/67: 1.387539029121399 / BPR loss: 1.3862724304199219 / Matching loss: 4.56971101812087e-05 / Item reconstruction: 0.002142814453691244 / Text reconstruction: 0.0007472049328498542\n",
            "loss in epoch 11/21 iteration 55/67: 1.3876157999038696 / BPR loss: 1.386369228363037 / Matching loss: 3.975941945100203e-05 / Item reconstruction: 0.00213695433922112 / Text reconstruction: 0.0006913876859471202\n",
            "loss in epoch 11/21 iteration 56/67: 1.3876409530639648 / BPR loss: 1.3863871097564697 / Matching loss: 4.675578747992404e-05 / Item reconstruction: 0.0021889840718358755 / Text reconstruction: 0.0005630812374874949\n",
            "loss in epoch 11/21 iteration 57/67: 1.3873562812805176 / BPR loss: 1.3862028121948242 / Matching loss: 3.576929884729907e-05 / Item reconstruction: 0.001971212215721607 / Text reconstruction: 0.000660205667372793\n",
            "loss in epoch 11/21 iteration 58/67: 1.3874280452728271 / BPR loss: 1.3862524032592773 / Matching loss: 3.936226130463183e-05 / Item reconstruction: 0.0020314729772508144 / Text reconstruction: 0.0006028759526088834\n",
            "loss in epoch 11/21 iteration 59/67: 1.3872721195220947 / BPR loss: 1.3860820531845093 / Matching loss: 4.111674934392795e-05 / Item reconstruction: 0.002101283986121416 / Text reconstruction: 0.0004919359344057739\n",
            "loss in epoch 11/21 iteration 60/67: 1.3876094818115234 / BPR loss: 1.3864198923110962 / Matching loss: 3.9740087231621146e-05 / Item reconstruction: 0.002067619701847434 / Text reconstruction: 0.0005805377149954438\n",
            "loss in epoch 11/21 iteration 61/67: 1.3876721858978271 / BPR loss: 1.3865156173706055 / Matching loss: 3.7797741242684424e-05 / Item reconstruction: 0.0020112991333007812 / Text reconstruction: 0.0005653804983012378\n",
            "loss in epoch 11/21 iteration 62/67: 1.3871935606002808 / BPR loss: 1.3859589099884033 / Matching loss: 3.041367199330125e-05 / Item reconstruction: 0.0020571276545524597 / Text reconstruction: 0.000878277700394392\n",
            "loss in epoch 11/21 iteration 63/67: 1.3876672983169556 / BPR loss: 1.3864049911499023 / Matching loss: 4.8334630264434963e-05 / Item reconstruction: 0.002245828043669462 / Text reconstruction: 0.0004554163897410035\n",
            "loss in epoch 11/21 iteration 64/67: 1.3874316215515137 / BPR loss: 1.3862204551696777 / Matching loss: 4.49048493464943e-05 / Item reconstruction: 0.0021448954939842224 / Text reconstruction: 0.00046927493531256914\n",
            "loss in epoch 11/21 iteration 65/67: 1.387426733970642 / BPR loss: 1.386265754699707 / Matching loss: 4.140165037824772e-05 / Item reconstruction: 0.002010755706578493 / Text reconstruction: 0.000571256154216826\n",
            "loss in epoch 11/21 iteration 66/67: 1.3873075246810913 / BPR loss: 1.3862578868865967 / Matching loss: 3.0970099032856524e-05 / Item reconstruction: 0.001738758641295135 / Text reconstruction: 0.0007464060327038169\n",
            "loss in epoch 11/21 iteration 67/67: 1.3874199390411377 / BPR loss: 1.3864175081253052 / Matching loss: 2.9526909202104434e-05 / Item reconstruction: 0.0016166542191058397 / Text reconstruction: 0.0008226656354963779\n",
            " 55% 11/20 [21:38<17:54, 119.42s/it]loss in epoch 12/21 iteration 0/67: 1.3871532678604126 / BPR loss: 1.3857228755950928 / Matching loss: 4.8503563448321074e-05 / Item reconstruction: 0.0023865962866693735 / Text reconstruction: 0.0009431155631318688\n",
            "loss in epoch 12/21 iteration 1/67: 1.3850327730178833 / BPR loss: 1.3834043741226196 / Matching loss: 3.812120121438056e-05 / Item reconstruction: 0.0022055930458009243 / Text reconstruction: 0.0024370159953832626\n",
            "loss in epoch 12/21 iteration 2/67: 1.382775068283081 / BPR loss: 1.3810417652130127 / Matching loss: 3.734758502105251e-05 / Item reconstruction: 0.0021404195576906204 / Text reconstruction: 0.0031284275464713573\n",
            "loss in epoch 12/21 iteration 3/67: 1.382353663444519 / BPR loss: 1.3807408809661865 / Matching loss: 3.4325752494623885e-05 / Item reconstruction: 0.0019371327944099903 / Text reconstruction: 0.003049177350476384\n",
            "loss in epoch 12/21 iteration 4/67: 1.3815315961837769 / BPR loss: 1.3800034523010254 / Matching loss: 3.900034062098712e-05 / Item reconstruction: 0.00191270571667701 / Text reconstruction: 0.002664468251168728\n",
            "loss in epoch 12/21 iteration 5/67: 1.3818901777267456 / BPR loss: 1.380464792251587 / Matching loss: 3.6373927287058905e-05 / Item reconstruction: 0.001802169717848301 / Text reconstruction: 0.00243985652923584\n",
            "loss in epoch 12/21 iteration 6/67: 1.3818765878677368 / BPR loss: 1.3805044889450073 / Matching loss: 3.27258967445232e-05 / Item reconstruction: 0.0017283681081607938 / Text reconstruction: 0.0023756695445626974\n",
            "loss in epoch 12/21 iteration 7/67: 1.3820985555648804 / BPR loss: 1.3807486295700073 / Matching loss: 3.0882423743605614e-05 / Item reconstruction: 0.001674031838774681 / Text reconstruction: 0.0024104423355311155\n",
            "loss in epoch 12/21 iteration 8/67: 1.3815393447875977 / BPR loss: 1.3802235126495361 / Matching loss: 3.0039540433790535e-05 / Item reconstruction: 0.001590148312970996 / Text reconstruction: 0.0024535900447517633\n",
            "loss in epoch 12/21 iteration 9/67: 1.3814213275909424 / BPR loss: 1.380154013633728 / Matching loss: 3.0003231586306356e-05 / Item reconstruction: 0.001571731991134584 / Text reconstruction: 0.002257184125483036\n",
            "loss in epoch 12/21 iteration 10/67: 1.3810738325119019 / BPR loss: 1.3798236846923828 / Matching loss: 3.231332084396854e-05 / Item reconstruction: 0.0015913534443825483 / Text reconstruction: 0.0021104048937559128\n",
            "loss in epoch 12/21 iteration 11/67: 1.3811004161834717 / BPR loss: 1.379887580871582 / Matching loss: 3.069928425247781e-05 / Item reconstruction: 0.001566356630064547 / Text reconstruction: 0.0019943234510719776\n",
            "loss in epoch 12/21 iteration 12/67: 1.381501317024231 / BPR loss: 1.3802251815795898 / Matching loss: 3.211354851373471e-05 / Item reconstruction: 0.0017187937628477812 / Text reconstruction: 0.0019236706430092454\n",
            "loss in epoch 12/21 iteration 13/67: 1.3814605474472046 / BPR loss: 1.3802179098129272 / Matching loss: 3.0366674764081836e-05 / Item reconstruction: 0.001623848918825388 / Text reconstruction: 0.0020015970803797245\n",
            "loss in epoch 12/21 iteration 14/67: 1.3819321393966675 / BPR loss: 1.3806908130645752 / Matching loss: 3.0629376851720735e-05 / Item reconstruction: 0.0016260531265288591 / Text reconstruction: 0.0019886100199073553\n",
            "loss in epoch 12/21 iteration 15/67: 1.3812843561172485 / BPR loss: 1.38005793094635 / Matching loss: 3.0374503694474697e-05 / Item reconstruction: 0.001547081395983696 / Text reconstruction: 0.002112671732902527\n",
            "loss in epoch 12/21 iteration 16/67: 1.3810491561889648 / BPR loss: 1.379828691482544 / Matching loss: 2.9175276722526178e-05 / Item reconstruction: 0.0015430658822879195 / Text reconstruction: 0.002098520752042532\n",
            "loss in epoch 12/21 iteration 17/67: 1.3812342882156372 / BPR loss: 1.3800361156463623 / Matching loss: 2.9484555852832273e-05 / Item reconstruction: 0.001521831494756043 / Text reconstruction: 0.0020391528960317373\n",
            "loss in epoch 12/21 iteration 18/67: 1.386073350906372 / BPR loss: 1.3843743801116943 / Matching loss: 3.964814095525071e-05 / Item reconstruction: 0.0023722313344478607 / Text reconstruction: 0.00236582662910223\n",
            "loss in epoch 12/21 iteration 19/67: 1.3880479335784912 / BPR loss: 1.3861314058303833 / Matching loss: 4.325029658502899e-05 / Item reconstruction: 0.002630739938467741 / Text reconstruction: 0.0027893998194485903\n",
            "loss in epoch 12/21 iteration 20/67: 1.3880127668380737 / BPR loss: 1.3862732648849487 / Matching loss: 4.043018270749599e-05 / Item reconstruction: 0.0025214646011590958 / Text reconstruction: 0.0021913880482316017\n",
            "loss in epoch 12/21 iteration 21/67: 1.3871042728424072 / BPR loss: 1.385396957397461 / Matching loss: 4.158719093538821e-05 / Item reconstruction: 0.002487215679138899 / Text reconstruction: 0.0021104379557073116\n",
            "loss in epoch 12/21 iteration 22/67: 1.3835653066635132 / BPR loss: 1.3821529150009155 / Matching loss: 3.1063565984368324e-05 / Item reconstruction: 0.002083576750010252 / Text reconstruction: 0.0016975351609289646\n",
            "loss in epoch 12/21 iteration 23/67: 1.3830174207687378 / BPR loss: 1.3816717863082886 / Matching loss: 3.0227849492803216e-05 / Item reconstruction: 0.001975070917978883 / Text reconstruction: 0.0016388969961553812\n",
            "loss in epoch 12/21 iteration 24/67: 1.3831827640533447 / BPR loss: 1.3818507194519043 / Matching loss: 3.076602297369391e-05 / Item reconstruction: 0.0019481016788631678 / Text reconstruction: 0.0016361003508791327\n",
            "loss in epoch 12/21 iteration 25/67: 1.3831233978271484 / BPR loss: 1.3818089962005615 / Matching loss: 3.055453271372244e-05 / Item reconstruction: 0.0019029158866032958 / Text reconstruction: 0.001662225229665637\n",
            "loss in epoch 12/21 iteration 26/67: 1.3833338022232056 / BPR loss: 1.3820586204528809 / Matching loss: 3.1328967452282086e-05 / Item reconstruction: 0.0017948208842426538 / Text reconstruction: 0.0017322435742244124\n",
            "loss in epoch 12/21 iteration 27/67: 1.3828531503677368 / BPR loss: 1.38157057762146 / Matching loss: 3.028318315045908e-05 / Item reconstruction: 0.0018339685630053282 / Text reconstruction: 0.0016769666690379381\n",
            "loss in epoch 12/21 iteration 28/67: 1.3827576637268066 / BPR loss: 1.3815363645553589 / Matching loss: 2.8191934688948095e-05 / Item reconstruction: 0.0017264451598748565 / Text reconstruction: 0.0016496509779244661\n",
            "loss in epoch 12/21 iteration 29/67: 1.3831068277359009 / BPR loss: 1.3819115161895752 / Matching loss: 2.6951653126161546e-05 / Item reconstruction: 0.0016716659301891923 / Text reconstruction: 0.001662903930991888\n",
            "loss in epoch 12/21 iteration 30/67: 1.3831251859664917 / BPR loss: 1.3819183111190796 / Matching loss: 2.803587631206028e-05 / Item reconstruction: 0.0017613563686609268 / Text reconstruction: 0.0014906725846230984\n",
            "loss in epoch 12/21 iteration 31/67: 1.382673978805542 / BPR loss: 1.3815586566925049 / Matching loss: 2.8138958441559225e-05 / Item reconstruction: 0.0016095252940431237 / Text reconstruction: 0.0014120200648903847\n",
            "loss in epoch 12/21 iteration 32/67: 1.383318543434143 / BPR loss: 1.3822263479232788 / Matching loss: 2.924663021985907e-05 / Item reconstruction: 0.001581308781169355 / Text reconstruction: 0.0013621463440358639\n",
            "loss in epoch 12/21 iteration 33/67: 1.3843053579330444 / BPR loss: 1.382673978805542 / Matching loss: 3.0200215405784547e-05 / Item reconstruction: 0.002444873098284006 / Text reconstruction: 0.00189364911057055\n",
            "loss in epoch 12/21 iteration 34/67: 1.3869284391403198 / BPR loss: 1.3853082656860352 / Matching loss: 2.812124148476869e-05 / Item reconstruction: 0.0025775828398764133 / Text reconstruction: 0.0015161074697971344\n",
            "loss in epoch 12/21 iteration 35/67: 1.3860760927200317 / BPR loss: 1.384461522102356 / Matching loss: 2.937452336482238e-05 / Item reconstruction: 0.0024979053996503353 / Text reconstruction: 0.0016813711263239384\n",
            "loss in epoch 12/21 iteration 36/67: 1.3872873783111572 / BPR loss: 1.3856494426727295 / Matching loss: 4.267186886863783e-05 / Item reconstruction: 0.0025753523223102093 / Text reconstruction: 0.0015379192773252726\n",
            "loss in epoch 12/21 iteration 37/67: 1.3872592449188232 / BPR loss: 1.3857241868972778 / Matching loss: 4.250540951034054e-05 / Item reconstruction: 0.0024965459015220404 / Text reconstruction: 0.0012211939319968224\n",
            "loss in epoch 12/21 iteration 38/67: 1.3869084119796753 / BPR loss: 1.385504961013794 / Matching loss: 3.60436606570147e-05 / Item reconstruction: 0.002334095072001219 / Text reconstruction: 0.0010016700252890587\n",
            "loss in epoch 12/21 iteration 39/67: 1.3870569467544556 / BPR loss: 1.385664701461792 / Matching loss: 3.717276194947772e-05 / Item reconstruction: 0.002306752372533083 / Text reconstruction: 0.001008779276162386\n",
            "loss in epoch 12/21 iteration 40/67: 1.3871499300003052 / BPR loss: 1.3857747316360474 / Matching loss: 4.3710999307222664e-05 / Item reconstruction: 0.002299794927239418 / Text reconstruction: 0.0009078830480575562\n",
            "loss in epoch 12/21 iteration 41/67: 1.385168433189392 / BPR loss: 1.3837690353393555 / Matching loss: 4.099867510376498e-05 / Item reconstruction: 0.0021410281769931316 / Text reconstruction: 0.0014392687007784843\n",
            "loss in epoch 12/21 iteration 42/67: 1.3826624155044556 / BPR loss: 1.3810571432113647 / Matching loss: 2.8653943445533514e-05 / Item reconstruction: 0.002049344591796398 / Text reconstruction: 0.0027599106542766094\n",
            "loss in epoch 12/21 iteration 43/67: 1.3817543983459473 / BPR loss: 1.3801777362823486 / Matching loss: 3.0105737096164376e-05 / Item reconstruction: 0.001986035145819187 / Text reconstruction: 0.0027675519231706858\n",
            "loss in epoch 12/21 iteration 44/67: 1.3863893747329712 / BPR loss: 1.3850911855697632 / Matching loss: 3.662625385913998e-05 / Item reconstruction: 0.0021763197146356106 / Text reconstruction: 0.0008674514247104526\n",
            "loss in epoch 12/21 iteration 45/67: 1.387163519859314 / BPR loss: 1.385922908782959 / Matching loss: 3.841552825178951e-05 / Item reconstruction: 0.0021547966171056032 / Text reconstruction: 0.0006241209339350462\n",
            "loss in epoch 12/21 iteration 46/67: 1.3867813348770142 / BPR loss: 1.3852827548980713 / Matching loss: 3.291983375675045e-05 / Item reconstruction: 0.002493907231837511 / Text reconstruction: 0.0010937866754829884\n",
            "loss in epoch 12/21 iteration 47/67: 1.386877179145813 / BPR loss: 1.3853809833526611 / Matching loss: 3.1444702472072095e-05 / Item reconstruction: 0.0024578762240707874 / Text reconstruction: 0.00117892911657691\n",
            "loss in epoch 12/21 iteration 48/67: 1.3869304656982422 / BPR loss: 1.385551929473877 / Matching loss: 3.3567117498023435e-05 / Item reconstruction: 0.0022793393582105637 / Text reconstruction: 0.001026112586259842\n",
            "loss in epoch 12/21 iteration 49/67: 1.3855384588241577 / BPR loss: 1.3841676712036133 / Matching loss: 3.204982203897089e-05 / Item reconstruction: 0.0022099162451922894 / Text reconstruction: 0.0011689953971654177\n",
            "loss in epoch 12/21 iteration 50/67: 1.3859387636184692 / BPR loss: 1.3845996856689453 / Matching loss: 3.685124829644337e-05 / Item reconstruction: 0.002186381723731756 / Text reconstruction: 0.0010455552255734801\n",
            "loss in epoch 12/21 iteration 51/67: 1.3874850273132324 / BPR loss: 1.3862228393554688 / Matching loss: 3.9173966797534376e-05 / Item reconstruction: 0.002176618669182062 / Text reconstruction: 0.000673549366183579\n",
            "loss in epoch 12/21 iteration 52/67: 1.3875281810760498 / BPR loss: 1.3861125707626343 / Matching loss: 3.84167033189442e-05 / Item reconstruction: 0.002384424675256014 / Text reconstruction: 0.0009248594287782907\n",
            "loss in epoch 12/21 iteration 53/67: 1.3874353170394897 / BPR loss: 1.3862028121948242 / Matching loss: 3.502477193251252e-05 / Item reconstruction: 0.002045373897999525 / Text reconstruction: 0.000874093035236001\n",
            "loss in epoch 12/21 iteration 54/67: 1.3875170946121216 / BPR loss: 1.386269211769104 / Matching loss: 4.158124647801742e-05 / Item reconstruction: 0.002155488356947899 / Text reconstruction: 0.0006426334148272872\n",
            "loss in epoch 12/21 iteration 55/67: 1.3876519203186035 / BPR loss: 1.3864120244979858 / Matching loss: 3.893300163326785e-05 / Item reconstruction: 0.002127469051629305 / Text reconstruction: 0.0006862194859422743\n",
            "loss in epoch 12/21 iteration 56/67: 1.387236475944519 / BPR loss: 1.3859927654266357 / Matching loss: 4.2160732846241444e-05 / Item reconstruction: 0.002143471036106348 / Text reconstruction: 0.0006490917876362801\n",
            "loss in epoch 12/21 iteration 57/67: 1.3874760866165161 / BPR loss: 1.3863005638122559 / Matching loss: 3.5449400456855074e-05 / Item reconstruction: 0.0019979781936854124 / Text reconstruction: 0.0007059208583086729\n",
            "loss in epoch 12/21 iteration 58/67: 1.3873231410980225 / BPR loss: 1.3861665725708008 / Matching loss: 3.470205774647184e-05 / Item reconstruction: 0.001956298016011715 / Text reconstruction: 0.0007191275944933295\n",
            "loss in epoch 12/21 iteration 59/67: 1.3872524499893188 / BPR loss: 1.386047124862671 / Matching loss: 3.978328459197655e-05 / Item reconstruction: 0.0020991582423448563 / Text reconstruction: 0.0005796336918137968\n",
            "loss in epoch 12/21 iteration 60/67: 1.38762366771698 / BPR loss: 1.386446237564087 / Matching loss: 3.6438650568015873e-05 / Item reconstruction: 0.0020294433925300837 / Text reconstruction: 0.000631340779364109\n",
            "loss in epoch 12/21 iteration 61/67: 1.38740873336792 / BPR loss: 1.3862574100494385 / Matching loss: 3.7244630220811814e-05 / Item reconstruction: 0.0019691702909767628 / Text reconstruction: 0.0006478636059910059\n",
            "loss in epoch 12/21 iteration 62/67: 1.3872889280319214 / BPR loss: 1.3859848976135254 / Matching loss: 3.172959259245545e-05 / Item reconstruction: 0.0021166293881833553 / Text reconstruction: 0.0010697476100176573\n",
            "loss in epoch 12/21 iteration 63/67: 1.3875635862350464 / BPR loss: 1.3863333463668823 / Matching loss: 4.388402885524556e-05 / Item reconstruction: 0.0021901787258684635 / Text reconstruction: 0.0004567130818031728\n",
            "loss in epoch 12/21 iteration 64/67: 1.3875690698623657 / BPR loss: 1.3863680362701416 / Matching loss: 4.260831337887794e-05 / Item reconstruction: 0.002092975191771984 / Text reconstruction: 0.0005599340656772256\n",
            "loss in epoch 12/21 iteration 65/67: 1.3873765468597412 / BPR loss: 1.386211633682251 / Matching loss: 4.153315967414528e-05 / Item reconstruction: 0.002028360031545162 / Text reconstruction: 0.0005459210951812565\n",
            "loss in epoch 12/21 iteration 66/67: 1.3875062465667725 / BPR loss: 1.3864635229110718 / Matching loss: 3.100161120528355e-05 / Item reconstruction: 0.0017415412003174424 / Text reconstruction: 0.0007046344107948244\n",
            "loss in epoch 12/21 iteration 67/67: 1.3871690034866333 / BPR loss: 1.3862330913543701 / Matching loss: 2.2988584532868117e-05 / Item reconstruction: 0.0015101323369890451 / Text reconstruction: 0.0007891767891123891\n",
            " 60% 12/20 [23:39<15:58, 119.79s/it]loss in epoch 13/21 iteration 0/67: 1.387113094329834 / BPR loss: 1.3857189416885376 / Matching loss: 4.487106343731284e-05 / Item reconstruction: 0.0023535159416496754 / Text reconstruction: 0.0008631427772343159\n",
            "loss in epoch 13/21 iteration 1/67: 1.384248971939087 / BPR loss: 1.3826661109924316 / Matching loss: 4.127909051021561e-05 / Item reconstruction: 0.002236901316791773 / Text reconstruction: 0.002115915296599269\n",
            "loss in epoch 13/21 iteration 2/67: 1.38223135471344 / BPR loss: 1.3805421590805054 / Matching loss: 3.691606980282813e-05 / Item reconstruction: 0.002093531657010317 / Text reconstruction: 0.0030273040756583214\n",
            "loss in epoch 13/21 iteration 3/67: 1.3810138702392578 / BPR loss: 1.379317045211792 / Matching loss: 3.604178345995024e-05 / Item reconstruction: 0.001949377590790391 / Text reconstruction: 0.003430670825764537\n",
            "loss in epoch 13/21 iteration 4/67: 1.3802660703659058 / BPR loss: 1.3786160945892334 / Matching loss: 3.538645978551358e-05 / Item reconstruction: 0.0019517913460731506 / Text reconstruction: 0.003193820593878627\n",
            "loss in epoch 13/21 iteration 5/67: 1.3814136981964111 / BPR loss: 1.3799290657043457 / Matching loss: 3.742382614291273e-05 / Item reconstruction: 0.0017801460344344378 / Text reconstruction: 0.0027861192356795073\n",
            "loss in epoch 13/21 iteration 6/67: 1.3809559345245361 / BPR loss: 1.3795676231384277 / Matching loss: 3.111304249614477e-05 / Item reconstruction: 0.0016682273708283901 / Text reconstruction: 0.002615657402202487\n",
            "loss in epoch 13/21 iteration 7/67: 1.3806995153427124 / BPR loss: 1.3793014287948608 / Matching loss: 3.0110635634628125e-05 / Item reconstruction: 0.0017332651186734438 / Text reconstruction: 0.0025061191990971565\n",
            "loss in epoch 13/21 iteration 8/67: 1.379917025566101 / BPR loss: 1.3786227703094482 / Matching loss: 2.8726328309858218e-05 / Item reconstruction: 0.0015714915934950113 / Text reconstruction: 0.0023991246707737446\n",
            "loss in epoch 13/21 iteration 9/67: 1.3802576065063477 / BPR loss: 1.3790295124053955 / Matching loss: 3.264228507759981e-05 / Item reconstruction: 0.0015890930080786347 / Text reconstruction: 0.002004404319450259\n",
            "loss in epoch 13/21 iteration 10/67: 1.3803424835205078 / BPR loss: 1.3791344165802002 / Matching loss: 3.277293581049889e-05 / Item reconstruction: 0.001525022555142641 / Text reconstruction: 0.002064200583845377\n",
            "loss in epoch 13/21 iteration 11/67: 1.3803017139434814 / BPR loss: 1.3791191577911377 / Matching loss: 2.8732983992085792e-05 / Item reconstruction: 0.0014770562993362546 / Text reconstruction: 0.002076489618048072\n",
            "loss in epoch 13/21 iteration 12/67: 1.3801262378692627 / BPR loss: 1.3788137435913086 / Matching loss: 3.158522304147482e-05 / Item reconstruction: 0.0016749606002122164 / Text reconstruction: 0.002217227825894952\n",
            "loss in epoch 13/21 iteration 13/67: 1.381028652191162 / BPR loss: 1.3797986507415771 / Matching loss: 2.9678376449737698e-05 / Item reconstruction: 0.0015449745114892721 / Text reconstruction: 0.0021393192000687122\n",
            "loss in epoch 13/21 iteration 14/67: 1.3807597160339355 / BPR loss: 1.3794386386871338 / Matching loss: 3.1837098504183814e-05 / Item reconstruction: 0.0016570998122915626 / Text reconstruction: 0.0023036585189402103\n",
            "loss in epoch 13/21 iteration 15/67: 1.3799889087677002 / BPR loss: 1.3786805868148804 / Matching loss: 2.8272797862882726e-05 / Item reconstruction: 0.0015997271984815598 / Text reconstruction: 0.002401030156761408\n",
            "loss in epoch 13/21 iteration 16/67: 1.3800886869430542 / BPR loss: 1.3789241313934326 / Matching loss: 2.9478160286089405e-05 / Item reconstruction: 0.0014549311017617583 / Text reconstruction: 0.0020386355463415384\n",
            "loss in epoch 13/21 iteration 17/67: 1.3800830841064453 / BPR loss: 1.3788549900054932 / Matching loss: 2.9724738851655275e-05 / Item reconstruction: 0.0015707920538261533 / Text reconstruction: 0.0020653754472732544\n",
            "loss in epoch 13/21 iteration 18/67: 1.3854832649230957 / BPR loss: 1.3836863040924072 / Matching loss: 4.3552634451771155e-05 / Item reconstruction: 0.0024134018458426 / Text reconstruction: 0.002733441535383463\n",
            "loss in epoch 13/21 iteration 19/67: 1.3881065845489502 / BPR loss: 1.386157751083374 / Matching loss: 4.336379060987383e-05 / Item reconstruction: 0.0025676372461020947 / Text reconstruction: 0.003108341246843338\n",
            "loss in epoch 13/21 iteration 20/67: 1.3878650665283203 / BPR loss: 1.38606858253479 / Matching loss: 3.9676153392065316e-05 / Item reconstruction: 0.0025109825655817986 / Text reconstruction: 0.0025061368942260742\n",
            "loss in epoch 13/21 iteration 21/67: 1.3867852687835693 / BPR loss: 1.3850493431091309 / Matching loss: 4.242701470502652e-05 / Item reconstruction: 0.002474444918334484 / Text reconstruction: 0.002280820393934846\n",
            "loss in epoch 13/21 iteration 22/67: 1.3824827671051025 / BPR loss: 1.3810268640518188 / Matching loss: 3.232280141673982e-05 / Item reconstruction: 0.0021066858898848295 / Text reconstruction: 0.0018513903487473726\n",
            "loss in epoch 13/21 iteration 23/67: 1.3818261623382568 / BPR loss: 1.380469799041748 / Matching loss: 2.775041684799362e-05 / Item reconstruction: 0.0018897086847573519 / Text reconstruction: 0.0019187668804079294\n",
            "loss in epoch 13/21 iteration 24/67: 1.3824288845062256 / BPR loss: 1.3810206651687622 / Matching loss: 3.067585203098133e-05 / Item reconstruction: 0.001928130048327148 / Text reconstruction: 0.0020677598658949137\n",
            "loss in epoch 13/21 iteration 25/67: 1.38166344165802 / BPR loss: 1.3803104162216187 / Matching loss: 2.8927337552886456e-05 / Item reconstruction: 0.001812215312384069 / Text reconstruction: 0.002089651534333825\n",
            "loss in epoch 13/21 iteration 26/67: 1.3822931051254272 / BPR loss: 1.3810412883758545 / Matching loss: 2.5917357561411336e-05 / Item reconstruction: 0.0017019424121826887 / Text reconstruction: 0.0018753187032416463\n",
            "loss in epoch 13/21 iteration 27/67: 1.381884217262268 / BPR loss: 1.3806099891662598 / Matching loss: 2.8695645596599206e-05 / Item reconstruction: 0.0017531798221170902 / Text reconstruction: 0.0018446160247549415\n",
            "loss in epoch 13/21 iteration 28/67: 1.3821519613265991 / BPR loss: 1.3809070587158203 / Matching loss: 2.9187480322434567e-05 / Item reconstruction: 0.001749594695866108 / Text reconstruction: 0.001704763388261199\n",
            "loss in epoch 13/21 iteration 29/67: 1.3818327188491821 / BPR loss: 1.380645751953125 / Matching loss: 2.7234742447035387e-05 / Item reconstruction: 0.0016584208933636546 / Text reconstruction: 0.0016527357511222363\n",
            "loss in epoch 13/21 iteration 30/67: 1.3818583488464355 / BPR loss: 1.3806447982788086 / Matching loss: 2.8314107112237252e-05 / Item reconstruction: 0.0017487102886661887 / Text reconstruction: 0.0015537901781499386\n",
            "loss in epoch 13/21 iteration 31/67: 1.3821580410003662 / BPR loss: 1.381021499633789 / Matching loss: 2.667963781277649e-05 / Item reconstruction: 0.0015845728339627385 / Text reconstruction: 0.0015876556281000376\n",
            "loss in epoch 13/21 iteration 32/67: 1.3817998170852661 / BPR loss: 1.3806620836257935 / Matching loss: 2.992928602907341e-05 / Item reconstruction: 0.001604157849214971 / Text reconstruction: 0.0015290257288143039\n",
            "loss in epoch 13/21 iteration 33/67: 1.3839904069900513 / BPR loss: 1.382370948791504 / Matching loss: 2.9152804927434772e-05 / Item reconstruction: 0.0024573183618485928 / Text reconstruction: 0.0018079779110848904\n",
            "loss in epoch 13/21 iteration 34/67: 1.3867970705032349 / BPR loss: 1.3850934505462646 / Matching loss: 2.995355134771671e-05 / Item reconstruction: 0.0026902081444859505 / Text reconstruction: 0.0016426455695182085\n",
            "loss in epoch 13/21 iteration 35/67: 1.385746717453003 / BPR loss: 1.3840285539627075 / Matching loss: 2.8606536943698302e-05 / Item reconstruction: 0.0026287927757948637 / Text reconstruction: 0.001875637797638774\n",
            "loss in epoch 13/21 iteration 36/67: 1.3871530294418335 / BPR loss: 1.3855822086334229 / Matching loss: 3.855236718663946e-05 / Item reconstruction: 0.0024909202475100756 / Text reconstruction: 0.0014340438647195697\n",
            "loss in epoch 13/21 iteration 37/67: 1.3870998620986938 / BPR loss: 1.3855645656585693 / Matching loss: 4.409348184708506e-05 / Item reconstruction: 0.0025184815749526024 / Text reconstruction: 0.00115966796875\n",
            "loss in epoch 13/21 iteration 38/67: 1.3869093656539917 / BPR loss: 1.3855013847351074 / Matching loss: 3.67865213775076e-05 / Item reconstruction: 0.00233635026961565 / Text reconstruction: 0.0010148484725505114\n",
            "loss in epoch 13/21 iteration 39/67: 1.3868918418884277 / BPR loss: 1.3854880332946777 / Matching loss: 3.6747969716088846e-05 / Item reconstruction: 0.0023027323186397552 / Text reconstruction: 0.0010789919178932905\n",
            "loss in epoch 13/21 iteration 40/67: 1.3871454000473022 / BPR loss: 1.3857917785644531 / Matching loss: 4.163314224570058e-05 / Item reconstruction: 0.0022898786701261997 / Text reconstruction: 0.0008356862235814333\n",
            "loss in epoch 13/21 iteration 41/67: 1.3844174146652222 / BPR loss: 1.382961630821228 / Matching loss: 4.032842116430402e-05 / Item reconstruction: 0.0021668439731001854 / Text reconstruction: 0.0016604610718786716\n",
            "loss in epoch 13/21 iteration 42/67: 1.381124496459961 / BPR loss: 1.3795201778411865 / Matching loss: 2.7421276172390208e-05 / Item reconstruction: 0.0019656685180962086 / Text reconstruction: 0.00297039607539773\n",
            "loss in epoch 13/21 iteration 43/67: 1.3807731866836548 / BPR loss: 1.3791236877441406 / Matching loss: 3.217982884962112e-05 / Item reconstruction: 0.001960195368155837 / Text reconstruction: 0.0031861651223152876\n",
            "loss in epoch 13/21 iteration 44/67: 1.3863414525985718 / BPR loss: 1.3850164413452148 / Matching loss: 3.485585330054164e-05 / Item reconstruction: 0.002160700736567378 / Text reconstruction: 0.0010491024004295468\n",
            "loss in epoch 13/21 iteration 45/67: 1.3874977827072144 / BPR loss: 1.3862431049346924 / Matching loss: 3.8331723771989346e-05 / Item reconstruction: 0.002158612944185734 / Text reconstruction: 0.0006850742502138019\n",
            "loss in epoch 13/21 iteration 46/67: 1.3866075277328491 / BPR loss: 1.3851007223129272 / Matching loss: 3.090489553869702e-05 / Item reconstruction: 0.0024478770792484283 / Text reconstruction: 0.0012602603528648615\n",
            "loss in epoch 13/21 iteration 47/67: 1.3867424726486206 / BPR loss: 1.3852019309997559 / Matching loss: 3.16750883939676e-05 / Item reconstruction: 0.002505379030480981 / Text reconstruction: 0.001280695665627718\n",
            "loss in epoch 13/21 iteration 48/67: 1.3869812488555908 / BPR loss: 1.3856210708618164 / Matching loss: 3.185685272910632e-05 / Item reconstruction: 0.0021916870027780533 / Text reconstruction: 0.001162507920525968\n",
            "loss in epoch 13/21 iteration 49/67: 1.385462760925293 / BPR loss: 1.3840982913970947 / Matching loss: 3.238605131627992e-05 / Item reconstruction: 0.0021734004840254784 / Text reconstruction: 0.0012265536934137344\n",
            "loss in epoch 13/21 iteration 50/67: 1.3857640027999878 / BPR loss: 1.3844058513641357 / Matching loss: 3.967442171415314e-05 / Item reconstruction: 0.0021996984723955393 / Text reconstruction: 0.0010930628050118685\n",
            "loss in epoch 13/21 iteration 51/67: 1.3874680995941162 / BPR loss: 1.3862053155899048 / Matching loss: 3.771694900933653e-05 / Item reconstruction: 0.0021870711352676153 / Text reconstruction: 0.0006577704334631562\n",
            "loss in epoch 13/21 iteration 52/67: 1.3873543739318848 / BPR loss: 1.3859764337539673 / Matching loss: 3.820860729319975e-05 / Item reconstruction: 0.0023268675431609154 / Text reconstruction: 0.0008807881968095899\n",
            "loss in epoch 13/21 iteration 53/67: 1.387007713317871 / BPR loss: 1.3857430219650269 / Matching loss: 3.3638905733823776e-05 / Item reconstruction: 0.002108532004058361 / Text reconstruction: 0.0008838576031848788\n",
            "loss in epoch 13/21 iteration 54/67: 1.3874430656433105 / BPR loss: 1.386155605316162 / Matching loss: 4.1574498027330264e-05 / Item reconstruction: 0.002218928188085556 / Text reconstruction: 0.0006817499524913728\n",
            "loss in epoch 13/21 iteration 55/67: 1.3879706859588623 / BPR loss: 1.3867251873016357 / Matching loss: 3.6875877412967384e-05 / Item reconstruction: 0.002133346861228347 / Text reconstruction: 0.0007096228655427694\n",
            "loss in epoch 13/21 iteration 56/67: 1.3874398469924927 / BPR loss: 1.3861886262893677 / Matching loss: 4.013774014310911e-05 / Item reconstruction: 0.002163425087928772 / Text reconstruction: 0.0006466738996095955\n",
            "loss in epoch 13/21 iteration 57/67: 1.3871649503707886 / BPR loss: 1.3859970569610596 / Matching loss: 3.354245563969016e-05 / Item reconstruction: 0.0019830099772661924 / Text reconstruction: 0.0007148233125917614\n",
            "loss in epoch 13/21 iteration 58/67: 1.387440800666809 / BPR loss: 1.386263370513916 / Matching loss: 3.563263817341067e-05 / Item reconstruction: 0.0020095049403607845 / Text reconstruction: 0.0006854896200820804\n",
            "loss in epoch 13/21 iteration 59/67: 1.3874539136886597 / BPR loss: 1.3862236738204956 / Matching loss: 3.9247410313691944e-05 / Item reconstruction: 0.0021521379239857197 / Text reconstruction: 0.0005745240487158298\n",
            "loss in epoch 13/21 iteration 60/67: 1.3875178098678589 / BPR loss: 1.3863117694854736 / Matching loss: 3.790860500885174e-05 / Item reconstruction: 0.002076470060274005 / Text reconstruction: 0.0006497267168015242\n",
            "loss in epoch 13/21 iteration 61/67: 1.3874518871307373 / BPR loss: 1.3862977027893066 / Matching loss: 3.420448047108948e-05 / Item reconstruction: 0.001974295824766159 / Text reconstruction: 0.0006640887004323304\n",
            "loss in epoch 13/21 iteration 62/67: 1.3874117136001587 / BPR loss: 1.3861212730407715 / Matching loss: 2.8596474294317886e-05 / Item reconstruction: 0.002024234738200903 / Text reconstruction: 0.001248666550964117\n",
            "loss in epoch 13/21 iteration 63/67: 1.3872716426849365 / BPR loss: 1.3859930038452148 / Matching loss: 4.4718435674440116e-05 / Item reconstruction: 0.0022605573758482933 / Text reconstruction: 0.0005183612229302526\n",
            "loss in epoch 13/21 iteration 64/67: 1.3870038986206055 / BPR loss: 1.3858110904693604 / Matching loss: 4.119742152397521e-05 / Item reconstruction: 0.0020937740337103605 / Text reconstruction: 0.0005230995593592525\n",
            "loss in epoch 13/21 iteration 65/67: 1.3876097202301025 / BPR loss: 1.3864219188690186 / Matching loss: 3.766390000237152e-05 / Item reconstruction: 0.0020667784847319126 / Text reconstruction: 0.000583731452934444\n",
            "loss in epoch 13/21 iteration 66/67: 1.3874150514602661 / BPR loss: 1.3863749504089355 / Matching loss: 2.9499009542632848e-05 / Item reconstruction: 0.0017395054455846548 / Text reconstruction: 0.0007046338287182152\n",
            "loss in epoch 13/21 iteration 67/67: 1.3872902393341064 / BPR loss: 1.3863216638565063 / Matching loss: 2.2778913262300193e-05 / Item reconstruction: 0.001588337472639978 / Text reconstruction: 0.0007581101963296533\n",
            " 65% 13/20 [25:38<13:57, 119.58s/it]loss in epoch 14/21 iteration 0/67: 1.3872390985488892 / BPR loss: 1.3858482837677002 / Matching loss: 4.212072599329986e-05 / Item reconstruction: 0.002369868103414774 / Text reconstruction: 0.0008190886583179235\n",
            "loss in epoch 14/21 iteration 1/67: 1.3839071989059448 / BPR loss: 1.3823282718658447 / Matching loss: 3.5860255593433976e-05 / Item reconstruction: 0.0021179895848035812 / Text reconstruction: 0.0024204656947404146\n",
            "loss in epoch 14/21 iteration 2/67: 1.3806525468826294 / BPR loss: 1.3789150714874268 / Matching loss: 3.495972850942053e-05 / Item reconstruction: 0.0020717496518045664 / Text reconstruction: 0.003333263099193573\n",
            "loss in epoch 14/21 iteration 3/67: 1.3806509971618652 / BPR loss: 1.3789453506469727 / Matching loss: 3.3017458918038756e-05 / Item reconstruction: 0.0018732165917754173 / Text reconstruction: 0.0036800233647227287\n",
            "loss in epoch 14/21 iteration 4/67: 1.3793525695800781 / BPR loss: 1.3776679039001465 / Matching loss: 3.446268601692282e-05 / Item reconstruction: 0.0019178930670022964 / Text reconstruction: 0.0034562305081635714\n",
            "loss in epoch 14/21 iteration 5/67: 1.3799480199813843 / BPR loss: 1.3784338235855103 / Matching loss: 3.483083492028527e-05 / Item reconstruction: 0.001751657109707594 / Text reconstruction: 0.0030179054010659456\n",
            "loss in epoch 14/21 iteration 6/67: 1.3795154094696045 / BPR loss: 1.3780680894851685 / Matching loss: 3.209223359590396e-05 / Item reconstruction: 0.0016654448118060827 / Text reconstruction: 0.0029129001777619123\n",
            "loss in epoch 14/21 iteration 7/67: 1.3792015314102173 / BPR loss: 1.3777596950531006 / Matching loss: 3.0337663702084683e-05 / Item reconstruction: 0.0016820399323478341 / Text reconstruction: 0.0028524156659841537\n",
            "loss in epoch 14/21 iteration 8/67: 1.3788279294967651 / BPR loss: 1.3774595260620117 / Matching loss: 2.9701499443035573e-05 / Item reconstruction: 0.0015585818327963352 / Text reconstruction: 0.0027971258386969566\n",
            "loss in epoch 14/21 iteration 9/67: 1.378994107246399 / BPR loss: 1.377705693244934 / Matching loss: 2.84003144770395e-05 / Item reconstruction: 0.0015716354828327894 / Text reconstruction: 0.0023710059467703104\n",
            "loss in epoch 14/21 iteration 10/67: 1.3794842958450317 / BPR loss: 1.378254771232605 / Matching loss: 3.0862483981763944e-05 / Item reconstruction: 0.0015554556157439947 / Text reconstruction: 0.002104403916746378\n",
            "loss in epoch 14/21 iteration 11/67: 1.3786827325820923 / BPR loss: 1.3775140047073364 / Matching loss: 3.0928255000617355e-05 / Item reconstruction: 0.0014439797960221767 / Text reconstruction: 0.00207967939786613\n",
            "loss in epoch 14/21 iteration 12/67: 1.3796817064285278 / BPR loss: 1.3784441947937012 / Matching loss: 2.8400325390975922e-05 / Item reconstruction: 0.0015331697650253773 / Text reconstruction: 0.002212313935160637\n",
            "loss in epoch 14/21 iteration 13/67: 1.3785912990570068 / BPR loss: 1.377260446548462 / Matching loss: 3.018242568941787e-05 / Item reconstruction: 0.0015873179072514176 / Text reconstruction: 0.00253493944182992\n",
            "loss in epoch 14/21 iteration 14/67: 1.3790690898895264 / BPR loss: 1.3777375221252441 / Matching loss: 3.0853614589432254e-05 / Item reconstruction: 0.0015637770993635058 / Text reconstruction: 0.0025940677151083946\n",
            "loss in epoch 14/21 iteration 15/67: 1.378810167312622 / BPR loss: 1.377427101135254 / Matching loss: 2.9731008908129297e-05 / Item reconstruction: 0.0016449210233986378 / Text reconstruction: 0.0026545547880232334\n",
            "loss in epoch 14/21 iteration 16/67: 1.379285216331482 / BPR loss: 1.3780405521392822 / Matching loss: 2.8702677809633315e-05 / Item reconstruction: 0.0014872924657538533 / Text reconstruction: 0.0023616659455001354\n",
            "loss in epoch 14/21 iteration 17/67: 1.378796935081482 / BPR loss: 1.3775551319122314 / Matching loss: 2.706787927309051e-05 / Item reconstruction: 0.001477451529353857 / Text reconstruction: 0.002380124293267727\n",
            "loss in epoch 14/21 iteration 18/67: 1.3852119445800781 / BPR loss: 1.3834619522094727 / Matching loss: 3.751509211724624e-05 / Item reconstruction: 0.0023627658374607563 / Text reconstruction: 0.0026551312766969204\n",
            "loss in epoch 14/21 iteration 19/67: 1.3880000114440918 / BPR loss: 1.3860336542129517 / Matching loss: 4.122948303120211e-05 / Item reconstruction: 0.002673625946044922 / Text reconstruction: 0.002941753948107362\n",
            "loss in epoch 14/21 iteration 20/67: 1.3876621723175049 / BPR loss: 1.3858510255813599 / Matching loss: 3.8301401218632236e-05 / Item reconstruction: 0.0024391282349824905 / Text reconstruction: 0.0027667018584907055\n",
            "loss in epoch 14/21 iteration 21/67: 1.3867695331573486 / BPR loss: 1.3850268125534058 / Matching loss: 4.242863360559568e-05 / Item reconstruction: 0.002418003510683775 / Text reconstruction: 0.0024560822639614344\n",
            "loss in epoch 14/21 iteration 22/67: 1.380885362625122 / BPR loss: 1.3794374465942383 / Matching loss: 3.141432534903288e-05 / Item reconstruction: 0.002079226542264223 / Text reconstruction: 0.001883822144009173\n",
            "loss in epoch 14/21 iteration 23/67: 1.3810880184173584 / BPR loss: 1.3797476291656494 / Matching loss: 2.794735337374732e-05 / Item reconstruction: 0.0018778933444991708 / Text reconstruction: 0.0018679974600672722\n",
            "loss in epoch 14/21 iteration 24/67: 1.3812023401260376 / BPR loss: 1.3798036575317383 / Matching loss: 2.8705089789582416e-05 / Item reconstruction: 0.0019487314857542515 / Text reconstruction: 0.0019779156427830458\n",
            "loss in epoch 14/21 iteration 25/67: 1.381868600845337 / BPR loss: 1.3804924488067627 / Matching loss: 2.7694899472407997e-05 / Item reconstruction: 0.0019016375299543142 / Text reconstruction: 0.001988692209124565\n",
            "loss in epoch 14/21 iteration 26/67: 1.3817827701568604 / BPR loss: 1.380462646484375 / Matching loss: 2.6128345780307427e-05 / Item reconstruction: 0.0018337712390348315 / Text reconstruction: 0.0018857269315049052\n",
            "loss in epoch 14/21 iteration 27/67: 1.3807939291000366 / BPR loss: 1.3794643878936768 / Matching loss: 2.732384018599987e-05 / Item reconstruction: 0.0017654087860137224 / Text reconstruction: 0.0020974676590412855\n",
            "loss in epoch 14/21 iteration 28/67: 1.3809818029403687 / BPR loss: 1.3797451257705688 / Matching loss: 2.6565854568616487e-05 / Item reconstruction: 0.0016873414861038327 / Text reconstruction: 0.0018325073178857565\n",
            "loss in epoch 14/21 iteration 29/67: 1.380854606628418 / BPR loss: 1.379586100578308 / Matching loss: 3.0204395443433896e-05 / Item reconstruction: 0.0017407047562301159 / Text reconstruction: 0.0018397115636616945\n",
            "loss in epoch 14/21 iteration 30/67: 1.3812367916107178 / BPR loss: 1.380017876625061 / Matching loss: 2.7031710487790406e-05 / Item reconstruction: 0.0016842882614582777 / Text reconstruction: 0.0017486666329205036\n",
            "loss in epoch 14/21 iteration 31/67: 1.3812617063522339 / BPR loss: 1.3801114559173584 / Matching loss: 2.6034011170850135e-05 / Item reconstruction: 0.0015825045993551612 / Text reconstruction: 0.001664955634623766\n",
            "loss in epoch 14/21 iteration 32/67: 1.380807638168335 / BPR loss: 1.3796182870864868 / Matching loss: 3.1461400794796646e-05 / Item reconstruction: 0.0016652299091219902 / Text reconstruction: 0.0016266154125332832\n",
            "loss in epoch 14/21 iteration 33/67: 1.3832745552062988 / BPR loss: 1.3815007209777832 / Matching loss: 3.3274558518314734e-05 / Item reconstruction: 0.0025463637430220842 / Text reconstruction: 0.0023373905569314957\n",
            "loss in epoch 14/21 iteration 34/67: 1.386670708656311 / BPR loss: 1.3849852085113525 / Matching loss: 2.8579735953826457e-05 / Item reconstruction: 0.002638434059917927 / Text reconstruction: 0.0016883757198229432\n",
            "loss in epoch 14/21 iteration 35/67: 1.385580062866211 / BPR loss: 1.383988380432129 / Matching loss: 2.60616943705827e-05 / Item reconstruction: 0.002473029773682356 / Text reconstruction: 0.0016450181137770414\n",
            "loss in epoch 14/21 iteration 36/67: 1.38717782497406 / BPR loss: 1.3855865001678467 / Matching loss: 3.775746881728992e-05 / Item reconstruction: 0.0025145639665424824 / Text reconstruction: 0.0014811638975515962\n",
            "loss in epoch 14/21 iteration 37/67: 1.3871843814849854 / BPR loss: 1.3856139183044434 / Matching loss: 4.027914837934077e-05 / Item reconstruction: 0.0024923356249928474 / Text reconstruction: 0.0014195978874340653\n",
            "loss in epoch 14/21 iteration 38/67: 1.386617660522461 / BPR loss: 1.3851287364959717 / Matching loss: 3.5876419133273885e-05 / Item reconstruction: 0.002458989853039384 / Text reconstruction: 0.0011178638087585568\n",
            "loss in epoch 14/21 iteration 39/67: 1.3868869543075562 / BPR loss: 1.3854632377624512 / Matching loss: 3.6769175494555384e-05 / Item reconstruction: 0.0023546870797872543 / Text reconstruction: 0.001048155827447772\n",
            "loss in epoch 14/21 iteration 40/67: 1.3871797323226929 / BPR loss: 1.3857694864273071 / Matching loss: 4.10729153372813e-05 / Item reconstruction: 0.00236332044005394 / Text reconstruction: 0.0009373812936246395\n",
            "loss in epoch 14/21 iteration 41/67: 1.3841780424118042 / BPR loss: 1.3827102184295654 / Matching loss: 3.7895460991421714e-05 / Item reconstruction: 0.002190115163102746 / Text reconstruction: 0.0016742055304348469\n",
            "loss in epoch 14/21 iteration 42/67: 1.3798049688339233 / BPR loss: 1.378216028213501 / Matching loss: 2.6868010536418296e-05 / Item reconstruction: 0.0019342859741300344 / Text reconstruction: 0.002974624512717128\n",
            "loss in epoch 14/21 iteration 43/67: 1.378804087638855 / BPR loss: 1.3771514892578125 / Matching loss: 3.02091175399255e-05 / Item reconstruction: 0.001969156553968787 / Text reconstruction: 0.003189648035913706\n",
            "loss in epoch 14/21 iteration 44/67: 1.3862241506576538 / BPR loss: 1.3848764896392822 / Matching loss: 3.0867948225932196e-05 / Item reconstruction: 0.002167654223740101 / Text reconstruction: 0.0011647543869912624\n",
            "loss in epoch 14/21 iteration 45/67: 1.387387990951538 / BPR loss: 1.3861429691314697 / Matching loss: 3.3227435778826475e-05 / Item reconstruction: 0.002114345319569111 / Text reconstruction: 0.0007730331271886826\n",
            "loss in epoch 14/21 iteration 46/67: 1.38651704788208 / BPR loss: 1.3849444389343262 / Matching loss: 3.493243639240973e-05 / Item reconstruction: 0.002494493732228875 / Text reconstruction: 0.0014517400413751602\n",
            "loss in epoch 14/21 iteration 47/67: 1.3867549896240234 / BPR loss: 1.3852052688598633 / Matching loss: 3.0443003197433427e-05 / Item reconstruction: 0.0024505192413926125 / Text reconstruction: 0.0014701697509735823\n",
            "loss in epoch 14/21 iteration 48/67: 1.3866422176361084 / BPR loss: 1.3852428197860718 / Matching loss: 3.200916398782283e-05 / Item reconstruction: 0.0022583832032978535 / Text reconstruction: 0.0011911183828487992\n",
            "loss in epoch 14/21 iteration 49/67: 1.385251760482788 / BPR loss: 1.3838506937026978 / Matching loss: 3.0695387977175415e-05 / Item reconstruction: 0.002175126923248172 / Text reconstruction: 0.001414166996255517\n",
            "loss in epoch 14/21 iteration 50/67: 1.3855211734771729 / BPR loss: 1.3841044902801514 / Matching loss: 3.858382842736319e-05 / Item reconstruction: 0.0022788860369473696 / Text reconstruction: 0.0011932447087019682\n",
            "loss in epoch 14/21 iteration 51/67: 1.3873248100280762 / BPR loss: 1.3860342502593994 / Matching loss: 3.780761471716687e-05 / Item reconstruction: 0.0022049974650144577 / Text reconstruction: 0.0007513907621614635\n",
            "loss in epoch 14/21 iteration 52/67: 1.3873591423034668 / BPR loss: 1.3860282897949219 / Matching loss: 3.31692754116375e-05 / Item reconstruction: 0.0022347604390233755 / Text reconstruction: 0.000901950872503221\n",
            "loss in epoch 14/21 iteration 53/67: 1.3866780996322632 / BPR loss: 1.385369062423706 / Matching loss: 3.5796198062598705e-05 / Item reconstruction: 0.002186194295063615 / Text reconstruction: 0.0009008269407786429\n",
            "loss in epoch 14/21 iteration 54/67: 1.387312412261963 / BPR loss: 1.3860905170440674 / Matching loss: 3.933401603717357e-05 / Item reconstruction: 0.0020998921245336533 / Text reconstruction: 0.000662748352624476\n",
            "loss in epoch 14/21 iteration 55/67: 1.3878231048583984 / BPR loss: 1.3865549564361572 / Matching loss: 3.813759030890651e-05 / Item reconstruction: 0.002121536759659648 / Text reconstruction: 0.000846355629619211\n",
            "loss in epoch 14/21 iteration 56/67: 1.3876979351043701 / BPR loss: 1.3864154815673828 / Matching loss: 4.3190622818656266e-05 / Item reconstruction: 0.0021828117314726114 / Text reconstruction: 0.000739763374440372\n",
            "loss in epoch 14/21 iteration 57/67: 1.3872393369674683 / BPR loss: 1.3860290050506592 / Matching loss: 3.671336162369698e-05 / Item reconstruction: 0.002060782629996538 / Text reconstruction: 0.0007156414212659001\n",
            "loss in epoch 14/21 iteration 58/67: 1.3872475624084473 / BPR loss: 1.3861000537872314 / Matching loss: 3.420116991037503e-05 / Item reconstruction: 0.0019474613945931196 / Text reconstruction: 0.0006981453043408692\n",
            "loss in epoch 14/21 iteration 59/67: 1.3874614238739014 / BPR loss: 1.3862504959106445 / Matching loss: 4.0836828702595085e-05 / Item reconstruction: 0.002104660961776972 / Text reconstruction: 0.0005885515711270273\n",
            "loss in epoch 14/21 iteration 60/67: 1.3879472017288208 / BPR loss: 1.38673734664917 / Matching loss: 3.8377118471544236e-05 / Item reconstruction: 0.002079041674733162 / Text reconstruction: 0.0006598089239560068\n",
            "loss in epoch 14/21 iteration 61/67: 1.3872380256652832 / BPR loss: 1.3860828876495361 / Matching loss: 3.584175283322111e-05 / Item reconstruction: 0.001986513379961252 / Text reconstruction: 0.0006298722000792623\n",
            "loss in epoch 14/21 iteration 62/67: 1.3866300582885742 / BPR loss: 1.3853787183761597 / Matching loss: 2.997605588461738e-05 / Item reconstruction: 0.0020270408131182194 / Text reconstruction: 0.0010394998826086521\n",
            "loss in epoch 14/21 iteration 63/67: 1.3872488737106323 / BPR loss: 1.3859829902648926 / Matching loss: 4.4765933125745505e-05 / Item reconstruction: 0.0022069676779210567 / Text reconstruction: 0.0005878361407667398\n",
            "loss in epoch 14/21 iteration 64/67: 1.3874449729919434 / BPR loss: 1.3862131834030151 / Matching loss: 4.303076275391504e-05 / Item reconstruction: 0.0021204757504165173 / Text reconstruction: 0.0006425514002330601\n",
            "loss in epoch 14/21 iteration 65/67: 1.3876121044158936 / BPR loss: 1.3864161968231201 / Matching loss: 3.897469287039712e-05 / Item reconstruction: 0.0020446288399398327 / Text reconstruction: 0.0006729245651513338\n",
            "loss in epoch 14/21 iteration 66/67: 1.38742196559906 / BPR loss: 1.3864120244979858 / Matching loss: 2.9822946089552715e-05 / Item reconstruction: 0.001659841276705265 / Text reconstruction: 0.0007512414595112205\n",
            "loss in epoch 14/21 iteration 67/67: 1.386979341506958 / BPR loss: 1.3860125541687012 / Matching loss: 2.431601387797855e-05 / Item reconstruction: 0.0015533280093222857 / Text reconstruction: 0.0008289201068691909\n",
            " 70% 14/20 [27:36<11:55, 119.23s/it]loss in epoch 15/21 iteration 0/67: 1.3866782188415527 / BPR loss: 1.3853262662887573 / Matching loss: 4.546783384284936e-05 / Item reconstruction: 0.0022909194231033325 / Text reconstruction: 0.0008049773750826716\n",
            "loss in epoch 15/21 iteration 1/67: 1.383306622505188 / BPR loss: 1.3816173076629639 / Matching loss: 4.0208313293987885e-05 / Item reconstruction: 0.002169941086322069 / Text reconstruction: 0.0028208005242049694\n",
            "loss in epoch 15/21 iteration 2/67: 1.379693627357483 / BPR loss: 1.3778600692749023 / Matching loss: 3.772583295358345e-05 / Item reconstruction: 0.0020684716291725636 / Text reconstruction: 0.0038080920930951834\n",
            "loss in epoch 15/21 iteration 3/67: 1.3785814046859741 / BPR loss: 1.3766895532608032 / Matching loss: 3.5866898542735726e-05 / Item reconstruction: 0.001983038615435362 / Text reconstruction: 0.004322628490626812\n",
            "loss in epoch 15/21 iteration 4/67: 1.3777872323989868 / BPR loss: 1.3760886192321777 / Matching loss: 3.4965363738592714e-05 / Item reconstruction: 0.00179883127566427 / Text reconstruction: 0.0038213031366467476\n",
            "loss in epoch 15/21 iteration 5/67: 1.3785330057144165 / BPR loss: 1.376893162727356 / Matching loss: 3.660749280243181e-05 / Item reconstruction: 0.0018675016472116113 / Text reconstruction: 0.00334720010869205\n",
            "loss in epoch 15/21 iteration 6/67: 1.3783378601074219 / BPR loss: 1.3767874240875244 / Matching loss: 3.4281896660104394e-05 / Item reconstruction: 0.001785431755706668 / Text reconstruction: 0.0031168865971267223\n",
            "loss in epoch 15/21 iteration 7/67: 1.3787553310394287 / BPR loss: 1.377209186553955 / Matching loss: 3.094190833508037e-05 / Item reconstruction: 0.0017678490839898586 / Text reconstruction: 0.0031559946946799755\n",
            "loss in epoch 15/21 iteration 8/67: 1.3767706155776978 / BPR loss: 1.3752570152282715 / Matching loss: 3.0435250664595515e-05 / Item reconstruction: 0.001644497155211866 / Text reconstruction: 0.0033046328462660313\n",
            "loss in epoch 15/21 iteration 9/67: 1.3788083791732788 / BPR loss: 1.3774380683898926 / Matching loss: 2.838989530573599e-05 / Item reconstruction: 0.0015483031747862697 / Text reconstruction: 0.002839150372892618\n",
            "loss in epoch 15/21 iteration 10/67: 1.3781596422195435 / BPR loss: 1.3767939805984497 / Matching loss: 3.095521969953552e-05 / Item reconstruction: 0.0015918335411697626 / Text reconstruction: 0.0026934780180454254\n",
            "loss in epoch 15/21 iteration 11/67: 1.376369595527649 / BPR loss: 1.3749459981918335 / Matching loss: 3.25774381053634e-05 / Item reconstruction: 0.001675232662819326 / Text reconstruction: 0.0027676583267748356\n",
            "loss in epoch 15/21 iteration 12/67: 1.3788268566131592 / BPR loss: 1.3774725198745728 / Matching loss: 3.35091317538172e-05 / Item reconstruction: 0.0017367848195135593 / Text reconstruction: 0.0022620507515966892\n",
            "loss in epoch 15/21 iteration 13/67: 1.377417802810669 / BPR loss: 1.3760285377502441 / Matching loss: 3.0371034881682135e-05 / Item reconstruction: 0.0016808416694402695 / Text reconstruction: 0.0025922413915395737\n",
            "loss in epoch 15/21 iteration 14/67: 1.3778554201126099 / BPR loss: 1.376427412033081 / Matching loss: 3.0486935429507867e-05 / Item reconstruction: 0.0016581711824983358 / Text reconstruction: 0.002842194866389036\n",
            "loss in epoch 15/21 iteration 15/67: 1.3777538537979126 / BPR loss: 1.3763418197631836 / Matching loss: 2.9309838282642886e-05 / Item reconstruction: 0.0016931314021348953 / Text reconstruction: 0.0026807072572410107\n",
            "loss in epoch 15/21 iteration 16/67: 1.3762136697769165 / BPR loss: 1.3747832775115967 / Matching loss: 3.287268918938935e-05 / Item reconstruction: 0.0015987303340807557 / Text reconstruction: 0.002990511478856206\n",
            "loss in epoch 15/21 iteration 17/67: 1.3771039247512817 / BPR loss: 1.3756656646728516 / Matching loss: 3.1255691283149645e-05 / Item reconstruction: 0.0016760058933869004 / Text reconstruction: 0.002845070557668805\n",
            "loss in epoch 15/21 iteration 18/67: 1.3851147890090942 / BPR loss: 1.3832616806030273 / Matching loss: 4.263012669980526e-05 / Item reconstruction: 0.002478319685906172 / Text reconstruction: 0.0028564119711518288\n",
            "loss in epoch 15/21 iteration 19/67: 1.3882218599319458 / BPR loss: 1.3861801624298096 / Matching loss: 4.169560270383954e-05 / Item reconstruction: 0.0026132522616535425 / Text reconstruction: 0.003466412890702486\n",
            "loss in epoch 15/21 iteration 20/67: 1.387526273727417 / BPR loss: 1.3855608701705933 / Matching loss: 3.730147727765143e-05 / Item reconstruction: 0.002559902612119913 / Text reconstruction: 0.003240911290049553\n",
            "loss in epoch 15/21 iteration 21/67: 1.3862347602844238 / BPR loss: 1.3844443559646606 / Matching loss: 4.239870031597093e-05 / Item reconstruction: 0.0024668960832059383 / Text reconstruction: 0.0025724084116518497\n",
            "loss in epoch 15/21 iteration 22/67: 1.3811023235321045 / BPR loss: 1.3796879053115845 / Matching loss: 2.9367727620410733e-05 / Item reconstruction: 0.0020013991743326187 / Text reconstruction: 0.0019222516566514969\n",
            "loss in epoch 15/21 iteration 23/67: 1.3796061277389526 / BPR loss: 1.3781671524047852 / Matching loss: 3.033106440852862e-05 / Item reconstruction: 0.001973026432096958 / Text reconstruction: 0.002111278008669615\n",
            "loss in epoch 15/21 iteration 24/67: 1.3807522058486938 / BPR loss: 1.3793458938598633 / Matching loss: 3.1340576242655516e-05 / Item reconstruction: 0.0019194621127098799 / Text reconstruction: 0.0020760856568813324\n",
            "loss in epoch 15/21 iteration 25/67: 1.3805928230285645 / BPR loss: 1.379215955734253 / Matching loss: 3.239140278310515e-05 / Item reconstruction: 0.0018375165527686477 / Text reconstruction: 0.0021284616086632013\n",
            "loss in epoch 15/21 iteration 26/67: 1.3800009489059448 / BPR loss: 1.378619909286499 / Matching loss: 2.9779577744193375e-05 / Item reconstruction: 0.0018134473357349634 / Text reconstruction: 0.0022228634916245937\n",
            "loss in epoch 15/21 iteration 27/67: 1.3801318407058716 / BPR loss: 1.3787897825241089 / Matching loss: 2.8103720978833735e-05 / Item reconstruction: 0.0017584206070750952 / Text reconstruction: 0.002173949498683214\n",
            "loss in epoch 15/21 iteration 28/67: 1.3800146579742432 / BPR loss: 1.3787546157836914 / Matching loss: 2.7334333935868926e-05 / Item reconstruction: 0.0016779282595962286 / Text reconstruction: 0.001968622673302889\n",
            "loss in epoch 15/21 iteration 29/67: 1.3799076080322266 / BPR loss: 1.378592848777771 / Matching loss: 2.7528272767085582e-05 / Item reconstruction: 0.0017352811992168427 / Text reconstruction: 0.002097916090860963\n",
            "loss in epoch 15/21 iteration 30/67: 1.3800098896026611 / BPR loss: 1.378755807876587 / Matching loss: 2.6548677851678804e-05 / Item reconstruction: 0.0016571634914726019 / Text reconstruction: 0.001994581427425146\n",
            "loss in epoch 15/21 iteration 31/67: 1.3799554109573364 / BPR loss: 1.378722071647644 / Matching loss: 2.6548874302534387e-05 / Item reconstruction: 0.0016692673088982701 / Text reconstruction: 0.0018610088154673576\n",
            "loss in epoch 15/21 iteration 32/67: 1.3806675672531128 / BPR loss: 1.3795549869537354 / Matching loss: 2.733529072429519e-05 / Item reconstruction: 0.0014766574604436755 / Text reconstruction: 0.0017345575615763664\n",
            "loss in epoch 15/21 iteration 33/67: 1.3825204372406006 / BPR loss: 1.3808135986328125 / Matching loss: 2.698427670111414e-05 / Item reconstruction: 0.002455330453813076 / Text reconstruction: 0.0022615103516727686\n",
            "loss in epoch 15/21 iteration 34/67: 1.3866146802902222 / BPR loss: 1.3848621845245361 / Matching loss: 2.845486596925184e-05 / Item reconstruction: 0.0027075428515672684 / Text reconstruction: 0.0018515349365770817\n",
            "loss in epoch 15/21 iteration 35/67: 1.3852978944778442 / BPR loss: 1.3835997581481934 / Matching loss: 2.7045991373597644e-05 / Item reconstruction: 0.00258239870890975 / Text reconstruction: 0.0018995872233062983\n",
            "loss in epoch 15/21 iteration 36/67: 1.3868440389633179 / BPR loss: 1.385195255279541 / Matching loss: 3.784386717597954e-05 / Item reconstruction: 0.002584807574748993 / Text reconstruction: 0.0015933215618133545\n",
            "loss in epoch 15/21 iteration 37/67: 1.3866238594055176 / BPR loss: 1.3850257396697998 / Matching loss: 3.9483027649112046e-05 / Item reconstruction: 0.0025497269816696644 / Text reconstruction: 0.0014189621433615685\n",
            "loss in epoch 15/21 iteration 38/67: 1.386336326599121 / BPR loss: 1.3848665952682495 / Matching loss: 3.504117194097489e-05 / Item reconstruction: 0.0023738304153084755 / Text reconstruction: 0.0012386448215693235\n",
            "loss in epoch 15/21 iteration 39/67: 1.3866695165634155 / BPR loss: 1.3852779865264893 / Matching loss: 3.327870217617601e-05 / Item reconstruction: 0.002221184317022562 / Text reconstruction: 0.0012387002352625132\n",
            "loss in epoch 15/21 iteration 40/67: 1.3870209455490112 / BPR loss: 1.3856440782546997 / Matching loss: 4.039208579342812e-05 / Item reconstruction: 0.0022914987057447433 / Text reconstruction: 0.0009535863646306098\n",
            "loss in epoch 15/21 iteration 41/67: 1.3835684061050415 / BPR loss: 1.3820475339889526 / Matching loss: 3.6290304706199095e-05 / Item reconstruction: 0.0022255373187363148 / Text reconstruction: 0.0018590319668874145\n",
            "loss in epoch 15/21 iteration 42/67: 1.3784716129302979 / BPR loss: 1.3767454624176025 / Matching loss: 2.9714894481003284e-05 / Item reconstruction: 0.0021284660324454308 / Text reconstruction: 0.003161631291732192\n",
            "loss in epoch 15/21 iteration 43/67: 1.3783190250396729 / BPR loss: 1.376528024673462 / Matching loss: 3.0496055842377245e-05 / Item reconstruction: 0.0020748840179294348 / Text reconstruction: 0.0036150291562080383\n",
            "loss in epoch 15/21 iteration 44/67: 1.3859498500823975 / BPR loss: 1.384608507156372 / Matching loss: 3.151586861349642e-05 / Item reconstruction: 0.0021606525406241417 / Text reconstruction: 0.0011477440129965544\n",
            "loss in epoch 15/21 iteration 45/67: 1.3873107433319092 / BPR loss: 1.3860478401184082 / Matching loss: 3.421004657866433e-05 / Item reconstruction: 0.002134292386472225 / Text reconstruction: 0.000807497650384903\n",
            "loss in epoch 15/21 iteration 46/67: 1.3860455751419067 / BPR loss: 1.3844369649887085 / Matching loss: 3.0136663554003462e-05 / Item reconstruction: 0.002602541819214821 / Text reconstruction: 0.0013859932078048587\n",
            "loss in epoch 15/21 iteration 47/67: 1.3860276937484741 / BPR loss: 1.3844306468963623 / Matching loss: 2.7706024411600083e-05 / Item reconstruction: 0.002548353746533394 / Text reconstruction: 0.0014760075137019157\n",
            "loss in epoch 15/21 iteration 48/67: 1.3866305351257324 / BPR loss: 1.3852367401123047 / Matching loss: 2.971692447317764e-05 / Item reconstruction: 0.0022536551114171743 / Text reconstruction: 0.0011861204402521253\n",
            "loss in epoch 15/21 iteration 49/67: 1.3846254348754883 / BPR loss: 1.3832091093063354 / Matching loss: 2.959483754239045e-05 / Item reconstruction: 0.0021864359732717276 / Text reconstruction: 0.001467265421524644\n",
            "loss in epoch 15/21 iteration 50/67: 1.385016918182373 / BPR loss: 1.3836627006530762 / Matching loss: 3.0278259146143682e-05 / Item reconstruction: 0.0021447413600981236 / Text reconstruction: 0.0012576590524986386\n",
            "loss in epoch 15/21 iteration 51/67: 1.3871766328811646 / BPR loss: 1.3858444690704346 / Matching loss: 3.592453140299767e-05 / Item reconstruction: 0.002240394474938512 / Text reconstruction: 0.0008804101380519569\n",
            "loss in epoch 15/21 iteration 52/67: 1.3875083923339844 / BPR loss: 1.3861579895019531 / Matching loss: 3.2456478948006406e-05 / Item reconstruction: 0.0022532090079039335 / Text reconstruction: 0.0009569101966917515\n",
            "loss in epoch 15/21 iteration 53/67: 1.3866941928863525 / BPR loss: 1.385416030883789 / Matching loss: 3.068877776968293e-05 / Item reconstruction: 0.0021290327422320843 / Text reconstruction: 0.0009150622063316405\n",
            "loss in epoch 15/21 iteration 54/67: 1.3875486850738525 / BPR loss: 1.3862800598144531 / Matching loss: 3.593339351937175e-05 / Item reconstruction: 0.0021593496203422546 / Text reconstruction: 0.0007650967454537749\n",
            "loss in epoch 15/21 iteration 55/67: 1.387947678565979 / BPR loss: 1.38668954372406 / Matching loss: 3.448702045716345e-05 / Item reconstruction: 0.002108954591676593 / Text reconstruction: 0.0008459460223093629\n",
            "loss in epoch 15/21 iteration 56/67: 1.3877289295196533 / BPR loss: 1.3864690065383911 / Matching loss: 3.6631099646911025e-05 / Item reconstruction: 0.002181672491133213 / Text reconstruction: 0.0006622549844905734\n",
            "loss in epoch 15/21 iteration 57/67: 1.3873608112335205 / BPR loss: 1.3861684799194336 / Matching loss: 2.9415587050607428e-05 / Item reconstruction: 0.002018821192905307 / Text reconstruction: 0.0007669394835829735\n",
            "loss in epoch 15/21 iteration 58/67: 1.3871939182281494 / BPR loss: 1.386016607284546 / Matching loss: 3.184708839398809e-05 / Item reconstruction: 0.001991042634472251 / Text reconstruction: 0.0007500756764784455\n",
            "loss in epoch 15/21 iteration 59/67: 1.3875985145568848 / BPR loss: 1.386352300643921 / Matching loss: 3.5059129004366696e-05 / Item reconstruction: 0.0021654837764799595 / Text reconstruction: 0.0006419207202270627\n",
            "loss in epoch 15/21 iteration 60/67: 1.3880436420440674 / BPR loss: 1.3868262767791748 / Matching loss: 3.5172161005903035e-05 / Item reconstruction: 0.0020621444564312696 / Text reconstruction: 0.0007558976649306715\n",
            "loss in epoch 15/21 iteration 61/67: 1.387754201889038 / BPR loss: 1.3865704536437988 / Matching loss: 3.3584728953428566e-05 / Item reconstruction: 0.0020070048049092293 / Text reconstruction: 0.0007331901579163969\n",
            "loss in epoch 15/21 iteration 62/67: 1.3867824077606201 / BPR loss: 1.385496735572815 / Matching loss: 2.5696372176753357e-05 / Item reconstruction: 0.002071250695735216 / Text reconstruction: 0.0011217035353183746\n",
            "loss in epoch 15/21 iteration 63/67: 1.3872584104537964 / BPR loss: 1.3859715461730957 / Matching loss: 4.053585143992677e-05 / Item reconstruction: 0.0022583664394915104 / Text reconstruction: 0.0005857506766915321\n",
            "loss in epoch 15/21 iteration 64/67: 1.3876668214797974 / BPR loss: 1.3864316940307617 / Matching loss: 3.998643660452217e-05 / Item reconstruction: 0.002129539381712675 / Text reconstruction: 0.0006517867441289127\n",
            "loss in epoch 15/21 iteration 65/67: 1.3876079320907593 / BPR loss: 1.3864257335662842 / Matching loss: 3.528144952724688e-05 / Item reconstruction: 0.0020418046042323112 / Text reconstruction: 0.0006300040404312313\n",
            "loss in epoch 15/21 iteration 66/67: 1.3876668214797974 / BPR loss: 1.3866111040115356 / Matching loss: 2.7875204978045076e-05 / Item reconstruction: 0.0017641151789575815 / Text reconstruction: 0.0007292465306818485\n",
            "loss in epoch 15/21 iteration 67/67: 1.387489914894104 / BPR loss: 1.3865106105804443 / Matching loss: 2.1474832465173677e-05 / Item reconstruction: 0.0015868282644078135 / Text reconstruction: 0.0008221310563385487\n",
            " 75% 15/20 [29:34<09:54, 118.89s/it]loss in epoch 16/21 iteration 0/67: 1.3866318464279175 / BPR loss: 1.3852688074111938 / Matching loss: 3.943548654206097e-05 / Item reconstruction: 0.002310452051460743 / Text reconstruction: 0.0008415012271143496\n",
            "loss in epoch 16/21 iteration 1/67: 1.3827463388442993 / BPR loss: 1.3808306455612183 / Matching loss: 4.7567838919349015e-05 / Item reconstruction: 0.002208680147305131 / Text reconstruction: 0.003818644443526864\n",
            "loss in epoch 16/21 iteration 2/67: 1.3785794973373413 / BPR loss: 1.3765429258346558 / Matching loss: 4.2142717575188726e-05 / Item reconstruction: 0.0021557332947850227 / Text reconstruction: 0.004582654684782028\n",
            "loss in epoch 16/21 iteration 3/67: 1.3771034479141235 / BPR loss: 1.3751239776611328 / Matching loss: 3.920571180060506e-05 / Item reconstruction: 0.002097364515066147 / Text reconstruction: 0.004457543138414621\n",
            "loss in epoch 16/21 iteration 4/67: 1.3767929077148438 / BPR loss: 1.3749973773956299 / Matching loss: 3.99606506107375e-05 / Item reconstruction: 0.0019740050192922354 / Text reconstruction: 0.0038427577819675207\n",
            "loss in epoch 16/21 iteration 5/67: 1.3767715692520142 / BPR loss: 1.3751221895217896 / Matching loss: 4.047233596793376e-05 / Item reconstruction: 0.0019208823796361685 / Text reconstruction: 0.0032420919742435217\n",
            "loss in epoch 16/21 iteration 6/67: 1.376133680343628 / BPR loss: 1.3746159076690674 / Matching loss: 3.85067323804833e-05 / Item reconstruction: 0.001795510994270444 / Text reconstruction: 0.0029073988553136587\n",
            "loss in epoch 16/21 iteration 7/67: 1.3764468431472778 / BPR loss: 1.3749628067016602 / Matching loss: 3.360315167810768e-05 / Item reconstruction: 0.001750625902786851 / Text reconstruction: 0.002875290811061859\n",
            "loss in epoch 16/21 iteration 8/67: 1.3759448528289795 / BPR loss: 1.374420166015625 / Matching loss: 3.1969855626812205e-05 / Item reconstruction: 0.0016505855601280928 / Text reconstruction: 0.0033369865268468857\n",
            "loss in epoch 16/21 iteration 9/67: 1.3770219087600708 / BPR loss: 1.3753869533538818 / Matching loss: 3.430572905926965e-05 / Item reconstruction: 0.0017835814505815506 / Text reconstruction: 0.0035439382772892714\n",
            "loss in epoch 16/21 iteration 10/67: 1.3754136562347412 / BPR loss: 1.3737937211990356 / Matching loss: 3.343784555909224e-05 / Item reconstruction: 0.001716977683827281 / Text reconstruction: 0.003639817703515291\n",
            "loss in epoch 16/21 iteration 11/67: 1.375209927558899 / BPR loss: 1.3736530542373657 / Matching loss: 3.361413109814748e-05 / Item reconstruction: 0.001704655820503831 / Text reconstruction: 0.0033547328785061836\n",
            "loss in epoch 16/21 iteration 12/67: 1.3766331672668457 / BPR loss: 1.375121831893921 / Matching loss: 3.33605166815687e-05 / Item reconstruction: 0.0017840550281107426 / Text reconstruction: 0.00292947911657393\n",
            "loss in epoch 16/21 iteration 13/67: 1.3764976263046265 / BPR loss: 1.375091552734375 / Matching loss: 3.2636424293741584e-05 / Item reconstruction: 0.0017189537174999714 / Text reconstruction: 0.0025695771910250187\n",
            "loss in epoch 16/21 iteration 14/67: 1.375913381576538 / BPR loss: 1.374516487121582 / Matching loss: 3.46490451192949e-05 / Item reconstruction: 0.001757246209308505 / Text reconstruction: 0.0024182922206819057\n",
            "loss in epoch 16/21 iteration 15/67: 1.375899314880371 / BPR loss: 1.374456524848938 / Matching loss: 3.2892832678044215e-05 / Item reconstruction: 0.0017473382176831365 / Text reconstruction: 0.00268108700402081\n",
            "loss in epoch 16/21 iteration 16/67: 1.3764907121658325 / BPR loss: 1.3750271797180176 / Matching loss: 3.1592582672601566e-05 / Item reconstruction: 0.0017764887306839228 / Text reconstruction: 0.002718621399253607\n",
            "loss in epoch 16/21 iteration 17/67: 1.376192331314087 / BPR loss: 1.3746695518493652 / Matching loss: 3.3242871722904965e-05 / Item reconstruction: 0.0016801059246063232 / Text reconstruction: 0.0032471404410898685\n",
            "loss in epoch 16/21 iteration 18/67: 1.3842887878417969 / BPR loss: 1.3823142051696777 / Matching loss: 3.8506263081217185e-05 / Item reconstruction: 0.002486573066562414 / Text reconstruction: 0.0034642773680388927\n",
            "loss in epoch 16/21 iteration 19/67: 1.3880614042282104 / BPR loss: 1.3859533071517944 / Matching loss: 3.88393054890912e-05 / Item reconstruction: 0.002660001628100872 / Text reconstruction: 0.0036960369907319546\n",
            "loss in epoch 16/21 iteration 20/67: 1.3875519037246704 / BPR loss: 1.3855572938919067 / Matching loss: 4.318743958720006e-05 / Item reconstruction: 0.0026481803506612778 / Text reconstruction: 0.0031371773220598698\n",
            "loss in epoch 16/21 iteration 21/67: 1.3860557079315186 / BPR loss: 1.384101152420044 / Matching loss: 4.213881402392872e-05 / Item reconstruction: 0.002475503832101822 / Text reconstruction: 0.0033738259226083755\n",
            "loss in epoch 16/21 iteration 22/67: 1.3787213563919067 / BPR loss: 1.3770713806152344 / Matching loss: 3.72366703231819e-05 / Item reconstruction: 0.0020641288720071316 / Text reconstruction: 0.002903408370912075\n",
            "loss in epoch 16/21 iteration 23/67: 1.378854513168335 / BPR loss: 1.3773820400238037 / Matching loss: 2.973662776639685e-05 / Item reconstruction: 0.0018776090582832694 / Text reconstruction: 0.002520171459764242\n",
            "loss in epoch 16/21 iteration 24/67: 1.3788901567459106 / BPR loss: 1.3774548768997192 / Matching loss: 3.2058967917691916e-05 / Item reconstruction: 0.0018972153775393963 / Text reconstruction: 0.002273100195452571\n",
            "loss in epoch 16/21 iteration 25/67: 1.3791208267211914 / BPR loss: 1.377765417098999 / Matching loss: 3.448628558544442e-05 / Item reconstruction: 0.0018387016607448459 / Text reconstruction: 0.0020078890956938267\n",
            "loss in epoch 16/21 iteration 26/67: 1.3797111511230469 / BPR loss: 1.3784098625183105 / Matching loss: 3.157367973471992e-05 / Item reconstruction: 0.001822823891416192 / Text reconstruction: 0.0017915498465299606\n",
            "loss in epoch 16/21 iteration 27/67: 1.3785922527313232 / BPR loss: 1.3772504329681396 / Matching loss: 3.2252344681182876e-05 / Item reconstruction: 0.0018102135509252548 / Text reconstruction: 0.0020216002594679594\n",
            "loss in epoch 16/21 iteration 28/67: 1.3791463375091553 / BPR loss: 1.3778290748596191 / Matching loss: 2.978232441819273e-05 / Item reconstruction: 0.001803044811822474 / Text reconstruction: 0.001929683261550963\n",
            "loss in epoch 16/21 iteration 29/67: 1.3799563646316528 / BPR loss: 1.3785995244979858 / Matching loss: 2.9315628125914373e-05 / Item reconstruction: 0.0017727487720549107 / Text reconstruction: 0.002206086181104183\n",
            "loss in epoch 16/21 iteration 30/67: 1.3792246580123901 / BPR loss: 1.377888798713684 / Matching loss: 2.714601214393042e-05 / Item reconstruction: 0.001704379334114492 / Text reconstruction: 0.00228203390724957\n",
            "loss in epoch 16/21 iteration 31/67: 1.379164218902588 / BPR loss: 1.3778514862060547 / Matching loss: 2.954667797894217e-05 / Item reconstruction: 0.0016383877955377102 / Text reconstruction: 0.002320100087672472\n",
            "loss in epoch 16/21 iteration 32/67: 1.3799670934677124 / BPR loss: 1.3787193298339844 / Matching loss: 2.8670612664427608e-05 / Item reconstruction: 0.0015583084896206856 / Text reconstruction: 0.002199318027123809\n",
            "loss in epoch 16/21 iteration 33/67: 1.381040334701538 / BPR loss: 1.379212498664856 / Matching loss: 3.1415329431183636e-05 / Item reconstruction: 0.0025942104402929544 / Text reconstruction: 0.002496271161362529\n",
            "loss in epoch 16/21 iteration 34/67: 1.3860015869140625 / BPR loss: 1.3843449354171753 / Matching loss: 2.780441354843788e-05 / Item reconstruction: 0.002564436988905072 / Text reconstruction: 0.0017330885166302323\n",
            "loss in epoch 16/21 iteration 35/67: 1.384246826171875 / BPR loss: 1.3825275897979736 / Matching loss: 3.0524803150910884e-05 / Item reconstruction: 0.0026456876657903194 / Text reconstruction: 0.001829042099416256\n",
            "loss in epoch 16/21 iteration 36/67: 1.3871643543243408 / BPR loss: 1.3855035305023193 / Matching loss: 3.910222585545853e-05 / Item reconstruction: 0.0026250239461660385 / Text reconstruction: 0.0015464293537661433\n",
            "loss in epoch 16/21 iteration 37/67: 1.3861957788467407 / BPR loss: 1.384556531906128 / Matching loss: 3.932271647499874e-05 / Item reconstruction: 0.002514269668608904 / Text reconstruction: 0.0017138412222266197\n",
            "loss in epoch 16/21 iteration 38/67: 1.3862881660461426 / BPR loss: 1.3848575353622437 / Matching loss: 3.238081626477651e-05 / Item reconstruction: 0.0023045185953378677 / Text reconstruction: 0.0012295825872570276\n",
            "loss in epoch 16/21 iteration 39/67: 1.3867782354354858 / BPR loss: 1.385416030883789 / Matching loss: 3.22672349284403e-05 / Item reconstruction: 0.0022238180972635746 / Text reconstruction: 0.0010902916546911001\n",
            "loss in epoch 16/21 iteration 40/67: 1.3865268230438232 / BPR loss: 1.3851447105407715 / Matching loss: 3.670954902190715e-05 / Item reconstruction: 0.002228922676295042 / Text reconstruction: 0.001154476311057806\n",
            "loss in epoch 16/21 iteration 41/67: 1.3828685283660889 / BPR loss: 1.3813238143920898 / Matching loss: 3.682375972857699e-05 / Item reconstruction: 0.002244176110252738 / Text reconstruction: 0.001928928541019559\n",
            "loss in epoch 16/21 iteration 42/67: 1.3787130117416382 / BPR loss: 1.37691068649292 / Matching loss: 3.0558774597011507e-05 / Item reconstruction: 0.002223289106041193 / Text reconstruction: 0.003300655400380492\n",
            "loss in epoch 16/21 iteration 43/67: 1.376697063446045 / BPR loss: 1.374820351600647 / Matching loss: 3.048303915420547e-05 / Item reconstruction: 0.0021641883067786694 / Text reconstruction: 0.0038203950971364975\n",
            "loss in epoch 16/21 iteration 44/67: 1.385731816291809 / BPR loss: 1.3843966722488403 / Matching loss: 3.0313804018078372e-05 / Item reconstruction: 0.0021160347387194633 / Text reconstruction: 0.0012341993860900402\n",
            "loss in epoch 16/21 iteration 45/67: 1.3875938653945923 / BPR loss: 1.3862698078155518 / Matching loss: 3.210587601643056e-05 / Item reconstruction: 0.0021577065344899893 / Text reconstruction: 0.001065681455656886\n",
            "loss in epoch 16/21 iteration 46/67: 1.3860009908676147 / BPR loss: 1.3844348192214966 / Matching loss: 2.9376937163760886e-05 / Item reconstruction: 0.002495943568646908 / Text reconstruction: 0.001444282941520214\n",
            "loss in epoch 16/21 iteration 47/67: 1.3862706422805786 / BPR loss: 1.3847140073776245 / Matching loss: 2.822807800839655e-05 / Item reconstruction: 0.0024601116310805082 / Text reconstruction: 0.0014918837696313858\n",
            "loss in epoch 16/21 iteration 48/67: 1.3867900371551514 / BPR loss: 1.385362982749939 / Matching loss: 3.137667226837948e-05 / Item reconstruction: 0.00231226091273129 / Text reconstruction: 0.0011982135474681854\n",
            "loss in epoch 16/21 iteration 49/67: 1.3846336603164673 / BPR loss: 1.3832473754882812 / Matching loss: 2.876678445318248e-05 / Item reconstruction: 0.0021527856588363647 / Text reconstruction: 0.001405973918735981\n",
            "loss in epoch 16/21 iteration 50/67: 1.3851208686828613 / BPR loss: 1.3837261199951172 / Matching loss: 3.296964496257715e-05 / Item reconstruction: 0.0022255268413573503 / Text reconstruction: 0.0012443708255887032\n",
            "loss in epoch 16/21 iteration 51/67: 1.387466311454773 / BPR loss: 1.3861374855041504 / Matching loss: 3.360509799676947e-05 / Item reconstruction: 0.002225200179964304 / Text reconstruction: 0.0009133012499660254\n",
            "loss in epoch 16/21 iteration 52/67: 1.3873181343078613 / BPR loss: 1.3859543800354004 / Matching loss: 2.9447612178046256e-05 / Item reconstruction: 0.0022392889950424433 / Text reconstruction: 0.0010737624252215028\n",
            "loss in epoch 16/21 iteration 53/67: 1.3866249322891235 / BPR loss: 1.3853297233581543 / Matching loss: 3.0278537451522425e-05 / Item reconstruction: 0.002121095545589924 / Text reconstruction: 0.0010215186048299074\n",
            "loss in epoch 16/21 iteration 54/67: 1.387848973274231 / BPR loss: 1.3865658044815063 / Matching loss: 3.7152010918362066e-05 / Item reconstruction: 0.002164598787203431 / Text reconstruction: 0.0008183721802197397\n",
            "loss in epoch 16/21 iteration 55/67: 1.3881481885910034 / BPR loss: 1.386858344078064 / Matching loss: 3.268672662670724e-05 / Item reconstruction: 0.002152763307094574 / Text reconstruction: 0.0009040546137839556\n",
            "loss in epoch 16/21 iteration 56/67: 1.3876088857650757 / BPR loss: 1.3863199949264526 / Matching loss: 3.622507938416675e-05 / Item reconstruction: 0.0021931950468569994 / Text reconstruction: 0.0007803550688549876\n",
            "loss in epoch 16/21 iteration 57/67: 1.3874337673187256 / BPR loss: 1.3862199783325195 / Matching loss: 3.0861330742482096e-05 / Item reconstruction: 0.002055209595710039 / Text reconstruction: 0.0007767593488097191\n",
            "loss in epoch 16/21 iteration 58/67: 1.3874049186706543 / BPR loss: 1.3862287998199463 / Matching loss: 3.026866033906117e-05 / Item reconstruction: 0.001980341039597988 / Text reconstruction: 0.0007786700152792037\n",
            "loss in epoch 16/21 iteration 59/67: 1.3870271444320679 / BPR loss: 1.385779857635498 / Matching loss: 3.349008329678327e-05 / Item reconstruction: 0.0021515190601348877 / Text reconstruction: 0.0006899859290570021\n",
            "loss in epoch 16/21 iteration 60/67: 1.3874624967575073 / BPR loss: 1.3862731456756592 / Matching loss: 3.171173739247024e-05 / Item reconstruction: 0.0020061940886080265 / Text reconstruction: 0.0007724438328295946\n",
            "loss in epoch 16/21 iteration 61/67: 1.3875958919525146 / BPR loss: 1.3864028453826904 / Matching loss: 3.205455868737772e-05 / Item reconstruction: 0.0019941464997828007 / Text reconstruction: 0.0008194484980776906\n",
            "loss in epoch 16/21 iteration 62/67: 1.3871006965637207 / BPR loss: 1.3857852220535278 / Matching loss: 2.4934266548370942e-05 / Item reconstruction: 0.002092100214213133 / Text reconstruction: 0.0012226218823343515\n",
            "loss in epoch 16/21 iteration 63/67: 1.3871572017669678 / BPR loss: 1.385887861251831 / Matching loss: 4.029461706522852e-05 / Item reconstruction: 0.0022068913094699383 / Text reconstruction: 0.0006281920941546559\n",
            "loss in epoch 16/21 iteration 64/67: 1.388240933418274 / BPR loss: 1.386986494064331 / Matching loss: 3.7310324842110276e-05 / Item reconstruction: 0.0021419492550194263 / Text reconstruction: 0.0007309150532819331\n",
            "loss in epoch 16/21 iteration 65/67: 1.3877168893814087 / BPR loss: 1.386514663696289 / Matching loss: 3.62588616553694e-05 / Item reconstruction: 0.0020298627205193043 / Text reconstruction: 0.0007550280424766243\n",
            "loss in epoch 16/21 iteration 66/67: 1.3873319625854492 / BPR loss: 1.386309027671814 / Matching loss: 2.4237520847236738e-05 / Item reconstruction: 0.001693948172032833 / Text reconstruction: 0.0007587558357045054\n",
            "loss in epoch 16/21 iteration 67/67: 1.3873356580734253 / BPR loss: 1.3863650560379028 / Matching loss: 1.987505311262794e-05 / Item reconstruction: 0.0015568493399769068 / Text reconstruction: 0.0008611931698396802\n",
            " 80% 16/20 [31:33<07:55, 118.90s/it]loss in epoch 17/21 iteration 0/67: 1.3870282173156738 / BPR loss: 1.3856128454208374 / Matching loss: 3.832812581094913e-05 / Item reconstruction: 0.0023391861468553543 / Text reconstruction: 0.001036857021972537\n",
            "loss in epoch 17/21 iteration 1/67: 1.3821672201156616 / BPR loss: 1.3802454471588135 / Matching loss: 3.5989287425763905e-05 / Item reconstruction: 0.0023708385415375233 / Text reconstruction: 0.003501799888908863\n",
            "loss in epoch 17/21 iteration 2/67: 1.37759268283844 / BPR loss: 1.3755708932876587 / Matching loss: 3.662869130494073e-05 / Item reconstruction: 0.002211819402873516 / Text reconstruction: 0.004396369215101004\n",
            "loss in epoch 17/21 iteration 3/67: 1.375488519668579 / BPR loss: 1.3733277320861816 / Matching loss: 3.452331657172181e-05 / Item reconstruction: 0.0022175738122314215 / Text reconstruction: 0.005087348632514477\n",
            "loss in epoch 17/21 iteration 4/67: 1.3750650882720947 / BPR loss: 1.3729755878448486 / Matching loss: 3.381336500751786e-05 / Item reconstruction: 0.002213072031736374 / Text reconstruction: 0.004745905287563801\n",
            "loss in epoch 17/21 iteration 5/67: 1.3750252723693848 / BPR loss: 1.373152732849121 / Matching loss: 3.437170016695745e-05 / Item reconstruction: 0.0020722951740026474 / Text reconstruction: 0.0040100631304085255\n",
            "loss in epoch 17/21 iteration 6/67: 1.375470519065857 / BPR loss: 1.3737714290618896 / Matching loss: 3.297260627732612e-05 / Item reconstruction: 0.0019333170494064689 / Text reconstruction: 0.003496789140626788\n",
            "loss in epoch 17/21 iteration 7/67: 1.3754628896713257 / BPR loss: 1.373794674873352 / Matching loss: 3.392320650164038e-05 / Item reconstruction: 0.0019138820935040712 / Text reconstruction: 0.0033868474420160055\n",
            "loss in epoch 17/21 iteration 8/67: 1.3744611740112305 / BPR loss: 1.3727567195892334 / Matching loss: 3.165179077768698e-05 / Item reconstruction: 0.0018868583720177412 / Text reconstruction: 0.0036463243886828423\n",
            "loss in epoch 17/21 iteration 9/67: 1.3771989345550537 / BPR loss: 1.3755900859832764 / Matching loss: 2.963771839858964e-05 / Item reconstruction: 0.0018128571100533009 / Text reconstruction: 0.003363488707691431\n",
            "loss in epoch 17/21 iteration 10/67: 1.3740054368972778 / BPR loss: 1.3724265098571777 / Matching loss: 3.1546915124636143e-05 / Item reconstruction: 0.0017499257810413837 / Text reconstruction: 0.0033618914894759655\n",
            "loss in epoch 17/21 iteration 11/67: 1.3745968341827393 / BPR loss: 1.3730835914611816 / Matching loss: 2.864183989004232e-05 / Item reconstruction: 0.0017681862227618694 / Text reconstruction: 0.0030031134374439716\n",
            "loss in epoch 17/21 iteration 12/67: 1.3752514123916626 / BPR loss: 1.3736382722854614 / Matching loss: 2.917153869930189e-05 / Item reconstruction: 0.001957700587809086 / Text reconstruction: 0.0030255839228630066\n",
            "loss in epoch 17/21 iteration 13/67: 1.3752447366714478 / BPR loss: 1.373699426651001 / Matching loss: 3.0173665436450392e-05 / Item reconstruction: 0.0018945543561130762 / Text reconstruction: 0.0028393063694238663\n",
            "loss in epoch 17/21 iteration 14/67: 1.3744255304336548 / BPR loss: 1.3728150129318237 / Matching loss: 3.0697639886057004e-05 / Item reconstruction: 0.0019152099266648293 / Text reconstruction: 0.0031109056435525417\n",
            "loss in epoch 17/21 iteration 15/67: 1.3740603923797607 / BPR loss: 1.3724892139434814 / Matching loss: 2.746016252785921e-05 / Item reconstruction: 0.0018359841778874397 / Text reconstruction: 0.0031288820318877697\n",
            "loss in epoch 17/21 iteration 16/67: 1.3738676309585571 / BPR loss: 1.3723400831222534 / Matching loss: 2.7127865905640647e-05 / Item reconstruction: 0.0017233577091246843 / Text reconstruction: 0.003193629439920187\n",
            "loss in epoch 17/21 iteration 17/67: 1.3744980096817017 / BPR loss: 1.3729090690612793 / Matching loss: 2.9616832762258127e-05 / Item reconstruction: 0.001835394068621099 / Text reconstruction: 0.0032084225676953793\n",
            "loss in epoch 17/21 iteration 18/67: 1.384462833404541 / BPR loss: 1.382418155670166 / Matching loss: 3.616131652961485e-05 / Item reconstruction: 0.0026675653643906116 / Text reconstruction: 0.0033734894823282957\n",
            "loss in epoch 17/21 iteration 19/67: 1.388116478919983 / BPR loss: 1.3858273029327393 / Matching loss: 3.83538608730305e-05 / Item reconstruction: 0.002937931101769209 / Text reconstruction: 0.0039091091603040695\n",
            "loss in epoch 17/21 iteration 20/67: 1.3876792192459106 / BPR loss: 1.3853975534439087 / Matching loss: 4.851379708270542e-05 / Item reconstruction: 0.002788152080029249 / Text reconstruction: 0.004195718094706535\n",
            "loss in epoch 17/21 iteration 21/67: 1.3856853246688843 / BPR loss: 1.3838716745376587 / Matching loss: 3.9835795178078115e-05 / Item reconstruction: 0.0025187665596604347 / Text reconstruction: 0.0025724167935550213\n",
            "loss in epoch 17/21 iteration 22/67: 1.3777828216552734 / BPR loss: 1.376225471496582 / Matching loss: 3.0196468287613243e-05 / Item reconstruction: 0.002077579963952303 / Text reconstruction: 0.002441876567900181\n",
            "loss in epoch 17/21 iteration 23/67: 1.3784620761871338 / BPR loss: 1.3768916130065918 / Matching loss: 3.14117714879103e-05 / Item reconstruction: 0.0020450479350984097 / Text reconstruction: 0.002582083223387599\n",
            "loss in epoch 17/21 iteration 24/67: 1.3775651454925537 / BPR loss: 1.3760173320770264 / Matching loss: 3.294824273325503e-05 / Item reconstruction: 0.0020382916554808617 / Text reconstruction: 0.002478820038959384\n",
            "loss in epoch 17/21 iteration 25/67: 1.3785505294799805 / BPR loss: 1.3770755529403687 / Matching loss: 2.8731112251989543e-05 / Item reconstruction: 0.0019838903099298477 / Text reconstruction: 0.002271452220156789\n",
            "loss in epoch 17/21 iteration 26/67: 1.3779683113098145 / BPR loss: 1.376551866531372 / Matching loss: 3.122953057754785e-05 / Item reconstruction: 0.001894523622468114 / Text reconstruction: 0.0021897221449762583\n",
            "loss in epoch 17/21 iteration 27/67: 1.376322865486145 / BPR loss: 1.374828577041626 / Matching loss: 2.969321758428123e-05 / Item reconstruction: 0.001956155290827155 / Text reconstruction: 0.002432241104543209\n",
            "loss in epoch 17/21 iteration 28/67: 1.3780920505523682 / BPR loss: 1.376723051071167 / Matching loss: 2.971996582346037e-05 / Item reconstruction: 0.0018043641466647387 / Text reconstruction: 0.0021855542436242104\n",
            "loss in epoch 17/21 iteration 29/67: 1.3778232336044312 / BPR loss: 1.3764395713806152 / Matching loss: 2.8175571060273796e-05 / Item reconstruction: 0.0017936339136213064 / Text reconstruction: 0.0022936160676181316\n",
            "loss in epoch 17/21 iteration 30/67: 1.377071738243103 / BPR loss: 1.3755881786346436 / Matching loss: 2.8938760806340724e-05 / Item reconstruction: 0.0018919293070212007 / Text reconstruction: 0.0025432640686631203\n",
            "loss in epoch 17/21 iteration 31/67: 1.378170371055603 / BPR loss: 1.3768010139465332 / Matching loss: 2.8445017960621044e-05 / Item reconstruction: 0.0017715730937197804 / Text reconstruction: 0.002274919068440795\n",
            "loss in epoch 17/21 iteration 32/67: 1.3776946067810059 / BPR loss: 1.3764526844024658 / Matching loss: 2.7532887543202378e-05 / Item reconstruction: 0.001553109847009182 / Text reconstruction: 0.0021895496174693108\n",
            "loss in epoch 17/21 iteration 33/67: 1.3807905912399292 / BPR loss: 1.378946304321289 / Matching loss: 3.1454772397410125e-05 / Item reconstruction: 0.0025988381821662188 / Text reconstruction: 0.0025668819434940815\n",
            "loss in epoch 17/21 iteration 34/67: 1.386084794998169 / BPR loss: 1.3843265771865845 / Matching loss: 2.770678656816017e-05 / Item reconstruction: 0.002696780953556299 / Text reconstruction: 0.001911205006763339\n",
            "loss in epoch 17/21 iteration 35/67: 1.3851683139801025 / BPR loss: 1.3834898471832275 / Matching loss: 2.6179724954999983e-05 / Item reconstruction: 0.002604277804493904 / Text reconstruction: 0.0017507256707176566\n",
            "loss in epoch 17/21 iteration 36/67: 1.3868579864501953 / BPR loss: 1.3851276636123657 / Matching loss: 3.7038818845758215e-05 / Item reconstruction: 0.002671427559107542 / Text reconstruction: 0.001787609769962728\n",
            "loss in epoch 17/21 iteration 37/67: 1.386910080909729 / BPR loss: 1.3852617740631104 / Matching loss: 3.663371899165213e-05 / Item reconstruction: 0.0025481986813247204 / Text reconstruction: 0.0016877835150808096\n",
            "loss in epoch 17/21 iteration 38/67: 1.38583505153656 / BPR loss: 1.3843295574188232 / Matching loss: 3.414266029722057e-05 / Item reconstruction: 0.002427911851555109 / Text reconstruction: 0.0012874770909547806\n",
            "loss in epoch 17/21 iteration 39/67: 1.3861647844314575 / BPR loss: 1.3846875429153442 / Matching loss: 3.207100962754339e-05 / Item reconstruction: 0.002325948793441057 / Text reconstruction: 0.0014111336786299944\n",
            "loss in epoch 17/21 iteration 40/67: 1.3864855766296387 / BPR loss: 1.3850083351135254 / Matching loss: 3.681941961986013e-05 / Item reconstruction: 0.0023591192439198494 / Text reconstruction: 0.0013042786158621311\n",
            "loss in epoch 17/21 iteration 41/67: 1.381757140159607 / BPR loss: 1.3801615238189697 / Matching loss: 3.525420106598176e-05 / Item reconstruction: 0.002303633838891983 / Text reconstruction: 0.0020429363939911127\n",
            "loss in epoch 17/21 iteration 42/67: 1.3771069049835205 / BPR loss: 1.3751375675201416 / Matching loss: 2.8398500944604166e-05 / Item reconstruction: 0.0024004620499908924 / Text reconstruction: 0.003703772323206067\n",
            "loss in epoch 17/21 iteration 43/67: 1.3756588697433472 / BPR loss: 1.3736069202423096 / Matching loss: 3.008704516105354e-05 / Item reconstruction: 0.0024067042395472527 / Text reconstruction: 0.004093264229595661\n",
            "loss in epoch 17/21 iteration 44/67: 1.385525107383728 / BPR loss: 1.3841314315795898 / Matching loss: 2.9815037123626098e-05 / Item reconstruction: 0.002168901264667511 / Text reconstruction: 0.0013970591826364398\n",
            "loss in epoch 17/21 iteration 45/67: 1.3872729539871216 / BPR loss: 1.385927438735962 / Matching loss: 3.3334999898215756e-05 / Item reconstruction: 0.0022025643847882748 / Text reconstruction: 0.001054337015375495\n",
            "loss in epoch 17/21 iteration 46/67: 1.3856853246688843 / BPR loss: 1.3841145038604736 / Matching loss: 2.8714057407341897e-05 / Item reconstruction: 0.0025021228939294815 / Text reconstruction: 0.0014550283085554838\n",
            "loss in epoch 17/21 iteration 47/67: 1.3856987953186035 / BPR loss: 1.3840651512145996 / Matching loss: 3.2055206247605383e-05 / Item reconstruction: 0.0025662160478532314 / Text reconstruction: 0.00159276626072824\n",
            "loss in epoch 17/21 iteration 48/67: 1.3862285614013672 / BPR loss: 1.384782314300537 / Matching loss: 2.8482483685365878e-05 / Item reconstruction: 0.0022670067846775055 / Text reconstruction: 0.001420804881490767\n",
            "loss in epoch 17/21 iteration 49/67: 1.3840129375457764 / BPR loss: 1.3825762271881104 / Matching loss: 2.946052154584322e-05 / Item reconstruction: 0.00222401088103652 / Text reconstruction: 0.0014763216022402048\n",
            "loss in epoch 17/21 iteration 50/67: 1.3845404386520386 / BPR loss: 1.383131504058838 / Matching loss: 3.060860399273224e-05 / Item reconstruction: 0.002238580957055092 / Text reconstruction: 0.0012951868120580912\n",
            "loss in epoch 17/21 iteration 51/67: 1.3870316743850708 / BPR loss: 1.385713815689087 / Matching loss: 3.370787817402743e-05 / Item reconstruction: 0.0022135255858302116 / Text reconstruction: 0.000887175789102912\n",
            "loss in epoch 17/21 iteration 52/67: 1.3876187801361084 / BPR loss: 1.3861713409423828 / Matching loss: 3.3584281482035294e-05 / Item reconstruction: 0.0023910393938422203 / Text reconstruction: 0.0010915304301306605\n",
            "loss in epoch 17/21 iteration 53/67: 1.3863766193389893 / BPR loss: 1.38506019115448 / Matching loss: 3.226572152925655e-05 / Item reconstruction: 0.002199052833020687 / Text reconstruction: 0.0009231391595676541\n",
            "loss in epoch 17/21 iteration 54/67: 1.3874340057373047 / BPR loss: 1.386167049407959 / Matching loss: 3.666470729513094e-05 / Item reconstruction: 0.0021651890128850937 / Text reconstruction: 0.0007382109761238098\n",
            "loss in epoch 17/21 iteration 55/67: 1.3881415128707886 / BPR loss: 1.3868765830993652 / Matching loss: 3.1879077141638845e-05 / Item reconstruction: 0.0021408647298812866 / Text reconstruction: 0.0008135898970067501\n",
            "loss in epoch 17/21 iteration 56/67: 1.3872953653335571 / BPR loss: 1.3860135078430176 / Matching loss: 3.497826764942147e-05 / Item reconstruction: 0.0021835905499756336 / Text reconstruction: 0.0007757378043606877\n",
            "loss in epoch 17/21 iteration 57/67: 1.3877681493759155 / BPR loss: 1.3865503072738647 / Matching loss: 3.421689325477928e-05 / Item reconstruction: 0.00201747240498662 / Text reconstruction: 0.0008741363417357206\n",
            "loss in epoch 17/21 iteration 58/67: 1.3873142004013062 / BPR loss: 1.3860859870910645 / Matching loss: 3.034749170183204e-05 / Item reconstruction: 0.002057898323982954 / Text reconstruction: 0.0008448371081613004\n",
            "loss in epoch 17/21 iteration 59/67: 1.3875106573104858 / BPR loss: 1.3862388134002686 / Matching loss: 3.521220060065389e-05 / Item reconstruction: 0.0021668728440999985 / Text reconstruction: 0.0007658571121282876\n",
            "loss in epoch 17/21 iteration 60/67: 1.387611746788025 / BPR loss: 1.386364459991455 / Matching loss: 3.230255970265716e-05 / Item reconstruction: 0.002078712685033679 / Text reconstruction: 0.0008777698967605829\n",
            "loss in epoch 17/21 iteration 61/67: 1.3878397941589355 / BPR loss: 1.3866548538208008 / Matching loss: 2.9180975616327487e-05 / Item reconstruction: 0.001960300374776125 / Text reconstruction: 0.0008782480144873261\n",
            "loss in epoch 17/21 iteration 62/67: 1.3867772817611694 / BPR loss: 1.3854135274887085 / Matching loss: 2.553602280386258e-05 / Item reconstruction: 0.0021251521538943052 / Text reconstruction: 0.0013777922140434384\n",
            "loss in epoch 17/21 iteration 63/67: 1.3875491619110107 / BPR loss: 1.3862543106079102 / Matching loss: 3.8336991565302014e-05 / Item reconstruction: 0.002222523558884859 / Text reconstruction: 0.0007262494182214141\n",
            "loss in epoch 17/21 iteration 64/67: 1.3880318403244019 / BPR loss: 1.3867790699005127 / Matching loss: 3.7217570934444666e-05 / Item reconstruction: 0.0021073962561786175 / Text reconstruction: 0.0008095555822364986\n",
            "loss in epoch 17/21 iteration 65/67: 1.3873356580734253 / BPR loss: 1.3861119747161865 / Matching loss: 3.548053791746497e-05 / Item reconstruction: 0.0020460798405110836 / Text reconstruction: 0.000825388531666249\n",
            "loss in epoch 17/21 iteration 66/67: 1.3876800537109375 / BPR loss: 1.3866245746612549 / Matching loss: 2.779286114673596e-05 / Item reconstruction: 0.0017199012218043208 / Text reconstruction: 0.0008385892724618316\n",
            "loss in epoch 17/21 iteration 67/67: 1.3873755931854248 / BPR loss: 1.3864223957061768 / Matching loss: 1.901175346574746e-05 / Item reconstruction: 0.0015041837468743324 / Text reconstruction: 0.0009105759672820568\n",
            " 85% 17/20 [33:40<06:03, 121.22s/it]loss in epoch 18/21 iteration 0/67: 1.386928915977478 / BPR loss: 1.385501503944397 / Matching loss: 3.7843296013306826e-05 / Item reconstruction: 0.0023277332074940205 / Text reconstruction: 0.0011291800765320659\n",
            "loss in epoch 18/21 iteration 1/67: 1.3811014890670776 / BPR loss: 1.3789000511169434 / Matching loss: 4.688249100581743e-05 / Item reconstruction: 0.0026167132891714573 / Text reconstruction: 0.004231525119394064\n",
            "loss in epoch 18/21 iteration 2/67: 1.3763526678085327 / BPR loss: 1.374045968055725 / Matching loss: 4.098641875316389e-05 / Item reconstruction: 0.002498367801308632 / Text reconstruction: 0.005082634277641773\n",
            "loss in epoch 18/21 iteration 3/67: 1.3749704360961914 / BPR loss: 1.3725886344909668 / Matching loss: 3.9236725569935516e-05 / Item reconstruction: 0.002586844377219677 / Text reconstruction: 0.005245846696197987\n",
            "loss in epoch 18/21 iteration 4/67: 1.3746166229248047 / BPR loss: 1.3724122047424316 / Matching loss: 3.948458834202029e-05 / Item reconstruction: 0.002461804775521159 / Text reconstruction: 0.004670063033699989\n",
            "loss in epoch 18/21 iteration 5/67: 1.3737983703613281 / BPR loss: 1.3717677593231201 / Matching loss: 3.317111259093508e-05 / Item reconstruction: 0.002285799477249384 / Text reconstruction: 0.004273208323866129\n",
            "loss in epoch 18/21 iteration 6/67: 1.3738535642623901 / BPR loss: 1.3719255924224854 / Matching loss: 3.271970490459353e-05 / Item reconstruction: 0.0021705280523747206 / Text reconstruction: 0.004049895331263542\n",
            "loss in epoch 18/21 iteration 7/67: 1.3736759424209595 / BPR loss: 1.3718386888504028 / Matching loss: 3.3094940590672195e-05 / Item reconstruction: 0.002072605537250638 / Text reconstruction: 0.0038392548449337482\n",
            "loss in epoch 18/21 iteration 8/67: 1.3719704151153564 / BPR loss: 1.3701189756393433 / Matching loss: 3.0854087526677176e-05 / Item reconstruction: 0.0020379682537168264 / Text reconstruction: 0.004007523413747549\n",
            "loss in epoch 18/21 iteration 9/67: 1.3736350536346436 / BPR loss: 1.3718476295471191 / Matching loss: 3.15271936415229e-05 / Item reconstruction: 0.002021016553044319 / Text reconstruction: 0.003726869821548462\n",
            "loss in epoch 18/21 iteration 10/67: 1.3724318742752075 / BPR loss: 1.3706226348876953 / Matching loss: 3.088611993007362e-05 / Item reconstruction: 0.0019363949541002512 / Text reconstruction: 0.004050776362419128\n",
            "loss in epoch 18/21 iteration 11/67: 1.3722835779190063 / BPR loss: 1.3705413341522217 / Matching loss: 2.91722608380951e-05 / Item reconstruction: 0.0019641751423478127 / Text reconstruction: 0.0036551556549966335\n",
            "loss in epoch 18/21 iteration 12/67: 1.374290943145752 / BPR loss: 1.3725073337554932 / Matching loss: 3.310680403956212e-05 / Item reconstruction: 0.002121587749570608 / Text reconstruction: 0.003448276547715068\n",
            "loss in epoch 18/21 iteration 13/67: 1.3734370470046997 / BPR loss: 1.3717679977416992 / Matching loss: 3.0826959118712693e-05 / Item reconstruction: 0.0020542233251035213 / Text reconstruction: 0.0030555962584912777\n",
            "loss in epoch 18/21 iteration 14/67: 1.3735092878341675 / BPR loss: 1.3717777729034424 / Matching loss: 3.088064113399014e-05 / Item reconstruction: 0.0021045925095677376 / Text reconstruction: 0.0032421729993075132\n",
            "loss in epoch 18/21 iteration 15/67: 1.3728747367858887 / BPR loss: 1.3711860179901123 / Matching loss: 3.0202281777746975e-05 / Item reconstruction: 0.002068794332444668 / Text reconstruction: 0.0031207490246742964\n",
            "loss in epoch 18/21 iteration 16/67: 1.371626377105713 / BPR loss: 1.3698627948760986 / Matching loss: 3.1006336939753965e-05 / Item reconstruction: 0.0020782623905688524 / Text reconstruction: 0.0034669884480535984\n",
            "loss in epoch 18/21 iteration 17/67: 1.3730840682983398 / BPR loss: 1.371260643005371 / Matching loss: 2.9680410079890862e-05 / Item reconstruction: 0.002051591407507658 / Text reconstruction: 0.0038397808093577623\n",
            "loss in epoch 18/21 iteration 18/67: 1.3838717937469482 / BPR loss: 1.3816280364990234 / Matching loss: 3.7527544918702915e-05 / Item reconstruction: 0.0029154981020838022 / Text reconstruction: 0.0037423274479806423\n",
            "loss in epoch 18/21 iteration 19/67: 1.3883448839187622 / BPR loss: 1.3858106136322021 / Matching loss: 3.8379133911803365e-05 / Item reconstruction: 0.003191279713064432 / Text reconstruction: 0.004501269198954105\n",
            "loss in epoch 18/21 iteration 20/67: 1.3879778385162354 / BPR loss: 1.385780692100525 / Matching loss: 3.717272193171084e-05 / Item reconstruction: 0.0029245857149362564 / Text reconstruction: 0.003487793728709221\n",
            "loss in epoch 18/21 iteration 21/67: 1.3859800100326538 / BPR loss: 1.3838903903961182 / Matching loss: 3.806902532232925e-05 / Item reconstruction: 0.002760539762675762 / Text reconstruction: 0.0033566071651875973\n",
            "loss in epoch 18/21 iteration 22/67: 1.3771333694458008 / BPR loss: 1.3754324913024902 / Matching loss: 2.8011563699692488e-05 / Item reconstruction: 0.0022341443691402674 / Text reconstruction: 0.0027787478175014257\n",
            "loss in epoch 18/21 iteration 23/67: 1.3764218091964722 / BPR loss: 1.3747986555099487 / Matching loss: 2.775426946755033e-05 / Item reconstruction: 0.0021673296578228474 / Text reconstruction: 0.0025589498691260815\n",
            "loss in epoch 18/21 iteration 24/67: 1.3771034479141235 / BPR loss: 1.375458002090454 / Matching loss: 3.149551776004955e-05 / Item reconstruction: 0.0022114908788353205 / Text reconstruction: 0.0025411113165318966\n",
            "loss in epoch 18/21 iteration 25/67: 1.37733793258667 / BPR loss: 1.3757996559143066 / Matching loss: 2.9172628273954615e-05 / Item reconstruction: 0.0020979326218366623 / Text reconstruction: 0.002300975378602743\n",
            "loss in epoch 18/21 iteration 26/67: 1.3776057958602905 / BPR loss: 1.3760970830917358 / Matching loss: 2.7065654649049975e-05 / Item reconstruction: 0.0020020962692797184 / Text reconstruction: 0.0024035265669226646\n",
            "loss in epoch 18/21 iteration 27/67: 1.3754993677139282 / BPR loss: 1.3739207983016968 / Matching loss: 2.8155405743746087e-05 / Item reconstruction: 0.002052054274827242 / Text reconstruction: 0.0026222094893455505\n",
            "loss in epoch 18/21 iteration 28/67: 1.377116322517395 / BPR loss: 1.3756234645843506 / Matching loss: 2.7513873646967113e-05 / Item reconstruction: 0.001968708820641041 / Text reconstruction: 0.002405099105089903\n",
            "loss in epoch 18/21 iteration 29/67: 1.3760569095611572 / BPR loss: 1.374542236328125 / Matching loss: 2.657010372786317e-05 / Item reconstruction: 0.0019352633971720934 / Text reconstruction: 0.0026022614911198616\n",
            "loss in epoch 18/21 iteration 30/67: 1.376395583152771 / BPR loss: 1.3748407363891602 / Matching loss: 2.6394078304292634e-05 / Item reconstruction: 0.001985548995435238 / Text reconstruction: 0.0026787903625518084\n",
            "loss in epoch 18/21 iteration 31/67: 1.3768409490585327 / BPR loss: 1.3753647804260254 / Matching loss: 2.8021211619488895e-05 / Item reconstruction: 0.0018921162700280547 / Text reconstruction: 0.0025104403030127287\n",
            "loss in epoch 18/21 iteration 32/67: 1.3762907981872559 / BPR loss: 1.374953269958496 / Matching loss: 2.6732683181762695e-05 / Item reconstruction: 0.001728652510792017 / Text reconstruction: 0.002233039354905486\n",
            "loss in epoch 18/21 iteration 33/67: 1.3802902698516846 / BPR loss: 1.3783199787139893 / Matching loss: 3.3110514777945355e-05 / Item reconstruction: 0.0027204607613384724 / Text reconstruction: 0.0028849774971604347\n",
            "loss in epoch 18/21 iteration 34/67: 1.3858534097671509 / BPR loss: 1.3840999603271484 / Matching loss: 2.8174974431749433e-05 / Item reconstruction: 0.002692539244890213 / Text reconstruction: 0.00189518416300416\n",
            "loss in epoch 18/21 iteration 35/67: 1.3840086460113525 / BPR loss: 1.3822486400604248 / Matching loss: 2.882386979763396e-05 / Item reconstruction: 0.002658129669725895 / Text reconstruction: 0.0020103035494685173\n",
            "loss in epoch 18/21 iteration 36/67: 1.3870508670806885 / BPR loss: 1.3853018283843994 / Matching loss: 3.4244807466166094e-05 / Item reconstruction: 0.0026003820821642876 / Text reconstruction: 0.0020732413977384567\n",
            "loss in epoch 18/21 iteration 37/67: 1.3868416547775269 / BPR loss: 1.385061502456665 / Matching loss: 3.799758633249439e-05 / Item reconstruction: 0.0026599313132464886 / Text reconstruction: 0.00206024874933064\n",
            "loss in epoch 18/21 iteration 38/67: 1.3857392072677612 / BPR loss: 1.38419771194458 / Matching loss: 3.309788735350594e-05 / Item reconstruction: 0.002432796638458967 / Text reconstruction: 0.0014597228728234768\n",
            "loss in epoch 18/21 iteration 39/67: 1.3870803117752075 / BPR loss: 1.3856189250946045 / Matching loss: 3.0293065719888546e-05 / Item reconstruction: 0.0023380406200885773 / Text reconstruction: 0.00131093745585531\n",
            "loss in epoch 18/21 iteration 40/67: 1.3870824575424194 / BPR loss: 1.3855926990509033 / Matching loss: 3.534372808644548e-05 / Item reconstruction: 0.0023872889578342438 / Text reconstruction: 0.0013044070219621062\n",
            "loss in epoch 18/21 iteration 41/67: 1.3815339803695679 / BPR loss: 1.3797707557678223 / Matching loss: 3.533584822434932e-05 / Item reconstruction: 0.00250258669257164 / Text reconstruction: 0.0023832586593925953\n",
            "loss in epoch 18/21 iteration 42/67: 1.3739458322525024 / BPR loss: 1.3717327117919922 / Matching loss: 2.7086180125479586e-05 / Item reconstruction: 0.0027208272367715836 / Text reconstruction: 0.004128440748900175\n",
            "loss in epoch 18/21 iteration 43/67: 1.3729300498962402 / BPR loss: 1.370612621307373 / Matching loss: 3.057824505958706e-05 / Item reconstruction: 0.0027225061785429716 / Text reconstruction: 0.004627807531505823\n",
            "loss in epoch 18/21 iteration 44/67: 1.3850367069244385 / BPR loss: 1.3836205005645752 / Matching loss: 2.9594784791697748e-05 / Item reconstruction: 0.0022264926228672266 / Text reconstruction: 0.0013666811864823103\n",
            "loss in epoch 18/21 iteration 45/67: 1.3869140148162842 / BPR loss: 1.3855972290039062 / Matching loss: 2.9004768293816596e-05 / Item reconstruction: 0.0021296220365911722 / Text reconstruction: 0.001114947022870183\n",
            "loss in epoch 18/21 iteration 46/67: 1.3845356702804565 / BPR loss: 1.382962942123413 / Matching loss: 2.7246418540016748e-05 / Item reconstruction: 0.002495226915925741 / Text reconstruction: 0.0014888711739331484\n",
            "loss in epoch 18/21 iteration 47/67: 1.3856244087219238 / BPR loss: 1.3840357065200806 / Matching loss: 2.5970644855988212e-05 / Item reconstruction: 0.002482794225215912 / Text reconstruction: 0.0016061931382864714\n",
            "loss in epoch 18/21 iteration 48/67: 1.3863486051559448 / BPR loss: 1.3849263191223145 / Matching loss: 2.6642796001397073e-05 / Item reconstruction: 0.002218877896666527 / Text reconstruction: 0.0014312828425318003\n",
            "loss in epoch 18/21 iteration 49/67: 1.3827027082443237 / BPR loss: 1.381170392036438 / Matching loss: 2.56180101132486e-05 / Item reconstruction: 0.0022809531074017286 / Text reconstruction: 0.001830932218581438\n",
            "loss in epoch 18/21 iteration 50/67: 1.3840996026992798 / BPR loss: 1.3825500011444092 / Matching loss: 3.1796655093785375e-05 / Item reconstruction: 0.00238525471650064 / Text reconstruction: 0.0016260917764157057\n",
            "loss in epoch 18/21 iteration 51/67: 1.3873575925827026 / BPR loss: 1.3860108852386475 / Matching loss: 3.1784558814251795e-05 / Item reconstruction: 0.002239109482616186 / Text reconstruction: 0.0009764480637386441\n",
            "loss in epoch 18/21 iteration 52/67: 1.3870410919189453 / BPR loss: 1.3856202363967896 / Matching loss: 2.785902688628994e-05 / Item reconstruction: 0.0023232661187648773 / Text reconstruction: 0.0011572169605642557\n",
            "loss in epoch 18/21 iteration 53/67: 1.3862773180007935 / BPR loss: 1.3849200010299683 / Matching loss: 2.7295423933537677e-05 / Item reconstruction: 0.002205468714237213 / Text reconstruction: 0.001136898878030479\n",
            "loss in epoch 18/21 iteration 54/67: 1.3882086277008057 / BPR loss: 1.3869142532348633 / Matching loss: 3.197965997969732e-05 / Item reconstruction: 0.0021826254669576883 / Text reconstruction: 0.0008550793863832951\n",
            "loss in epoch 18/21 iteration 55/67: 1.3882346153259277 / BPR loss: 1.3869189023971558 / Matching loss: 2.9117929443600588e-05 / Item reconstruction: 0.0021826440934091806 / Text reconstruction: 0.000976261799223721\n",
            "loss in epoch 18/21 iteration 56/67: 1.3879046440124512 / BPR loss: 1.386600375175476 / Matching loss: 3.113708953605965e-05 / Item reconstruction: 0.0021812203340232372 / Text reconstruction: 0.0009122960036620498\n",
            "loss in epoch 18/21 iteration 57/67: 1.3875749111175537 / BPR loss: 1.3863434791564941 / Matching loss: 2.8433281840989366e-05 / Item reconstruction: 0.0020510528702288866 / Text reconstruction: 0.0008872098405845463\n",
            "loss in epoch 18/21 iteration 58/67: 1.3874266147613525 / BPR loss: 1.3862314224243164 / Matching loss: 2.6568310204311274e-05 / Item reconstruction: 0.0019844057969748974 / Text reconstruction: 0.0008821657975204289\n",
            "loss in epoch 18/21 iteration 59/67: 1.3872517347335815 / BPR loss: 1.3859446048736572 / Matching loss: 3.227622801205143e-05 / Item reconstruction: 0.002235337160527706 / Text reconstruction: 0.0007856516749598086\n",
            "loss in epoch 18/21 iteration 60/67: 1.388049602508545 / BPR loss: 1.3867998123168945 / Matching loss: 2.933611540356651e-05 / Item reconstruction: 0.002074932213872671 / Text reconstruction: 0.0009147734381258488\n",
            "loss in epoch 18/21 iteration 61/67: 1.3878517150878906 / BPR loss: 1.3865869045257568 / Matching loss: 3.0946779588703066e-05 / Item reconstruction: 0.0020967437885701656 / Text reconstruction: 0.0009273559553548694\n",
            "loss in epoch 18/21 iteration 62/67: 1.3868870735168457 / BPR loss: 1.385575532913208 / Matching loss: 2.2580465156352147e-05 / Item reconstruction: 0.0020718127489089966 / Text reconstruction: 0.0012654673773795366\n",
            "loss in epoch 18/21 iteration 63/67: 1.3874174356460571 / BPR loss: 1.3861446380615234 / Matching loss: 3.519435995258391e-05 / Item reconstruction: 0.0021832429338246584 / Text reconstruction: 0.000730270694475621\n",
            "loss in epoch 18/21 iteration 64/67: 1.3875499963760376 / BPR loss: 1.3862481117248535 / Matching loss: 3.4258198866155e-05 / Item reconstruction: 0.002178617287427187 / Text reconstruction: 0.0008917531231418252\n",
            "loss in epoch 18/21 iteration 65/67: 1.3878933191299438 / BPR loss: 1.3866348266601562 / Matching loss: 3.100554022239521e-05 / Item reconstruction: 0.0021098130382597446 / Text reconstruction: 0.0008631474920548499\n",
            "loss in epoch 18/21 iteration 66/67: 1.3876949548721313 / BPR loss: 1.386645793914795 / Matching loss: 2.2863783669890836e-05 / Item reconstruction: 0.0017079757526516914 / Text reconstruction: 0.0008614184334874153\n",
            "loss in epoch 18/21 iteration 67/67: 1.3873372077941895 / BPR loss: 1.386373519897461 / Matching loss: 2.0696370484074578e-05 / Item reconstruction: 0.001559993252158165 / Text reconstruction: 0.0008147096959874034\n",
            " 90% 18/20 [35:55<04:11, 125.56s/it]loss in epoch 19/21 iteration 0/67: 1.386237382888794 / BPR loss: 1.384760856628418 / Matching loss: 3.361483322805725e-05 / Item reconstruction: 0.0024458770640194416 / Text reconstruction: 0.0010995003394782543\n",
            "loss in epoch 19/21 iteration 1/67: 1.3801965713500977 / BPR loss: 1.3781297206878662 / Matching loss: 3.739559178939089e-05 / Item reconstruction: 0.0027398127131164074 / Text reconstruction: 0.003297058865427971\n",
            "loss in epoch 19/21 iteration 2/67: 1.3748325109481812 / BPR loss: 1.3724374771118164 / Matching loss: 3.561651101335883e-05 / Item reconstruction: 0.0027893551159650087 / Text reconstruction: 0.0048237089067697525\n",
            "loss in epoch 19/21 iteration 3/67: 1.3730223178863525 / BPR loss: 1.370442509651184 / Matching loss: 3.350269253132865e-05 / Item reconstruction: 0.0027788805309683084 / Text reconstruction: 0.005784729495644569\n",
            "loss in epoch 19/21 iteration 4/67: 1.3717212677001953 / BPR loss: 1.3691291809082031 / Matching loss: 3.628577178460546e-05 / Item reconstruction: 0.0027711368165910244 / Text reconstruction: 0.005851279012858868\n",
            "loss in epoch 19/21 iteration 5/67: 1.3720399141311646 / BPR loss: 1.3696708679199219 / Matching loss: 3.221938823116943e-05 / Item reconstruction: 0.002563814865425229 / Text reconstruction: 0.0052749961614608765\n",
            "loss in epoch 19/21 iteration 6/67: 1.3725488185882568 / BPR loss: 1.3704237937927246 / Matching loss: 3.102650953223929e-05 / Item reconstruction: 0.002393601927906275 / Text reconstruction: 0.004486657679080963\n",
            "loss in epoch 19/21 iteration 7/67: 1.3726482391357422 / BPR loss: 1.3706026077270508 / Matching loss: 3.100016692769714e-05 / Item reconstruction: 0.002392865251749754 / Text reconstruction: 0.004091197624802589\n",
            "loss in epoch 19/21 iteration 8/67: 1.3706982135772705 / BPR loss: 1.36871337890625 / Matching loss: 3.145499067613855e-05 / Item reconstruction: 0.0023152995854616165 / Text reconstruction: 0.0039788163267076015\n",
            "loss in epoch 19/21 iteration 9/67: 1.371707797050476 / BPR loss: 1.369797706604004 / Matching loss: 2.8340926292003132e-05 / Item reconstruction: 0.0022770999930799007 / Text reconstruction: 0.0037160213105380535\n",
            "loss in epoch 19/21 iteration 10/67: 1.370486855506897 / BPR loss: 1.368467092514038 / Matching loss: 2.775700340862386e-05 / Item reconstruction: 0.0023600650019943714 / Text reconstruction: 0.004059921950101852\n",
            "loss in epoch 19/21 iteration 11/67: 1.3703731298446655 / BPR loss: 1.36848783493042 / Matching loss: 2.8658136216108687e-05 / Item reconstruction: 0.0021488924976438284 / Text reconstruction: 0.003911142237484455\n",
            "loss in epoch 19/21 iteration 12/67: 1.3726707696914673 / BPR loss: 1.3706492185592651 / Matching loss: 2.964236045954749e-05 / Item reconstruction: 0.0024472265504300594 / Text reconstruction: 0.0038417025934904814\n",
            "loss in epoch 19/21 iteration 13/67: 1.3717095851898193 / BPR loss: 1.3696887493133545 / Matching loss: 3.087679942836985e-05 / Item reconstruction: 0.0023449091240763664 / Text reconstruction: 0.004087513312697411\n",
            "loss in epoch 19/21 iteration 14/67: 1.3707612752914429 / BPR loss: 1.3688827753067017 / Matching loss: 3.2826210372149944e-05 / Item reconstruction: 0.0021985925268381834 / Text reconstruction: 0.0037317529786378145\n",
            "loss in epoch 19/21 iteration 15/67: 1.3721843957901 / BPR loss: 1.3703312873840332 / Matching loss: 2.823835347953718e-05 / Item reconstruction: 0.0023134038783609867 / Text reconstruction: 0.003340865718200803\n",
            "loss in epoch 19/21 iteration 16/67: 1.3695429563522339 / BPR loss: 1.3676135540008545 / Matching loss: 2.7878542823600583e-05 / Item reconstruction: 0.0023666159249842167 / Text reconstruction: 0.0035912750754505396\n",
            "loss in epoch 19/21 iteration 17/67: 1.3704496622085571 / BPR loss: 1.368557095527649 / Matching loss: 2.8358615963952616e-05 / Item reconstruction: 0.0023398068733513355 / Text reconstruction: 0.003471530508249998\n",
            "loss in epoch 19/21 iteration 18/67: 1.3825937509536743 / BPR loss: 1.38020658493042 / Matching loss: 3.779528560698964e-05 / Item reconstruction: 0.0032061513047665358 / Text reconstruction: 0.003731344360858202\n",
            "loss in epoch 19/21 iteration 19/67: 1.3889926671981812 / BPR loss: 1.386260747909546 / Matching loss: 4.15168033214286e-05 / Item reconstruction: 0.003470195457339287 / Text reconstruction: 0.0047766463831067085\n",
            "loss in epoch 19/21 iteration 20/67: 1.3878333568572998 / BPR loss: 1.385329008102417 / Matching loss: 3.2846437534317374e-05 / Item reconstruction: 0.0032968996092677116 / Text reconstruction: 0.00411527045071125\n",
            "loss in epoch 19/21 iteration 21/67: 1.3855589628219604 / BPR loss: 1.3833446502685547 / Matching loss: 4.001181878265925e-05 / Item reconstruction: 0.003081144765019417 / Text reconstruction: 0.003168785013258457\n",
            "loss in epoch 19/21 iteration 22/67: 1.3752634525299072 / BPR loss: 1.3733131885528564 / Matching loss: 3.0476454412564635e-05 / Item reconstruction: 0.002499498426914215 / Text reconstruction: 0.0033498890697956085\n",
            "loss in epoch 19/21 iteration 23/67: 1.3756844997406006 / BPR loss: 1.373895525932312 / Matching loss: 3.249087603762746e-05 / Item reconstruction: 0.0022717281244695187 / Text reconstruction: 0.0031029083766043186\n",
            "loss in epoch 19/21 iteration 24/67: 1.376265525817871 / BPR loss: 1.3745245933532715 / Matching loss: 2.812696766341105e-05 / Item reconstruction: 0.0022944165393710136 / Text reconstruction: 0.0028283908031880856\n",
            "loss in epoch 19/21 iteration 25/67: 1.3757516145706177 / BPR loss: 1.3740589618682861 / Matching loss: 3.021552402060479e-05 / Item reconstruction: 0.0022497843019664288 / Text reconstruction: 0.0026880165096372366\n",
            "loss in epoch 19/21 iteration 26/67: 1.3755319118499756 / BPR loss: 1.3739347457885742 / Matching loss: 2.7800246243714355e-05 / Item reconstruction: 0.002130704466253519 / Text reconstruction: 0.002519835950806737\n",
            "loss in epoch 19/21 iteration 27/67: 1.3743281364440918 / BPR loss: 1.3726541996002197 / Matching loss: 2.829014920280315e-05 / Item reconstruction: 0.0021888434421271086 / Text reconstruction: 0.002756276400759816\n",
            "loss in epoch 19/21 iteration 28/67: 1.374955177307129 / BPR loss: 1.3733153343200684 / Matching loss: 2.6214465833618306e-05 / Item reconstruction: 0.002154096495360136 / Text reconstruction: 0.002682913327589631\n",
            "loss in epoch 19/21 iteration 29/67: 1.374261736869812 / BPR loss: 1.3726112842559814 / Matching loss: 2.8307998945820145e-05 / Item reconstruction: 0.0021143292542546988 / Text reconstruction: 0.0028254110366106033\n",
            "loss in epoch 19/21 iteration 30/67: 1.3746777772903442 / BPR loss: 1.3730136156082153 / Matching loss: 2.6953699489240535e-05 / Item reconstruction: 0.002153791720047593 / Text reconstruction: 0.0028016497381031513\n",
            "loss in epoch 19/21 iteration 31/67: 1.3757338523864746 / BPR loss: 1.3741421699523926 / Matching loss: 2.612948082969524e-05 / Item reconstruction: 0.00202989112585783 / Text reconstruction: 0.002753227949142456\n",
            "loss in epoch 19/21 iteration 32/67: 1.375662922859192 / BPR loss: 1.374197006225586 / Matching loss: 2.4452940124319866e-05 / Item reconstruction: 0.0018551471875980496 / Text reconstruction: 0.0025692901108413935\n",
            "loss in epoch 19/21 iteration 33/67: 1.3781012296676636 / BPR loss: 1.376062035560608 / Matching loss: 2.9276190616656095e-05 / Item reconstruction: 0.0028679692186415195 / Text reconstruction: 0.0028796570841223\n",
            "loss in epoch 19/21 iteration 34/67: 1.3856418132781982 / BPR loss: 1.383899450302124 / Matching loss: 2.2124962924863212e-05 / Item reconstruction: 0.0026778674218803644 / Text reconstruction: 0.0019063841318711638\n",
            "loss in epoch 19/21 iteration 35/67: 1.3836086988449097 / BPR loss: 1.3817702531814575 / Matching loss: 2.729770858422853e-05 / Item reconstruction: 0.002796444809064269 / Text reconstruction: 0.002064609667286277\n",
            "loss in epoch 19/21 iteration 36/67: 1.3870712518692017 / BPR loss: 1.3852192163467407 / Matching loss: 3.5038967325817794e-05 / Item reconstruction: 0.0027438211254775524 / Text reconstruction: 0.00222574919462204\n",
            "loss in epoch 19/21 iteration 37/67: 1.3867199420928955 / BPR loss: 1.384914517402649 / Matching loss: 3.617107722675428e-05 / Item reconstruction: 0.0027331020683050156 / Text reconstruction: 0.0020141249988228083\n",
            "loss in epoch 19/21 iteration 38/67: 1.3846772909164429 / BPR loss: 1.3830749988555908 / Matching loss: 3.387951437616721e-05 / Item reconstruction: 0.0025543654337525368 / Text reconstruction: 0.0014561451971530914\n",
            "loss in epoch 19/21 iteration 39/67: 1.3867918252944946 / BPR loss: 1.3853132724761963 / Matching loss: 2.9779437682009302e-05 / Item reconstruction: 0.002337880665436387 / Text reconstruction: 0.001398879336193204\n",
            "loss in epoch 19/21 iteration 40/67: 1.3870468139648438 / BPR loss: 1.3854937553405762 / Matching loss: 3.38009194820188e-05 / Item reconstruction: 0.002423916943371296 / Text reconstruction: 0.0015357816591858864\n",
            "loss in epoch 19/21 iteration 41/67: 1.3817319869995117 / BPR loss: 1.3798611164093018 / Matching loss: 3.547376036294736e-05 / Item reconstruction: 0.002709517255425453 / Text reconstruction: 0.002402510028332472\n",
            "loss in epoch 19/21 iteration 42/67: 1.3741164207458496 / BPR loss: 1.3717275857925415 / Matching loss: 2.7147103537572548e-05 / Item reconstruction: 0.003044173587113619 / Text reconstruction: 0.004197687841951847\n",
            "loss in epoch 19/21 iteration 43/67: 1.3715834617614746 / BPR loss: 1.369011402130127 / Matching loss: 2.9250202715047635e-05 / Item reconstruction: 0.0031508347019553185 / Text reconstruction: 0.004836995154619217\n",
            "loss in epoch 19/21 iteration 44/67: 1.3852319717407227 / BPR loss: 1.3837870359420776 / Matching loss: 2.8437692890292965e-05 / Item reconstruction: 0.002246287651360035 / Text reconstruction: 0.001466298708692193\n",
            "loss in epoch 19/21 iteration 45/67: 1.387252926826477 / BPR loss: 1.3858189582824707 / Matching loss: 2.893964119721204e-05 / Item reconstruction: 0.002257235813885927 / Text reconstruction: 0.0013815562706440687\n",
            "loss in epoch 19/21 iteration 46/67: 1.3846107721328735 / BPR loss: 1.382983684539795 / Matching loss: 2.833960206771735e-05 / Item reconstruction: 0.002516046166419983 / Text reconstruction: 0.0017032789764925838\n",
            "loss in epoch 19/21 iteration 47/67: 1.385498285293579 / BPR loss: 1.3839373588562012 / Matching loss: 2.5602967070881277e-05 / Item reconstruction: 0.0024894122034311295 / Text reconstruction: 0.0014530511107295752\n",
            "loss in epoch 19/21 iteration 48/67: 1.3857862949371338 / BPR loss: 1.38429594039917 / Matching loss: 2.8113474400015548e-05 / Item reconstruction: 0.0023288605734705925 / Text reconstruction: 0.0014889466110616922\n",
            "loss in epoch 19/21 iteration 49/67: 1.3831253051757812 / BPR loss: 1.3816399574279785 / Matching loss: 2.5269539037253708e-05 / Item reconstruction: 0.002332476433366537 / Text reconstruction: 0.001468984642997384\n",
            "loss in epoch 19/21 iteration 50/67: 1.3837870359420776 / BPR loss: 1.3822240829467773 / Matching loss: 3.0027644243091345e-05 / Item reconstruction: 0.0024528028443455696 / Text reconstruction: 0.001532682916149497\n",
            "loss in epoch 19/21 iteration 51/67: 1.3864006996154785 / BPR loss: 1.3850208520889282 / Matching loss: 3.0236717066145502e-05 / Item reconstruction: 0.002269755583256483 / Text reconstruction: 0.0010733776725828648\n",
            "loss in epoch 19/21 iteration 52/67: 1.3869004249572754 / BPR loss: 1.3854708671569824 / Matching loss: 2.7827112717204727e-05 / Item reconstruction: 0.0022956673055887222 / Text reconstruction: 0.001269371248781681\n",
            "loss in epoch 19/21 iteration 53/67: 1.3865140676498413 / BPR loss: 1.3851921558380127 / Matching loss: 2.5844521587714553e-05 / Item reconstruction: 0.002144006546586752 / Text reconstruction: 0.001119938213378191\n",
            "loss in epoch 19/21 iteration 54/67: 1.387818455696106 / BPR loss: 1.3864736557006836 / Matching loss: 3.582786666811444e-05 / Item reconstruction: 0.002226445125415921 / Text reconstruction: 0.0009786663576960564\n",
            "loss in epoch 19/21 iteration 55/67: 1.388000249862671 / BPR loss: 1.3866732120513916 / Matching loss: 2.9267202990013175e-05 / Item reconstruction: 0.0021415776573121548 / Text reconstruction: 0.0011349903652444482\n",
            "loss in epoch 19/21 iteration 56/67: 1.3878000974655151 / BPR loss: 1.386487603187561 / Matching loss: 3.0500494176521897e-05 / Item reconstruction: 0.0021808375604450703 / Text reconstruction: 0.000957990123424679\n",
            "loss in epoch 19/21 iteration 57/67: 1.3871526718139648 / BPR loss: 1.3859169483184814 / Matching loss: 2.6052584871649742e-05 / Item reconstruction: 0.002051129937171936 / Text reconstruction: 0.0009205812821164727\n",
            "loss in epoch 19/21 iteration 58/67: 1.387457251548767 / BPR loss: 1.3861761093139648 / Matching loss: 2.6253874239046127e-05 / Item reconstruction: 0.002112843794748187 / Text reconstruction: 0.0009923570323735476\n",
            "loss in epoch 19/21 iteration 59/67: 1.3871536254882812 / BPR loss: 1.3858277797698975 / Matching loss: 3.0466517273453064e-05 / Item reconstruction: 0.0022057790774852037 / Text reconstruction: 0.0009622618090361357\n",
            "loss in epoch 19/21 iteration 60/67: 1.3878986835479736 / BPR loss: 1.386613368988037 / Matching loss: 2.8679351089522243e-05 / Item reconstruction: 0.0021159513853490353 / Text reconstruction: 0.000992820831015706\n",
            "loss in epoch 19/21 iteration 61/67: 1.3876707553863525 / BPR loss: 1.386425495147705 / Matching loss: 2.7694510208675638e-05 / Item reconstruction: 0.0020453487522900105 / Text reconstruction: 0.0009742548572830856\n",
            "loss in epoch 19/21 iteration 62/67: 1.3869019746780396 / BPR loss: 1.3855664730072021 / Matching loss: 2.190909617638681e-05 / Item reconstruction: 0.002103729173541069 / Text reconstruction: 0.0013084376696497202\n",
            "loss in epoch 19/21 iteration 63/67: 1.3874070644378662 / BPR loss: 1.3861122131347656 / Matching loss: 3.5221146390540525e-05 / Item reconstruction: 0.00219808891415596 / Text reconstruction: 0.0008033863268792629\n",
            "loss in epoch 19/21 iteration 64/67: 1.3878058195114136 / BPR loss: 1.3865106105804443 / Matching loss: 3.159002517350018e-05 / Item reconstruction: 0.0021483066957443953 / Text reconstruction: 0.0009471434750594199\n",
            "loss in epoch 19/21 iteration 65/67: 1.3871536254882812 / BPR loss: 1.385911464691162 / Matching loss: 3.144999573123641e-05 / Item reconstruction: 0.0020721284672617912 / Text reconstruction: 0.0008730241097509861\n",
            "loss in epoch 19/21 iteration 66/67: 1.3874691724777222 / BPR loss: 1.3863990306854248 / Matching loss: 2.133325324393809e-05 / Item reconstruction: 0.0017467120196670294 / Text reconstruction: 0.0008773910230956972\n",
            "loss in epoch 19/21 iteration 67/67: 1.3871169090270996 / BPR loss: 1.3860957622528076 / Matching loss: 1.7294096323894337e-05 / Item reconstruction: 0.0016067535616457462 / Text reconstruction: 0.0010022768983617425\n",
            " 95% 19/20 [37:55<02:03, 123.73s/it]loss in epoch 20/21 iteration 0/67: 1.3858739137649536 / BPR loss: 1.3843574523925781 / Matching loss: 3.439575812080875e-05 / Item reconstruction: 0.002451992593705654 / Text reconstruction: 0.0012805245351046324\n",
            "loss in epoch 20/21 iteration 1/67: 1.3788225650787354 / BPR loss: 1.3763909339904785 / Matching loss: 4.049591370858252e-05 / Item reconstruction: 0.0030149826779961586 / Text reconstruction: 0.004417947493493557\n",
            "loss in epoch 20/21 iteration 2/67: 1.3720592260360718 / BPR loss: 1.3692858219146729 / Matching loss: 3.710095916176215e-05 / Item reconstruction: 0.003211159724742174 / Text reconstruction: 0.005653741769492626\n",
            "loss in epoch 20/21 iteration 3/67: 1.3715921640396118 / BPR loss: 1.368661642074585 / Matching loss: 3.705248673213646e-05 / Item reconstruction: 0.00337590416893363 / Text reconstruction: 0.006027450785040855\n",
            "loss in epoch 20/21 iteration 4/67: 1.371155858039856 / BPR loss: 1.3683650493621826 / Matching loss: 3.5627213947009295e-05 / Item reconstruction: 0.003220485057681799 / Text reconstruction: 0.005724643357098103\n",
            "loss in epoch 20/21 iteration 5/67: 1.3710442781448364 / BPR loss: 1.3684923648834229 / Matching loss: 3.39636389981024e-05 / Item reconstruction: 0.002973895985633135 / Text reconstruction: 0.005155077204108238\n",
            "loss in epoch 20/21 iteration 6/67: 1.3704091310501099 / BPR loss: 1.3679921627044678 / Matching loss: 3.267961437813938e-05 / Item reconstruction: 0.002882388886064291 / Text reconstruction: 0.004715076182037592\n",
            "loss in epoch 20/21 iteration 7/67: 1.369739055633545 / BPR loss: 1.367376446723938 / Matching loss: 3.160299820592627e-05 / Item reconstruction: 0.0027532281819730997 / Text reconstruction: 0.0047721038572490215\n",
            "loss in epoch 20/21 iteration 8/67: 1.3694208860397339 / BPR loss: 1.3670598268508911 / Matching loss: 3.15748511638958e-05 / Item reconstruction: 0.0027285232208669186 / Text reconstruction: 0.004826475866138935\n",
            "loss in epoch 20/21 iteration 9/67: 1.3701491355895996 / BPR loss: 1.3678292036056519 / Matching loss: 2.855342609109357e-05 / Item reconstruction: 0.0027051696088165045 / Text reconstruction: 0.004694150295108557\n",
            "loss in epoch 20/21 iteration 10/67: 1.3692808151245117 / BPR loss: 1.3672083616256714 / Matching loss: 2.7065088943345472e-05 / Item reconstruction: 0.0024268331471830606 / Text reconstruction: 0.004159625619649887\n",
            "loss in epoch 20/21 iteration 11/67: 1.3681963682174683 / BPR loss: 1.3660718202590942 / Matching loss: 2.8541962819872424e-05 / Item reconstruction: 0.0026012826710939407 / Text reconstruction: 0.003976590931415558\n",
            "loss in epoch 20/21 iteration 12/67: 1.3705750703811646 / BPR loss: 1.3685626983642578 / Matching loss: 2.797696288325824e-05 / Item reconstruction: 0.002538063796237111 / Text reconstruction: 0.003576657734811306\n",
            "loss in epoch 20/21 iteration 13/67: 1.3693071603775024 / BPR loss: 1.3671936988830566 / Matching loss: 2.9666294722119346e-05 / Item reconstruction: 0.0026573948562145233 / Text reconstruction: 0.0037752583157271147\n",
            "loss in epoch 20/21 iteration 14/67: 1.370084285736084 / BPR loss: 1.3679665327072144 / Matching loss: 2.723867874010466e-05 / Item reconstruction: 0.0026476485654711723 / Text reconstruction: 0.003833694150671363\n",
            "loss in epoch 20/21 iteration 15/67: 1.3697820901870728 / BPR loss: 1.3676955699920654 / Matching loss: 2.778073030640371e-05 / Item reconstruction: 0.0025640903040766716 / Text reconstruction: 0.003883515950292349\n",
            "loss in epoch 20/21 iteration 16/67: 1.3683910369873047 / BPR loss: 1.3661682605743408 / Matching loss: 2.9404236556729302e-05 / Item reconstruction: 0.002665682230144739 / Text reconstruction: 0.004302043002098799\n",
            "loss in epoch 20/21 iteration 17/67: 1.3688387870788574 / BPR loss: 1.3668023347854614 / Matching loss: 2.7125475753564388e-05 / Item reconstruction: 0.0025064863730221987 / Text reconstruction: 0.003780362429097295\n",
            "loss in epoch 20/21 iteration 18/67: 1.382163643836975 / BPR loss: 1.379443645477295 / Matching loss: 3.690893208840862e-05 / Item reconstruction: 0.0036678030155599117 / Text reconstruction: 0.004245796240866184\n",
            "loss in epoch 20/21 iteration 19/67: 1.388680100440979 / BPR loss: 1.3857970237731934 / Matching loss: 3.672671300591901e-05 / Item reconstruction: 0.0039010141044855118 / Text reconstruction: 0.004479406401515007\n",
            "loss in epoch 20/21 iteration 20/67: 1.3883098363876343 / BPR loss: 1.3857656717300415 / Matching loss: 3.209818169125356e-05 / Item reconstruction: 0.0035049589350819588 / Text reconstruction: 0.0037977651227265596\n",
            "loss in epoch 20/21 iteration 21/67: 1.3864493370056152 / BPR loss: 1.384141206741333 / Matching loss: 3.2856769394129515e-05 / Item reconstruction: 0.0031801871955394745 / Text reconstruction: 0.003425235627219081\n",
            "loss in epoch 20/21 iteration 22/67: 1.374198317527771 / BPR loss: 1.372179627418518 / Matching loss: 3.0048424378037453e-05 / Item reconstruction: 0.002758380025625229 / Text reconstruction: 0.0030476676765829325\n",
            "loss in epoch 20/21 iteration 23/67: 1.3738795518875122 / BPR loss: 1.3719466924667358 / Matching loss: 2.8544640372274444e-05 / Item reconstruction: 0.0026617245748639107 / Text reconstruction: 0.002867777831852436\n",
            "loss in epoch 20/21 iteration 24/67: 1.3745111227035522 / BPR loss: 1.3726316690444946 / Matching loss: 2.9050030207145028e-05 / Item reconstruction: 0.00255833612754941 / Text reconstruction: 0.002856351900845766\n",
            "loss in epoch 20/21 iteration 25/67: 1.3735853433609009 / BPR loss: 1.3717401027679443 / Matching loss: 2.517700704629533e-05 / Item reconstruction: 0.0024825730361044407 / Text reconstruction: 0.002893600147217512\n",
            "loss in epoch 20/21 iteration 26/67: 1.3751589059829712 / BPR loss: 1.3734709024429321 / Matching loss: 2.57493866229197e-05 / Item reconstruction: 0.002333042211830616 / Text reconstruction: 0.0024792375043034554\n",
            "loss in epoch 20/21 iteration 27/67: 1.3730844259262085 / BPR loss: 1.3711652755737305 / Matching loss: 2.5249006284866482e-05 / Item reconstruction: 0.0024940501898527145 / Text reconstruction: 0.003233907278627157\n",
            "loss in epoch 20/21 iteration 28/67: 1.3747520446777344 / BPR loss: 1.3728892803192139 / Matching loss: 2.8273734642425552e-05 / Item reconstruction: 0.0024499669671058655 / Text reconstruction: 0.003047330304980278\n",
            "loss in epoch 20/21 iteration 29/67: 1.37348210811615 / BPR loss: 1.37168288230896 / Matching loss: 2.6795016310643405e-05 / Item reconstruction: 0.002418139250949025 / Text reconstruction: 0.0028166379779577255\n",
            "loss in epoch 20/21 iteration 30/67: 1.3728235960006714 / BPR loss: 1.3710310459136963 / Matching loss: 2.4287368432851508e-05 / Item reconstruction: 0.0023839264176785946 / Text reconstruction: 0.0028810896910727024\n",
            "loss in epoch 20/21 iteration 31/67: 1.3734785318374634 / BPR loss: 1.3717663288116455 / Matching loss: 2.460832183714956e-05 / Item reconstruction: 0.002288544550538063 / Text reconstruction: 0.0027167843654751778\n",
            "loss in epoch 20/21 iteration 32/67: 1.3758145570755005 / BPR loss: 1.3742918968200684 / Matching loss: 2.4949133148766123e-05 / Item reconstruction: 0.0020546107552945614 / Text reconstruction: 0.00235202768817544\n",
            "loss in epoch 20/21 iteration 33/67: 1.3789118528366089 / BPR loss: 1.3767499923706055 / Matching loss: 2.8568234483827837e-05 / Item reconstruction: 0.003047799225896597 / Text reconstruction: 0.0030469167977571487\n",
            "loss in epoch 20/21 iteration 34/67: 1.3846653699874878 / BPR loss: 1.382700800895691 / Matching loss: 2.5472236302448437e-05 / Item reconstruction: 0.002896308433264494 / Text reconstruction: 0.0024548061192035675\n",
            "loss in epoch 20/21 iteration 35/67: 1.3827210664749146 / BPR loss: 1.380780577659607 / Matching loss: 2.4840992409735918e-05 / Item reconstruction: 0.0029088137671351433 / Text reconstruction: 0.0023067740257829428\n",
            "loss in epoch 20/21 iteration 36/67: 1.3862437009811401 / BPR loss: 1.3842580318450928 / Matching loss: 3.393829319975339e-05 / Item reconstruction: 0.0028278122190386057 / Text reconstruction: 0.0026885443367064\n",
            "loss in epoch 20/21 iteration 37/67: 1.386107087135315 / BPR loss: 1.3842273950576782 / Matching loss: 3.35417571477592e-05 / Item reconstruction: 0.0027969242073595524 / Text reconstruction: 0.0022387150675058365\n",
            "loss in epoch 20/21 iteration 38/67: 1.385365605354309 / BPR loss: 1.3837624788284302 / Matching loss: 3.2139290851773694e-05 / Item reconstruction: 0.0025242031551897526 / Text reconstruction: 0.0015444719465449452\n",
            "loss in epoch 20/21 iteration 39/67: 1.3864070177078247 / BPR loss: 1.384867548942566 / Matching loss: 2.8028081942466088e-05 / Item reconstruction: 0.002397804521024227 / Text reconstruction: 0.0015625393716618419\n",
            "loss in epoch 20/21 iteration 40/67: 1.3871054649353027 / BPR loss: 1.3855788707733154 / Matching loss: 3.370692866155878e-05 / Item reconstruction: 0.002416837029159069 / Text reconstruction: 0.001422249129973352\n",
            "loss in epoch 20/21 iteration 41/67: 1.3810700178146362 / BPR loss: 1.3790762424468994 / Matching loss: 3.2669882784830406e-05 / Item reconstruction: 0.0028742621652781963 / Text reconstruction: 0.0026196155231446028\n",
            "loss in epoch 20/21 iteration 42/67: 1.3748931884765625 / BPR loss: 1.3722821474075317 / Matching loss: 2.648295230756048e-05 / Item reconstruction: 0.0034901825711131096 / Text reconstruction: 0.00419735349714756\n",
            "loss in epoch 20/21 iteration 43/67: 1.3692119121551514 / BPR loss: 1.3663415908813477 / Matching loss: 2.8859078156528994e-05 / Item reconstruction: 0.003713460173457861 / Text reconstruction: 0.004923902451992035\n",
            "loss in epoch 20/21 iteration 44/67: 1.3850083351135254 / BPR loss: 1.3834401369094849 / Matching loss: 2.6812205760506913e-05 / Item reconstruction: 0.0023965847212821245 / Text reconstruction: 0.0017156677786260843\n",
            "loss in epoch 20/21 iteration 45/67: 1.386820673942566 / BPR loss: 1.3853211402893066 / Matching loss: 2.6185978640569374e-05 / Item reconstruction: 0.002331929048523307 / Text reconstruction: 0.0015365011058747768\n",
            "loss in epoch 20/21 iteration 46/67: 1.3852100372314453 / BPR loss: 1.3835816383361816 / Matching loss: 2.4340712116099894e-05 / Item reconstruction: 0.0025096796452999115 / Text reconstruction: 0.0017464302945882082\n",
            "loss in epoch 20/21 iteration 47/67: 1.3849126100540161 / BPR loss: 1.3832757472991943 / Matching loss: 2.491140185156837e-05 / Item reconstruction: 0.0025270937476307154 / Text reconstruction: 0.0017423199024051428\n",
            "loss in epoch 20/21 iteration 48/67: 1.3858366012573242 / BPR loss: 1.3842740058898926 / Matching loss: 2.6124927899218164e-05 / Item reconstruction: 0.002428553532809019 / Text reconstruction: 0.001611313782632351\n",
            "loss in epoch 20/21 iteration 49/67: 1.3820366859436035 / BPR loss: 1.3804514408111572 / Matching loss: 2.522818249417469e-05 / Item reconstruction: 0.002412320813164115 / Text reconstruction: 0.0017690169624984264\n",
            "loss in epoch 20/21 iteration 50/67: 1.383329153060913 / BPR loss: 1.3817265033721924 / Matching loss: 3.0236422389862128e-05 / Item reconstruction: 0.002434153575450182 / Text reconstruction: 0.0017763080541044474\n",
            "loss in epoch 20/21 iteration 51/67: 1.3866163492202759 / BPR loss: 1.3851816654205322 / Matching loss: 3.0506402254104614e-05 / Item reconstruction: 0.0023074522614479065 / Text reconstruction: 0.0012524403864517808\n",
            "loss in epoch 20/21 iteration 52/67: 1.3868733644485474 / BPR loss: 1.3854434490203857 / Matching loss: 2.5232067855540663e-05 / Item reconstruction: 0.00232106726616621 / Text reconstruction: 0.0012207510881125927\n",
            "loss in epoch 20/21 iteration 53/67: 1.3848804235458374 / BPR loss: 1.3834644556045532 / Matching loss: 2.5609553631511517e-05 / Item reconstruction: 0.002266833558678627 / Text reconstruction: 0.0012846863828599453\n",
            "loss in epoch 20/21 iteration 54/67: 1.3871617317199707 / BPR loss: 1.3857297897338867 / Matching loss: 3.1936331652104855e-05 / Item reconstruction: 0.002322892425581813 / Text reconstruction: 0.0011925837025046349\n",
            "loss in epoch 20/21 iteration 55/67: 1.3884265422821045 / BPR loss: 1.3870227336883545 / Matching loss: 2.7402738851378672e-05 / Item reconstruction: 0.002278331434354186 / Text reconstruction: 0.0011862777173519135\n",
            "loss in epoch 20/21 iteration 56/67: 1.3875325918197632 / BPR loss: 1.3861629962921143 / Matching loss: 2.9649512725882232e-05 / Item reconstruction: 0.0022633038461208344 / Text reconstruction: 0.0010412047849968076\n",
            "loss in epoch 20/21 iteration 57/67: 1.3873381614685059 / BPR loss: 1.3860692977905273 / Matching loss: 2.4923998353187926e-05 / Item reconstruction: 0.0020950250327587128 / Text reconstruction: 0.0009820477571338415\n",
            "loss in epoch 20/21 iteration 58/67: 1.3873053789138794 / BPR loss: 1.3860745429992676 / Matching loss: 2.494074942660518e-05 / Item reconstruction: 0.0020154451485723257 / Text reconstruction: 0.0009915052214637399\n",
            "loss in epoch 20/21 iteration 59/67: 1.3866633176803589 / BPR loss: 1.3853198289871216 / Matching loss: 2.768163540167734e-05 / Item reconstruction: 0.002235320396721363 / Text reconstruction: 0.000990373082458973\n",
            "loss in epoch 20/21 iteration 60/67: 1.3876484632492065 / BPR loss: 1.386326551437378 / Matching loss: 2.9142040148144588e-05 / Item reconstruction: 0.002152729080989957 / Text reconstruction: 0.0010823649354279041\n",
            "loss in epoch 20/21 iteration 61/67: 1.3877322673797607 / BPR loss: 1.3864266872406006 / Matching loss: 2.9853566957172006e-05 / Item reconstruction: 0.002078212797641754 / Text reconstruction: 0.001182944979518652\n",
            "loss in epoch 20/21 iteration 62/67: 1.3872034549713135 / BPR loss: 1.3858389854431152 / Matching loss: 2.1937579731456935e-05 / Item reconstruction: 0.002155281137675047 / Text reconstruction: 0.001324529992416501\n",
            "loss in epoch 20/21 iteration 63/67: 1.3877922296524048 / BPR loss: 1.3864829540252686 / Matching loss: 3.2937539799604565e-05 / Item reconstruction: 0.002191903069615364 / Text reconstruction: 0.0009015516843646765\n",
            "loss in epoch 20/21 iteration 64/67: 1.388105034828186 / BPR loss: 1.3868026733398438 / Matching loss: 3.1168176064966246e-05 / Item reconstruction: 0.0021827034652233124 / Text reconstruction: 0.0008994024246931076\n",
            "loss in epoch 20/21 iteration 65/67: 1.3876370191574097 / BPR loss: 1.386381983757019 / Matching loss: 3.0118157155811787e-05 / Item reconstruction: 0.002096012234687805 / Text reconstruction: 0.0008843560935929418\n",
            "loss in epoch 20/21 iteration 66/67: 1.3876277208328247 / BPR loss: 1.3865256309509277 / Matching loss: 2.1108111468493007e-05 / Item reconstruction: 0.0018172194249927998 / Text reconstruction: 0.0008621050510555506\n",
            "loss in epoch 20/21 iteration 67/67: 1.3872878551483154 / BPR loss: 1.3863188028335571 / Matching loss: 1.6066032912931405e-05 / Item reconstruction: 0.001561718643642962 / Text reconstruction: 0.0008606439223513007\n",
            "100% 20/20 [40:08<00:00, 120.42s/it]\n",
            "train time : 2408.334004878998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check current accelerate installation\n",
        "!pip show accelerate\n",
        "\n",
        "# If needed, reinstall accelerate\n",
        "!pip install accelerate --upgrade\n",
        "\n",
        "# Import accelerate to ensure it's properly loaded\n",
        "import accelerate\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k-Syy_udZhf3",
        "outputId": "9a0fbf79-26de-4789-f1c6-8a6cd5282535"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: accelerate\n",
            "Version: 0.25.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: sylvain@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/site-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (0.25.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/site-packages (from accelerate) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (2.8.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (65.6.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
            "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.25.0\n",
            "    Uninstalling accelerate-0.25.0:\n",
            "      Successfully uninstalled accelerate-0.25.0\n",
            "Successfully installed accelerate-1.10.0\n",
            "Accelerate version: 1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train stage 2\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --pretrain_stage2 --rec_pre_trained_data All_Beauty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RzL1XeJfNBVf",
        "outputId": "b2db0192-d53d-4ba9-da75-8644ff21e8ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec strat train phase-2\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2169\n",
            "  0% 0/1 [00:00<?, ?it/s]A-LLMRec model loss in epoch 1/2 iteration 0/1084: 3.552583694458008\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1/1084: 1.0540530681610107\n",
            "A-LLMRec model loss in epoch 1/2 iteration 2/1084: 1.0040638446807861\n",
            "A-LLMRec model loss in epoch 1/2 iteration 3/1084: 1.1693212985992432\n",
            "A-LLMRec model loss in epoch 1/2 iteration 4/1084: 0.9538640379905701\n",
            "A-LLMRec model loss in epoch 1/2 iteration 5/1084: 0.6920675039291382\n",
            "A-LLMRec model loss in epoch 1/2 iteration 6/1084: 0.7552080750465393\n",
            "A-LLMRec model loss in epoch 1/2 iteration 7/1084: 0.6488726735115051\n",
            "A-LLMRec model loss in epoch 1/2 iteration 8/1084: 0.5492401123046875\n",
            "A-LLMRec model loss in epoch 1/2 iteration 9/1084: 0.4182896316051483\n",
            "A-LLMRec model loss in epoch 1/2 iteration 10/1084: 0.5631835460662842\n",
            "A-LLMRec model loss in epoch 1/2 iteration 11/1084: 0.23670798540115356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 12/1084: 0.2834239900112152\n",
            "A-LLMRec model loss in epoch 1/2 iteration 13/1084: 0.6346365213394165\n",
            "A-LLMRec model loss in epoch 1/2 iteration 14/1084: 0.4944794178009033\n",
            "A-LLMRec model loss in epoch 1/2 iteration 15/1084: 0.2317594438791275\n",
            "A-LLMRec model loss in epoch 1/2 iteration 16/1084: 0.48154112696647644\n",
            "A-LLMRec model loss in epoch 1/2 iteration 17/1084: 0.3545326292514801\n",
            "A-LLMRec model loss in epoch 1/2 iteration 18/1084: 0.1516716480255127\n",
            "A-LLMRec model loss in epoch 1/2 iteration 19/1084: 0.2881348729133606\n",
            "A-LLMRec model loss in epoch 1/2 iteration 20/1084: 0.20488689839839935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 21/1084: 0.126580148935318\n",
            "A-LLMRec model loss in epoch 1/2 iteration 22/1084: 0.22841861844062805\n",
            "A-LLMRec model loss in epoch 1/2 iteration 23/1084: 0.2522953450679779\n",
            "A-LLMRec model loss in epoch 1/2 iteration 24/1084: 0.22453579306602478\n",
            "A-LLMRec model loss in epoch 1/2 iteration 25/1084: 0.15689514577388763\n",
            "A-LLMRec model loss in epoch 1/2 iteration 26/1084: 0.3167992830276489\n",
            "A-LLMRec model loss in epoch 1/2 iteration 27/1084: 0.17996446788311005\n",
            "A-LLMRec model loss in epoch 1/2 iteration 28/1084: 0.19807083904743195\n",
            "A-LLMRec model loss in epoch 1/2 iteration 29/1084: 0.05783121660351753\n",
            "A-LLMRec model loss in epoch 1/2 iteration 30/1084: 0.4869292974472046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 31/1084: 0.06646694988012314\n",
            "A-LLMRec model loss in epoch 1/2 iteration 32/1084: 0.13807541131973267\n",
            "A-LLMRec model loss in epoch 1/2 iteration 33/1084: 0.22666995227336884\n",
            "A-LLMRec model loss in epoch 1/2 iteration 34/1084: 0.10331566631793976\n",
            "A-LLMRec model loss in epoch 1/2 iteration 35/1084: 0.19429193437099457\n",
            "A-LLMRec model loss in epoch 1/2 iteration 36/1084: 0.11323314160108566\n",
            "A-LLMRec model loss in epoch 1/2 iteration 37/1084: 0.1431288868188858\n",
            "A-LLMRec model loss in epoch 1/2 iteration 38/1084: 0.16724540293216705\n",
            "A-LLMRec model loss in epoch 1/2 iteration 39/1084: 0.09666858613491058\n",
            "A-LLMRec model loss in epoch 1/2 iteration 40/1084: 0.11877860128879547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 41/1084: 0.17712917923927307\n",
            "A-LLMRec model loss in epoch 1/2 iteration 42/1084: 0.10522174835205078\n",
            "A-LLMRec model loss in epoch 1/2 iteration 43/1084: 0.1201007068157196\n",
            "A-LLMRec model loss in epoch 1/2 iteration 44/1084: 0.41758888959884644\n",
            "A-LLMRec model loss in epoch 1/2 iteration 45/1084: 0.03758571296930313\n",
            "A-LLMRec model loss in epoch 1/2 iteration 46/1084: 0.20048919320106506\n",
            "A-LLMRec model loss in epoch 1/2 iteration 47/1084: 0.1047588586807251\n",
            "A-LLMRec model loss in epoch 1/2 iteration 48/1084: 0.19318608939647675\n",
            "A-LLMRec model loss in epoch 1/2 iteration 49/1084: 0.16220250725746155\n",
            "A-LLMRec model loss in epoch 1/2 iteration 50/1084: 0.033778611570596695\n",
            "A-LLMRec model loss in epoch 1/2 iteration 51/1084: 0.028794271871447563\n",
            "A-LLMRec model loss in epoch 1/2 iteration 52/1084: 0.16503189504146576\n",
            "A-LLMRec model loss in epoch 1/2 iteration 53/1084: 0.21253123879432678\n",
            "A-LLMRec model loss in epoch 1/2 iteration 54/1084: 0.10164619982242584\n",
            "A-LLMRec model loss in epoch 1/2 iteration 55/1084: 0.11232320219278336\n",
            "A-LLMRec model loss in epoch 1/2 iteration 56/1084: 0.6174631714820862\n",
            "A-LLMRec model loss in epoch 1/2 iteration 57/1084: 0.12355218827724457\n",
            "A-LLMRec model loss in epoch 1/2 iteration 58/1084: 0.13164934515953064\n",
            "A-LLMRec model loss in epoch 1/2 iteration 59/1084: 0.2288753092288971\n",
            "A-LLMRec model loss in epoch 1/2 iteration 60/1084: 0.3250620663166046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 61/1084: 0.1887892484664917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 62/1084: 0.44584178924560547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 63/1084: 0.27854180335998535\n",
            "A-LLMRec model loss in epoch 1/2 iteration 64/1084: 0.1064470186829567\n",
            "A-LLMRec model loss in epoch 1/2 iteration 65/1084: 0.16557011008262634\n",
            "A-LLMRec model loss in epoch 1/2 iteration 66/1084: 0.1308693289756775\n",
            "A-LLMRec model loss in epoch 1/2 iteration 67/1084: 0.08343323320150375\n",
            "A-LLMRec model loss in epoch 1/2 iteration 68/1084: 0.35063034296035767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 69/1084: 0.13497966527938843\n",
            "A-LLMRec model loss in epoch 1/2 iteration 70/1084: 0.024311386048793793\n",
            "A-LLMRec model loss in epoch 1/2 iteration 71/1084: 0.18238599598407745\n",
            "A-LLMRec model loss in epoch 1/2 iteration 72/1084: 0.29680773615837097\n",
            "A-LLMRec model loss in epoch 1/2 iteration 73/1084: 0.3461725413799286\n",
            "A-LLMRec model loss in epoch 1/2 iteration 74/1084: 0.052588727325201035\n",
            "A-LLMRec model loss in epoch 1/2 iteration 75/1084: 0.2124602496623993\n",
            "A-LLMRec model loss in epoch 1/2 iteration 76/1084: 0.023555461317300797\n",
            "A-LLMRec model loss in epoch 1/2 iteration 77/1084: 0.15886560082435608\n",
            "A-LLMRec model loss in epoch 1/2 iteration 78/1084: 0.09762407094240189\n",
            "A-LLMRec model loss in epoch 1/2 iteration 79/1084: 0.09602561593055725\n",
            "A-LLMRec model loss in epoch 1/2 iteration 80/1084: 0.05537714064121246\n",
            "A-LLMRec model loss in epoch 1/2 iteration 81/1084: 0.09164319932460785\n",
            "A-LLMRec model loss in epoch 1/2 iteration 82/1084: 0.017016518861055374\n",
            "A-LLMRec model loss in epoch 1/2 iteration 83/1084: 0.08372455090284348\n",
            "A-LLMRec model loss in epoch 1/2 iteration 84/1084: 0.34321698546409607\n",
            "A-LLMRec model loss in epoch 1/2 iteration 85/1084: 0.09464012086391449\n",
            "A-LLMRec model loss in epoch 1/2 iteration 86/1084: 0.1981898993253708\n",
            "A-LLMRec model loss in epoch 1/2 iteration 87/1084: 0.08366755396127701\n",
            "A-LLMRec model loss in epoch 1/2 iteration 88/1084: 0.07341624051332474\n",
            "A-LLMRec model loss in epoch 1/2 iteration 89/1084: 0.2653038799762726\n",
            "A-LLMRec model loss in epoch 1/2 iteration 90/1084: 0.21067142486572266\n",
            "A-LLMRec model loss in epoch 1/2 iteration 91/1084: 0.5667454600334167\n",
            "A-LLMRec model loss in epoch 1/2 iteration 92/1084: 0.16427132487297058\n",
            "A-LLMRec model loss in epoch 1/2 iteration 93/1084: 0.2207173854112625\n",
            "A-LLMRec model loss in epoch 1/2 iteration 94/1084: 0.15358643233776093\n",
            "A-LLMRec model loss in epoch 1/2 iteration 95/1084: 0.3555333614349365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 96/1084: 0.19525346159934998\n",
            "A-LLMRec model loss in epoch 1/2 iteration 97/1084: 0.14384110271930695\n",
            "A-LLMRec model loss in epoch 1/2 iteration 98/1084: 0.20075081288814545\n",
            "A-LLMRec model loss in epoch 1/2 iteration 99/1084: 0.11887465417385101\n",
            "A-LLMRec model loss in epoch 1/2 iteration 100/1084: 0.028495794162154198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 101/1084: 0.1530889868736267\n",
            "A-LLMRec model loss in epoch 1/2 iteration 102/1084: 0.3365356922149658\n",
            "A-LLMRec model loss in epoch 1/2 iteration 103/1084: 0.3054506778717041\n",
            "A-LLMRec model loss in epoch 1/2 iteration 104/1084: 0.16872555017471313\n",
            "A-LLMRec model loss in epoch 1/2 iteration 105/1084: 0.16830705106258392\n",
            "A-LLMRec model loss in epoch 1/2 iteration 106/1084: 0.019657300785183907\n",
            "A-LLMRec model loss in epoch 1/2 iteration 107/1084: 0.02011491358280182\n",
            "A-LLMRec model loss in epoch 1/2 iteration 108/1084: 0.03486091271042824\n",
            "A-LLMRec model loss in epoch 1/2 iteration 109/1084: 0.04193606227636337\n",
            "A-LLMRec model loss in epoch 1/2 iteration 110/1084: 0.05245077237486839\n",
            "A-LLMRec model loss in epoch 1/2 iteration 111/1084: 0.023819155991077423\n",
            "A-LLMRec model loss in epoch 1/2 iteration 112/1084: 0.024562614038586617\n",
            "A-LLMRec model loss in epoch 1/2 iteration 113/1084: 0.041310328990221024\n",
            "A-LLMRec model loss in epoch 1/2 iteration 114/1084: 0.081512950360775\n",
            "A-LLMRec model loss in epoch 1/2 iteration 115/1084: 0.030230514705181122\n",
            "A-LLMRec model loss in epoch 1/2 iteration 116/1084: 0.0951932966709137\n",
            "A-LLMRec model loss in epoch 1/2 iteration 117/1084: 0.04056720435619354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 118/1084: 0.1647389978170395\n",
            "A-LLMRec model loss in epoch 1/2 iteration 119/1084: 0.15576417744159698\n",
            "A-LLMRec model loss in epoch 1/2 iteration 120/1084: 0.00978910643607378\n",
            "A-LLMRec model loss in epoch 1/2 iteration 121/1084: 0.17181852459907532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 122/1084: 0.08563898503780365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 123/1084: 0.021456321701407433\n",
            "A-LLMRec model loss in epoch 1/2 iteration 124/1084: 0.04466923326253891\n",
            "A-LLMRec model loss in epoch 1/2 iteration 125/1084: 0.14151154458522797\n",
            "A-LLMRec model loss in epoch 1/2 iteration 126/1084: 0.18342548608779907\n",
            "A-LLMRec model loss in epoch 1/2 iteration 127/1084: 0.089830681681633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 128/1084: 0.1154383048415184\n",
            "A-LLMRec model loss in epoch 1/2 iteration 129/1084: 0.14651305973529816\n",
            "A-LLMRec model loss in epoch 1/2 iteration 130/1084: 0.1322086602449417\n",
            "A-LLMRec model loss in epoch 1/2 iteration 131/1084: 0.1808810979127884\n",
            "A-LLMRec model loss in epoch 1/2 iteration 132/1084: 0.06067954748868942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 133/1084: 0.08703593164682388\n",
            "A-LLMRec model loss in epoch 1/2 iteration 134/1084: 0.03050689771771431\n",
            "A-LLMRec model loss in epoch 1/2 iteration 135/1084: 0.06755381077528\n",
            "A-LLMRec model loss in epoch 1/2 iteration 136/1084: 0.029977215453982353\n",
            "A-LLMRec model loss in epoch 1/2 iteration 137/1084: 0.03861692175269127\n",
            "A-LLMRec model loss in epoch 1/2 iteration 138/1084: 0.3022291958332062\n",
            "A-LLMRec model loss in epoch 1/2 iteration 139/1084: 0.08711179345846176\n",
            "A-LLMRec model loss in epoch 1/2 iteration 140/1084: 0.20908603072166443\n",
            "A-LLMRec model loss in epoch 1/2 iteration 141/1084: 0.06131426990032196\n",
            "A-LLMRec model loss in epoch 1/2 iteration 142/1084: 0.18232311308383942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 143/1084: 0.01095638982951641\n",
            "A-LLMRec model loss in epoch 1/2 iteration 144/1084: 0.04033900797367096\n",
            "A-LLMRec model loss in epoch 1/2 iteration 145/1084: 0.016868138685822487\n",
            "A-LLMRec model loss in epoch 1/2 iteration 146/1084: 0.1364954560995102\n",
            "A-LLMRec model loss in epoch 1/2 iteration 147/1084: 0.09139831364154816\n",
            "A-LLMRec model loss in epoch 1/2 iteration 148/1084: 0.098407082259655\n",
            "A-LLMRec model loss in epoch 1/2 iteration 149/1084: 0.04942147433757782\n",
            "A-LLMRec model loss in epoch 1/2 iteration 150/1084: 0.03040139377117157\n",
            "A-LLMRec model loss in epoch 1/2 iteration 151/1084: 0.25624415278434753\n",
            "A-LLMRec model loss in epoch 1/2 iteration 152/1084: 0.026822565123438835\n",
            "A-LLMRec model loss in epoch 1/2 iteration 153/1084: 0.08133387565612793\n",
            "A-LLMRec model loss in epoch 1/2 iteration 154/1084: 0.16290439665317535\n",
            "A-LLMRec model loss in epoch 1/2 iteration 155/1084: 0.3356315791606903\n",
            "A-LLMRec model loss in epoch 1/2 iteration 156/1084: 0.05054729804396629\n",
            "A-LLMRec model loss in epoch 1/2 iteration 157/1084: 0.07158804684877396\n",
            "A-LLMRec model loss in epoch 1/2 iteration 158/1084: 0.14228461682796478\n",
            "A-LLMRec model loss in epoch 1/2 iteration 159/1084: 0.08009767532348633\n",
            "A-LLMRec model loss in epoch 1/2 iteration 160/1084: 0.015122323296964169\n",
            "A-LLMRec model loss in epoch 1/2 iteration 161/1084: 0.444608211517334\n",
            "A-LLMRec model loss in epoch 1/2 iteration 162/1084: 0.2593781352043152\n",
            "A-LLMRec model loss in epoch 1/2 iteration 163/1084: 0.015638846904039383\n",
            "A-LLMRec model loss in epoch 1/2 iteration 164/1084: 0.135819673538208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 165/1084: 0.09402033686637878\n",
            "A-LLMRec model loss in epoch 1/2 iteration 166/1084: 0.014740994200110435\n",
            "A-LLMRec model loss in epoch 1/2 iteration 167/1084: 0.00985032506287098\n",
            "A-LLMRec model loss in epoch 1/2 iteration 168/1084: 0.23703737556934357\n",
            "A-LLMRec model loss in epoch 1/2 iteration 169/1084: 0.1581934690475464\n",
            "A-LLMRec model loss in epoch 1/2 iteration 170/1084: 0.2322481870651245\n",
            "A-LLMRec model loss in epoch 1/2 iteration 171/1084: 0.02510695345699787\n",
            "A-LLMRec model loss in epoch 1/2 iteration 172/1084: 0.03712795302271843\n",
            "A-LLMRec model loss in epoch 1/2 iteration 173/1084: 0.020861277356743813\n",
            "A-LLMRec model loss in epoch 1/2 iteration 174/1084: 0.23172733187675476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 175/1084: 0.11162122339010239\n",
            "A-LLMRec model loss in epoch 1/2 iteration 176/1084: 0.03189456835389137\n",
            "A-LLMRec model loss in epoch 1/2 iteration 177/1084: 0.10365205258131027\n",
            "A-LLMRec model loss in epoch 1/2 iteration 178/1084: 0.1952160745859146\n",
            "A-LLMRec model loss in epoch 1/2 iteration 179/1084: 0.09820044785737991\n",
            "A-LLMRec model loss in epoch 1/2 iteration 180/1084: 0.1749325692653656\n",
            "A-LLMRec model loss in epoch 1/2 iteration 181/1084: 0.14574526250362396\n",
            "A-LLMRec model loss in epoch 1/2 iteration 182/1084: 0.22614850103855133\n",
            "A-LLMRec model loss in epoch 1/2 iteration 183/1084: 0.31349775195121765\n",
            "A-LLMRec model loss in epoch 1/2 iteration 184/1084: 0.0860016793012619\n",
            "A-LLMRec model loss in epoch 1/2 iteration 185/1084: 0.1799670159816742\n",
            "A-LLMRec model loss in epoch 1/2 iteration 186/1084: 0.08535110950469971\n",
            "A-LLMRec model loss in epoch 1/2 iteration 187/1084: 0.2593575119972229\n",
            "A-LLMRec model loss in epoch 1/2 iteration 188/1084: 0.12660957872867584\n",
            "A-LLMRec model loss in epoch 1/2 iteration 189/1084: 0.019587937742471695\n",
            "A-LLMRec model loss in epoch 1/2 iteration 190/1084: 0.29290345311164856\n",
            "A-LLMRec model loss in epoch 1/2 iteration 191/1084: 0.5040735006332397\n",
            "A-LLMRec model loss in epoch 1/2 iteration 192/1084: 0.049529779702425\n",
            "A-LLMRec model loss in epoch 1/2 iteration 193/1084: 0.044756315648555756\n",
            "A-LLMRec model loss in epoch 1/2 iteration 194/1084: 0.12330429255962372\n",
            "A-LLMRec model loss in epoch 1/2 iteration 195/1084: 0.05412248894572258\n",
            "A-LLMRec model loss in epoch 1/2 iteration 196/1084: 0.0810345858335495\n",
            "A-LLMRec model loss in epoch 1/2 iteration 197/1084: 0.11643673479557037\n",
            "A-LLMRec model loss in epoch 1/2 iteration 198/1084: 0.2559014856815338\n",
            "A-LLMRec model loss in epoch 1/2 iteration 199/1084: 0.017061229795217514\n",
            "A-LLMRec model loss in epoch 1/2 iteration 200/1084: 0.032797232270240784\n",
            "A-LLMRec model loss in epoch 1/2 iteration 201/1084: 0.14530813694000244\n",
            "A-LLMRec model loss in epoch 1/2 iteration 202/1084: 0.21921619772911072\n",
            "A-LLMRec model loss in epoch 1/2 iteration 203/1084: 0.09480408579111099\n",
            "A-LLMRec model loss in epoch 1/2 iteration 204/1084: 0.016748875379562378\n",
            "A-LLMRec model loss in epoch 1/2 iteration 205/1084: 0.10844209045171738\n",
            "A-LLMRec model loss in epoch 1/2 iteration 206/1084: 0.21599146723747253\n",
            "A-LLMRec model loss in epoch 1/2 iteration 207/1084: 0.08536238968372345\n",
            "A-LLMRec model loss in epoch 1/2 iteration 208/1084: 0.1728202998638153\n",
            "A-LLMRec model loss in epoch 1/2 iteration 209/1084: 0.0318109467625618\n",
            "A-LLMRec model loss in epoch 1/2 iteration 210/1084: 0.19108501076698303\n",
            "A-LLMRec model loss in epoch 1/2 iteration 211/1084: 0.010613646358251572\n",
            "A-LLMRec model loss in epoch 1/2 iteration 212/1084: 0.06856342405080795\n",
            "A-LLMRec model loss in epoch 1/2 iteration 213/1084: 0.5099008083343506\n",
            "A-LLMRec model loss in epoch 1/2 iteration 214/1084: 0.02977149747312069\n",
            "A-LLMRec model loss in epoch 1/2 iteration 215/1084: 0.03881269693374634\n",
            "A-LLMRec model loss in epoch 1/2 iteration 216/1084: 0.01430527400225401\n",
            "A-LLMRec model loss in epoch 1/2 iteration 217/1084: 0.06038758531212807\n",
            "A-LLMRec model loss in epoch 1/2 iteration 218/1084: 0.10973114520311356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 219/1084: 0.24077743291854858\n",
            "A-LLMRec model loss in epoch 1/2 iteration 220/1084: 0.02813275158405304\n",
            "A-LLMRec model loss in epoch 1/2 iteration 221/1084: 0.06421952694654465\n",
            "A-LLMRec model loss in epoch 1/2 iteration 222/1084: 0.02780398167669773\n",
            "A-LLMRec model loss in epoch 1/2 iteration 223/1084: 0.010779066011309624\n",
            "A-LLMRec model loss in epoch 1/2 iteration 224/1084: 0.2837183475494385\n",
            "A-LLMRec model loss in epoch 1/2 iteration 225/1084: 0.06587915867567062\n",
            "A-LLMRec model loss in epoch 1/2 iteration 226/1084: 0.03414098173379898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 227/1084: 0.0284408126026392\n",
            "A-LLMRec model loss in epoch 1/2 iteration 228/1084: 0.003597512375563383\n",
            "A-LLMRec model loss in epoch 1/2 iteration 229/1084: 0.021208658814430237\n",
            "A-LLMRec model loss in epoch 1/2 iteration 230/1084: 0.2277992069721222\n",
            "A-LLMRec model loss in epoch 1/2 iteration 231/1084: 0.27455824613571167\n",
            "A-LLMRec model loss in epoch 1/2 iteration 232/1084: 0.12588515877723694\n",
            "A-LLMRec model loss in epoch 1/2 iteration 233/1084: 0.01898767426609993\n",
            "A-LLMRec model loss in epoch 1/2 iteration 234/1084: 0.3179318308830261\n",
            "A-LLMRec model loss in epoch 1/2 iteration 235/1084: 0.18538473546504974\n",
            "A-LLMRec model loss in epoch 1/2 iteration 236/1084: 0.06989956647157669\n",
            "A-LLMRec model loss in epoch 1/2 iteration 237/1084: 0.2517069876194\n",
            "A-LLMRec model loss in epoch 1/2 iteration 238/1084: 0.11841379106044769\n",
            "A-LLMRec model loss in epoch 1/2 iteration 239/1084: 0.29453200101852417\n",
            "A-LLMRec model loss in epoch 1/2 iteration 240/1084: 0.08406912535429001\n",
            "A-LLMRec model loss in epoch 1/2 iteration 241/1084: 0.11514068394899368\n",
            "A-LLMRec model loss in epoch 1/2 iteration 242/1084: 0.06308642029762268\n",
            "A-LLMRec model loss in epoch 1/2 iteration 243/1084: 0.21562406420707703\n",
            "A-LLMRec model loss in epoch 1/2 iteration 244/1084: 0.10550932586193085\n",
            "A-LLMRec model loss in epoch 1/2 iteration 245/1084: 0.09113572537899017\n",
            "A-LLMRec model loss in epoch 1/2 iteration 246/1084: 0.09684769809246063\n",
            "A-LLMRec model loss in epoch 1/2 iteration 247/1084: 0.06677648425102234\n",
            "A-LLMRec model loss in epoch 1/2 iteration 248/1084: 0.09208821505308151\n",
            "A-LLMRec model loss in epoch 1/2 iteration 249/1084: 0.009219929575920105\n",
            "A-LLMRec model loss in epoch 1/2 iteration 250/1084: 0.14275282621383667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 251/1084: 0.10812630504369736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 252/1084: 0.04003632068634033\n",
            "A-LLMRec model loss in epoch 1/2 iteration 253/1084: 0.1404992640018463\n",
            "A-LLMRec model loss in epoch 1/2 iteration 254/1084: 0.2338784784078598\n",
            "A-LLMRec model loss in epoch 1/2 iteration 255/1084: 0.2154364287853241\n",
            "A-LLMRec model loss in epoch 1/2 iteration 256/1084: 0.3736709654331207\n",
            "A-LLMRec model loss in epoch 1/2 iteration 257/1084: 0.20835068821907043\n",
            "A-LLMRec model loss in epoch 1/2 iteration 258/1084: 0.014766344800591469\n",
            "A-LLMRec model loss in epoch 1/2 iteration 259/1084: 0.23846639692783356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 260/1084: 0.01900908350944519\n",
            "A-LLMRec model loss in epoch 1/2 iteration 261/1084: 0.04798542708158493\n",
            "A-LLMRec model loss in epoch 1/2 iteration 262/1084: 0.012396754696965218\n",
            "A-LLMRec model loss in epoch 1/2 iteration 263/1084: 0.15222197771072388\n",
            "A-LLMRec model loss in epoch 1/2 iteration 264/1084: 0.0882326290011406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 265/1084: 0.013401465490460396\n",
            "A-LLMRec model loss in epoch 1/2 iteration 266/1084: 0.19297979772090912\n",
            "A-LLMRec model loss in epoch 1/2 iteration 267/1084: 0.062055058777332306\n",
            "A-LLMRec model loss in epoch 1/2 iteration 268/1084: 0.14030791819095612\n",
            "A-LLMRec model loss in epoch 1/2 iteration 269/1084: 0.27427801489830017\n",
            "A-LLMRec model loss in epoch 1/2 iteration 270/1084: 0.013408476486802101\n",
            "A-LLMRec model loss in epoch 1/2 iteration 271/1084: 0.05395808815956116\n",
            "A-LLMRec model loss in epoch 1/2 iteration 272/1084: 0.08018388599157333\n",
            "A-LLMRec model loss in epoch 1/2 iteration 273/1084: 0.013620717450976372\n",
            "A-LLMRec model loss in epoch 1/2 iteration 274/1084: 0.03224477171897888\n",
            "A-LLMRec model loss in epoch 1/2 iteration 275/1084: 0.1537705361843109\n",
            "A-LLMRec model loss in epoch 1/2 iteration 276/1084: 0.013657665811479092\n",
            "A-LLMRec model loss in epoch 1/2 iteration 277/1084: 0.16344593465328217\n",
            "A-LLMRec model loss in epoch 1/2 iteration 278/1084: 0.21607504785060883\n",
            "A-LLMRec model loss in epoch 1/2 iteration 279/1084: 0.009236571379005909\n",
            "A-LLMRec model loss in epoch 1/2 iteration 280/1084: 0.09511315822601318\n",
            "A-LLMRec model loss in epoch 1/2 iteration 281/1084: 0.36450329422950745\n",
            "A-LLMRec model loss in epoch 1/2 iteration 282/1084: 0.146192729473114\n",
            "A-LLMRec model loss in epoch 1/2 iteration 283/1084: 0.01566372625529766\n",
            "A-LLMRec model loss in epoch 1/2 iteration 284/1084: 0.02115360088646412\n",
            "A-LLMRec model loss in epoch 1/2 iteration 285/1084: 0.05022977292537689\n",
            "A-LLMRec model loss in epoch 1/2 iteration 286/1084: 0.06216955929994583\n",
            "A-LLMRec model loss in epoch 1/2 iteration 287/1084: 0.020244497805833817\n",
            "A-LLMRec model loss in epoch 1/2 iteration 288/1084: 0.2053845077753067\n",
            "A-LLMRec model loss in epoch 1/2 iteration 289/1084: 0.03266487270593643\n",
            "A-LLMRec model loss in epoch 1/2 iteration 290/1084: 0.2533358633518219\n",
            "A-LLMRec model loss in epoch 1/2 iteration 291/1084: 0.04795289784669876\n",
            "A-LLMRec model loss in epoch 1/2 iteration 292/1084: 0.004775984678417444\n",
            "A-LLMRec model loss in epoch 1/2 iteration 293/1084: 0.22054126858711243\n",
            "A-LLMRec model loss in epoch 1/2 iteration 294/1084: 0.03479578346014023\n",
            "A-LLMRec model loss in epoch 1/2 iteration 295/1084: 0.07634670287370682\n",
            "A-LLMRec model loss in epoch 1/2 iteration 296/1084: 0.1375308483839035\n",
            "A-LLMRec model loss in epoch 1/2 iteration 297/1084: 0.07415009289979935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 298/1084: 0.00892594549804926\n",
            "A-LLMRec model loss in epoch 1/2 iteration 299/1084: 0.6132693290710449\n",
            "A-LLMRec model loss in epoch 1/2 iteration 300/1084: 0.06320459395647049\n",
            "A-LLMRec model loss in epoch 1/2 iteration 301/1084: 0.08097241073846817\n",
            "A-LLMRec model loss in epoch 1/2 iteration 302/1084: 0.013727481476962566\n",
            "A-LLMRec model loss in epoch 1/2 iteration 303/1084: 0.010514500550925732\n",
            "A-LLMRec model loss in epoch 1/2 iteration 304/1084: 0.14329978823661804\n",
            "A-LLMRec model loss in epoch 1/2 iteration 305/1084: 0.05289515107870102\n",
            "A-LLMRec model loss in epoch 1/2 iteration 306/1084: 0.28573906421661377\n",
            "A-LLMRec model loss in epoch 1/2 iteration 307/1084: 0.07927612215280533\n",
            "A-LLMRec model loss in epoch 1/2 iteration 308/1084: 0.047910116612911224\n",
            "A-LLMRec model loss in epoch 1/2 iteration 309/1084: 0.2373046725988388\n",
            "A-LLMRec model loss in epoch 1/2 iteration 310/1084: 0.04078153520822525\n",
            "A-LLMRec model loss in epoch 1/2 iteration 311/1084: 0.1541971117258072\n",
            "A-LLMRec model loss in epoch 1/2 iteration 312/1084: 0.3340418338775635\n",
            "A-LLMRec model loss in epoch 1/2 iteration 313/1084: 0.23432406783103943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 314/1084: 0.06243996322154999\n",
            "A-LLMRec model loss in epoch 1/2 iteration 315/1084: 0.10024365037679672\n",
            "A-LLMRec model loss in epoch 1/2 iteration 316/1084: 0.08621448278427124\n",
            "A-LLMRec model loss in epoch 1/2 iteration 317/1084: 0.1513207107782364\n",
            "A-LLMRec model loss in epoch 1/2 iteration 318/1084: 0.0386623851954937\n",
            "A-LLMRec model loss in epoch 1/2 iteration 319/1084: 0.029443759471178055\n",
            "A-LLMRec model loss in epoch 1/2 iteration 320/1084: 0.051176633685827255\n",
            "A-LLMRec model loss in epoch 1/2 iteration 321/1084: 0.054553233087062836\n",
            "A-LLMRec model loss in epoch 1/2 iteration 322/1084: 0.07528423517942429\n",
            "A-LLMRec model loss in epoch 1/2 iteration 323/1084: 0.10005079209804535\n",
            "A-LLMRec model loss in epoch 1/2 iteration 324/1084: 0.26596084237098694\n",
            "A-LLMRec model loss in epoch 1/2 iteration 325/1084: 0.05840110406279564\n",
            "A-LLMRec model loss in epoch 1/2 iteration 326/1084: 0.153728649020195\n",
            "A-LLMRec model loss in epoch 1/2 iteration 327/1084: 0.09276755154132843\n",
            "A-LLMRec model loss in epoch 1/2 iteration 328/1084: 0.0925067588686943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 329/1084: 0.020559020340442657\n",
            "A-LLMRec model loss in epoch 1/2 iteration 330/1084: 0.019547652453184128\n",
            "A-LLMRec model loss in epoch 1/2 iteration 331/1084: 0.010973514057695866\n",
            "A-LLMRec model loss in epoch 1/2 iteration 332/1084: 0.022367194294929504\n",
            "A-LLMRec model loss in epoch 1/2 iteration 333/1084: 0.028796225786209106\n",
            "A-LLMRec model loss in epoch 1/2 iteration 334/1084: 0.010897455736994743\n",
            "A-LLMRec model loss in epoch 1/2 iteration 335/1084: 0.07656276971101761\n",
            "A-LLMRec model loss in epoch 1/2 iteration 336/1084: 0.0070377797819674015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 337/1084: 0.009437162429094315\n",
            "A-LLMRec model loss in epoch 1/2 iteration 338/1084: 0.009050414897501469\n",
            "A-LLMRec model loss in epoch 1/2 iteration 339/1084: 0.1232774406671524\n",
            "A-LLMRec model loss in epoch 1/2 iteration 340/1084: 0.004991545341908932\n",
            "A-LLMRec model loss in epoch 1/2 iteration 341/1084: 0.03798506781458855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 342/1084: 0.04183052107691765\n",
            "A-LLMRec model loss in epoch 1/2 iteration 343/1084: 0.004547866992652416\n",
            "A-LLMRec model loss in epoch 1/2 iteration 344/1084: 0.007892095483839512\n",
            "A-LLMRec model loss in epoch 1/2 iteration 345/1084: 0.1913112848997116\n",
            "A-LLMRec model loss in epoch 1/2 iteration 346/1084: 0.1965726912021637\n",
            "A-LLMRec model loss in epoch 1/2 iteration 347/1084: 0.006800455506891012\n",
            "A-LLMRec model loss in epoch 1/2 iteration 348/1084: 0.08738493174314499\n",
            "A-LLMRec model loss in epoch 1/2 iteration 349/1084: 0.18683494627475739\n",
            "A-LLMRec model loss in epoch 1/2 iteration 350/1084: 0.15472900867462158\n",
            "A-LLMRec model loss in epoch 1/2 iteration 351/1084: 0.16777978837490082\n",
            "A-LLMRec model loss in epoch 1/2 iteration 352/1084: 0.15932627022266388\n",
            "A-LLMRec model loss in epoch 1/2 iteration 353/1084: 0.009142987430095673\n",
            "A-LLMRec model loss in epoch 1/2 iteration 354/1084: 0.0389610193669796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 355/1084: 0.059625398367643356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 356/1084: 0.08231282234191895\n",
            "A-LLMRec model loss in epoch 1/2 iteration 357/1084: 0.013843814842402935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 358/1084: 0.1398313045501709\n",
            "A-LLMRec model loss in epoch 1/2 iteration 359/1084: 0.14925037324428558\n",
            "A-LLMRec model loss in epoch 1/2 iteration 360/1084: 0.15615063905715942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 361/1084: 0.03310210630297661\n",
            "A-LLMRec model loss in epoch 1/2 iteration 362/1084: 0.014545039273798466\n",
            "A-LLMRec model loss in epoch 1/2 iteration 363/1084: 0.05178283154964447\n",
            "A-LLMRec model loss in epoch 1/2 iteration 364/1084: 0.09605501592159271\n",
            "A-LLMRec model loss in epoch 1/2 iteration 365/1084: 0.016225185245275497\n",
            "A-LLMRec model loss in epoch 1/2 iteration 366/1084: 0.036111343652009964\n",
            "A-LLMRec model loss in epoch 1/2 iteration 367/1084: 0.1538037359714508\n",
            "A-LLMRec model loss in epoch 1/2 iteration 368/1084: 0.09645910561084747\n",
            "A-LLMRec model loss in epoch 1/2 iteration 369/1084: 0.14654143154621124\n",
            "A-LLMRec model loss in epoch 1/2 iteration 370/1084: 0.07319889217615128\n",
            "A-LLMRec model loss in epoch 1/2 iteration 371/1084: 0.3191877603530884\n",
            "A-LLMRec model loss in epoch 1/2 iteration 372/1084: 0.011648616753518581\n",
            "A-LLMRec model loss in epoch 1/2 iteration 373/1084: 0.014598841778934002\n",
            "A-LLMRec model loss in epoch 1/2 iteration 374/1084: 0.11646897345781326\n",
            "A-LLMRec model loss in epoch 1/2 iteration 375/1084: 0.017855284735560417\n",
            "A-LLMRec model loss in epoch 1/2 iteration 376/1084: 0.2072543352842331\n",
            "A-LLMRec model loss in epoch 1/2 iteration 377/1084: 0.26060715317726135\n",
            "A-LLMRec model loss in epoch 1/2 iteration 378/1084: 0.23269356787204742\n",
            "A-LLMRec model loss in epoch 1/2 iteration 379/1084: 0.2245255708694458\n",
            "A-LLMRec model loss in epoch 1/2 iteration 380/1084: 0.28366661071777344\n",
            "A-LLMRec model loss in epoch 1/2 iteration 381/1084: 0.07387640327215195\n",
            "A-LLMRec model loss in epoch 1/2 iteration 382/1084: 0.06766970455646515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 383/1084: 0.01761697605252266\n",
            "A-LLMRec model loss in epoch 1/2 iteration 384/1084: 0.01063554733991623\n",
            "A-LLMRec model loss in epoch 1/2 iteration 385/1084: 0.10975740849971771\n",
            "A-LLMRec model loss in epoch 1/2 iteration 386/1084: 0.04499611631035805\n",
            "A-LLMRec model loss in epoch 1/2 iteration 387/1084: 0.009418030269443989\n",
            "A-LLMRec model loss in epoch 1/2 iteration 388/1084: 0.014579513110220432\n",
            "A-LLMRec model loss in epoch 1/2 iteration 389/1084: 0.07717231661081314\n",
            "A-LLMRec model loss in epoch 1/2 iteration 390/1084: 0.14128951728343964\n",
            "A-LLMRec model loss in epoch 1/2 iteration 391/1084: 0.04702020063996315\n",
            "A-LLMRec model loss in epoch 1/2 iteration 392/1084: 0.018149245530366898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 393/1084: 0.10692688077688217\n",
            "A-LLMRec model loss in epoch 1/2 iteration 394/1084: 0.1265011876821518\n",
            "A-LLMRec model loss in epoch 1/2 iteration 395/1084: 0.03214455023407936\n",
            "A-LLMRec model loss in epoch 1/2 iteration 396/1084: 0.14585691690444946\n",
            "A-LLMRec model loss in epoch 1/2 iteration 397/1084: 0.15940378606319427\n",
            "A-LLMRec model loss in epoch 1/2 iteration 398/1084: 0.13539116084575653\n",
            "A-LLMRec model loss in epoch 1/2 iteration 399/1084: 0.0121072456240654\n",
            "A-LLMRec model loss in epoch 1/2 iteration 400/1084: 0.13914257287979126\n",
            "A-LLMRec model loss in epoch 1/2 iteration 401/1084: 0.07060500234365463\n",
            "A-LLMRec model loss in epoch 1/2 iteration 402/1084: 0.0766742080450058\n",
            "A-LLMRec model loss in epoch 1/2 iteration 403/1084: 0.11881538480520248\n",
            "A-LLMRec model loss in epoch 1/2 iteration 404/1084: 0.050845131278038025\n",
            "A-LLMRec model loss in epoch 1/2 iteration 405/1084: 0.021311093121767044\n",
            "A-LLMRec model loss in epoch 1/2 iteration 406/1084: 0.42663130164146423\n",
            "A-LLMRec model loss in epoch 1/2 iteration 407/1084: 0.08351638168096542\n",
            "A-LLMRec model loss in epoch 1/2 iteration 408/1084: 0.054461244493722916\n",
            "A-LLMRec model loss in epoch 1/2 iteration 409/1084: 0.012947676703333855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 410/1084: 0.012408466078341007\n",
            "A-LLMRec model loss in epoch 1/2 iteration 411/1084: 0.03886929899454117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 412/1084: 0.009176285937428474\n",
            "A-LLMRec model loss in epoch 1/2 iteration 413/1084: 0.2532423436641693\n",
            "A-LLMRec model loss in epoch 1/2 iteration 414/1084: 0.022633446380496025\n",
            "A-LLMRec model loss in epoch 1/2 iteration 415/1084: 0.07597950845956802\n",
            "A-LLMRec model loss in epoch 1/2 iteration 416/1084: 0.08842558413743973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 417/1084: 0.09520784020423889\n",
            "A-LLMRec model loss in epoch 1/2 iteration 418/1084: 0.1530279517173767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 419/1084: 0.07402356714010239\n",
            "A-LLMRec model loss in epoch 1/2 iteration 420/1084: 0.060206614434719086\n",
            "A-LLMRec model loss in epoch 1/2 iteration 421/1084: 0.022026732563972473\n",
            "A-LLMRec model loss in epoch 1/2 iteration 422/1084: 0.05372964218258858\n",
            "A-LLMRec model loss in epoch 1/2 iteration 423/1084: 0.01956712082028389\n",
            "A-LLMRec model loss in epoch 1/2 iteration 424/1084: 0.0698077380657196\n",
            "A-LLMRec model loss in epoch 1/2 iteration 425/1084: 0.0174610186368227\n",
            "A-LLMRec model loss in epoch 1/2 iteration 426/1084: 0.07569434493780136\n",
            "A-LLMRec model loss in epoch 1/2 iteration 427/1084: 0.013111638836562634\n",
            "A-LLMRec model loss in epoch 1/2 iteration 428/1084: 0.044803690165281296\n",
            "A-LLMRec model loss in epoch 1/2 iteration 429/1084: 0.07006367295980453\n",
            "A-LLMRec model loss in epoch 1/2 iteration 430/1084: 0.15728692710399628\n",
            "A-LLMRec model loss in epoch 1/2 iteration 431/1084: 0.1866464912891388\n",
            "A-LLMRec model loss in epoch 1/2 iteration 432/1084: 0.37675920128822327\n",
            "A-LLMRec model loss in epoch 1/2 iteration 433/1084: 0.004757539369165897\n",
            "A-LLMRec model loss in epoch 1/2 iteration 434/1084: 0.4288787245750427\n",
            "A-LLMRec model loss in epoch 1/2 iteration 435/1084: 0.014177120290696621\n",
            "A-LLMRec model loss in epoch 1/2 iteration 436/1084: 0.0652289092540741\n",
            "A-LLMRec model loss in epoch 1/2 iteration 437/1084: 0.0052324808202683926\n",
            "A-LLMRec model loss in epoch 1/2 iteration 438/1084: 0.15844711661338806\n",
            "A-LLMRec model loss in epoch 1/2 iteration 439/1084: 0.1559780091047287\n",
            "A-LLMRec model loss in epoch 1/2 iteration 440/1084: 0.26827484369277954\n",
            "A-LLMRec model loss in epoch 1/2 iteration 441/1084: 0.05027603358030319\n",
            "A-LLMRec model loss in epoch 1/2 iteration 442/1084: 0.041787289083004\n",
            "A-LLMRec model loss in epoch 1/2 iteration 443/1084: 0.014889686368405819\n",
            "A-LLMRec model loss in epoch 1/2 iteration 444/1084: 0.0059783984906971455\n",
            "A-LLMRec model loss in epoch 1/2 iteration 445/1084: 0.010148249566555023\n",
            "A-LLMRec model loss in epoch 1/2 iteration 446/1084: 0.016416247934103012\n",
            "A-LLMRec model loss in epoch 1/2 iteration 447/1084: 0.025154056027531624\n",
            "A-LLMRec model loss in epoch 1/2 iteration 448/1084: 0.08250036835670471\n",
            "A-LLMRec model loss in epoch 1/2 iteration 449/1084: 0.023918848484754562\n",
            "A-LLMRec model loss in epoch 1/2 iteration 450/1084: 0.035249609500169754\n",
            "A-LLMRec model loss in epoch 1/2 iteration 451/1084: 0.347920686006546\n",
            "A-LLMRec model loss in epoch 1/2 iteration 452/1084: 0.030599625781178474\n",
            "A-LLMRec model loss in epoch 1/2 iteration 453/1084: 0.010478610172867775\n",
            "A-LLMRec model loss in epoch 1/2 iteration 454/1084: 0.11132167279720306\n",
            "A-LLMRec model loss in epoch 1/2 iteration 455/1084: 0.019281886518001556\n",
            "A-LLMRec model loss in epoch 1/2 iteration 456/1084: 0.004745469894260168\n",
            "A-LLMRec model loss in epoch 1/2 iteration 457/1084: 0.09956416487693787\n",
            "A-LLMRec model loss in epoch 1/2 iteration 458/1084: 0.006936228834092617\n",
            "A-LLMRec model loss in epoch 1/2 iteration 459/1084: 0.0792558416724205\n",
            "A-LLMRec model loss in epoch 1/2 iteration 460/1084: 0.07352098822593689\n",
            "A-LLMRec model loss in epoch 1/2 iteration 461/1084: 0.03548450395464897\n",
            "A-LLMRec model loss in epoch 1/2 iteration 462/1084: 0.04395769163966179\n",
            "A-LLMRec model loss in epoch 1/2 iteration 463/1084: 0.05631294846534729\n",
            "A-LLMRec model loss in epoch 1/2 iteration 464/1084: 0.015716176480054855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 465/1084: 0.3257071375846863\n",
            "A-LLMRec model loss in epoch 1/2 iteration 466/1084: 0.035619862377643585\n",
            "A-LLMRec model loss in epoch 1/2 iteration 467/1084: 0.1342831254005432\n",
            "A-LLMRec model loss in epoch 1/2 iteration 468/1084: 0.004576528910547495\n",
            "A-LLMRec model loss in epoch 1/2 iteration 469/1084: 0.003079777117818594\n",
            "A-LLMRec model loss in epoch 1/2 iteration 470/1084: 0.0035059077199548483\n",
            "A-LLMRec model loss in epoch 1/2 iteration 471/1084: 0.0032287610229104757\n",
            "A-LLMRec model loss in epoch 1/2 iteration 472/1084: 0.0053094858303666115\n",
            "A-LLMRec model loss in epoch 1/2 iteration 473/1084: 0.07538674771785736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 474/1084: 0.19800354540348053\n",
            "A-LLMRec model loss in epoch 1/2 iteration 475/1084: 0.20025306940078735\n",
            "A-LLMRec model loss in epoch 1/2 iteration 476/1084: 0.27589061856269836\n",
            "A-LLMRec model loss in epoch 1/2 iteration 477/1084: 0.022369127720594406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 478/1084: 0.16849994659423828\n",
            "A-LLMRec model loss in epoch 1/2 iteration 479/1084: 0.14275649189949036\n",
            "A-LLMRec model loss in epoch 1/2 iteration 480/1084: 0.2581174075603485\n",
            "A-LLMRec model loss in epoch 1/2 iteration 481/1084: 0.03213607147336006\n",
            "A-LLMRec model loss in epoch 1/2 iteration 482/1084: 0.011060938239097595\n",
            "A-LLMRec model loss in epoch 1/2 iteration 483/1084: 0.0058600218035280704\n",
            "A-LLMRec model loss in epoch 1/2 iteration 484/1084: 0.20417876541614532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 485/1084: 0.017325958237051964\n",
            "A-LLMRec model loss in epoch 1/2 iteration 486/1084: 0.01928102970123291\n",
            "A-LLMRec model loss in epoch 1/2 iteration 487/1084: 0.08512657880783081\n",
            "A-LLMRec model loss in epoch 1/2 iteration 488/1084: 0.009522182866930962\n",
            "A-LLMRec model loss in epoch 1/2 iteration 489/1084: 0.013392667286098003\n",
            "A-LLMRec model loss in epoch 1/2 iteration 490/1084: 0.011399922892451286\n",
            "A-LLMRec model loss in epoch 1/2 iteration 491/1084: 0.0713767409324646\n",
            "A-LLMRec model loss in epoch 1/2 iteration 492/1084: 0.08714864403009415\n",
            "A-LLMRec model loss in epoch 1/2 iteration 493/1084: 0.0048271967098116875\n",
            "A-LLMRec model loss in epoch 1/2 iteration 494/1084: 0.26609185338020325\n",
            "A-LLMRec model loss in epoch 1/2 iteration 495/1084: 0.03144964575767517\n",
            "A-LLMRec model loss in epoch 1/2 iteration 496/1084: 0.26533278822898865\n",
            "A-LLMRec model loss in epoch 1/2 iteration 497/1084: 0.14260044693946838\n",
            "A-LLMRec model loss in epoch 1/2 iteration 498/1084: 0.0697546899318695\n",
            "A-LLMRec model loss in epoch 1/2 iteration 499/1084: 0.022899257019162178\n",
            "A-LLMRec model loss in epoch 1/2 iteration 500/1084: 0.16524969041347504\n",
            "A-LLMRec model loss in epoch 1/2 iteration 501/1084: 0.01403387263417244\n",
            "A-LLMRec model loss in epoch 1/2 iteration 502/1084: 0.18648912012577057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 503/1084: 0.10795899480581284\n",
            "A-LLMRec model loss in epoch 1/2 iteration 504/1084: 0.05098395049571991\n",
            "A-LLMRec model loss in epoch 1/2 iteration 505/1084: 0.043631404638290405\n",
            "A-LLMRec model loss in epoch 1/2 iteration 506/1084: 0.014235042966902256\n",
            "A-LLMRec model loss in epoch 1/2 iteration 507/1084: 0.09815188497304916\n",
            "A-LLMRec model loss in epoch 1/2 iteration 508/1084: 0.04873856529593468\n",
            "A-LLMRec model loss in epoch 1/2 iteration 509/1084: 0.24702851474285126\n",
            "A-LLMRec model loss in epoch 1/2 iteration 510/1084: 0.012181744910776615\n",
            "A-LLMRec model loss in epoch 1/2 iteration 511/1084: 0.16989164054393768\n",
            "A-LLMRec model loss in epoch 1/2 iteration 512/1084: 0.015550173819065094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 513/1084: 0.2382691204547882\n",
            "A-LLMRec model loss in epoch 1/2 iteration 514/1084: 0.044181544333696365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 515/1084: 0.013981464318931103\n",
            "A-LLMRec model loss in epoch 1/2 iteration 516/1084: 0.012907273136079311\n",
            "A-LLMRec model loss in epoch 1/2 iteration 517/1084: 0.06495264172554016\n",
            "A-LLMRec model loss in epoch 1/2 iteration 518/1084: 0.00668630376458168\n",
            "A-LLMRec model loss in epoch 1/2 iteration 519/1084: 0.0355391725897789\n",
            "A-LLMRec model loss in epoch 1/2 iteration 520/1084: 0.024296440184116364\n",
            "A-LLMRec model loss in epoch 1/2 iteration 521/1084: 0.06991074234247208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 522/1084: 0.08377619087696075\n",
            "A-LLMRec model loss in epoch 1/2 iteration 523/1084: 0.13234703242778778\n",
            "A-LLMRec model loss in epoch 1/2 iteration 524/1084: 0.009654788300395012\n",
            "A-LLMRec model loss in epoch 1/2 iteration 525/1084: 0.009031235240399837\n",
            "A-LLMRec model loss in epoch 1/2 iteration 526/1084: 0.00857775192707777\n",
            "A-LLMRec model loss in epoch 1/2 iteration 527/1084: 0.05465955287218094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 528/1084: 0.14998996257781982\n",
            "A-LLMRec model loss in epoch 1/2 iteration 529/1084: 0.025219982489943504\n",
            "A-LLMRec model loss in epoch 1/2 iteration 530/1084: 0.2387911081314087\n",
            "A-LLMRec model loss in epoch 1/2 iteration 531/1084: 0.024281641468405724\n",
            "A-LLMRec model loss in epoch 1/2 iteration 532/1084: 0.13778354227542877\n",
            "A-LLMRec model loss in epoch 1/2 iteration 533/1084: 0.23456473648548126\n",
            "A-LLMRec model loss in epoch 1/2 iteration 534/1084: 0.034352242946624756\n",
            "A-LLMRec model loss in epoch 1/2 iteration 535/1084: 0.01209325809031725\n",
            "A-LLMRec model loss in epoch 1/2 iteration 536/1084: 0.006124516017735004\n",
            "A-LLMRec model loss in epoch 1/2 iteration 537/1084: 0.0226924829185009\n",
            "A-LLMRec model loss in epoch 1/2 iteration 538/1084: 0.06832811236381531\n",
            "A-LLMRec model loss in epoch 1/2 iteration 539/1084: 0.32696089148521423\n",
            "A-LLMRec model loss in epoch 1/2 iteration 540/1084: 0.13277645409107208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 541/1084: 0.3376801013946533\n",
            "A-LLMRec model loss in epoch 1/2 iteration 542/1084: 0.1828782558441162\n",
            "A-LLMRec model loss in epoch 1/2 iteration 543/1084: 0.47845613956451416\n",
            "A-LLMRec model loss in epoch 1/2 iteration 544/1084: 0.20995423197746277\n",
            "A-LLMRec model loss in epoch 1/2 iteration 545/1084: 0.0109202666208148\n",
            "A-LLMRec model loss in epoch 1/2 iteration 546/1084: 0.029493993148207664\n",
            "A-LLMRec model loss in epoch 1/2 iteration 547/1084: 0.02191787026822567\n",
            "A-LLMRec model loss in epoch 1/2 iteration 548/1084: 0.18722467124462128\n",
            "A-LLMRec model loss in epoch 1/2 iteration 549/1084: 0.033646903932094574\n",
            "A-LLMRec model loss in epoch 1/2 iteration 550/1084: 0.03206589072942734\n",
            "A-LLMRec model loss in epoch 1/2 iteration 551/1084: 0.12317243218421936\n",
            "A-LLMRec model loss in epoch 1/2 iteration 552/1084: 0.16259367763996124\n",
            "A-LLMRec model loss in epoch 1/2 iteration 553/1084: 0.06886600703001022\n",
            "A-LLMRec model loss in epoch 1/2 iteration 554/1084: 0.03903736174106598\n",
            "A-LLMRec model loss in epoch 1/2 iteration 555/1084: 0.024037955328822136\n",
            "A-LLMRec model loss in epoch 1/2 iteration 556/1084: 0.036693766713142395\n",
            "A-LLMRec model loss in epoch 1/2 iteration 557/1084: 0.24046491086483002\n",
            "A-LLMRec model loss in epoch 1/2 iteration 558/1084: 0.170842707157135\n",
            "A-LLMRec model loss in epoch 1/2 iteration 559/1084: 0.01335935015231371\n",
            "A-LLMRec model loss in epoch 1/2 iteration 560/1084: 0.025407498702406883\n",
            "A-LLMRec model loss in epoch 1/2 iteration 561/1084: 0.12671878933906555\n",
            "A-LLMRec model loss in epoch 1/2 iteration 562/1084: 0.27410709857940674\n",
            "A-LLMRec model loss in epoch 1/2 iteration 563/1084: 0.08988390862941742\n",
            "A-LLMRec model loss in epoch 1/2 iteration 564/1084: 0.02665165439248085\n",
            "A-LLMRec model loss in epoch 1/2 iteration 565/1084: 0.0941140279173851\n",
            "A-LLMRec model loss in epoch 1/2 iteration 566/1084: 0.021295597776770592\n",
            "A-LLMRec model loss in epoch 1/2 iteration 567/1084: 0.020476246252655983\n",
            "A-LLMRec model loss in epoch 1/2 iteration 568/1084: 0.016610460355877876\n",
            "A-LLMRec model loss in epoch 1/2 iteration 569/1084: 0.0034650727175176144\n",
            "A-LLMRec model loss in epoch 1/2 iteration 570/1084: 0.19178946316242218\n",
            "A-LLMRec model loss in epoch 1/2 iteration 571/1084: 0.20951053500175476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 572/1084: 0.19769887626171112\n",
            "A-LLMRec model loss in epoch 1/2 iteration 573/1084: 0.13775111734867096\n",
            "A-LLMRec model loss in epoch 1/2 iteration 574/1084: 0.06648433953523636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 575/1084: 0.008237835019826889\n",
            "A-LLMRec model loss in epoch 1/2 iteration 576/1084: 0.02626262977719307\n",
            "A-LLMRec model loss in epoch 1/2 iteration 577/1084: 0.042402785271406174\n",
            "A-LLMRec model loss in epoch 1/2 iteration 578/1084: 0.008829549886286259\n",
            "A-LLMRec model loss in epoch 1/2 iteration 579/1084: 0.008059083484113216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 580/1084: 0.03125585988163948\n",
            "A-LLMRec model loss in epoch 1/2 iteration 581/1084: 0.032267291098833084\n",
            "A-LLMRec model loss in epoch 1/2 iteration 582/1084: 0.009494722820818424\n",
            "A-LLMRec model loss in epoch 1/2 iteration 583/1084: 0.02921372652053833\n",
            "A-LLMRec model loss in epoch 1/2 iteration 584/1084: 0.011631130240857601\n",
            "A-LLMRec model loss in epoch 1/2 iteration 585/1084: 0.01741020940244198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 586/1084: 0.05184078961610794\n",
            "A-LLMRec model loss in epoch 1/2 iteration 587/1084: 0.11966431885957718\n",
            "A-LLMRec model loss in epoch 1/2 iteration 588/1084: 0.13575683534145355\n",
            "A-LLMRec model loss in epoch 1/2 iteration 589/1084: 0.13849961757659912\n",
            "A-LLMRec model loss in epoch 1/2 iteration 590/1084: 0.007900357246398926\n",
            "A-LLMRec model loss in epoch 1/2 iteration 591/1084: 0.17710761725902557\n",
            "A-LLMRec model loss in epoch 1/2 iteration 592/1084: 0.23725996911525726\n",
            "A-LLMRec model loss in epoch 1/2 iteration 593/1084: 0.08475124835968018\n",
            "A-LLMRec model loss in epoch 1/2 iteration 594/1084: 0.13982172310352325\n",
            "A-LLMRec model loss in epoch 1/2 iteration 595/1084: 0.14069764316082\n",
            "A-LLMRec model loss in epoch 1/2 iteration 596/1084: 0.08004026859998703\n",
            "A-LLMRec model loss in epoch 1/2 iteration 597/1084: 0.10075684636831284\n",
            "A-LLMRec model loss in epoch 1/2 iteration 598/1084: 0.08666979521512985\n",
            "A-LLMRec model loss in epoch 1/2 iteration 599/1084: 0.03226983919739723\n",
            "A-LLMRec model loss in epoch 1/2 iteration 600/1084: 0.14189426600933075\n",
            "A-LLMRec model loss in epoch 1/2 iteration 601/1084: 0.1244996041059494\n",
            "A-LLMRec model loss in epoch 1/2 iteration 602/1084: 0.15660449862480164\n",
            "A-LLMRec model loss in epoch 1/2 iteration 603/1084: 0.015419741161167622\n",
            "A-LLMRec model loss in epoch 1/2 iteration 604/1084: 0.012181969359517097\n",
            "A-LLMRec model loss in epoch 1/2 iteration 605/1084: 0.10427691787481308\n",
            "A-LLMRec model loss in epoch 1/2 iteration 606/1084: 0.014789337292313576\n",
            "A-LLMRec model loss in epoch 1/2 iteration 607/1084: 0.10887637734413147\n",
            "A-LLMRec model loss in epoch 1/2 iteration 608/1084: 0.03529168665409088\n",
            "A-LLMRec model loss in epoch 1/2 iteration 609/1084: 0.10691814124584198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 610/1084: 0.058888185769319534\n",
            "A-LLMRec model loss in epoch 1/2 iteration 611/1084: 0.20473892986774445\n",
            "A-LLMRec model loss in epoch 1/2 iteration 612/1084: 0.1317741423845291\n",
            "A-LLMRec model loss in epoch 1/2 iteration 613/1084: 0.09146907925605774\n",
            "A-LLMRec model loss in epoch 1/2 iteration 614/1084: 0.34876805543899536\n",
            "A-LLMRec model loss in epoch 1/2 iteration 615/1084: 0.1343420147895813\n",
            "A-LLMRec model loss in epoch 1/2 iteration 616/1084: 0.04717249050736427\n",
            "A-LLMRec model loss in epoch 1/2 iteration 617/1084: 0.06173228099942207\n",
            "A-LLMRec model loss in epoch 1/2 iteration 618/1084: 0.1722625494003296\n",
            "A-LLMRec model loss in epoch 1/2 iteration 619/1084: 0.04959103465080261\n",
            "A-LLMRec model loss in epoch 1/2 iteration 620/1084: 0.16309569776058197\n",
            "A-LLMRec model loss in epoch 1/2 iteration 621/1084: 0.035949770361185074\n",
            "A-LLMRec model loss in epoch 1/2 iteration 622/1084: 0.20369257032871246\n",
            "A-LLMRec model loss in epoch 1/2 iteration 623/1084: 0.3439742922782898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 624/1084: 0.15932151675224304\n",
            "A-LLMRec model loss in epoch 1/2 iteration 625/1084: 0.09795349836349487\n",
            "A-LLMRec model loss in epoch 1/2 iteration 626/1084: 0.24251027405261993\n",
            "A-LLMRec model loss in epoch 1/2 iteration 627/1084: 0.054633285850286484\n",
            "A-LLMRec model loss in epoch 1/2 iteration 628/1084: 0.0312923789024353\n",
            "A-LLMRec model loss in epoch 1/2 iteration 629/1084: 0.2503684461116791\n",
            "A-LLMRec model loss in epoch 1/2 iteration 630/1084: 0.1495591700077057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 631/1084: 0.1063116118311882\n",
            "A-LLMRec model loss in epoch 1/2 iteration 632/1084: 0.029626214876770973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 633/1084: 0.24557223916053772\n",
            "A-LLMRec model loss in epoch 1/2 iteration 634/1084: 0.018295451998710632\n",
            "A-LLMRec model loss in epoch 1/2 iteration 635/1084: 0.22333680093288422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 636/1084: 0.2627454996109009\n",
            "A-LLMRec model loss in epoch 1/2 iteration 637/1084: 0.030787743628025055\n",
            "A-LLMRec model loss in epoch 1/2 iteration 638/1084: 0.11833129078149796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 639/1084: 0.012331088073551655\n",
            "A-LLMRec model loss in epoch 1/2 iteration 640/1084: 0.1531773954629898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 641/1084: 0.205550417304039\n",
            "A-LLMRec model loss in epoch 1/2 iteration 642/1084: 0.047673240303993225\n",
            "A-LLMRec model loss in epoch 1/2 iteration 643/1084: 0.060714807361364365\n",
            "A-LLMRec model loss in epoch 1/2 iteration 644/1084: 0.1769762486219406\n",
            "A-LLMRec model loss in epoch 1/2 iteration 645/1084: 0.15851718187332153\n",
            "A-LLMRec model loss in epoch 1/2 iteration 646/1084: 0.11709678173065186\n",
            "A-LLMRec model loss in epoch 1/2 iteration 647/1084: 0.04976338520646095\n",
            "A-LLMRec model loss in epoch 1/2 iteration 648/1084: 0.034470442682504654\n",
            "A-LLMRec model loss in epoch 1/2 iteration 649/1084: 0.03597263991832733\n",
            "A-LLMRec model loss in epoch 1/2 iteration 650/1084: 0.2964921295642853\n",
            "A-LLMRec model loss in epoch 1/2 iteration 651/1084: 0.12693297863006592\n",
            "A-LLMRec model loss in epoch 1/2 iteration 652/1084: 0.025197405368089676\n",
            "A-LLMRec model loss in epoch 1/2 iteration 653/1084: 0.036921754479408264\n",
            "A-LLMRec model loss in epoch 1/2 iteration 654/1084: 0.05843538045883179\n",
            "A-LLMRec model loss in epoch 1/2 iteration 655/1084: 0.018470842391252518\n",
            "A-LLMRec model loss in epoch 1/2 iteration 656/1084: 0.007883045822381973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 657/1084: 0.01571687124669552\n",
            "A-LLMRec model loss in epoch 1/2 iteration 658/1084: 0.19321344792842865\n",
            "A-LLMRec model loss in epoch 1/2 iteration 659/1084: 0.04765607416629791\n",
            "A-LLMRec model loss in epoch 1/2 iteration 660/1084: 0.00891974288970232\n",
            "A-LLMRec model loss in epoch 1/2 iteration 661/1084: 0.09467840939760208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 662/1084: 0.13494642078876495\n",
            "A-LLMRec model loss in epoch 1/2 iteration 663/1084: 0.13900765776634216\n",
            "A-LLMRec model loss in epoch 1/2 iteration 664/1084: 0.03970428556203842\n",
            "A-LLMRec model loss in epoch 1/2 iteration 665/1084: 0.06958537548780441\n",
            "A-LLMRec model loss in epoch 1/2 iteration 666/1084: 0.015549987554550171\n",
            "A-LLMRec model loss in epoch 1/2 iteration 667/1084: 0.07394476234912872\n",
            "A-LLMRec model loss in epoch 1/2 iteration 668/1084: 0.01675010472536087\n",
            "A-LLMRec model loss in epoch 1/2 iteration 669/1084: 0.004180671647191048\n",
            "A-LLMRec model loss in epoch 1/2 iteration 670/1084: 0.013423394411802292\n",
            "A-LLMRec model loss in epoch 1/2 iteration 671/1084: 0.012378078885376453\n",
            "A-LLMRec model loss in epoch 1/2 iteration 672/1084: 0.01238736230880022\n",
            "A-LLMRec model loss in epoch 1/2 iteration 673/1084: 0.05373556539416313\n",
            "A-LLMRec model loss in epoch 1/2 iteration 674/1084: 0.5782999992370605\n",
            "A-LLMRec model loss in epoch 1/2 iteration 675/1084: 0.22922739386558533\n",
            "A-LLMRec model loss in epoch 1/2 iteration 676/1084: 0.33748599886894226\n",
            "A-LLMRec model loss in epoch 1/2 iteration 677/1084: 0.07069483399391174\n",
            "A-LLMRec model loss in epoch 1/2 iteration 678/1084: 0.005994788371026516\n",
            "A-LLMRec model loss in epoch 1/2 iteration 679/1084: 0.008948639035224915\n",
            "A-LLMRec model loss in epoch 1/2 iteration 680/1084: 0.004682226572185755\n",
            "A-LLMRec model loss in epoch 1/2 iteration 681/1084: 0.014883816242218018\n",
            "A-LLMRec model loss in epoch 1/2 iteration 682/1084: 0.45769819617271423\n",
            "A-LLMRec model loss in epoch 1/2 iteration 683/1084: 0.1109817773103714\n",
            "A-LLMRec model loss in epoch 1/2 iteration 684/1084: 0.3884589970111847\n",
            "A-LLMRec model loss in epoch 1/2 iteration 685/1084: 0.012299522757530212\n",
            "A-LLMRec model loss in epoch 1/2 iteration 686/1084: 0.02202482335269451\n",
            "A-LLMRec model loss in epoch 1/2 iteration 687/1084: 0.014933033846318722\n",
            "A-LLMRec model loss in epoch 1/2 iteration 688/1084: 0.23903630673885345\n",
            "A-LLMRec model loss in epoch 1/2 iteration 689/1084: 0.1078418716788292\n",
            "A-LLMRec model loss in epoch 1/2 iteration 690/1084: 0.2911381721496582\n",
            "A-LLMRec model loss in epoch 1/2 iteration 691/1084: 0.015044116415083408\n",
            "A-LLMRec model loss in epoch 1/2 iteration 692/1084: 0.15499097108840942\n",
            "A-LLMRec model loss in epoch 1/2 iteration 693/1084: 0.12589937448501587\n",
            "A-LLMRec model loss in epoch 1/2 iteration 694/1084: 0.027745267376303673\n",
            "A-LLMRec model loss in epoch 1/2 iteration 695/1084: 0.1213560402393341\n",
            "A-LLMRec model loss in epoch 1/2 iteration 696/1084: 0.09032490104436874\n",
            "A-LLMRec model loss in epoch 1/2 iteration 697/1084: 0.054334480315446854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 698/1084: 0.07463054358959198\n",
            "A-LLMRec model loss in epoch 1/2 iteration 699/1084: 0.10765603929758072\n",
            "A-LLMRec model loss in epoch 1/2 iteration 700/1084: 0.20348653197288513\n",
            "A-LLMRec model loss in epoch 1/2 iteration 701/1084: 0.2044493407011032\n",
            "A-LLMRec model loss in epoch 1/2 iteration 702/1084: 0.12472236156463623\n",
            "A-LLMRec model loss in epoch 1/2 iteration 703/1084: 0.022172212600708008\n",
            "A-LLMRec model loss in epoch 1/2 iteration 704/1084: 0.1379658281803131\n",
            "A-LLMRec model loss in epoch 1/2 iteration 705/1084: 0.1280115842819214\n",
            "A-LLMRec model loss in epoch 1/2 iteration 706/1084: 0.007267128676176071\n",
            "A-LLMRec model loss in epoch 1/2 iteration 707/1084: 0.011846182867884636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 708/1084: 0.21880654990673065\n",
            "A-LLMRec model loss in epoch 1/2 iteration 709/1084: 0.12084472179412842\n",
            "A-LLMRec model loss in epoch 1/2 iteration 710/1084: 0.31823670864105225\n",
            "A-LLMRec model loss in epoch 1/2 iteration 711/1084: 0.071802519261837\n",
            "A-LLMRec model loss in epoch 1/2 iteration 712/1084: 0.1791146695613861\n",
            "A-LLMRec model loss in epoch 1/2 iteration 713/1084: 0.019806314259767532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 714/1084: 0.2557513415813446\n",
            "A-LLMRec model loss in epoch 1/2 iteration 715/1084: 0.06379695981740952\n",
            "A-LLMRec model loss in epoch 1/2 iteration 716/1084: 0.08499205857515335\n",
            "A-LLMRec model loss in epoch 1/2 iteration 717/1084: 0.0165783129632473\n",
            "A-LLMRec model loss in epoch 1/2 iteration 718/1084: 0.07898128032684326\n",
            "A-LLMRec model loss in epoch 1/2 iteration 719/1084: 0.01986173540353775\n",
            "A-LLMRec model loss in epoch 1/2 iteration 720/1084: 0.014997648075222969\n",
            "A-LLMRec model loss in epoch 1/2 iteration 721/1084: 0.09080357104539871\n",
            "A-LLMRec model loss in epoch 1/2 iteration 722/1084: 0.017122922465205193\n",
            "A-LLMRec model loss in epoch 1/2 iteration 723/1084: 0.16525892913341522\n",
            "A-LLMRec model loss in epoch 1/2 iteration 724/1084: 0.09697748720645905\n",
            "A-LLMRec model loss in epoch 1/2 iteration 725/1084: 0.24673335254192352\n",
            "A-LLMRec model loss in epoch 1/2 iteration 726/1084: 0.14321057498455048\n",
            "A-LLMRec model loss in epoch 1/2 iteration 727/1084: 0.06796227395534515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 728/1084: 0.08950990438461304\n",
            "A-LLMRec model loss in epoch 1/2 iteration 729/1084: 0.06363912671804428\n",
            "A-LLMRec model loss in epoch 1/2 iteration 730/1084: 0.0708690881729126\n",
            "A-LLMRec model loss in epoch 1/2 iteration 731/1084: 0.19237858057022095\n",
            "A-LLMRec model loss in epoch 1/2 iteration 732/1084: 0.10319960862398148\n",
            "A-LLMRec model loss in epoch 1/2 iteration 733/1084: 0.009521475061774254\n",
            "A-LLMRec model loss in epoch 1/2 iteration 734/1084: 0.03217519447207451\n",
            "A-LLMRec model loss in epoch 1/2 iteration 735/1084: 0.016150696203112602\n",
            "A-LLMRec model loss in epoch 1/2 iteration 736/1084: 0.07458075135946274\n",
            "A-LLMRec model loss in epoch 1/2 iteration 737/1084: 0.012712831608951092\n",
            "A-LLMRec model loss in epoch 1/2 iteration 738/1084: 0.22946394979953766\n",
            "A-LLMRec model loss in epoch 1/2 iteration 739/1084: 0.18048028647899628\n",
            "A-LLMRec model loss in epoch 1/2 iteration 740/1084: 0.012537669390439987\n",
            "A-LLMRec model loss in epoch 1/2 iteration 741/1084: 0.03741409629583359\n",
            "A-LLMRec model loss in epoch 1/2 iteration 742/1084: 0.013575454242527485\n",
            "A-LLMRec model loss in epoch 1/2 iteration 743/1084: 0.04567968100309372\n",
            "A-LLMRec model loss in epoch 1/2 iteration 744/1084: 0.014614267274737358\n",
            "A-LLMRec model loss in epoch 1/2 iteration 745/1084: 0.05289590731263161\n",
            "A-LLMRec model loss in epoch 1/2 iteration 746/1084: 0.18560217320919037\n",
            "A-LLMRec model loss in epoch 1/2 iteration 747/1084: 0.009270396083593369\n",
            "A-LLMRec model loss in epoch 1/2 iteration 748/1084: 0.12638071179389954\n",
            "A-LLMRec model loss in epoch 1/2 iteration 749/1084: 0.004786178469657898\n",
            "A-LLMRec model loss in epoch 1/2 iteration 750/1084: 0.09676294773817062\n",
            "A-LLMRec model loss in epoch 1/2 iteration 751/1084: 0.26313820481300354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 752/1084: 0.013925882987678051\n",
            "A-LLMRec model loss in epoch 1/2 iteration 753/1084: 0.08727535605430603\n",
            "A-LLMRec model loss in epoch 1/2 iteration 754/1084: 0.10624566674232483\n",
            "A-LLMRec model loss in epoch 1/2 iteration 755/1084: 0.08668406307697296\n",
            "A-LLMRec model loss in epoch 1/2 iteration 756/1084: 0.07906758785247803\n",
            "A-LLMRec model loss in epoch 1/2 iteration 757/1084: 0.04426180198788643\n",
            "A-LLMRec model loss in epoch 1/2 iteration 758/1084: 0.27153685688972473\n",
            "A-LLMRec model loss in epoch 1/2 iteration 759/1084: 0.0709790363907814\n",
            "A-LLMRec model loss in epoch 1/2 iteration 760/1084: 0.11278112232685089\n",
            "A-LLMRec model loss in epoch 1/2 iteration 761/1084: 0.014586308971047401\n",
            "A-LLMRec model loss in epoch 1/2 iteration 762/1084: 0.015481332316994667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 763/1084: 0.009132405743002892\n",
            "A-LLMRec model loss in epoch 1/2 iteration 764/1084: 0.24381090700626373\n",
            "A-LLMRec model loss in epoch 1/2 iteration 765/1084: 0.01038272399455309\n",
            "A-LLMRec model loss in epoch 1/2 iteration 766/1084: 0.3350889980792999\n",
            "A-LLMRec model loss in epoch 1/2 iteration 767/1084: 0.1621115356683731\n",
            "A-LLMRec model loss in epoch 1/2 iteration 768/1084: 0.0538800023496151\n",
            "A-LLMRec model loss in epoch 1/2 iteration 769/1084: 0.02994406595826149\n",
            "A-LLMRec model loss in epoch 1/2 iteration 770/1084: 0.09341992437839508\n",
            "A-LLMRec model loss in epoch 1/2 iteration 771/1084: 0.07733367383480072\n",
            "A-LLMRec model loss in epoch 1/2 iteration 772/1084: 0.1900968700647354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 773/1084: 0.016815513372421265\n",
            "A-LLMRec model loss in epoch 1/2 iteration 774/1084: 0.046512071043252945\n",
            "A-LLMRec model loss in epoch 1/2 iteration 775/1084: 0.16314157843589783\n",
            "A-LLMRec model loss in epoch 1/2 iteration 776/1084: 0.27911674976348877\n",
            "A-LLMRec model loss in epoch 1/2 iteration 777/1084: 0.4646874964237213\n",
            "A-LLMRec model loss in epoch 1/2 iteration 778/1084: 0.006557374726980925\n",
            "A-LLMRec model loss in epoch 1/2 iteration 779/1084: 0.28131040930747986\n",
            "A-LLMRec model loss in epoch 1/2 iteration 780/1084: 0.008237523958086967\n",
            "A-LLMRec model loss in epoch 1/2 iteration 781/1084: 0.05189594253897667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 782/1084: 0.01202679518610239\n",
            "A-LLMRec model loss in epoch 1/2 iteration 783/1084: 0.1361868679523468\n",
            "A-LLMRec model loss in epoch 1/2 iteration 784/1084: 0.07326705753803253\n",
            "A-LLMRec model loss in epoch 1/2 iteration 785/1084: 0.14715808629989624\n",
            "A-LLMRec model loss in epoch 1/2 iteration 786/1084: 0.008464712649583817\n",
            "A-LLMRec model loss in epoch 1/2 iteration 787/1084: 0.1947769671678543\n",
            "A-LLMRec model loss in epoch 1/2 iteration 788/1084: 0.03503696620464325\n",
            "A-LLMRec model loss in epoch 1/2 iteration 789/1084: 0.008153093047440052\n",
            "A-LLMRec model loss in epoch 1/2 iteration 790/1084: 0.04623018577694893\n",
            "A-LLMRec model loss in epoch 1/2 iteration 791/1084: 0.09752880036830902\n",
            "A-LLMRec model loss in epoch 1/2 iteration 792/1084: 0.023806339129805565\n",
            "A-LLMRec model loss in epoch 1/2 iteration 793/1084: 0.030319178476929665\n",
            "A-LLMRec model loss in epoch 1/2 iteration 794/1084: 0.012711322866380215\n",
            "A-LLMRec model loss in epoch 1/2 iteration 795/1084: 0.03801971673965454\n",
            "A-LLMRec model loss in epoch 1/2 iteration 796/1084: 0.1261053830385208\n",
            "A-LLMRec model loss in epoch 1/2 iteration 797/1084: 0.016067033633589745\n",
            "A-LLMRec model loss in epoch 1/2 iteration 798/1084: 0.10505365580320358\n",
            "A-LLMRec model loss in epoch 1/2 iteration 799/1084: 0.12550945580005646\n",
            "A-LLMRec model loss in epoch 1/2 iteration 800/1084: 0.03226469084620476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 801/1084: 0.14128448069095612\n",
            "A-LLMRec model loss in epoch 1/2 iteration 802/1084: 0.31834450364112854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 803/1084: 0.022005019709467888\n",
            "A-LLMRec model loss in epoch 1/2 iteration 804/1084: 0.1686490774154663\n",
            "A-LLMRec model loss in epoch 1/2 iteration 805/1084: 0.18656887114048004\n",
            "A-LLMRec model loss in epoch 1/2 iteration 806/1084: 0.022655967622995377\n",
            "A-LLMRec model loss in epoch 1/2 iteration 807/1084: 0.1445058137178421\n",
            "A-LLMRec model loss in epoch 1/2 iteration 808/1084: 0.015122280456125736\n",
            "A-LLMRec model loss in epoch 1/2 iteration 809/1084: 0.14655713737010956\n",
            "A-LLMRec model loss in epoch 1/2 iteration 810/1084: 0.023280424997210503\n",
            "A-LLMRec model loss in epoch 1/2 iteration 811/1084: 0.12297441065311432\n",
            "A-LLMRec model loss in epoch 1/2 iteration 812/1084: 0.007307233288884163\n",
            "A-LLMRec model loss in epoch 1/2 iteration 813/1084: 0.24059821665287018\n",
            "A-LLMRec model loss in epoch 1/2 iteration 814/1084: 0.004119226709008217\n",
            "A-LLMRec model loss in epoch 1/2 iteration 815/1084: 0.024143731221556664\n",
            "A-LLMRec model loss in epoch 1/2 iteration 816/1084: 0.14524808526039124\n",
            "A-LLMRec model loss in epoch 1/2 iteration 817/1084: 0.4219224154949188\n",
            "A-LLMRec model loss in epoch 1/2 iteration 818/1084: 0.2213185876607895\n",
            "A-LLMRec model loss in epoch 1/2 iteration 819/1084: 0.33647963404655457\n",
            "A-LLMRec model loss in epoch 1/2 iteration 820/1084: 0.012593249790370464\n",
            "A-LLMRec model loss in epoch 1/2 iteration 821/1084: 0.012597350403666496\n",
            "A-LLMRec model loss in epoch 1/2 iteration 822/1084: 0.008942673914134502\n",
            "A-LLMRec model loss in epoch 1/2 iteration 823/1084: 0.007850196212530136\n",
            "A-LLMRec model loss in epoch 1/2 iteration 824/1084: 0.019711652770638466\n",
            "A-LLMRec model loss in epoch 1/2 iteration 825/1084: 0.0172326248139143\n",
            "A-LLMRec model loss in epoch 1/2 iteration 826/1084: 0.03562900051474571\n",
            "A-LLMRec model loss in epoch 1/2 iteration 827/1084: 0.05512484908103943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 828/1084: 0.15386159718036652\n",
            "A-LLMRec model loss in epoch 1/2 iteration 829/1084: 0.29831448197364807\n",
            "A-LLMRec model loss in epoch 1/2 iteration 830/1084: 0.0032057962380349636\n",
            "A-LLMRec model loss in epoch 1/2 iteration 831/1084: 0.10395465791225433\n",
            "A-LLMRec model loss in epoch 1/2 iteration 832/1084: 0.13229946792125702\n",
            "A-LLMRec model loss in epoch 1/2 iteration 833/1084: 0.30659031867980957\n",
            "A-LLMRec model loss in epoch 1/2 iteration 834/1084: 0.10790407657623291\n",
            "A-LLMRec model loss in epoch 1/2 iteration 835/1084: 0.011759919114410877\n",
            "A-LLMRec model loss in epoch 1/2 iteration 836/1084: 0.0761289969086647\n",
            "A-LLMRec model loss in epoch 1/2 iteration 837/1084: 0.008571062237024307\n",
            "A-LLMRec model loss in epoch 1/2 iteration 838/1084: 0.10742789506912231\n",
            "A-LLMRec model loss in epoch 1/2 iteration 839/1084: 0.07882646471261978\n",
            "A-LLMRec model loss in epoch 1/2 iteration 840/1084: 0.14656120538711548\n",
            "A-LLMRec model loss in epoch 1/2 iteration 841/1084: 0.05104666203260422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 842/1084: 0.15038685500621796\n",
            "A-LLMRec model loss in epoch 1/2 iteration 843/1084: 0.0899176076054573\n",
            "A-LLMRec model loss in epoch 1/2 iteration 844/1084: 0.02886280044913292\n",
            "A-LLMRec model loss in epoch 1/2 iteration 845/1084: 0.09300026297569275\n",
            "A-LLMRec model loss in epoch 1/2 iteration 846/1084: 0.10401088744401932\n",
            "A-LLMRec model loss in epoch 1/2 iteration 847/1084: 0.16621118783950806\n",
            "A-LLMRec model loss in epoch 1/2 iteration 848/1084: 0.03803436830639839\n",
            "A-LLMRec model loss in epoch 1/2 iteration 849/1084: 0.20391708612442017\n",
            "A-LLMRec model loss in epoch 1/2 iteration 850/1084: 0.060864947736263275\n",
            "A-LLMRec model loss in epoch 1/2 iteration 851/1084: 0.18717746436595917\n",
            "A-LLMRec model loss in epoch 1/2 iteration 852/1084: 0.09804238379001617\n",
            "A-LLMRec model loss in epoch 1/2 iteration 853/1084: 0.21023543179035187\n",
            "A-LLMRec model loss in epoch 1/2 iteration 854/1084: 0.09929157048463821\n",
            "A-LLMRec model loss in epoch 1/2 iteration 855/1084: 0.05772402137517929\n",
            "A-LLMRec model loss in epoch 1/2 iteration 856/1084: 0.0916714295744896\n",
            "A-LLMRec model loss in epoch 1/2 iteration 857/1084: 0.09821808338165283\n",
            "A-LLMRec model loss in epoch 1/2 iteration 858/1084: 0.09963686019182205\n",
            "A-LLMRec model loss in epoch 1/2 iteration 859/1084: 0.05280768498778343\n",
            "A-LLMRec model loss in epoch 1/2 iteration 860/1084: 0.38790369033813477\n",
            "A-LLMRec model loss in epoch 1/2 iteration 861/1084: 0.2823244035243988\n",
            "A-LLMRec model loss in epoch 1/2 iteration 862/1084: 0.12661203742027283\n",
            "A-LLMRec model loss in epoch 1/2 iteration 863/1084: 0.19085747003555298\n",
            "A-LLMRec model loss in epoch 1/2 iteration 864/1084: 0.03763410449028015\n",
            "A-LLMRec model loss in epoch 1/2 iteration 865/1084: 0.11909931898117065\n",
            "A-LLMRec model loss in epoch 1/2 iteration 866/1084: 0.04745575785636902\n",
            "A-LLMRec model loss in epoch 1/2 iteration 867/1084: 0.12254501134157181\n",
            "A-LLMRec model loss in epoch 1/2 iteration 868/1084: 0.056891389191150665\n",
            "A-LLMRec model loss in epoch 1/2 iteration 869/1084: 0.030432211235165596\n",
            "A-LLMRec model loss in epoch 1/2 iteration 870/1084: 0.04053495079278946\n",
            "A-LLMRec model loss in epoch 1/2 iteration 871/1084: 0.11418909579515457\n",
            "A-LLMRec model loss in epoch 1/2 iteration 872/1084: 0.14836692810058594\n",
            "A-LLMRec model loss in epoch 1/2 iteration 873/1084: 0.009260538034141064\n",
            "A-LLMRec model loss in epoch 1/2 iteration 874/1084: 0.029192108660936356\n",
            "A-LLMRec model loss in epoch 1/2 iteration 875/1084: 0.12541238963603973\n",
            "A-LLMRec model loss in epoch 1/2 iteration 876/1084: 0.010766933672130108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 877/1084: 0.13984791934490204\n",
            "A-LLMRec model loss in epoch 1/2 iteration 878/1084: 0.006515533197671175\n",
            "A-LLMRec model loss in epoch 1/2 iteration 879/1084: 0.026974882930517197\n",
            "A-LLMRec model loss in epoch 1/2 iteration 880/1084: 0.004570340737700462\n",
            "A-LLMRec model loss in epoch 1/2 iteration 881/1084: 0.08730784803628922\n",
            "A-LLMRec model loss in epoch 1/2 iteration 882/1084: 0.006401617079973221\n",
            "A-LLMRec model loss in epoch 1/2 iteration 883/1084: 0.238011434674263\n",
            "A-LLMRec model loss in epoch 1/2 iteration 884/1084: 0.007313099689781666\n",
            "A-LLMRec model loss in epoch 1/2 iteration 885/1084: 0.004096583928912878\n",
            "A-LLMRec model loss in epoch 1/2 iteration 886/1084: 0.024345235899090767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 887/1084: 0.023231545463204384\n",
            "A-LLMRec model loss in epoch 1/2 iteration 888/1084: 0.005434140563011169\n",
            "A-LLMRec model loss in epoch 1/2 iteration 889/1084: 0.008018224500119686\n",
            "A-LLMRec model loss in epoch 1/2 iteration 890/1084: 0.007639478426426649\n",
            "A-LLMRec model loss in epoch 1/2 iteration 891/1084: 0.051963962614536285\n",
            "A-LLMRec model loss in epoch 1/2 iteration 892/1084: 0.053767938166856766\n",
            "A-LLMRec model loss in epoch 1/2 iteration 893/1084: 0.035177722573280334\n",
            "A-LLMRec model loss in epoch 1/2 iteration 894/1084: 0.00749558862298727\n",
            "A-LLMRec model loss in epoch 1/2 iteration 895/1084: 0.023729313164949417\n",
            "A-LLMRec model loss in epoch 1/2 iteration 896/1084: 0.21497026085853577\n",
            "A-LLMRec model loss in epoch 1/2 iteration 897/1084: 0.005470493342727423\n",
            "A-LLMRec model loss in epoch 1/2 iteration 898/1084: 0.006415131967514753\n",
            "A-LLMRec model loss in epoch 1/2 iteration 899/1084: 0.10167359560728073\n",
            "A-LLMRec model loss in epoch 1/2 iteration 900/1084: 0.005947831552475691\n",
            "A-LLMRec model loss in epoch 1/2 iteration 901/1084: 0.05259498581290245\n",
            "A-LLMRec model loss in epoch 1/2 iteration 902/1084: 0.008617885410785675\n",
            "A-LLMRec model loss in epoch 1/2 iteration 903/1084: 0.045430250465869904\n",
            "A-LLMRec model loss in epoch 1/2 iteration 904/1084: 0.006388247944414616\n",
            "A-LLMRec model loss in epoch 1/2 iteration 905/1084: 0.0072654839605093\n",
            "A-LLMRec model loss in epoch 1/2 iteration 906/1084: 0.01139120664447546\n",
            "A-LLMRec model loss in epoch 1/2 iteration 907/1084: 0.12491593509912491\n",
            "A-LLMRec model loss in epoch 1/2 iteration 908/1084: 0.05982859060168266\n",
            "A-LLMRec model loss in epoch 1/2 iteration 909/1084: 0.1870652437210083\n",
            "A-LLMRec model loss in epoch 1/2 iteration 910/1084: 0.08413983881473541\n",
            "A-LLMRec model loss in epoch 1/2 iteration 911/1084: 0.045182354748249054\n",
            "A-LLMRec model loss in epoch 1/2 iteration 912/1084: 0.23091763257980347\n",
            "A-LLMRec model loss in epoch 1/2 iteration 913/1084: 0.014332656748592854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 914/1084: 0.02315780520439148\n",
            "A-LLMRec model loss in epoch 1/2 iteration 915/1084: 0.04052400961518288\n",
            "A-LLMRec model loss in epoch 1/2 iteration 916/1084: 0.0052812471985816956\n",
            "A-LLMRec model loss in epoch 1/2 iteration 917/1084: 0.008603478781878948\n",
            "A-LLMRec model loss in epoch 1/2 iteration 918/1084: 0.026167407631874084\n",
            "A-LLMRec model loss in epoch 1/2 iteration 919/1084: 0.1099342405796051\n",
            "A-LLMRec model loss in epoch 1/2 iteration 920/1084: 0.03903644531965256\n",
            "A-LLMRec model loss in epoch 1/2 iteration 921/1084: 0.07621928304433823\n",
            "A-LLMRec model loss in epoch 1/2 iteration 922/1084: 0.004923705942928791\n",
            "A-LLMRec model loss in epoch 1/2 iteration 923/1084: 0.06056984141469002\n",
            "A-LLMRec model loss in epoch 1/2 iteration 924/1084: 0.14191558957099915\n",
            "A-LLMRec model loss in epoch 1/2 iteration 925/1084: 0.008321687579154968\n",
            "A-LLMRec model loss in epoch 1/2 iteration 926/1084: 0.05955452471971512\n",
            "A-LLMRec model loss in epoch 1/2 iteration 927/1084: 0.008483855985105038\n",
            "A-LLMRec model loss in epoch 1/2 iteration 928/1084: 0.1117832288146019\n",
            "A-LLMRec model loss in epoch 1/2 iteration 929/1084: 0.23529240489006042\n",
            "A-LLMRec model loss in epoch 1/2 iteration 930/1084: 0.012053251266479492\n",
            "A-LLMRec model loss in epoch 1/2 iteration 931/1084: 0.018432272598147392\n",
            "A-LLMRec model loss in epoch 1/2 iteration 932/1084: 0.1692200005054474\n",
            "A-LLMRec model loss in epoch 1/2 iteration 933/1084: 0.008829335682094097\n",
            "A-LLMRec model loss in epoch 1/2 iteration 934/1084: 0.10151245445013046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 935/1084: 0.008278919383883476\n",
            "A-LLMRec model loss in epoch 1/2 iteration 936/1084: 0.03387998417019844\n",
            "A-LLMRec model loss in epoch 1/2 iteration 937/1084: 0.024490157142281532\n",
            "A-LLMRec model loss in epoch 1/2 iteration 938/1084: 0.045421626418828964\n",
            "A-LLMRec model loss in epoch 1/2 iteration 939/1084: 0.2791875898838043\n",
            "A-LLMRec model loss in epoch 1/2 iteration 940/1084: 0.0055465782061219215\n",
            "A-LLMRec model loss in epoch 1/2 iteration 941/1084: 0.007320677395910025\n",
            "A-LLMRec model loss in epoch 1/2 iteration 942/1084: 0.01880454830825329\n",
            "A-LLMRec model loss in epoch 1/2 iteration 943/1084: 0.08130048215389252\n",
            "A-LLMRec model loss in epoch 1/2 iteration 944/1084: 0.2097543627023697\n",
            "A-LLMRec model loss in epoch 1/2 iteration 945/1084: 0.020006339997053146\n",
            "A-LLMRec model loss in epoch 1/2 iteration 946/1084: 0.13192567229270935\n",
            "A-LLMRec model loss in epoch 1/2 iteration 947/1084: 0.03554018586874008\n",
            "A-LLMRec model loss in epoch 1/2 iteration 948/1084: 0.32141008973121643\n",
            "A-LLMRec model loss in epoch 1/2 iteration 949/1084: 0.013048334047198296\n",
            "A-LLMRec model loss in epoch 1/2 iteration 950/1084: 0.012619190849363804\n",
            "A-LLMRec model loss in epoch 1/2 iteration 951/1084: 0.2220255732536316\n",
            "A-LLMRec model loss in epoch 1/2 iteration 952/1084: 0.007577755954116583\n",
            "A-LLMRec model loss in epoch 1/2 iteration 953/1084: 0.009915185160934925\n",
            "A-LLMRec model loss in epoch 1/2 iteration 954/1084: 0.15111109614372253\n",
            "A-LLMRec model loss in epoch 1/2 iteration 955/1084: 0.04791940376162529\n",
            "A-LLMRec model loss in epoch 1/2 iteration 956/1084: 0.09438057988882065\n",
            "A-LLMRec model loss in epoch 1/2 iteration 957/1084: 0.10168808698654175\n",
            "A-LLMRec model loss in epoch 1/2 iteration 958/1084: 0.13039810955524445\n",
            "A-LLMRec model loss in epoch 1/2 iteration 959/1084: 0.00983726978302002\n",
            "A-LLMRec model loss in epoch 1/2 iteration 960/1084: 0.09210876375436783\n",
            "A-LLMRec model loss in epoch 1/2 iteration 961/1084: 0.025708861649036407\n",
            "A-LLMRec model loss in epoch 1/2 iteration 962/1084: 0.006794981192797422\n",
            "A-LLMRec model loss in epoch 1/2 iteration 963/1084: 0.06350646913051605\n",
            "A-LLMRec model loss in epoch 1/2 iteration 964/1084: 0.007039906457066536\n",
            "A-LLMRec model loss in epoch 1/2 iteration 965/1084: 0.004936091601848602\n",
            "A-LLMRec model loss in epoch 1/2 iteration 966/1084: 0.09432029724121094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 967/1084: 0.44955188035964966\n",
            "A-LLMRec model loss in epoch 1/2 iteration 968/1084: 0.009549989365041256\n",
            "A-LLMRec model loss in epoch 1/2 iteration 969/1084: 0.010299617424607277\n",
            "A-LLMRec model loss in epoch 1/2 iteration 970/1084: 0.011781291104853153\n",
            "A-LLMRec model loss in epoch 1/2 iteration 971/1084: 0.010612455196678638\n",
            "A-LLMRec model loss in epoch 1/2 iteration 972/1084: 0.005836495663970709\n",
            "A-LLMRec model loss in epoch 1/2 iteration 973/1084: 0.13892193138599396\n",
            "A-LLMRec model loss in epoch 1/2 iteration 974/1084: 0.3158033788204193\n",
            "A-LLMRec model loss in epoch 1/2 iteration 975/1084: 0.019933944568037987\n",
            "A-LLMRec model loss in epoch 1/2 iteration 976/1084: 0.024954207241535187\n",
            "A-LLMRec model loss in epoch 1/2 iteration 977/1084: 0.45753422379493713\n",
            "A-LLMRec model loss in epoch 1/2 iteration 978/1084: 0.0860927477478981\n",
            "A-LLMRec model loss in epoch 1/2 iteration 979/1084: 0.050950199365615845\n",
            "A-LLMRec model loss in epoch 1/2 iteration 980/1084: 0.21843105554580688\n",
            "A-LLMRec model loss in epoch 1/2 iteration 981/1084: 0.1219295859336853\n",
            "A-LLMRec model loss in epoch 1/2 iteration 982/1084: 0.09319450706243515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 983/1084: 0.08804865926504135\n",
            "A-LLMRec model loss in epoch 1/2 iteration 984/1084: 0.02478812448680401\n",
            "A-LLMRec model loss in epoch 1/2 iteration 985/1084: 0.06371474266052246\n",
            "A-LLMRec model loss in epoch 1/2 iteration 986/1084: 0.48752328753471375\n",
            "A-LLMRec model loss in epoch 1/2 iteration 987/1084: 0.13418367505073547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 988/1084: 0.12730376422405243\n",
            "A-LLMRec model loss in epoch 1/2 iteration 989/1084: 0.15107882022857666\n",
            "A-LLMRec model loss in epoch 1/2 iteration 990/1084: 0.12458528578281403\n",
            "A-LLMRec model loss in epoch 1/2 iteration 991/1084: 0.13577574491500854\n",
            "A-LLMRec model loss in epoch 1/2 iteration 992/1084: 0.015378089621663094\n",
            "A-LLMRec model loss in epoch 1/2 iteration 993/1084: 0.01631717011332512\n",
            "A-LLMRec model loss in epoch 1/2 iteration 994/1084: 0.12989717721939087\n",
            "A-LLMRec model loss in epoch 1/2 iteration 995/1084: 0.10879376530647278\n",
            "A-LLMRec model loss in epoch 1/2 iteration 996/1084: 0.08873029798269272\n",
            "A-LLMRec model loss in epoch 1/2 iteration 997/1084: 0.03213845565915108\n",
            "A-LLMRec model loss in epoch 1/2 iteration 998/1084: 0.15810629725456238\n",
            "A-LLMRec model loss in epoch 1/2 iteration 999/1084: 0.05238950997591019\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1000/1084: 0.0871383473277092\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1001/1084: 0.015459735877811909\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1002/1084: 0.22569015622138977\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1003/1084: 0.013257735408842564\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1004/1084: 0.1268959641456604\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1005/1084: 0.04084683582186699\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1006/1084: 0.021352041512727737\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1007/1084: 0.342509388923645\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1008/1084: 0.013555843383073807\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1009/1084: 0.09689340740442276\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1010/1084: 0.21763765811920166\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1011/1084: 0.19723528623580933\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1012/1084: 0.08535706996917725\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1013/1084: 0.06774847954511642\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1014/1084: 0.17188005149364471\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1015/1084: 0.005541617516428232\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1016/1084: 0.03621630743145943\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1017/1084: 0.009971273131668568\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1018/1084: 0.043654367327690125\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1019/1084: 0.2086976170539856\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1020/1084: 0.054329365491867065\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1021/1084: 0.011110752820968628\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1022/1084: 0.01375064067542553\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1023/1084: 0.009990669786930084\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1024/1084: 0.0730801671743393\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1025/1084: 0.05082240328192711\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1026/1084: 0.05502058565616608\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1027/1084: 0.051229994744062424\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1028/1084: 0.16761834919452667\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1029/1084: 0.006182695273309946\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1030/1084: 0.004564542323350906\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1031/1084: 0.06290043145418167\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1032/1084: 0.04899250343441963\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1033/1084: 0.007823019288480282\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1034/1084: 0.04519219323992729\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1035/1084: 0.16382727026939392\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1036/1084: 0.12013130635023117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1037/1084: 0.007012059912085533\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1038/1084: 0.07571376860141754\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1039/1084: 0.12944376468658447\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1040/1084: 0.12295641005039215\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1041/1084: 0.08952076733112335\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1042/1084: 0.004383917897939682\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1043/1084: 0.013904232531785965\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1044/1084: 0.011879545636475086\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1045/1084: 0.0715906172990799\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1046/1084: 0.2734476327896118\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1047/1084: 0.15943998098373413\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1048/1084: 0.09017445892095566\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1049/1084: 0.21189577877521515\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1050/1084: 0.0389866940677166\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1051/1084: 0.13736417889595032\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1052/1084: 0.009526382200419903\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1053/1084: 0.052179817110300064\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1054/1084: 0.07897411286830902\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1055/1084: 0.024587558582425117\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1056/1084: 0.00721720652654767\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1057/1084: 0.008415344171226025\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1058/1084: 0.22201518714427948\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1059/1084: 0.03863482177257538\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1060/1084: 0.015654169023036957\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1061/1084: 0.06905069947242737\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1062/1084: 0.12009185552597046\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1063/1084: 0.0116517199203372\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1064/1084: 0.003754830453544855\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1065/1084: 0.24920332431793213\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1066/1084: 0.0779133215546608\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1067/1084: 0.05206131935119629\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1068/1084: 0.11071401834487915\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1069/1084: 0.49239614605903625\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1070/1084: 0.07790911197662354\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1071/1084: 0.00474892370402813\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1072/1084: 0.005084428936243057\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1073/1084: 0.006959551014006138\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1074/1084: 0.03421120345592499\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1075/1084: 0.008185949176549911\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1076/1084: 0.15520018339157104\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1077/1084: 0.13253521919250488\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1078/1084: 0.34249550104141235\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1079/1084: 0.01682485267519951\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1080/1084: 0.03679627925157547\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1081/1084: 0.07587901502847672\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1082/1084: 0.024669529870152473\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1083/1084: 0.07730798423290253\n",
            "A-LLMRec model loss in epoch 1/2 iteration 1084/1084: 0.5149166584014893\n",
            "100% 1/1 [08:30<00:00, 510.50s/it]\n",
            "phase2 train time : 510.50127387046814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python /content/drive/MyDrive/Rec_Proj_DL/main.py --inference --rec_pre_trained_data All_Beauty\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQmwg8EQNSJj",
        "outputId": "6e664c84-538a-45ba-b034-0150cfa1c83f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-LLMRec start inference\n",
            "\n",
            "user num: 2169 item num: 1854\n",
            "average sequence length: 2.86\n",
            "Initializing with num_user: 2099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Rec_Proj_DL/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t68hjqoQo3YL",
        "outputId": "e49b6e23-718e-41f5-eadd-345e3e32f422"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2099 2099\n",
            "2099\n",
            "ndcg at 1: 0.3515959980943306\n",
            "hit at 1: 0.3515959980943306\n"
          ]
        }
      ]
    }
  ]
}